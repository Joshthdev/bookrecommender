{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9eb80f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dc229a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61572f3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isbn13</th>\n",
       "      <th>isbn10</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>categories</th>\n",
       "      <th>thumbnail</th>\n",
       "      <th>description</th>\n",
       "      <th>published_year</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>title_and_subtitle</th>\n",
       "      <th>tagged_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9780002005883</td>\n",
       "      <td>0002005883</td>\n",
       "      <td>Gilead</td>\n",
       "      <td>Marilynne Robinson</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>http://books.google.com/books/content?id=KQZCP...</td>\n",
       "      <td>A NOVEL THAT READERS and critics have been eag...</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>247.0</td>\n",
       "      <td>361.0</td>\n",
       "      <td>Gilead</td>\n",
       "      <td>9780002005883 A NOVEL THAT READERS and critics...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9780002261982</td>\n",
       "      <td>0002261987</td>\n",
       "      <td>Spider's Web</td>\n",
       "      <td>Charles Osborne;Agatha Christie</td>\n",
       "      <td>Detective and mystery stories</td>\n",
       "      <td>http://books.google.com/books/content?id=gA5GP...</td>\n",
       "      <td>A new 'Christie for Christmas' -- a full-lengt...</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>3.83</td>\n",
       "      <td>241.0</td>\n",
       "      <td>5164.0</td>\n",
       "      <td>Spider's Web:A Novel</td>\n",
       "      <td>9780002261982 A new 'Christie for Christmas' -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9780006178736</td>\n",
       "      <td>0006178731</td>\n",
       "      <td>Rage of angels</td>\n",
       "      <td>Sidney Sheldon</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>http://books.google.com/books/content?id=FKo2T...</td>\n",
       "      <td>A memorable, mesmerizing heroine Jennifer -- b...</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>3.93</td>\n",
       "      <td>512.0</td>\n",
       "      <td>29532.0</td>\n",
       "      <td>Rage of angels</td>\n",
       "      <td>9780006178736 A memorable, mesmerizing heroine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9780006280897</td>\n",
       "      <td>0006280897</td>\n",
       "      <td>The Four Loves</td>\n",
       "      <td>Clive Staples Lewis</td>\n",
       "      <td>Christian life</td>\n",
       "      <td>http://books.google.com/books/content?id=XhQ5X...</td>\n",
       "      <td>Lewis' work on the nature of love divides love...</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>4.15</td>\n",
       "      <td>170.0</td>\n",
       "      <td>33684.0</td>\n",
       "      <td>The Four Loves</td>\n",
       "      <td>9780006280897 Lewis' work on the nature of lov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9780006280934</td>\n",
       "      <td>0006280935</td>\n",
       "      <td>The Problem of Pain</td>\n",
       "      <td>Clive Staples Lewis</td>\n",
       "      <td>Christian life</td>\n",
       "      <td>http://books.google.com/books/content?id=Kk-uV...</td>\n",
       "      <td>\"In The Problem of Pain, C.S. Lewis, one of th...</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>4.09</td>\n",
       "      <td>176.0</td>\n",
       "      <td>37569.0</td>\n",
       "      <td>The Problem of Pain</td>\n",
       "      <td>9780006280934 \"In The Problem of Pain, C.S. Le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5192</th>\n",
       "      <td>9788172235222</td>\n",
       "      <td>8172235224</td>\n",
       "      <td>Mistaken Identity</td>\n",
       "      <td>Nayantara Sahgal</td>\n",
       "      <td>Indic fiction (English)</td>\n",
       "      <td>http://books.google.com/books/content?id=q-tKP...</td>\n",
       "      <td>On A Train Journey Home To North India After L...</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>2.93</td>\n",
       "      <td>324.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Mistaken Identity</td>\n",
       "      <td>9788172235222 On A Train Journey Home To North...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5193</th>\n",
       "      <td>9788173031014</td>\n",
       "      <td>8173031010</td>\n",
       "      <td>Journey to the East</td>\n",
       "      <td>Hermann Hesse</td>\n",
       "      <td>Adventure stories</td>\n",
       "      <td>http://books.google.com/books/content?id=rq6JP...</td>\n",
       "      <td>This book tells the tale of a man who goes on ...</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>3.70</td>\n",
       "      <td>175.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Journey to the East</td>\n",
       "      <td>9788173031014 This book tells the tale of a ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5194</th>\n",
       "      <td>9788179921623</td>\n",
       "      <td>817992162X</td>\n",
       "      <td>The Monk Who Sold His Ferrari: A Fable About F...</td>\n",
       "      <td>Robin Sharma</td>\n",
       "      <td>Health &amp; Fitness</td>\n",
       "      <td>http://books.google.com/books/content?id=c_7mf...</td>\n",
       "      <td>Wisdom to Create a Life of Passion, Purpose, a...</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>3.82</td>\n",
       "      <td>198.0</td>\n",
       "      <td>1568.0</td>\n",
       "      <td>The Monk Who Sold His Ferrari: A Fable About F...</td>\n",
       "      <td>9788179921623 Wisdom to Create a Life of Passi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5195</th>\n",
       "      <td>9788185300535</td>\n",
       "      <td>8185300534</td>\n",
       "      <td>I Am that</td>\n",
       "      <td>Sri Nisargadatta Maharaj;Sudhakar S. Dikshit</td>\n",
       "      <td>Philosophy</td>\n",
       "      <td>http://books.google.com/books/content?id=Fv_JP...</td>\n",
       "      <td>This collection of the timeless teachings of o...</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>4.51</td>\n",
       "      <td>531.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>I Am that:Talks with Sri Nisargadatta Maharaj</td>\n",
       "      <td>9788185300535 This collection of the timeless ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5196</th>\n",
       "      <td>9789027712059</td>\n",
       "      <td>9027712050</td>\n",
       "      <td>The Berlin Phenomenology</td>\n",
       "      <td>Georg Wilhelm Friedrich Hegel</td>\n",
       "      <td>History</td>\n",
       "      <td>http://books.google.com/books/content?id=Vy7Sk...</td>\n",
       "      <td>Since the three volume edition ofHegel's Philo...</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>210.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The Berlin Phenomenology</td>\n",
       "      <td>9789027712059 Since the three volume edition o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5197 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             isbn13      isbn10  \\\n",
       "0     9780002005883  0002005883   \n",
       "1     9780002261982  0002261987   \n",
       "2     9780006178736  0006178731   \n",
       "3     9780006280897  0006280897   \n",
       "4     9780006280934  0006280935   \n",
       "...             ...         ...   \n",
       "5192  9788172235222  8172235224   \n",
       "5193  9788173031014  8173031010   \n",
       "5194  9788179921623  817992162X   \n",
       "5195  9788185300535  8185300534   \n",
       "5196  9789027712059  9027712050   \n",
       "\n",
       "                                                  title  \\\n",
       "0                                                Gilead   \n",
       "1                                          Spider's Web   \n",
       "2                                        Rage of angels   \n",
       "3                                        The Four Loves   \n",
       "4                                   The Problem of Pain   \n",
       "...                                                 ...   \n",
       "5192                                  Mistaken Identity   \n",
       "5193                                Journey to the East   \n",
       "5194  The Monk Who Sold His Ferrari: A Fable About F...   \n",
       "5195                                          I Am that   \n",
       "5196                           The Berlin Phenomenology   \n",
       "\n",
       "                                           authors  \\\n",
       "0                               Marilynne Robinson   \n",
       "1                  Charles Osborne;Agatha Christie   \n",
       "2                                   Sidney Sheldon   \n",
       "3                              Clive Staples Lewis   \n",
       "4                              Clive Staples Lewis   \n",
       "...                                            ...   \n",
       "5192                              Nayantara Sahgal   \n",
       "5193                                 Hermann Hesse   \n",
       "5194                                  Robin Sharma   \n",
       "5195  Sri Nisargadatta Maharaj;Sudhakar S. Dikshit   \n",
       "5196                 Georg Wilhelm Friedrich Hegel   \n",
       "\n",
       "                         categories  \\\n",
       "0                           Fiction   \n",
       "1     Detective and mystery stories   \n",
       "2                           Fiction   \n",
       "3                    Christian life   \n",
       "4                    Christian life   \n",
       "...                             ...   \n",
       "5192        Indic fiction (English)   \n",
       "5193              Adventure stories   \n",
       "5194               Health & Fitness   \n",
       "5195                     Philosophy   \n",
       "5196                        History   \n",
       "\n",
       "                                              thumbnail  \\\n",
       "0     http://books.google.com/books/content?id=KQZCP...   \n",
       "1     http://books.google.com/books/content?id=gA5GP...   \n",
       "2     http://books.google.com/books/content?id=FKo2T...   \n",
       "3     http://books.google.com/books/content?id=XhQ5X...   \n",
       "4     http://books.google.com/books/content?id=Kk-uV...   \n",
       "...                                                 ...   \n",
       "5192  http://books.google.com/books/content?id=q-tKP...   \n",
       "5193  http://books.google.com/books/content?id=rq6JP...   \n",
       "5194  http://books.google.com/books/content?id=c_7mf...   \n",
       "5195  http://books.google.com/books/content?id=Fv_JP...   \n",
       "5196  http://books.google.com/books/content?id=Vy7Sk...   \n",
       "\n",
       "                                            description  published_year  \\\n",
       "0     A NOVEL THAT READERS and critics have been eag...          2004.0   \n",
       "1     A new 'Christie for Christmas' -- a full-lengt...          2000.0   \n",
       "2     A memorable, mesmerizing heroine Jennifer -- b...          1993.0   \n",
       "3     Lewis' work on the nature of love divides love...          2002.0   \n",
       "4     \"In The Problem of Pain, C.S. Lewis, one of th...          2002.0   \n",
       "...                                                 ...             ...   \n",
       "5192  On A Train Journey Home To North India After L...          2003.0   \n",
       "5193  This book tells the tale of a man who goes on ...          2002.0   \n",
       "5194  Wisdom to Create a Life of Passion, Purpose, a...          2003.0   \n",
       "5195  This collection of the timeless teachings of o...          1999.0   \n",
       "5196  Since the three volume edition ofHegel's Philo...          1981.0   \n",
       "\n",
       "      average_rating  num_pages  ratings_count  \\\n",
       "0               3.85      247.0          361.0   \n",
       "1               3.83      241.0         5164.0   \n",
       "2               3.93      512.0        29532.0   \n",
       "3               4.15      170.0        33684.0   \n",
       "4               4.09      176.0        37569.0   \n",
       "...              ...        ...            ...   \n",
       "5192            2.93      324.0            0.0   \n",
       "5193            3.70      175.0           24.0   \n",
       "5194            3.82      198.0         1568.0   \n",
       "5195            4.51      531.0          104.0   \n",
       "5196            0.00      210.0            0.0   \n",
       "\n",
       "                                     title_and_subtitle  \\\n",
       "0                                                Gilead   \n",
       "1                                  Spider's Web:A Novel   \n",
       "2                                        Rage of angels   \n",
       "3                                        The Four Loves   \n",
       "4                                   The Problem of Pain   \n",
       "...                                                 ...   \n",
       "5192                                  Mistaken Identity   \n",
       "5193                                Journey to the East   \n",
       "5194  The Monk Who Sold His Ferrari: A Fable About F...   \n",
       "5195      I Am that:Talks with Sri Nisargadatta Maharaj   \n",
       "5196                           The Berlin Phenomenology   \n",
       "\n",
       "                                     tagged_description  \n",
       "0     9780002005883 A NOVEL THAT READERS and critics...  \n",
       "1     9780002261982 A new 'Christie for Christmas' -...  \n",
       "2     9780006178736 A memorable, mesmerizing heroine...  \n",
       "3     9780006280897 Lewis' work on the nature of lov...  \n",
       "4     9780006280934 \"In The Problem of Pain, C.S. Le...  \n",
       "...                                                 ...  \n",
       "5192  9788172235222 On A Train Journey Home To North...  \n",
       "5193  9788173031014 This book tells the tale of a ma...  \n",
       "5194  9788179921623 Wisdom to Create a Life of Passi...  \n",
       "5195  9788185300535 This collection of the timeless ...  \n",
       "5196  9789027712059 Since the three volume edition o...  \n",
       "\n",
       "[5197 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "books = pd.read_csv(\"books_cleaned.csv\")\n",
    "books = books.copy()\n",
    "\n",
    "books[\"tagged_description\"] = books[\"tagged_description\"].str.replace(\":\", \" \", n=1)\n",
    "books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee769890",
   "metadata": {},
   "outputs": [],
   "source": [
    "books[\"tagged_description\"].to_csv(\n",
    "    \"tagged_description.txt\",\n",
    "    sep=\"\\n\",\n",
    "    index=False,\n",
    "    header=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a376003",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1168, which is longer than the specified 0\n",
      "Created a chunk of size 1214, which is longer than the specified 0\n",
      "Created a chunk of size 373, which is longer than the specified 0\n",
      "Created a chunk of size 309, which is longer than the specified 0\n",
      "Created a chunk of size 483, which is longer than the specified 0\n",
      "Created a chunk of size 482, which is longer than the specified 0\n",
      "Created a chunk of size 960, which is longer than the specified 0\n",
      "Created a chunk of size 188, which is longer than the specified 0\n",
      "Created a chunk of size 843, which is longer than the specified 0\n",
      "Created a chunk of size 296, which is longer than the specified 0\n",
      "Created a chunk of size 197, which is longer than the specified 0\n",
      "Created a chunk of size 881, which is longer than the specified 0\n",
      "Created a chunk of size 1088, which is longer than the specified 0\n",
      "Created a chunk of size 1189, which is longer than the specified 0\n",
      "Created a chunk of size 304, which is longer than the specified 0\n",
      "Created a chunk of size 270, which is longer than the specified 0\n",
      "Created a chunk of size 211, which is longer than the specified 0\n",
      "Created a chunk of size 214, which is longer than the specified 0\n",
      "Created a chunk of size 513, which is longer than the specified 0\n",
      "Created a chunk of size 752, which is longer than the specified 0\n",
      "Created a chunk of size 388, which is longer than the specified 0\n",
      "Created a chunk of size 263, which is longer than the specified 0\n",
      "Created a chunk of size 253, which is longer than the specified 0\n",
      "Created a chunk of size 306, which is longer than the specified 0\n",
      "Created a chunk of size 728, which is longer than the specified 0\n",
      "Created a chunk of size 721, which is longer than the specified 0\n",
      "Created a chunk of size 256, which is longer than the specified 0\n",
      "Created a chunk of size 473, which is longer than the specified 0\n",
      "Created a chunk of size 270, which is longer than the specified 0\n",
      "Created a chunk of size 1267, which is longer than the specified 0\n",
      "Created a chunk of size 681, which is longer than the specified 0\n",
      "Created a chunk of size 243, which is longer than the specified 0\n",
      "Created a chunk of size 553, which is longer than the specified 0\n",
      "Created a chunk of size 521, which is longer than the specified 0\n",
      "Created a chunk of size 280, which is longer than the specified 0\n",
      "Created a chunk of size 787, which is longer than the specified 0\n",
      "Created a chunk of size 564, which is longer than the specified 0\n",
      "Created a chunk of size 523, which is longer than the specified 0\n",
      "Created a chunk of size 177, which is longer than the specified 0\n",
      "Created a chunk of size 297, which is longer than the specified 0\n",
      "Created a chunk of size 533, which is longer than the specified 0\n",
      "Created a chunk of size 559, which is longer than the specified 0\n",
      "Created a chunk of size 563, which is longer than the specified 0\n",
      "Created a chunk of size 385, which is longer than the specified 0\n",
      "Created a chunk of size 410, which is longer than the specified 0\n",
      "Created a chunk of size 461, which is longer than the specified 0\n",
      "Created a chunk of size 595, which is longer than the specified 0\n",
      "Created a chunk of size 476, which is longer than the specified 0\n",
      "Created a chunk of size 459, which is longer than the specified 0\n",
      "Created a chunk of size 257, which is longer than the specified 0\n",
      "Created a chunk of size 304, which is longer than the specified 0\n",
      "Created a chunk of size 614, which is longer than the specified 0\n",
      "Created a chunk of size 419, which is longer than the specified 0\n",
      "Created a chunk of size 887, which is longer than the specified 0\n",
      "Created a chunk of size 693, which is longer than the specified 0\n",
      "Created a chunk of size 302, which is longer than the specified 0\n",
      "Created a chunk of size 217, which is longer than the specified 0\n",
      "Created a chunk of size 277, which is longer than the specified 0\n",
      "Created a chunk of size 2010, which is longer than the specified 0\n",
      "Created a chunk of size 173, which is longer than the specified 0\n",
      "Created a chunk of size 479, which is longer than the specified 0\n",
      "Created a chunk of size 300, which is longer than the specified 0\n",
      "Created a chunk of size 520, which is longer than the specified 0\n",
      "Created a chunk of size 647, which is longer than the specified 0\n",
      "Created a chunk of size 778, which is longer than the specified 0\n",
      "Created a chunk of size 165, which is longer than the specified 0\n",
      "Created a chunk of size 686, which is longer than the specified 0\n",
      "Created a chunk of size 548, which is longer than the specified 0\n",
      "Created a chunk of size 1225, which is longer than the specified 0\n",
      "Created a chunk of size 406, which is longer than the specified 0\n",
      "Created a chunk of size 1184, which is longer than the specified 0\n",
      "Created a chunk of size 1214, which is longer than the specified 0\n",
      "Created a chunk of size 1191, which is longer than the specified 0\n",
      "Created a chunk of size 1057, which is longer than the specified 0\n",
      "Created a chunk of size 244, which is longer than the specified 0\n",
      "Created a chunk of size 688, which is longer than the specified 0\n",
      "Created a chunk of size 876, which is longer than the specified 0\n",
      "Created a chunk of size 284, which is longer than the specified 0\n",
      "Created a chunk of size 766, which is longer than the specified 0\n",
      "Created a chunk of size 389, which is longer than the specified 0\n",
      "Created a chunk of size 417, which is longer than the specified 0\n",
      "Created a chunk of size 208, which is longer than the specified 0\n",
      "Created a chunk of size 209, which is longer than the specified 0\n",
      "Created a chunk of size 723, which is longer than the specified 0\n",
      "Created a chunk of size 209, which is longer than the specified 0\n",
      "Created a chunk of size 163, which is longer than the specified 0\n",
      "Created a chunk of size 526, which is longer than the specified 0\n",
      "Created a chunk of size 521, which is longer than the specified 0\n",
      "Created a chunk of size 214, which is longer than the specified 0\n",
      "Created a chunk of size 338, which is longer than the specified 0\n",
      "Created a chunk of size 899, which is longer than the specified 0\n",
      "Created a chunk of size 1270, which is longer than the specified 0\n",
      "Created a chunk of size 558, which is longer than the specified 0\n",
      "Created a chunk of size 1635, which is longer than the specified 0\n",
      "Created a chunk of size 436, which is longer than the specified 0\n",
      "Created a chunk of size 249, which is longer than the specified 0\n",
      "Created a chunk of size 777, which is longer than the specified 0\n",
      "Created a chunk of size 716, which is longer than the specified 0\n",
      "Created a chunk of size 514, which is longer than the specified 0\n",
      "Created a chunk of size 958, which is longer than the specified 0\n",
      "Created a chunk of size 198, which is longer than the specified 0\n",
      "Created a chunk of size 1132, which is longer than the specified 0\n",
      "Created a chunk of size 168, which is longer than the specified 0\n",
      "Created a chunk of size 1325, which is longer than the specified 0\n",
      "Created a chunk of size 851, which is longer than the specified 0\n",
      "Created a chunk of size 272, which is longer than the specified 0\n",
      "Created a chunk of size 801, which is longer than the specified 0\n",
      "Created a chunk of size 1119, which is longer than the specified 0\n",
      "Created a chunk of size 836, which is longer than the specified 0\n",
      "Created a chunk of size 260, which is longer than the specified 0\n",
      "Created a chunk of size 235, which is longer than the specified 0\n",
      "Created a chunk of size 732, which is longer than the specified 0\n",
      "Created a chunk of size 1195, which is longer than the specified 0\n",
      "Created a chunk of size 710, which is longer than the specified 0\n",
      "Created a chunk of size 773, which is longer than the specified 0\n",
      "Created a chunk of size 278, which is longer than the specified 0\n",
      "Created a chunk of size 307, which is longer than the specified 0\n",
      "Created a chunk of size 356, which is longer than the specified 0\n",
      "Created a chunk of size 766, which is longer than the specified 0\n",
      "Created a chunk of size 767, which is longer than the specified 0\n",
      "Created a chunk of size 716, which is longer than the specified 0\n",
      "Created a chunk of size 2012, which is longer than the specified 0\n",
      "Created a chunk of size 308, which is longer than the specified 0\n",
      "Created a chunk of size 1286, which is longer than the specified 0\n",
      "Created a chunk of size 1231, which is longer than the specified 0\n",
      "Created a chunk of size 729, which is longer than the specified 0\n",
      "Created a chunk of size 750, which is longer than the specified 0\n",
      "Created a chunk of size 445, which is longer than the specified 0\n",
      "Created a chunk of size 1242, which is longer than the specified 0\n",
      "Created a chunk of size 309, which is longer than the specified 0\n",
      "Created a chunk of size 912, which is longer than the specified 0\n",
      "Created a chunk of size 304, which is longer than the specified 0\n",
      "Created a chunk of size 844, which is longer than the specified 0\n",
      "Created a chunk of size 1126, which is longer than the specified 0\n",
      "Created a chunk of size 1073, which is longer than the specified 0\n",
      "Created a chunk of size 1318, which is longer than the specified 0\n",
      "Created a chunk of size 361, which is longer than the specified 0\n",
      "Created a chunk of size 2834, which is longer than the specified 0\n",
      "Created a chunk of size 237, which is longer than the specified 0\n",
      "Created a chunk of size 240, which is longer than the specified 0\n",
      "Created a chunk of size 171, which is longer than the specified 0\n",
      "Created a chunk of size 204, which is longer than the specified 0\n",
      "Created a chunk of size 570, which is longer than the specified 0\n",
      "Created a chunk of size 206, which is longer than the specified 0\n",
      "Created a chunk of size 367, which is longer than the specified 0\n",
      "Created a chunk of size 1141, which is longer than the specified 0\n",
      "Created a chunk of size 1004, which is longer than the specified 0\n",
      "Created a chunk of size 715, which is longer than the specified 0\n",
      "Created a chunk of size 710, which is longer than the specified 0\n",
      "Created a chunk of size 2510, which is longer than the specified 0\n",
      "Created a chunk of size 954, which is longer than the specified 0\n",
      "Created a chunk of size 307, which is longer than the specified 0\n",
      "Created a chunk of size 351, which is longer than the specified 0\n",
      "Created a chunk of size 639, which is longer than the specified 0\n",
      "Created a chunk of size 405, which is longer than the specified 0\n",
      "Created a chunk of size 523, which is longer than the specified 0\n",
      "Created a chunk of size 793, which is longer than the specified 0\n",
      "Created a chunk of size 165, which is longer than the specified 0\n",
      "Created a chunk of size 389, which is longer than the specified 0\n",
      "Created a chunk of size 254, which is longer than the specified 0\n",
      "Created a chunk of size 1422, which is longer than the specified 0\n",
      "Created a chunk of size 1083, which is longer than the specified 0\n",
      "Created a chunk of size 1144, which is longer than the specified 0\n",
      "Created a chunk of size 1268, which is longer than the specified 0\n",
      "Created a chunk of size 790, which is longer than the specified 0\n",
      "Created a chunk of size 297, which is longer than the specified 0\n",
      "Created a chunk of size 1086, which is longer than the specified 0\n",
      "Created a chunk of size 874, which is longer than the specified 0\n",
      "Created a chunk of size 256, which is longer than the specified 0\n",
      "Created a chunk of size 876, which is longer than the specified 0\n",
      "Created a chunk of size 806, which is longer than the specified 0\n",
      "Created a chunk of size 1812, which is longer than the specified 0\n",
      "Created a chunk of size 1830, which is longer than the specified 0\n",
      "Created a chunk of size 1064, which is longer than the specified 0\n",
      "Created a chunk of size 955, which is longer than the specified 0\n",
      "Created a chunk of size 1180, which is longer than the specified 0\n",
      "Created a chunk of size 281, which is longer than the specified 0\n",
      "Created a chunk of size 281, which is longer than the specified 0\n",
      "Created a chunk of size 286, which is longer than the specified 0\n",
      "Created a chunk of size 1284, which is longer than the specified 0\n",
      "Created a chunk of size 1642, which is longer than the specified 0\n",
      "Created a chunk of size 757, which is longer than the specified 0\n",
      "Created a chunk of size 1930, which is longer than the specified 0\n",
      "Created a chunk of size 872, which is longer than the specified 0\n",
      "Created a chunk of size 2008, which is longer than the specified 0\n",
      "Created a chunk of size 2285, which is longer than the specified 0\n",
      "Created a chunk of size 173, which is longer than the specified 0\n",
      "Created a chunk of size 1003, which is longer than the specified 0\n",
      "Created a chunk of size 577, which is longer than the specified 0\n",
      "Created a chunk of size 288, which is longer than the specified 0\n",
      "Created a chunk of size 255, which is longer than the specified 0\n",
      "Created a chunk of size 1142, which is longer than the specified 0\n",
      "Created a chunk of size 557, which is longer than the specified 0\n",
      "Created a chunk of size 1143, which is longer than the specified 0\n",
      "Created a chunk of size 243, which is longer than the specified 0\n",
      "Created a chunk of size 1086, which is longer than the specified 0\n",
      "Created a chunk of size 1483, which is longer than the specified 0\n",
      "Created a chunk of size 221, which is longer than the specified 0\n",
      "Created a chunk of size 1135, which is longer than the specified 0\n",
      "Created a chunk of size 722, which is longer than the specified 0\n",
      "Created a chunk of size 668, which is longer than the specified 0\n",
      "Created a chunk of size 765, which is longer than the specified 0\n",
      "Created a chunk of size 606, which is longer than the specified 0\n",
      "Created a chunk of size 570, which is longer than the specified 0\n",
      "Created a chunk of size 965, which is longer than the specified 0\n",
      "Created a chunk of size 857, which is longer than the specified 0\n",
      "Created a chunk of size 1032, which is longer than the specified 0\n",
      "Created a chunk of size 189, which is longer than the specified 0\n",
      "Created a chunk of size 367, which is longer than the specified 0\n",
      "Created a chunk of size 495, which is longer than the specified 0\n",
      "Created a chunk of size 652, which is longer than the specified 0\n",
      "Created a chunk of size 348, which is longer than the specified 0\n",
      "Created a chunk of size 733, which is longer than the specified 0\n",
      "Created a chunk of size 525, which is longer than the specified 0\n",
      "Created a chunk of size 1015, which is longer than the specified 0\n",
      "Created a chunk of size 970, which is longer than the specified 0\n",
      "Created a chunk of size 204, which is longer than the specified 0\n",
      "Created a chunk of size 688, which is longer than the specified 0\n",
      "Created a chunk of size 544, which is longer than the specified 0\n",
      "Created a chunk of size 242, which is longer than the specified 0\n",
      "Created a chunk of size 207, which is longer than the specified 0\n",
      "Created a chunk of size 376, which is longer than the specified 0\n",
      "Created a chunk of size 931, which is longer than the specified 0\n",
      "Created a chunk of size 564, which is longer than the specified 0\n",
      "Created a chunk of size 854, which is longer than the specified 0\n",
      "Created a chunk of size 715, which is longer than the specified 0\n",
      "Created a chunk of size 749, which is longer than the specified 0\n",
      "Created a chunk of size 712, which is longer than the specified 0\n",
      "Created a chunk of size 324, which is longer than the specified 0\n",
      "Created a chunk of size 241, which is longer than the specified 0\n",
      "Created a chunk of size 1088, which is longer than the specified 0\n",
      "Created a chunk of size 723, which is longer than the specified 0\n",
      "Created a chunk of size 245, which is longer than the specified 0\n",
      "Created a chunk of size 227, which is longer than the specified 0\n",
      "Created a chunk of size 704, which is longer than the specified 0\n",
      "Created a chunk of size 1912, which is longer than the specified 0\n",
      "Created a chunk of size 395, which is longer than the specified 0\n",
      "Created a chunk of size 485, which is longer than the specified 0\n",
      "Created a chunk of size 622, which is longer than the specified 0\n",
      "Created a chunk of size 559, which is longer than the specified 0\n",
      "Created a chunk of size 556, which is longer than the specified 0\n",
      "Created a chunk of size 386, which is longer than the specified 0\n",
      "Created a chunk of size 229, which is longer than the specified 0\n",
      "Created a chunk of size 425, which is longer than the specified 0\n",
      "Created a chunk of size 418, which is longer than the specified 0\n",
      "Created a chunk of size 284, which is longer than the specified 0\n",
      "Created a chunk of size 166, which is longer than the specified 0\n",
      "Created a chunk of size 624, which is longer than the specified 0\n",
      "Created a chunk of size 2616, which is longer than the specified 0\n",
      "Created a chunk of size 1580, which is longer than the specified 0\n",
      "Created a chunk of size 389, which is longer than the specified 0\n",
      "Created a chunk of size 994, which is longer than the specified 0\n",
      "Created a chunk of size 847, which is longer than the specified 0\n",
      "Created a chunk of size 263, which is longer than the specified 0\n",
      "Created a chunk of size 336, which is longer than the specified 0\n",
      "Created a chunk of size 1530, which is longer than the specified 0\n",
      "Created a chunk of size 213, which is longer than the specified 0\n",
      "Created a chunk of size 291, which is longer than the specified 0\n",
      "Created a chunk of size 2030, which is longer than the specified 0\n",
      "Created a chunk of size 396, which is longer than the specified 0\n",
      "Created a chunk of size 1619, which is longer than the specified 0\n",
      "Created a chunk of size 698, which is longer than the specified 0\n",
      "Created a chunk of size 822, which is longer than the specified 0\n",
      "Created a chunk of size 354, which is longer than the specified 0\n",
      "Created a chunk of size 843, which is longer than the specified 0\n",
      "Created a chunk of size 1189, which is longer than the specified 0\n",
      "Created a chunk of size 195, which is longer than the specified 0\n",
      "Created a chunk of size 508, which is longer than the specified 0\n",
      "Created a chunk of size 663, which is longer than the specified 0\n",
      "Created a chunk of size 1282, which is longer than the specified 0\n",
      "Created a chunk of size 260, which is longer than the specified 0\n",
      "Created a chunk of size 242, which is longer than the specified 0\n",
      "Created a chunk of size 215, which is longer than the specified 0\n",
      "Created a chunk of size 198, which is longer than the specified 0\n",
      "Created a chunk of size 1268, which is longer than the specified 0\n",
      "Created a chunk of size 1277, which is longer than the specified 0\n",
      "Created a chunk of size 198, which is longer than the specified 0\n",
      "Created a chunk of size 1056, which is longer than the specified 0\n",
      "Created a chunk of size 378, which is longer than the specified 0\n",
      "Created a chunk of size 269, which is longer than the specified 0\n",
      "Created a chunk of size 177, which is longer than the specified 0\n",
      "Created a chunk of size 225, which is longer than the specified 0\n",
      "Created a chunk of size 222, which is longer than the specified 0\n",
      "Created a chunk of size 784, which is longer than the specified 0\n",
      "Created a chunk of size 969, which is longer than the specified 0\n",
      "Created a chunk of size 613, which is longer than the specified 0\n",
      "Created a chunk of size 163, which is longer than the specified 0\n",
      "Created a chunk of size 757, which is longer than the specified 0\n",
      "Created a chunk of size 289, which is longer than the specified 0\n",
      "Created a chunk of size 245, which is longer than the specified 0\n",
      "Created a chunk of size 963, which is longer than the specified 0\n",
      "Created a chunk of size 232, which is longer than the specified 0\n",
      "Created a chunk of size 843, which is longer than the specified 0\n",
      "Created a chunk of size 786, which is longer than the specified 0\n",
      "Created a chunk of size 648, which is longer than the specified 0\n",
      "Created a chunk of size 984, which is longer than the specified 0\n",
      "Created a chunk of size 799, which is longer than the specified 0\n",
      "Created a chunk of size 193, which is longer than the specified 0\n",
      "Created a chunk of size 1163, which is longer than the specified 0\n",
      "Created a chunk of size 253, which is longer than the specified 0\n",
      "Created a chunk of size 203, which is longer than the specified 0\n",
      "Created a chunk of size 1058, which is longer than the specified 0\n",
      "Created a chunk of size 246, which is longer than the specified 0\n",
      "Created a chunk of size 875, which is longer than the specified 0\n",
      "Created a chunk of size 817, which is longer than the specified 0\n",
      "Created a chunk of size 378, which is longer than the specified 0\n",
      "Created a chunk of size 755, which is longer than the specified 0\n",
      "Created a chunk of size 569, which is longer than the specified 0\n",
      "Created a chunk of size 628, which is longer than the specified 0\n",
      "Created a chunk of size 868, which is longer than the specified 0\n",
      "Created a chunk of size 620, which is longer than the specified 0\n",
      "Created a chunk of size 621, which is longer than the specified 0\n",
      "Created a chunk of size 1084, which is longer than the specified 0\n",
      "Created a chunk of size 2762, which is longer than the specified 0\n",
      "Created a chunk of size 1033, which is longer than the specified 0\n",
      "Created a chunk of size 758, which is longer than the specified 0\n",
      "Created a chunk of size 773, which is longer than the specified 0\n",
      "Created a chunk of size 634, which is longer than the specified 0\n",
      "Created a chunk of size 1010, which is longer than the specified 0\n",
      "Created a chunk of size 189, which is longer than the specified 0\n",
      "Created a chunk of size 1064, which is longer than the specified 0\n",
      "Created a chunk of size 492, which is longer than the specified 0\n",
      "Created a chunk of size 795, which is longer than the specified 0\n",
      "Created a chunk of size 699, which is longer than the specified 0\n",
      "Created a chunk of size 485, which is longer than the specified 0\n",
      "Created a chunk of size 372, which is longer than the specified 0\n",
      "Created a chunk of size 275, which is longer than the specified 0\n",
      "Created a chunk of size 1224, which is longer than the specified 0\n",
      "Created a chunk of size 223, which is longer than the specified 0\n",
      "Created a chunk of size 345, which is longer than the specified 0\n",
      "Created a chunk of size 657, which is longer than the specified 0\n",
      "Created a chunk of size 199, which is longer than the specified 0\n",
      "Created a chunk of size 767, which is longer than the specified 0\n",
      "Created a chunk of size 553, which is longer than the specified 0\n",
      "Created a chunk of size 227, which is longer than the specified 0\n",
      "Created a chunk of size 233, which is longer than the specified 0\n",
      "Created a chunk of size 590, which is longer than the specified 0\n",
      "Created a chunk of size 238, which is longer than the specified 0\n",
      "Created a chunk of size 299, which is longer than the specified 0\n",
      "Created a chunk of size 726, which is longer than the specified 0\n",
      "Created a chunk of size 1805, which is longer than the specified 0\n",
      "Created a chunk of size 1017, which is longer than the specified 0\n",
      "Created a chunk of size 684, which is longer than the specified 0\n",
      "Created a chunk of size 739, which is longer than the specified 0\n",
      "Created a chunk of size 236, which is longer than the specified 0\n",
      "Created a chunk of size 449, which is longer than the specified 0\n",
      "Created a chunk of size 472, which is longer than the specified 0\n",
      "Created a chunk of size 922, which is longer than the specified 0\n",
      "Created a chunk of size 220, which is longer than the specified 0\n",
      "Created a chunk of size 162, which is longer than the specified 0\n",
      "Created a chunk of size 967, which is longer than the specified 0\n",
      "Created a chunk of size 477, which is longer than the specified 0\n",
      "Created a chunk of size 220, which is longer than the specified 0\n",
      "Created a chunk of size 645, which is longer than the specified 0\n",
      "Created a chunk of size 676, which is longer than the specified 0\n",
      "Created a chunk of size 712, which is longer than the specified 0\n",
      "Created a chunk of size 799, which is longer than the specified 0\n",
      "Created a chunk of size 854, which is longer than the specified 0\n",
      "Created a chunk of size 670, which is longer than the specified 0\n",
      "Created a chunk of size 211, which is longer than the specified 0\n",
      "Created a chunk of size 854, which is longer than the specified 0\n",
      "Created a chunk of size 275, which is longer than the specified 0\n",
      "Created a chunk of size 760, which is longer than the specified 0\n",
      "Created a chunk of size 796, which is longer than the specified 0\n",
      "Created a chunk of size 679, which is longer than the specified 0\n",
      "Created a chunk of size 927, which is longer than the specified 0\n",
      "Created a chunk of size 1268, which is longer than the specified 0\n",
      "Created a chunk of size 733, which is longer than the specified 0\n",
      "Created a chunk of size 868, which is longer than the specified 0\n",
      "Created a chunk of size 931, which is longer than the specified 0\n",
      "Created a chunk of size 772, which is longer than the specified 0\n",
      "Created a chunk of size 770, which is longer than the specified 0\n",
      "Created a chunk of size 335, which is longer than the specified 0\n",
      "Created a chunk of size 649, which is longer than the specified 0\n",
      "Created a chunk of size 1771, which is longer than the specified 0\n",
      "Created a chunk of size 534, which is longer than the specified 0\n",
      "Created a chunk of size 824, which is longer than the specified 0\n",
      "Created a chunk of size 261, which is longer than the specified 0\n",
      "Created a chunk of size 599, which is longer than the specified 0\n",
      "Created a chunk of size 486, which is longer than the specified 0\n",
      "Created a chunk of size 969, which is longer than the specified 0\n",
      "Created a chunk of size 275, which is longer than the specified 0\n",
      "Created a chunk of size 554, which is longer than the specified 0\n",
      "Created a chunk of size 491, which is longer than the specified 0\n",
      "Created a chunk of size 844, which is longer than the specified 0\n",
      "Created a chunk of size 876, which is longer than the specified 0\n",
      "Created a chunk of size 670, which is longer than the specified 0\n",
      "Created a chunk of size 273, which is longer than the specified 0\n",
      "Created a chunk of size 707, which is longer than the specified 0\n",
      "Created a chunk of size 225, which is longer than the specified 0\n",
      "Created a chunk of size 654, which is longer than the specified 0\n",
      "Created a chunk of size 1270, which is longer than the specified 0\n",
      "Created a chunk of size 260, which is longer than the specified 0\n",
      "Created a chunk of size 261, which is longer than the specified 0\n",
      "Created a chunk of size 736, which is longer than the specified 0\n",
      "Created a chunk of size 203, which is longer than the specified 0\n",
      "Created a chunk of size 250, which is longer than the specified 0\n",
      "Created a chunk of size 292, which is longer than the specified 0\n",
      "Created a chunk of size 1019, which is longer than the specified 0\n",
      "Created a chunk of size 364, which is longer than the specified 0\n",
      "Created a chunk of size 187, which is longer than the specified 0\n",
      "Created a chunk of size 777, which is longer than the specified 0\n",
      "Created a chunk of size 682, which is longer than the specified 0\n",
      "Created a chunk of size 225, which is longer than the specified 0\n",
      "Created a chunk of size 598, which is longer than the specified 0\n",
      "Created a chunk of size 663, which is longer than the specified 0\n",
      "Created a chunk of size 595, which is longer than the specified 0\n",
      "Created a chunk of size 857, which is longer than the specified 0\n",
      "Created a chunk of size 595, which is longer than the specified 0\n",
      "Created a chunk of size 235, which is longer than the specified 0\n",
      "Created a chunk of size 240, which is longer than the specified 0\n",
      "Created a chunk of size 157, which is longer than the specified 0\n",
      "Created a chunk of size 537, which is longer than the specified 0\n",
      "Created a chunk of size 567, which is longer than the specified 0\n",
      "Created a chunk of size 278, which is longer than the specified 0\n",
      "Created a chunk of size 705, which is longer than the specified 0\n",
      "Created a chunk of size 848, which is longer than the specified 0\n",
      "Created a chunk of size 233, which is longer than the specified 0\n",
      "Created a chunk of size 346, which is longer than the specified 0\n",
      "Created a chunk of size 255, which is longer than the specified 0\n",
      "Created a chunk of size 542, which is longer than the specified 0\n",
      "Created a chunk of size 214, which is longer than the specified 0\n",
      "Created a chunk of size 214, which is longer than the specified 0\n",
      "Created a chunk of size 1177, which is longer than the specified 0\n",
      "Created a chunk of size 187, which is longer than the specified 0\n",
      "Created a chunk of size 458, which is longer than the specified 0\n",
      "Created a chunk of size 904, which is longer than the specified 0\n",
      "Created a chunk of size 852, which is longer than the specified 0\n",
      "Created a chunk of size 507, which is longer than the specified 0\n",
      "Created a chunk of size 218, which is longer than the specified 0\n",
      "Created a chunk of size 1715, which is longer than the specified 0\n",
      "Created a chunk of size 245, which is longer than the specified 0\n",
      "Created a chunk of size 189, which is longer than the specified 0\n",
      "Created a chunk of size 398, which is longer than the specified 0\n",
      "Created a chunk of size 845, which is longer than the specified 0\n",
      "Created a chunk of size 1681, which is longer than the specified 0\n",
      "Created a chunk of size 721, which is longer than the specified 0\n",
      "Created a chunk of size 659, which is longer than the specified 0\n",
      "Created a chunk of size 603, which is longer than the specified 0\n",
      "Created a chunk of size 991, which is longer than the specified 0\n",
      "Created a chunk of size 1128, which is longer than the specified 0\n",
      "Created a chunk of size 462, which is longer than the specified 0\n",
      "Created a chunk of size 2005, which is longer than the specified 0\n",
      "Created a chunk of size 218, which is longer than the specified 0\n",
      "Created a chunk of size 183, which is longer than the specified 0\n",
      "Created a chunk of size 1171, which is longer than the specified 0\n",
      "Created a chunk of size 2141, which is longer than the specified 0\n",
      "Created a chunk of size 662, which is longer than the specified 0\n",
      "Created a chunk of size 1322, which is longer than the specified 0\n",
      "Created a chunk of size 526, which is longer than the specified 0\n",
      "Created a chunk of size 336, which is longer than the specified 0\n",
      "Created a chunk of size 372, which is longer than the specified 0\n",
      "Created a chunk of size 1112, which is longer than the specified 0\n",
      "Created a chunk of size 664, which is longer than the specified 0\n",
      "Created a chunk of size 908, which is longer than the specified 0\n",
      "Created a chunk of size 1316, which is longer than the specified 0\n",
      "Created a chunk of size 155, which is longer than the specified 0\n",
      "Created a chunk of size 691, which is longer than the specified 0\n",
      "Created a chunk of size 950, which is longer than the specified 0\n",
      "Created a chunk of size 1121, which is longer than the specified 0\n",
      "Created a chunk of size 776, which is longer than the specified 0\n",
      "Created a chunk of size 615, which is longer than the specified 0\n",
      "Created a chunk of size 423, which is longer than the specified 0\n",
      "Created a chunk of size 533, which is longer than the specified 0\n",
      "Created a chunk of size 1018, which is longer than the specified 0\n",
      "Created a chunk of size 725, which is longer than the specified 0\n",
      "Created a chunk of size 612, which is longer than the specified 0\n",
      "Created a chunk of size 629, which is longer than the specified 0\n",
      "Created a chunk of size 463, which is longer than the specified 0\n",
      "Created a chunk of size 269, which is longer than the specified 0\n",
      "Created a chunk of size 1007, which is longer than the specified 0\n",
      "Created a chunk of size 616, which is longer than the specified 0\n",
      "Created a chunk of size 884, which is longer than the specified 0\n",
      "Created a chunk of size 579, which is longer than the specified 0\n",
      "Created a chunk of size 911, which is longer than the specified 0\n",
      "Created a chunk of size 1057, which is longer than the specified 0\n",
      "Created a chunk of size 630, which is longer than the specified 0\n",
      "Created a chunk of size 1255, which is longer than the specified 0\n",
      "Created a chunk of size 337, which is longer than the specified 0\n",
      "Created a chunk of size 572, which is longer than the specified 0\n",
      "Created a chunk of size 1098, which is longer than the specified 0\n",
      "Created a chunk of size 907, which is longer than the specified 0\n",
      "Created a chunk of size 621, which is longer than the specified 0\n",
      "Created a chunk of size 381, which is longer than the specified 0\n",
      "Created a chunk of size 288, which is longer than the specified 0\n",
      "Created a chunk of size 354, which is longer than the specified 0\n",
      "Created a chunk of size 183, which is longer than the specified 0\n",
      "Created a chunk of size 409, which is longer than the specified 0\n",
      "Created a chunk of size 448, which is longer than the specified 0\n",
      "Created a chunk of size 877, which is longer than the specified 0\n",
      "Created a chunk of size 338, which is longer than the specified 0\n",
      "Created a chunk of size 1143, which is longer than the specified 0\n",
      "Created a chunk of size 877, which is longer than the specified 0\n",
      "Created a chunk of size 349, which is longer than the specified 0\n",
      "Created a chunk of size 620, which is longer than the specified 0\n",
      "Created a chunk of size 625, which is longer than the specified 0\n",
      "Created a chunk of size 232, which is longer than the specified 0\n",
      "Created a chunk of size 551, which is longer than the specified 0\n",
      "Created a chunk of size 396, which is longer than the specified 0\n",
      "Created a chunk of size 385, which is longer than the specified 0\n",
      "Created a chunk of size 841, which is longer than the specified 0\n",
      "Created a chunk of size 481, which is longer than the specified 0\n",
      "Created a chunk of size 714, which is longer than the specified 0\n",
      "Created a chunk of size 921, which is longer than the specified 0\n",
      "Created a chunk of size 213, which is longer than the specified 0\n",
      "Created a chunk of size 349, which is longer than the specified 0\n",
      "Created a chunk of size 581, which is longer than the specified 0\n",
      "Created a chunk of size 744, which is longer than the specified 0\n",
      "Created a chunk of size 554, which is longer than the specified 0\n",
      "Created a chunk of size 800, which is longer than the specified 0\n",
      "Created a chunk of size 346, which is longer than the specified 0\n",
      "Created a chunk of size 541, which is longer than the specified 0\n",
      "Created a chunk of size 259, which is longer than the specified 0\n",
      "Created a chunk of size 750, which is longer than the specified 0\n",
      "Created a chunk of size 612, which is longer than the specified 0\n",
      "Created a chunk of size 495, which is longer than the specified 0\n",
      "Created a chunk of size 250, which is longer than the specified 0\n",
      "Created a chunk of size 209, which is longer than the specified 0\n",
      "Created a chunk of size 611, which is longer than the specified 0\n",
      "Created a chunk of size 587, which is longer than the specified 0\n",
      "Created a chunk of size 311, which is longer than the specified 0\n",
      "Created a chunk of size 288, which is longer than the specified 0\n",
      "Created a chunk of size 361, which is longer than the specified 0\n",
      "Created a chunk of size 809, which is longer than the specified 0\n",
      "Created a chunk of size 599, which is longer than the specified 0\n",
      "Created a chunk of size 276, which is longer than the specified 0\n",
      "Created a chunk of size 1550, which is longer than the specified 0\n",
      "Created a chunk of size 590, which is longer than the specified 0\n",
      "Created a chunk of size 827, which is longer than the specified 0\n",
      "Created a chunk of size 664, which is longer than the specified 0\n",
      "Created a chunk of size 877, which is longer than the specified 0\n",
      "Created a chunk of size 267, which is longer than the specified 0\n",
      "Created a chunk of size 736, which is longer than the specified 0\n",
      "Created a chunk of size 429, which is longer than the specified 0\n",
      "Created a chunk of size 723, which is longer than the specified 0\n",
      "Created a chunk of size 507, which is longer than the specified 0\n",
      "Created a chunk of size 288, which is longer than the specified 0\n",
      "Created a chunk of size 422, which is longer than the specified 0\n",
      "Created a chunk of size 385, which is longer than the specified 0\n",
      "Created a chunk of size 923, which is longer than the specified 0\n",
      "Created a chunk of size 330, which is longer than the specified 0\n",
      "Created a chunk of size 547, which is longer than the specified 0\n",
      "Created a chunk of size 349, which is longer than the specified 0\n",
      "Created a chunk of size 303, which is longer than the specified 0\n",
      "Created a chunk of size 264, which is longer than the specified 0\n",
      "Created a chunk of size 182, which is longer than the specified 0\n",
      "Created a chunk of size 337, which is longer than the specified 0\n",
      "Created a chunk of size 224, which is longer than the specified 0\n",
      "Created a chunk of size 1652, which is longer than the specified 0\n",
      "Created a chunk of size 873, which is longer than the specified 0\n",
      "Created a chunk of size 1495, which is longer than the specified 0\n",
      "Created a chunk of size 362, which is longer than the specified 0\n",
      "Created a chunk of size 474, which is longer than the specified 0\n",
      "Created a chunk of size 736, which is longer than the specified 0\n",
      "Created a chunk of size 527, which is longer than the specified 0\n",
      "Created a chunk of size 612, which is longer than the specified 0\n",
      "Created a chunk of size 799, which is longer than the specified 0\n",
      "Created a chunk of size 228, which is longer than the specified 0\n",
      "Created a chunk of size 436, which is longer than the specified 0\n",
      "Created a chunk of size 538, which is longer than the specified 0\n",
      "Created a chunk of size 217, which is longer than the specified 0\n",
      "Created a chunk of size 545, which is longer than the specified 0\n",
      "Created a chunk of size 329, which is longer than the specified 0\n",
      "Created a chunk of size 461, which is longer than the specified 0\n",
      "Created a chunk of size 226, which is longer than the specified 0\n",
      "Created a chunk of size 313, which is longer than the specified 0\n",
      "Created a chunk of size 293, which is longer than the specified 0\n",
      "Created a chunk of size 174, which is longer than the specified 0\n",
      "Created a chunk of size 239, which is longer than the specified 0\n",
      "Created a chunk of size 473, which is longer than the specified 0\n",
      "Created a chunk of size 204, which is longer than the specified 0\n",
      "Created a chunk of size 723, which is longer than the specified 0\n",
      "Created a chunk of size 249, which is longer than the specified 0\n",
      "Created a chunk of size 976, which is longer than the specified 0\n",
      "Created a chunk of size 217, which is longer than the specified 0\n",
      "Created a chunk of size 175, which is longer than the specified 0\n",
      "Created a chunk of size 926, which is longer than the specified 0\n",
      "Created a chunk of size 198, which is longer than the specified 0\n",
      "Created a chunk of size 250, which is longer than the specified 0\n",
      "Created a chunk of size 269, which is longer than the specified 0\n",
      "Created a chunk of size 309, which is longer than the specified 0\n",
      "Created a chunk of size 257, which is longer than the specified 0\n",
      "Created a chunk of size 226, which is longer than the specified 0\n",
      "Created a chunk of size 356, which is longer than the specified 0\n",
      "Created a chunk of size 182, which is longer than the specified 0\n",
      "Created a chunk of size 554, which is longer than the specified 0\n",
      "Created a chunk of size 674, which is longer than the specified 0\n",
      "Created a chunk of size 789, which is longer than the specified 0\n",
      "Created a chunk of size 280, which is longer than the specified 0\n",
      "Created a chunk of size 228, which is longer than the specified 0\n",
      "Created a chunk of size 636, which is longer than the specified 0\n",
      "Created a chunk of size 216, which is longer than the specified 0\n",
      "Created a chunk of size 342, which is longer than the specified 0\n",
      "Created a chunk of size 223, which is longer than the specified 0\n",
      "Created a chunk of size 160, which is longer than the specified 0\n",
      "Created a chunk of size 284, which is longer than the specified 0\n",
      "Created a chunk of size 416, which is longer than the specified 0\n",
      "Created a chunk of size 229, which is longer than the specified 0\n",
      "Created a chunk of size 271, which is longer than the specified 0\n",
      "Created a chunk of size 264, which is longer than the specified 0\n",
      "Created a chunk of size 615, which is longer than the specified 0\n",
      "Created a chunk of size 324, which is longer than the specified 0\n",
      "Created a chunk of size 253, which is longer than the specified 0\n",
      "Created a chunk of size 991, which is longer than the specified 0\n",
      "Created a chunk of size 246, which is longer than the specified 0\n",
      "Created a chunk of size 265, which is longer than the specified 0\n",
      "Created a chunk of size 448, which is longer than the specified 0\n",
      "Created a chunk of size 307, which is longer than the specified 0\n",
      "Created a chunk of size 280, which is longer than the specified 0\n",
      "Created a chunk of size 248, which is longer than the specified 0\n",
      "Created a chunk of size 341, which is longer than the specified 0\n",
      "Created a chunk of size 676, which is longer than the specified 0\n",
      "Created a chunk of size 247, which is longer than the specified 0\n",
      "Created a chunk of size 262, which is longer than the specified 0\n",
      "Created a chunk of size 231, which is longer than the specified 0\n",
      "Created a chunk of size 293, which is longer than the specified 0\n",
      "Created a chunk of size 292, which is longer than the specified 0\n",
      "Created a chunk of size 450, which is longer than the specified 0\n",
      "Created a chunk of size 581, which is longer than the specified 0\n",
      "Created a chunk of size 583, which is longer than the specified 0\n",
      "Created a chunk of size 255, which is longer than the specified 0\n",
      "Created a chunk of size 270, which is longer than the specified 0\n",
      "Created a chunk of size 775, which is longer than the specified 0\n",
      "Created a chunk of size 187, which is longer than the specified 0\n",
      "Created a chunk of size 261, which is longer than the specified 0\n",
      "Created a chunk of size 530, which is longer than the specified 0\n",
      "Created a chunk of size 178, which is longer than the specified 0\n",
      "Created a chunk of size 302, which is longer than the specified 0\n",
      "Created a chunk of size 258, which is longer than the specified 0\n",
      "Created a chunk of size 178, which is longer than the specified 0\n",
      "Created a chunk of size 199, which is longer than the specified 0\n",
      "Created a chunk of size 243, which is longer than the specified 0\n",
      "Created a chunk of size 613, which is longer than the specified 0\n",
      "Created a chunk of size 832, which is longer than the specified 0\n",
      "Created a chunk of size 276, which is longer than the specified 0\n",
      "Created a chunk of size 318, which is longer than the specified 0\n",
      "Created a chunk of size 434, which is longer than the specified 0\n",
      "Created a chunk of size 187, which is longer than the specified 0\n",
      "Created a chunk of size 824, which is longer than the specified 0\n",
      "Created a chunk of size 314, which is longer than the specified 0\n",
      "Created a chunk of size 237, which is longer than the specified 0\n",
      "Created a chunk of size 194, which is longer than the specified 0\n",
      "Created a chunk of size 465, which is longer than the specified 0\n",
      "Created a chunk of size 202, which is longer than the specified 0\n",
      "Created a chunk of size 177, which is longer than the specified 0\n",
      "Created a chunk of size 195, which is longer than the specified 0\n",
      "Created a chunk of size 262, which is longer than the specified 0\n",
      "Created a chunk of size 886, which is longer than the specified 0\n",
      "Created a chunk of size 1277, which is longer than the specified 0\n",
      "Created a chunk of size 363, which is longer than the specified 0\n",
      "Created a chunk of size 223, which is longer than the specified 0\n",
      "Created a chunk of size 666, which is longer than the specified 0\n",
      "Created a chunk of size 847, which is longer than the specified 0\n",
      "Created a chunk of size 200, which is longer than the specified 0\n",
      "Created a chunk of size 1046, which is longer than the specified 0\n",
      "Created a chunk of size 670, which is longer than the specified 0\n",
      "Created a chunk of size 331, which is longer than the specified 0\n",
      "Created a chunk of size 465, which is longer than the specified 0\n",
      "Created a chunk of size 224, which is longer than the specified 0\n",
      "Created a chunk of size 178, which is longer than the specified 0\n",
      "Created a chunk of size 554, which is longer than the specified 0\n",
      "Created a chunk of size 914, which is longer than the specified 0\n",
      "Created a chunk of size 755, which is longer than the specified 0\n",
      "Created a chunk of size 757, which is longer than the specified 0\n",
      "Created a chunk of size 945, which is longer than the specified 0\n",
      "Created a chunk of size 905, which is longer than the specified 0\n",
      "Created a chunk of size 847, which is longer than the specified 0\n",
      "Created a chunk of size 865, which is longer than the specified 0\n",
      "Created a chunk of size 189, which is longer than the specified 0\n",
      "Created a chunk of size 802, which is longer than the specified 0\n",
      "Created a chunk of size 837, which is longer than the specified 0\n",
      "Created a chunk of size 754, which is longer than the specified 0\n",
      "Created a chunk of size 864, which is longer than the specified 0\n",
      "Created a chunk of size 799, which is longer than the specified 0\n",
      "Created a chunk of size 678, which is longer than the specified 0\n",
      "Created a chunk of size 169, which is longer than the specified 0\n",
      "Created a chunk of size 171, which is longer than the specified 0\n",
      "Created a chunk of size 513, which is longer than the specified 0\n",
      "Created a chunk of size 169, which is longer than the specified 0\n",
      "Created a chunk of size 360, which is longer than the specified 0\n",
      "Created a chunk of size 542, which is longer than the specified 0\n",
      "Created a chunk of size 816, which is longer than the specified 0\n",
      "Created a chunk of size 743, which is longer than the specified 0\n",
      "Created a chunk of size 672, which is longer than the specified 0\n",
      "Created a chunk of size 670, which is longer than the specified 0\n",
      "Created a chunk of size 476, which is longer than the specified 0\n",
      "Created a chunk of size 990, which is longer than the specified 0\n",
      "Created a chunk of size 767, which is longer than the specified 0\n",
      "Created a chunk of size 406, which is longer than the specified 0\n",
      "Created a chunk of size 994, which is longer than the specified 0\n",
      "Created a chunk of size 231, which is longer than the specified 0\n",
      "Created a chunk of size 572, which is longer than the specified 0\n",
      "Created a chunk of size 232, which is longer than the specified 0\n",
      "Created a chunk of size 272, which is longer than the specified 0\n",
      "Created a chunk of size 226, which is longer than the specified 0\n",
      "Created a chunk of size 237, which is longer than the specified 0\n",
      "Created a chunk of size 474, which is longer than the specified 0\n",
      "Created a chunk of size 639, which is longer than the specified 0\n",
      "Created a chunk of size 607, which is longer than the specified 0\n",
      "Created a chunk of size 266, which is longer than the specified 0\n",
      "Created a chunk of size 269, which is longer than the specified 0\n",
      "Created a chunk of size 206, which is longer than the specified 0\n",
      "Created a chunk of size 1666, which is longer than the specified 0\n",
      "Created a chunk of size 374, which is longer than the specified 0\n",
      "Created a chunk of size 1616, which is longer than the specified 0\n",
      "Created a chunk of size 778, which is longer than the specified 0\n",
      "Created a chunk of size 194, which is longer than the specified 0\n",
      "Created a chunk of size 153, which is longer than the specified 0\n",
      "Created a chunk of size 574, which is longer than the specified 0\n",
      "Created a chunk of size 669, which is longer than the specified 0\n",
      "Created a chunk of size 816, which is longer than the specified 0\n",
      "Created a chunk of size 240, which is longer than the specified 0\n",
      "Created a chunk of size 211, which is longer than the specified 0\n",
      "Created a chunk of size 165, which is longer than the specified 0\n",
      "Created a chunk of size 234, which is longer than the specified 0\n",
      "Created a chunk of size 194, which is longer than the specified 0\n",
      "Created a chunk of size 442, which is longer than the specified 0\n",
      "Created a chunk of size 249, which is longer than the specified 0\n",
      "Created a chunk of size 520, which is longer than the specified 0\n",
      "Created a chunk of size 243, which is longer than the specified 0\n",
      "Created a chunk of size 188, which is longer than the specified 0\n",
      "Created a chunk of size 487, which is longer than the specified 0\n",
      "Created a chunk of size 359, which is longer than the specified 0\n",
      "Created a chunk of size 607, which is longer than the specified 0\n",
      "Created a chunk of size 303, which is longer than the specified 0\n",
      "Created a chunk of size 733, which is longer than the specified 0\n",
      "Created a chunk of size 1095, which is longer than the specified 0\n",
      "Created a chunk of size 1597, which is longer than the specified 0\n",
      "Created a chunk of size 944, which is longer than the specified 0\n",
      "Created a chunk of size 1960, which is longer than the specified 0\n",
      "Created a chunk of size 291, which is longer than the specified 0\n",
      "Created a chunk of size 595, which is longer than the specified 0\n",
      "Created a chunk of size 1708, which is longer than the specified 0\n",
      "Created a chunk of size 895, which is longer than the specified 0\n",
      "Created a chunk of size 357, which is longer than the specified 0\n",
      "Created a chunk of size 634, which is longer than the specified 0\n",
      "Created a chunk of size 306, which is longer than the specified 0\n",
      "Created a chunk of size 994, which is longer than the specified 0\n",
      "Created a chunk of size 1947, which is longer than the specified 0\n",
      "Created a chunk of size 184, which is longer than the specified 0\n",
      "Created a chunk of size 1027, which is longer than the specified 0\n",
      "Created a chunk of size 259, which is longer than the specified 0\n",
      "Created a chunk of size 616, which is longer than the specified 0\n",
      "Created a chunk of size 272, which is longer than the specified 0\n",
      "Created a chunk of size 308, which is longer than the specified 0\n",
      "Created a chunk of size 307, which is longer than the specified 0\n",
      "Created a chunk of size 494, which is longer than the specified 0\n",
      "Created a chunk of size 181, which is longer than the specified 0\n",
      "Created a chunk of size 466, which is longer than the specified 0\n",
      "Created a chunk of size 203, which is longer than the specified 0\n",
      "Created a chunk of size 218, which is longer than the specified 0\n",
      "Created a chunk of size 1807, which is longer than the specified 0\n",
      "Created a chunk of size 277, which is longer than the specified 0\n",
      "Created a chunk of size 617, which is longer than the specified 0\n",
      "Created a chunk of size 400, which is longer than the specified 0\n",
      "Created a chunk of size 358, which is longer than the specified 0\n",
      "Created a chunk of size 307, which is longer than the specified 0\n",
      "Created a chunk of size 307, which is longer than the specified 0\n",
      "Created a chunk of size 241, which is longer than the specified 0\n",
      "Created a chunk of size 305, which is longer than the specified 0\n",
      "Created a chunk of size 245, which is longer than the specified 0\n",
      "Created a chunk of size 201, which is longer than the specified 0\n",
      "Created a chunk of size 642, which is longer than the specified 0\n",
      "Created a chunk of size 206, which is longer than the specified 0\n",
      "Created a chunk of size 178, which is longer than the specified 0\n",
      "Created a chunk of size 294, which is longer than the specified 0\n",
      "Created a chunk of size 286, which is longer than the specified 0\n",
      "Created a chunk of size 356, which is longer than the specified 0\n",
      "Created a chunk of size 295, which is longer than the specified 0\n",
      "Created a chunk of size 1518, which is longer than the specified 0\n",
      "Created a chunk of size 753, which is longer than the specified 0\n",
      "Created a chunk of size 255, which is longer than the specified 0\n",
      "Created a chunk of size 201, which is longer than the specified 0\n",
      "Created a chunk of size 371, which is longer than the specified 0\n",
      "Created a chunk of size 244, which is longer than the specified 0\n",
      "Created a chunk of size 298, which is longer than the specified 0\n",
      "Created a chunk of size 152, which is longer than the specified 0\n",
      "Created a chunk of size 301, which is longer than the specified 0\n",
      "Created a chunk of size 332, which is longer than the specified 0\n",
      "Created a chunk of size 218, which is longer than the specified 0\n",
      "Created a chunk of size 259, which is longer than the specified 0\n",
      "Created a chunk of size 616, which is longer than the specified 0\n",
      "Created a chunk of size 459, which is longer than the specified 0\n",
      "Created a chunk of size 177, which is longer than the specified 0\n",
      "Created a chunk of size 688, which is longer than the specified 0\n",
      "Created a chunk of size 232, which is longer than the specified 0\n",
      "Created a chunk of size 348, which is longer than the specified 0\n",
      "Created a chunk of size 253, which is longer than the specified 0\n",
      "Created a chunk of size 194, which is longer than the specified 0\n",
      "Created a chunk of size 288, which is longer than the specified 0\n",
      "Created a chunk of size 228, which is longer than the specified 0\n",
      "Created a chunk of size 198, which is longer than the specified 0\n",
      "Created a chunk of size 258, which is longer than the specified 0\n",
      "Created a chunk of size 275, which is longer than the specified 0\n",
      "Created a chunk of size 385, which is longer than the specified 0\n",
      "Created a chunk of size 215, which is longer than the specified 0\n",
      "Created a chunk of size 229, which is longer than the specified 0\n",
      "Created a chunk of size 306, which is longer than the specified 0\n",
      "Created a chunk of size 327, which is longer than the specified 0\n",
      "Created a chunk of size 182, which is longer than the specified 0\n",
      "Created a chunk of size 244, which is longer than the specified 0\n",
      "Created a chunk of size 218, which is longer than the specified 0\n",
      "Created a chunk of size 260, which is longer than the specified 0\n",
      "Created a chunk of size 270, which is longer than the specified 0\n",
      "Created a chunk of size 302, which is longer than the specified 0\n",
      "Created a chunk of size 809, which is longer than the specified 0\n",
      "Created a chunk of size 261, which is longer than the specified 0\n",
      "Created a chunk of size 536, which is longer than the specified 0\n",
      "Created a chunk of size 238, which is longer than the specified 0\n",
      "Created a chunk of size 263, which is longer than the specified 0\n",
      "Created a chunk of size 187, which is longer than the specified 0\n",
      "Created a chunk of size 180, which is longer than the specified 0\n",
      "Created a chunk of size 202, which is longer than the specified 0\n",
      "Created a chunk of size 270, which is longer than the specified 0\n",
      "Created a chunk of size 219, which is longer than the specified 0\n",
      "Created a chunk of size 160, which is longer than the specified 0\n",
      "Created a chunk of size 163, which is longer than the specified 0\n",
      "Created a chunk of size 220, which is longer than the specified 0\n",
      "Created a chunk of size 252, which is longer than the specified 0\n",
      "Created a chunk of size 177, which is longer than the specified 0\n",
      "Created a chunk of size 224, which is longer than the specified 0\n",
      "Created a chunk of size 239, which is longer than the specified 0\n",
      "Created a chunk of size 243, which is longer than the specified 0\n",
      "Created a chunk of size 177, which is longer than the specified 0\n",
      "Created a chunk of size 305, which is longer than the specified 0\n",
      "Created a chunk of size 155, which is longer than the specified 0\n",
      "Created a chunk of size 290, which is longer than the specified 0\n",
      "Created a chunk of size 192, which is longer than the specified 0\n",
      "Created a chunk of size 231, which is longer than the specified 0\n",
      "Created a chunk of size 869, which is longer than the specified 0\n",
      "Created a chunk of size 378, which is longer than the specified 0\n",
      "Created a chunk of size 337, which is longer than the specified 0\n",
      "Created a chunk of size 483, which is longer than the specified 0\n",
      "Created a chunk of size 314, which is longer than the specified 0\n",
      "Created a chunk of size 182, which is longer than the specified 0\n",
      "Created a chunk of size 196, which is longer than the specified 0\n",
      "Created a chunk of size 890, which is longer than the specified 0\n",
      "Created a chunk of size 235, which is longer than the specified 0\n",
      "Created a chunk of size 221, which is longer than the specified 0\n",
      "Created a chunk of size 337, which is longer than the specified 0\n",
      "Created a chunk of size 255, which is longer than the specified 0\n",
      "Created a chunk of size 219, which is longer than the specified 0\n",
      "Created a chunk of size 249, which is longer than the specified 0\n",
      "Created a chunk of size 343, which is longer than the specified 0\n",
      "Created a chunk of size 231, which is longer than the specified 0\n",
      "Created a chunk of size 559, which is longer than the specified 0\n",
      "Created a chunk of size 1087, which is longer than the specified 0\n",
      "Created a chunk of size 416, which is longer than the specified 0\n",
      "Created a chunk of size 320, which is longer than the specified 0\n",
      "Created a chunk of size 248, which is longer than the specified 0\n",
      "Created a chunk of size 306, which is longer than the specified 0\n",
      "Created a chunk of size 241, which is longer than the specified 0\n",
      "Created a chunk of size 234, which is longer than the specified 0\n",
      "Created a chunk of size 333, which is longer than the specified 0\n",
      "Created a chunk of size 258, which is longer than the specified 0\n",
      "Created a chunk of size 183, which is longer than the specified 0\n",
      "Created a chunk of size 272, which is longer than the specified 0\n",
      "Created a chunk of size 264, which is longer than the specified 0\n",
      "Created a chunk of size 329, which is longer than the specified 0\n",
      "Created a chunk of size 730, which is longer than the specified 0\n",
      "Created a chunk of size 202, which is longer than the specified 0\n",
      "Created a chunk of size 295, which is longer than the specified 0\n",
      "Created a chunk of size 188, which is longer than the specified 0\n",
      "Created a chunk of size 207, which is longer than the specified 0\n",
      "Created a chunk of size 353, which is longer than the specified 0\n",
      "Created a chunk of size 385, which is longer than the specified 0\n",
      "Created a chunk of size 333, which is longer than the specified 0\n",
      "Created a chunk of size 305, which is longer than the specified 0\n",
      "Created a chunk of size 237, which is longer than the specified 0\n",
      "Created a chunk of size 283, which is longer than the specified 0\n",
      "Created a chunk of size 207, which is longer than the specified 0\n",
      "Created a chunk of size 532, which is longer than the specified 0\n",
      "Created a chunk of size 175, which is longer than the specified 0\n",
      "Created a chunk of size 615, which is longer than the specified 0\n",
      "Created a chunk of size 283, which is longer than the specified 0\n",
      "Created a chunk of size 232, which is longer than the specified 0\n",
      "Created a chunk of size 216, which is longer than the specified 0\n",
      "Created a chunk of size 273, which is longer than the specified 0\n",
      "Created a chunk of size 239, which is longer than the specified 0\n",
      "Created a chunk of size 211, which is longer than the specified 0\n",
      "Created a chunk of size 206, which is longer than the specified 0\n",
      "Created a chunk of size 209, which is longer than the specified 0\n",
      "Created a chunk of size 294, which is longer than the specified 0\n",
      "Created a chunk of size 192, which is longer than the specified 0\n",
      "Created a chunk of size 245, which is longer than the specified 0\n",
      "Created a chunk of size 200, which is longer than the specified 0\n",
      "Created a chunk of size 148, which is longer than the specified 0\n",
      "Created a chunk of size 209, which is longer than the specified 0\n",
      "Created a chunk of size 193, which is longer than the specified 0\n",
      "Created a chunk of size 257, which is longer than the specified 0\n",
      "Created a chunk of size 257, which is longer than the specified 0\n",
      "Created a chunk of size 176, which is longer than the specified 0\n",
      "Created a chunk of size 346, which is longer than the specified 0\n",
      "Created a chunk of size 239, which is longer than the specified 0\n",
      "Created a chunk of size 311, which is longer than the specified 0\n",
      "Created a chunk of size 307, which is longer than the specified 0\n",
      "Created a chunk of size 256, which is longer than the specified 0\n",
      "Created a chunk of size 400, which is longer than the specified 0\n",
      "Created a chunk of size 306, which is longer than the specified 0\n",
      "Created a chunk of size 256, which is longer than the specified 0\n",
      "Created a chunk of size 195, which is longer than the specified 0\n",
      "Created a chunk of size 1093, which is longer than the specified 0\n",
      "Created a chunk of size 225, which is longer than the specified 0\n",
      "Created a chunk of size 258, which is longer than the specified 0\n",
      "Created a chunk of size 435, which is longer than the specified 0\n",
      "Created a chunk of size 248, which is longer than the specified 0\n",
      "Created a chunk of size 290, which is longer than the specified 0\n",
      "Created a chunk of size 257, which is longer than the specified 0\n",
      "Created a chunk of size 255, which is longer than the specified 0\n",
      "Created a chunk of size 294, which is longer than the specified 0\n",
      "Created a chunk of size 365, which is longer than the specified 0\n",
      "Created a chunk of size 379, which is longer than the specified 0\n",
      "Created a chunk of size 196, which is longer than the specified 0\n",
      "Created a chunk of size 279, which is longer than the specified 0\n",
      "Created a chunk of size 337, which is longer than the specified 0\n",
      "Created a chunk of size 261, which is longer than the specified 0\n",
      "Created a chunk of size 268, which is longer than the specified 0\n",
      "Created a chunk of size 256, which is longer than the specified 0\n",
      "Created a chunk of size 215, which is longer than the specified 0\n",
      "Created a chunk of size 201, which is longer than the specified 0\n",
      "Created a chunk of size 407, which is longer than the specified 0\n",
      "Created a chunk of size 407, which is longer than the specified 0\n",
      "Created a chunk of size 362, which is longer than the specified 0\n",
      "Created a chunk of size 234, which is longer than the specified 0\n",
      "Created a chunk of size 378, which is longer than the specified 0\n",
      "Created a chunk of size 234, which is longer than the specified 0\n",
      "Created a chunk of size 279, which is longer than the specified 0\n",
      "Created a chunk of size 233, which is longer than the specified 0\n",
      "Created a chunk of size 325, which is longer than the specified 0\n",
      "Created a chunk of size 251, which is longer than the specified 0\n",
      "Created a chunk of size 201, which is longer than the specified 0\n",
      "Created a chunk of size 208, which is longer than the specified 0\n",
      "Created a chunk of size 244, which is longer than the specified 0\n",
      "Created a chunk of size 225, which is longer than the specified 0\n",
      "Created a chunk of size 177, which is longer than the specified 0\n",
      "Created a chunk of size 149, which is longer than the specified 0\n",
      "Created a chunk of size 195, which is longer than the specified 0\n",
      "Created a chunk of size 238, which is longer than the specified 0\n",
      "Created a chunk of size 283, which is longer than the specified 0\n",
      "Created a chunk of size 303, which is longer than the specified 0\n",
      "Created a chunk of size 193, which is longer than the specified 0\n",
      "Created a chunk of size 184, which is longer than the specified 0\n",
      "Created a chunk of size 878, which is longer than the specified 0\n",
      "Created a chunk of size 320, which is longer than the specified 0\n",
      "Created a chunk of size 979, which is longer than the specified 0\n",
      "Created a chunk of size 175, which is longer than the specified 0\n",
      "Created a chunk of size 988, which is longer than the specified 0\n",
      "Created a chunk of size 535, which is longer than the specified 0\n",
      "Created a chunk of size 1167, which is longer than the specified 0\n",
      "Created a chunk of size 1259, which is longer than the specified 0\n",
      "Created a chunk of size 273, which is longer than the specified 0\n",
      "Created a chunk of size 220, which is longer than the specified 0\n",
      "Created a chunk of size 1480, which is longer than the specified 0\n",
      "Created a chunk of size 320, which is longer than the specified 0\n",
      "Created a chunk of size 816, which is longer than the specified 0\n",
      "Created a chunk of size 1037, which is longer than the specified 0\n",
      "Created a chunk of size 1085, which is longer than the specified 0\n",
      "Created a chunk of size 165, which is longer than the specified 0\n",
      "Created a chunk of size 230, which is longer than the specified 0\n",
      "Created a chunk of size 1443, which is longer than the specified 0\n",
      "Created a chunk of size 1266, which is longer than the specified 0\n",
      "Created a chunk of size 1144, which is longer than the specified 0\n",
      "Created a chunk of size 1369, which is longer than the specified 0\n",
      "Created a chunk of size 1622, which is longer than the specified 0\n",
      "Created a chunk of size 1165, which is longer than the specified 0\n",
      "Created a chunk of size 152, which is longer than the specified 0\n",
      "Created a chunk of size 583, which is longer than the specified 0\n",
      "Created a chunk of size 783, which is longer than the specified 0\n",
      "Created a chunk of size 201, which is longer than the specified 0\n",
      "Created a chunk of size 1176, which is longer than the specified 0\n",
      "Created a chunk of size 1179, which is longer than the specified 0\n",
      "Created a chunk of size 730, which is longer than the specified 0\n",
      "Created a chunk of size 826, which is longer than the specified 0\n",
      "Created a chunk of size 595, which is longer than the specified 0\n",
      "Created a chunk of size 998, which is longer than the specified 0\n",
      "Created a chunk of size 200, which is longer than the specified 0\n",
      "Created a chunk of size 460, which is longer than the specified 0\n",
      "Created a chunk of size 282, which is longer than the specified 0\n",
      "Created a chunk of size 1009, which is longer than the specified 0\n",
      "Created a chunk of size 663, which is longer than the specified 0\n",
      "Created a chunk of size 1022, which is longer than the specified 0\n",
      "Created a chunk of size 745, which is longer than the specified 0\n",
      "Created a chunk of size 1357, which is longer than the specified 0\n",
      "Created a chunk of size 813, which is longer than the specified 0\n",
      "Created a chunk of size 237, which is longer than the specified 0\n",
      "Created a chunk of size 363, which is longer than the specified 0\n",
      "Created a chunk of size 424, which is longer than the specified 0\n",
      "Created a chunk of size 1172, which is longer than the specified 0\n",
      "Created a chunk of size 1394, which is longer than the specified 0\n",
      "Created a chunk of size 1216, which is longer than the specified 0\n",
      "Created a chunk of size 247, which is longer than the specified 0\n",
      "Created a chunk of size 463, which is longer than the specified 0\n",
      "Created a chunk of size 421, which is longer than the specified 0\n",
      "Created a chunk of size 269, which is longer than the specified 0\n",
      "Created a chunk of size 603, which is longer than the specified 0\n",
      "Created a chunk of size 229, which is longer than the specified 0\n",
      "Created a chunk of size 202, which is longer than the specified 0\n",
      "Created a chunk of size 2209, which is longer than the specified 0\n",
      "Created a chunk of size 1371, which is longer than the specified 0\n",
      "Created a chunk of size 2877, which is longer than the specified 0\n",
      "Created a chunk of size 793, which is longer than the specified 0\n",
      "Created a chunk of size 789, which is longer than the specified 0\n",
      "Created a chunk of size 218, which is longer than the specified 0\n",
      "Created a chunk of size 1279, which is longer than the specified 0\n",
      "Created a chunk of size 168, which is longer than the specified 0\n",
      "Created a chunk of size 252, which is longer than the specified 0\n",
      "Created a chunk of size 777, which is longer than the specified 0\n",
      "Created a chunk of size 1714, which is longer than the specified 0\n",
      "Created a chunk of size 181, which is longer than the specified 0\n",
      "Created a chunk of size 262, which is longer than the specified 0\n",
      "Created a chunk of size 346, which is longer than the specified 0\n",
      "Created a chunk of size 1638, which is longer than the specified 0\n",
      "Created a chunk of size 756, which is longer than the specified 0\n",
      "Created a chunk of size 511, which is longer than the specified 0\n",
      "Created a chunk of size 169, which is longer than the specified 0\n",
      "Created a chunk of size 269, which is longer than the specified 0\n",
      "Created a chunk of size 517, which is longer than the specified 0\n",
      "Created a chunk of size 2398, which is longer than the specified 0\n",
      "Created a chunk of size 825, which is longer than the specified 0\n",
      "Created a chunk of size 343, which is longer than the specified 0\n",
      "Created a chunk of size 2120, which is longer than the specified 0\n",
      "Created a chunk of size 173, which is longer than the specified 0\n",
      "Created a chunk of size 1488, which is longer than the specified 0\n",
      "Created a chunk of size 247, which is longer than the specified 0\n",
      "Created a chunk of size 426, which is longer than the specified 0\n",
      "Created a chunk of size 313, which is longer than the specified 0\n",
      "Created a chunk of size 1691, which is longer than the specified 0\n",
      "Created a chunk of size 198, which is longer than the specified 0\n",
      "Created a chunk of size 765, which is longer than the specified 0\n",
      "Created a chunk of size 269, which is longer than the specified 0\n",
      "Created a chunk of size 843, which is longer than the specified 0\n",
      "Created a chunk of size 1418, which is longer than the specified 0\n",
      "Created a chunk of size 791, which is longer than the specified 0\n",
      "Created a chunk of size 1173, which is longer than the specified 0\n",
      "Created a chunk of size 1359, which is longer than the specified 0\n",
      "Created a chunk of size 458, which is longer than the specified 0\n",
      "Created a chunk of size 826, which is longer than the specified 0\n",
      "Created a chunk of size 915, which is longer than the specified 0\n",
      "Created a chunk of size 434, which is longer than the specified 0\n",
      "Created a chunk of size 272, which is longer than the specified 0\n",
      "Created a chunk of size 2181, which is longer than the specified 0\n",
      "Created a chunk of size 1093, which is longer than the specified 0\n",
      "Created a chunk of size 2171, which is longer than the specified 0\n",
      "Created a chunk of size 239, which is longer than the specified 0\n",
      "Created a chunk of size 1454, which is longer than the specified 0\n",
      "Created a chunk of size 1454, which is longer than the specified 0\n",
      "Created a chunk of size 188, which is longer than the specified 0\n",
      "Created a chunk of size 210, which is longer than the specified 0\n",
      "Created a chunk of size 358, which is longer than the specified 0\n",
      "Created a chunk of size 179, which is longer than the specified 0\n",
      "Created a chunk of size 582, which is longer than the specified 0\n",
      "Created a chunk of size 1973, which is longer than the specified 0\n",
      "Created a chunk of size 1987, which is longer than the specified 0\n",
      "Created a chunk of size 281, which is longer than the specified 0\n",
      "Created a chunk of size 175, which is longer than the specified 0\n",
      "Created a chunk of size 1648, which is longer than the specified 0\n",
      "Created a chunk of size 301, which is longer than the specified 0\n",
      "Created a chunk of size 2723, which is longer than the specified 0\n",
      "Created a chunk of size 346, which is longer than the specified 0\n",
      "Created a chunk of size 1632, which is longer than the specified 0\n",
      "Created a chunk of size 476, which is longer than the specified 0\n",
      "Created a chunk of size 938, which is longer than the specified 0\n",
      "Created a chunk of size 249, which is longer than the specified 0\n",
      "Created a chunk of size 503, which is longer than the specified 0\n",
      "Created a chunk of size 1284, which is longer than the specified 0\n",
      "Created a chunk of size 1484, which is longer than the specified 0\n",
      "Created a chunk of size 311, which is longer than the specified 0\n",
      "Created a chunk of size 692, which is longer than the specified 0\n",
      "Created a chunk of size 1049, which is longer than the specified 0\n",
      "Created a chunk of size 282, which is longer than the specified 0\n",
      "Created a chunk of size 467, which is longer than the specified 0\n",
      "Created a chunk of size 411, which is longer than the specified 0\n",
      "Created a chunk of size 224, which is longer than the specified 0\n",
      "Created a chunk of size 1003, which is longer than the specified 0\n",
      "Created a chunk of size 392, which is longer than the specified 0\n",
      "Created a chunk of size 208, which is longer than the specified 0\n",
      "Created a chunk of size 1150, which is longer than the specified 0\n",
      "Created a chunk of size 228, which is longer than the specified 0\n",
      "Created a chunk of size 175, which is longer than the specified 0\n",
      "Created a chunk of size 451, which is longer than the specified 0\n",
      "Created a chunk of size 166, which is longer than the specified 0\n",
      "Created a chunk of size 219, which is longer than the specified 0\n",
      "Created a chunk of size 1216, which is longer than the specified 0\n",
      "Created a chunk of size 899, which is longer than the specified 0\n",
      "Created a chunk of size 368, which is longer than the specified 0\n",
      "Created a chunk of size 610, which is longer than the specified 0\n",
      "Created a chunk of size 411, which is longer than the specified 0\n",
      "Created a chunk of size 175, which is longer than the specified 0\n",
      "Created a chunk of size 945, which is longer than the specified 0\n",
      "Created a chunk of size 203, which is longer than the specified 0\n",
      "Created a chunk of size 216, which is longer than the specified 0\n",
      "Created a chunk of size 165, which is longer than the specified 0\n",
      "Created a chunk of size 216, which is longer than the specified 0\n",
      "Created a chunk of size 1032, which is longer than the specified 0\n",
      "Created a chunk of size 188, which is longer than the specified 0\n",
      "Created a chunk of size 2456, which is longer than the specified 0\n",
      "Created a chunk of size 983, which is longer than the specified 0\n",
      "Created a chunk of size 1349, which is longer than the specified 0\n",
      "Created a chunk of size 1271, which is longer than the specified 0\n",
      "Created a chunk of size 1117, which is longer than the specified 0\n",
      "Created a chunk of size 1548, which is longer than the specified 0\n",
      "Created a chunk of size 1201, which is longer than the specified 0\n",
      "Created a chunk of size 552, which is longer than the specified 0\n",
      "Created a chunk of size 502, which is longer than the specified 0\n",
      "Created a chunk of size 757, which is longer than the specified 0\n",
      "Created a chunk of size 975, which is longer than the specified 0\n",
      "Created a chunk of size 541, which is longer than the specified 0\n",
      "Created a chunk of size 996, which is longer than the specified 0\n",
      "Created a chunk of size 1160, which is longer than the specified 0\n",
      "Created a chunk of size 620, which is longer than the specified 0\n",
      "Created a chunk of size 283, which is longer than the specified 0\n",
      "Created a chunk of size 722, which is longer than the specified 0\n",
      "Created a chunk of size 200, which is longer than the specified 0\n",
      "Created a chunk of size 304, which is longer than the specified 0\n",
      "Created a chunk of size 591, which is longer than the specified 0\n",
      "Created a chunk of size 287, which is longer than the specified 0\n",
      "Created a chunk of size 1149, which is longer than the specified 0\n",
      "Created a chunk of size 407, which is longer than the specified 0\n",
      "Created a chunk of size 837, which is longer than the specified 0\n",
      "Created a chunk of size 252, which is longer than the specified 0\n",
      "Created a chunk of size 964, which is longer than the specified 0\n",
      "Created a chunk of size 1024, which is longer than the specified 0\n",
      "Created a chunk of size 359, which is longer than the specified 0\n",
      "Created a chunk of size 251, which is longer than the specified 0\n",
      "Created a chunk of size 380, which is longer than the specified 0\n",
      "Created a chunk of size 273, which is longer than the specified 0\n",
      "Created a chunk of size 1774, which is longer than the specified 0\n",
      "Created a chunk of size 1165, which is longer than the specified 0\n",
      "Created a chunk of size 539, which is longer than the specified 0\n",
      "Created a chunk of size 1009, which is longer than the specified 0\n",
      "Created a chunk of size 214, which is longer than the specified 0\n",
      "Created a chunk of size 577, which is longer than the specified 0\n",
      "Created a chunk of size 200, which is longer than the specified 0\n",
      "Created a chunk of size 753, which is longer than the specified 0\n",
      "Created a chunk of size 203, which is longer than the specified 0\n",
      "Created a chunk of size 172, which is longer than the specified 0\n",
      "Created a chunk of size 328, which is longer than the specified 0\n",
      "Created a chunk of size 197, which is longer than the specified 0\n",
      "Created a chunk of size 255, which is longer than the specified 0\n",
      "Created a chunk of size 278, which is longer than the specified 0\n",
      "Created a chunk of size 257, which is longer than the specified 0\n",
      "Created a chunk of size 278, which is longer than the specified 0\n",
      "Created a chunk of size 237, which is longer than the specified 0\n",
      "Created a chunk of size 427, which is longer than the specified 0\n",
      "Created a chunk of size 192, which is longer than the specified 0\n",
      "Created a chunk of size 368, which is longer than the specified 0\n",
      "Created a chunk of size 431, which is longer than the specified 0\n",
      "Created a chunk of size 204, which is longer than the specified 0\n",
      "Created a chunk of size 253, which is longer than the specified 0\n",
      "Created a chunk of size 1017, which is longer than the specified 0\n",
      "Created a chunk of size 187, which is longer than the specified 0\n",
      "Created a chunk of size 371, which is longer than the specified 0\n",
      "Created a chunk of size 352, which is longer than the specified 0\n",
      "Created a chunk of size 214, which is longer than the specified 0\n",
      "Created a chunk of size 275, which is longer than the specified 0\n",
      "Created a chunk of size 203, which is longer than the specified 0\n",
      "Created a chunk of size 191, which is longer than the specified 0\n",
      "Created a chunk of size 220, which is longer than the specified 0\n",
      "Created a chunk of size 1323, which is longer than the specified 0\n",
      "Created a chunk of size 144, which is longer than the specified 0\n",
      "Created a chunk of size 268, which is longer than the specified 0\n",
      "Created a chunk of size 247, which is longer than the specified 0\n",
      "Created a chunk of size 229, which is longer than the specified 0\n",
      "Created a chunk of size 1213, which is longer than the specified 0\n",
      "Created a chunk of size 909, which is longer than the specified 0\n",
      "Created a chunk of size 291, which is longer than the specified 0\n",
      "Created a chunk of size 176, which is longer than the specified 0\n",
      "Created a chunk of size 301, which is longer than the specified 0\n",
      "Created a chunk of size 277, which is longer than the specified 0\n",
      "Created a chunk of size 234, which is longer than the specified 0\n",
      "Created a chunk of size 208, which is longer than the specified 0\n",
      "Created a chunk of size 464, which is longer than the specified 0\n",
      "Created a chunk of size 399, which is longer than the specified 0\n",
      "Created a chunk of size 259, which is longer than the specified 0\n",
      "Created a chunk of size 663, which is longer than the specified 0\n",
      "Created a chunk of size 753, which is longer than the specified 0\n",
      "Created a chunk of size 375, which is longer than the specified 0\n",
      "Created a chunk of size 155, which is longer than the specified 0\n",
      "Created a chunk of size 198, which is longer than the specified 0\n",
      "Created a chunk of size 221, which is longer than the specified 0\n",
      "Created a chunk of size 280, which is longer than the specified 0\n",
      "Created a chunk of size 556, which is longer than the specified 0\n",
      "Created a chunk of size 262, which is longer than the specified 0\n",
      "Created a chunk of size 200, which is longer than the specified 0\n",
      "Created a chunk of size 233, which is longer than the specified 0\n",
      "Created a chunk of size 1123, which is longer than the specified 0\n",
      "Created a chunk of size 253, which is longer than the specified 0\n",
      "Created a chunk of size 607, which is longer than the specified 0\n",
      "Created a chunk of size 272, which is longer than the specified 0\n",
      "Created a chunk of size 221, which is longer than the specified 0\n",
      "Created a chunk of size 255, which is longer than the specified 0\n",
      "Created a chunk of size 457, which is longer than the specified 0\n",
      "Created a chunk of size 211, which is longer than the specified 0\n",
      "Created a chunk of size 1598, which is longer than the specified 0\n",
      "Created a chunk of size 196, which is longer than the specified 0\n",
      "Created a chunk of size 241, which is longer than the specified 0\n",
      "Created a chunk of size 223, which is longer than the specified 0\n",
      "Created a chunk of size 296, which is longer than the specified 0\n",
      "Created a chunk of size 493, which is longer than the specified 0\n",
      "Created a chunk of size 209, which is longer than the specified 0\n",
      "Created a chunk of size 1963, which is longer than the specified 0\n",
      "Created a chunk of size 185, which is longer than the specified 0\n",
      "Created a chunk of size 257, which is longer than the specified 0\n",
      "Created a chunk of size 894, which is longer than the specified 0\n",
      "Created a chunk of size 311, which is longer than the specified 0\n",
      "Created a chunk of size 691, which is longer than the specified 0\n",
      "Created a chunk of size 314, which is longer than the specified 0\n",
      "Created a chunk of size 223, which is longer than the specified 0\n",
      "Created a chunk of size 284, which is longer than the specified 0\n",
      "Created a chunk of size 509, which is longer than the specified 0\n",
      "Created a chunk of size 246, which is longer than the specified 0\n",
      "Created a chunk of size 179, which is longer than the specified 0\n",
      "Created a chunk of size 940, which is longer than the specified 0\n",
      "Created a chunk of size 2450, which is longer than the specified 0\n",
      "Created a chunk of size 1796, which is longer than the specified 0\n",
      "Created a chunk of size 1568, which is longer than the specified 0\n",
      "Created a chunk of size 296, which is longer than the specified 0\n",
      "Created a chunk of size 219, which is longer than the specified 0\n",
      "Created a chunk of size 213, which is longer than the specified 0\n",
      "Created a chunk of size 244, which is longer than the specified 0\n",
      "Created a chunk of size 260, which is longer than the specified 0\n",
      "Created a chunk of size 326, which is longer than the specified 0\n",
      "Created a chunk of size 218, which is longer than the specified 0\n",
      "Created a chunk of size 1219, which is longer than the specified 0\n",
      "Created a chunk of size 238, which is longer than the specified 0\n",
      "Created a chunk of size 248, which is longer than the specified 0\n",
      "Created a chunk of size 337, which is longer than the specified 0\n",
      "Created a chunk of size 235, which is longer than the specified 0\n",
      "Created a chunk of size 240, which is longer than the specified 0\n",
      "Created a chunk of size 221, which is longer than the specified 0\n",
      "Created a chunk of size 260, which is longer than the specified 0\n",
      "Created a chunk of size 321, which is longer than the specified 0\n",
      "Created a chunk of size 757, which is longer than the specified 0\n",
      "Created a chunk of size 297, which is longer than the specified 0\n",
      "Created a chunk of size 222, which is longer than the specified 0\n",
      "Created a chunk of size 262, which is longer than the specified 0\n",
      "Created a chunk of size 247, which is longer than the specified 0\n",
      "Created a chunk of size 264, which is longer than the specified 0\n",
      "Created a chunk of size 880, which is longer than the specified 0\n",
      "Created a chunk of size 263, which is longer than the specified 0\n",
      "Created a chunk of size 1380, which is longer than the specified 0\n",
      "Created a chunk of size 401, which is longer than the specified 0\n",
      "Created a chunk of size 854, which is longer than the specified 0\n",
      "Created a chunk of size 1452, which is longer than the specified 0\n",
      "Created a chunk of size 288, which is longer than the specified 0\n",
      "Created a chunk of size 269, which is longer than the specified 0\n",
      "Created a chunk of size 251, which is longer than the specified 0\n",
      "Created a chunk of size 1102, which is longer than the specified 0\n",
      "Created a chunk of size 233, which is longer than the specified 0\n",
      "Created a chunk of size 212, which is longer than the specified 0\n",
      "Created a chunk of size 400, which is longer than the specified 0\n",
      "Created a chunk of size 337, which is longer than the specified 0\n",
      "Created a chunk of size 273, which is longer than the specified 0\n",
      "Created a chunk of size 256, which is longer than the specified 0\n",
      "Created a chunk of size 271, which is longer than the specified 0\n",
      "Created a chunk of size 280, which is longer than the specified 0\n",
      "Created a chunk of size 334, which is longer than the specified 0\n",
      "Created a chunk of size 237, which is longer than the specified 0\n",
      "Created a chunk of size 406, which is longer than the specified 0\n",
      "Created a chunk of size 1298, which is longer than the specified 0\n",
      "Created a chunk of size 334, which is longer than the specified 0\n",
      "Created a chunk of size 492, which is longer than the specified 0\n",
      "Created a chunk of size 204, which is longer than the specified 0\n",
      "Created a chunk of size 262, which is longer than the specified 0\n",
      "Created a chunk of size 776, which is longer than the specified 0\n",
      "Created a chunk of size 335, which is longer than the specified 0\n",
      "Created a chunk of size 907, which is longer than the specified 0\n",
      "Created a chunk of size 202, which is longer than the specified 0\n",
      "Created a chunk of size 355, which is longer than the specified 0\n",
      "Created a chunk of size 237, which is longer than the specified 0\n",
      "Created a chunk of size 993, which is longer than the specified 0\n",
      "Created a chunk of size 235, which is longer than the specified 0\n",
      "Created a chunk of size 220, which is longer than the specified 0\n",
      "Created a chunk of size 218, which is longer than the specified 0\n",
      "Created a chunk of size 773, which is longer than the specified 0\n",
      "Created a chunk of size 235, which is longer than the specified 0\n",
      "Created a chunk of size 169, which is longer than the specified 0\n",
      "Created a chunk of size 1761, which is longer than the specified 0\n",
      "Created a chunk of size 249, which is longer than the specified 0\n",
      "Created a chunk of size 291, which is longer than the specified 0\n",
      "Created a chunk of size 1004, which is longer than the specified 0\n",
      "Created a chunk of size 336, which is longer than the specified 0\n",
      "Created a chunk of size 283, which is longer than the specified 0\n",
      "Created a chunk of size 1022, which is longer than the specified 0\n",
      "Created a chunk of size 768, which is longer than the specified 0\n",
      "Created a chunk of size 184, which is longer than the specified 0\n",
      "Created a chunk of size 213, which is longer than the specified 0\n",
      "Created a chunk of size 267, which is longer than the specified 0\n",
      "Created a chunk of size 212, which is longer than the specified 0\n",
      "Created a chunk of size 272, which is longer than the specified 0\n",
      "Created a chunk of size 656, which is longer than the specified 0\n",
      "Created a chunk of size 196, which is longer than the specified 0\n",
      "Created a chunk of size 387, which is longer than the specified 0\n",
      "Created a chunk of size 465, which is longer than the specified 0\n",
      "Created a chunk of size 235, which is longer than the specified 0\n",
      "Created a chunk of size 358, which is longer than the specified 0\n",
      "Created a chunk of size 281, which is longer than the specified 0\n",
      "Created a chunk of size 224, which is longer than the specified 0\n",
      "Created a chunk of size 318, which is longer than the specified 0\n",
      "Created a chunk of size 267, which is longer than the specified 0\n",
      "Created a chunk of size 282, which is longer than the specified 0\n",
      "Created a chunk of size 242, which is longer than the specified 0\n",
      "Created a chunk of size 235, which is longer than the specified 0\n",
      "Created a chunk of size 353, which is longer than the specified 0\n",
      "Created a chunk of size 236, which is longer than the specified 0\n",
      "Created a chunk of size 258, which is longer than the specified 0\n",
      "Created a chunk of size 235, which is longer than the specified 0\n",
      "Created a chunk of size 584, which is longer than the specified 0\n",
      "Created a chunk of size 174, which is longer than the specified 0\n",
      "Created a chunk of size 640, which is longer than the specified 0\n",
      "Created a chunk of size 295, which is longer than the specified 0\n",
      "Created a chunk of size 194, which is longer than the specified 0\n",
      "Created a chunk of size 227, which is longer than the specified 0\n",
      "Created a chunk of size 216, which is longer than the specified 0\n",
      "Created a chunk of size 234, which is longer than the specified 0\n",
      "Created a chunk of size 731, which is longer than the specified 0\n",
      "Created a chunk of size 352, which is longer than the specified 0\n",
      "Created a chunk of size 382, which is longer than the specified 0\n",
      "Created a chunk of size 287, which is longer than the specified 0\n",
      "Created a chunk of size 634, which is longer than the specified 0\n",
      "Created a chunk of size 923, which is longer than the specified 0\n",
      "Created a chunk of size 238, which is longer than the specified 0\n",
      "Created a chunk of size 377, which is longer than the specified 0\n",
      "Created a chunk of size 246, which is longer than the specified 0\n",
      "Created a chunk of size 279, which is longer than the specified 0\n",
      "Created a chunk of size 297, which is longer than the specified 0\n",
      "Created a chunk of size 349, which is longer than the specified 0\n",
      "Created a chunk of size 238, which is longer than the specified 0\n",
      "Created a chunk of size 243, which is longer than the specified 0\n",
      "Created a chunk of size 365, which is longer than the specified 0\n",
      "Created a chunk of size 1064, which is longer than the specified 0\n",
      "Created a chunk of size 868, which is longer than the specified 0\n",
      "Created a chunk of size 308, which is longer than the specified 0\n",
      "Created a chunk of size 1009, which is longer than the specified 0\n",
      "Created a chunk of size 880, which is longer than the specified 0\n",
      "Created a chunk of size 765, which is longer than the specified 0\n",
      "Created a chunk of size 177, which is longer than the specified 0\n",
      "Created a chunk of size 988, which is longer than the specified 0\n",
      "Created a chunk of size 788, which is longer than the specified 0\n",
      "Created a chunk of size 723, which is longer than the specified 0\n",
      "Created a chunk of size 340, which is longer than the specified 0\n",
      "Created a chunk of size 1064, which is longer than the specified 0\n",
      "Created a chunk of size 338, which is longer than the specified 0\n",
      "Created a chunk of size 1629, which is longer than the specified 0\n",
      "Created a chunk of size 228, which is longer than the specified 0\n",
      "Created a chunk of size 1593, which is longer than the specified 0\n",
      "Created a chunk of size 623, which is longer than the specified 0\n",
      "Created a chunk of size 825, which is longer than the specified 0\n",
      "Created a chunk of size 314, which is longer than the specified 0\n",
      "Created a chunk of size 1587, which is longer than the specified 0\n",
      "Created a chunk of size 182, which is longer than the specified 0\n",
      "Created a chunk of size 229, which is longer than the specified 0\n",
      "Created a chunk of size 405, which is longer than the specified 0\n",
      "Created a chunk of size 255, which is longer than the specified 0\n",
      "Created a chunk of size 332, which is longer than the specified 0\n",
      "Created a chunk of size 571, which is longer than the specified 0\n",
      "Created a chunk of size 1259, which is longer than the specified 0\n",
      "Created a chunk of size 1128, which is longer than the specified 0\n",
      "Created a chunk of size 219, which is longer than the specified 0\n",
      "Created a chunk of size 1105, which is longer than the specified 0\n",
      "Created a chunk of size 235, which is longer than the specified 0\n",
      "Created a chunk of size 481, which is longer than the specified 0\n",
      "Created a chunk of size 345, which is longer than the specified 0\n",
      "Created a chunk of size 848, which is longer than the specified 0\n",
      "Created a chunk of size 792, which is longer than the specified 0\n",
      "Created a chunk of size 782, which is longer than the specified 0\n",
      "Created a chunk of size 657, which is longer than the specified 0\n",
      "Created a chunk of size 949, which is longer than the specified 0\n",
      "Created a chunk of size 476, which is longer than the specified 0\n",
      "Created a chunk of size 257, which is longer than the specified 0\n",
      "Created a chunk of size 847, which is longer than the specified 0\n",
      "Created a chunk of size 758, which is longer than the specified 0\n",
      "Created a chunk of size 971, which is longer than the specified 0\n",
      "Created a chunk of size 683, which is longer than the specified 0\n",
      "Created a chunk of size 1080, which is longer than the specified 0\n",
      "Created a chunk of size 1533, which is longer than the specified 0\n",
      "Created a chunk of size 188, which is longer than the specified 0\n",
      "Created a chunk of size 371, which is longer than the specified 0\n",
      "Created a chunk of size 790, which is longer than the specified 0\n",
      "Created a chunk of size 166, which is longer than the specified 0\n",
      "Created a chunk of size 823, which is longer than the specified 0\n",
      "Created a chunk of size 290, which is longer than the specified 0\n",
      "Created a chunk of size 292, which is longer than the specified 0\n",
      "Created a chunk of size 1202, which is longer than the specified 0\n",
      "Created a chunk of size 1093, which is longer than the specified 0\n",
      "Created a chunk of size 253, which is longer than the specified 0\n",
      "Created a chunk of size 1247, which is longer than the specified 0\n",
      "Created a chunk of size 1056, which is longer than the specified 0\n",
      "Created a chunk of size 668, which is longer than the specified 0\n",
      "Created a chunk of size 192, which is longer than the specified 0\n",
      "Created a chunk of size 306, which is longer than the specified 0\n",
      "Created a chunk of size 356, which is longer than the specified 0\n",
      "Created a chunk of size 267, which is longer than the specified 0\n",
      "Created a chunk of size 509, which is longer than the specified 0\n",
      "Created a chunk of size 369, which is longer than the specified 0\n",
      "Created a chunk of size 1211, which is longer than the specified 0\n",
      "Created a chunk of size 272, which is longer than the specified 0\n",
      "Created a chunk of size 334, which is longer than the specified 0\n",
      "Created a chunk of size 550, which is longer than the specified 0\n",
      "Created a chunk of size 930, which is longer than the specified 0\n",
      "Created a chunk of size 311, which is longer than the specified 0\n",
      "Created a chunk of size 250, which is longer than the specified 0\n",
      "Created a chunk of size 179, which is longer than the specified 0\n",
      "Created a chunk of size 1011, which is longer than the specified 0\n",
      "Created a chunk of size 243, which is longer than the specified 0\n",
      "Created a chunk of size 283, which is longer than the specified 0\n",
      "Created a chunk of size 230, which is longer than the specified 0\n",
      "Created a chunk of size 996, which is longer than the specified 0\n",
      "Created a chunk of size 377, which is longer than the specified 0\n",
      "Created a chunk of size 361, which is longer than the specified 0\n",
      "Created a chunk of size 281, which is longer than the specified 0\n",
      "Created a chunk of size 547, which is longer than the specified 0\n",
      "Created a chunk of size 1352, which is longer than the specified 0\n",
      "Created a chunk of size 1412, which is longer than the specified 0\n",
      "Created a chunk of size 183, which is longer than the specified 0\n",
      "Created a chunk of size 877, which is longer than the specified 0\n",
      "Created a chunk of size 1023, which is longer than the specified 0\n",
      "Created a chunk of size 1216, which is longer than the specified 0\n",
      "Created a chunk of size 260, which is longer than the specified 0\n",
      "Created a chunk of size 836, which is longer than the specified 0\n",
      "Created a chunk of size 1131, which is longer than the specified 0\n",
      "Created a chunk of size 492, which is longer than the specified 0\n",
      "Created a chunk of size 738, which is longer than the specified 0\n",
      "Created a chunk of size 682, which is longer than the specified 0\n",
      "Created a chunk of size 387, which is longer than the specified 0\n",
      "Created a chunk of size 183, which is longer than the specified 0\n",
      "Created a chunk of size 514, which is longer than the specified 0\n",
      "Created a chunk of size 307, which is longer than the specified 0\n",
      "Created a chunk of size 603, which is longer than the specified 0\n",
      "Created a chunk of size 242, which is longer than the specified 0\n",
      "Created a chunk of size 232, which is longer than the specified 0\n",
      "Created a chunk of size 772, which is longer than the specified 0\n",
      "Created a chunk of size 777, which is longer than the specified 0\n",
      "Created a chunk of size 255, which is longer than the specified 0\n",
      "Created a chunk of size 985, which is longer than the specified 0\n",
      "Created a chunk of size 376, which is longer than the specified 0\n",
      "Created a chunk of size 804, which is longer than the specified 0\n",
      "Created a chunk of size 284, which is longer than the specified 0\n",
      "Created a chunk of size 229, which is longer than the specified 0\n",
      "Created a chunk of size 182, which is longer than the specified 0\n",
      "Created a chunk of size 956, which is longer than the specified 0\n",
      "Created a chunk of size 217, which is longer than the specified 0\n",
      "Created a chunk of size 159, which is longer than the specified 0\n",
      "Created a chunk of size 203, which is longer than the specified 0\n",
      "Created a chunk of size 885, which is longer than the specified 0\n",
      "Created a chunk of size 157, which is longer than the specified 0\n",
      "Created a chunk of size 235, which is longer than the specified 0\n",
      "Created a chunk of size 319, which is longer than the specified 0\n",
      "Created a chunk of size 292, which is longer than the specified 0\n",
      "Created a chunk of size 263, which is longer than the specified 0\n",
      "Created a chunk of size 557, which is longer than the specified 0\n",
      "Created a chunk of size 264, which is longer than the specified 0\n",
      "Created a chunk of size 255, which is longer than the specified 0\n",
      "Created a chunk of size 311, which is longer than the specified 0\n",
      "Created a chunk of size 248, which is longer than the specified 0\n",
      "Created a chunk of size 288, which is longer than the specified 0\n",
      "Created a chunk of size 269, which is longer than the specified 0\n",
      "Created a chunk of size 175, which is longer than the specified 0\n",
      "Created a chunk of size 278, which is longer than the specified 0\n",
      "Created a chunk of size 304, which is longer than the specified 0\n",
      "Created a chunk of size 367, which is longer than the specified 0\n",
      "Created a chunk of size 235, which is longer than the specified 0\n",
      "Created a chunk of size 590, which is longer than the specified 0\n",
      "Created a chunk of size 277, which is longer than the specified 0\n",
      "Created a chunk of size 246, which is longer than the specified 0\n",
      "Created a chunk of size 166, which is longer than the specified 0\n",
      "Created a chunk of size 176, which is longer than the specified 0\n",
      "Created a chunk of size 1197, which is longer than the specified 0\n",
      "Created a chunk of size 229, which is longer than the specified 0\n",
      "Created a chunk of size 186, which is longer than the specified 0\n",
      "Created a chunk of size 270, which is longer than the specified 0\n",
      "Created a chunk of size 231, which is longer than the specified 0\n",
      "Created a chunk of size 257, which is longer than the specified 0\n",
      "Created a chunk of size 235, which is longer than the specified 0\n",
      "Created a chunk of size 385, which is longer than the specified 0\n",
      "Created a chunk of size 195, which is longer than the specified 0\n",
      "Created a chunk of size 169, which is longer than the specified 0\n",
      "Created a chunk of size 253, which is longer than the specified 0\n",
      "Created a chunk of size 210, which is longer than the specified 0\n",
      "Created a chunk of size 276, which is longer than the specified 0\n",
      "Created a chunk of size 252, which is longer than the specified 0\n",
      "Created a chunk of size 181, which is longer than the specified 0\n",
      "Created a chunk of size 390, which is longer than the specified 0\n",
      "Created a chunk of size 248, which is longer than the specified 0\n",
      "Created a chunk of size 198, which is longer than the specified 0\n",
      "Created a chunk of size 196, which is longer than the specified 0\n",
      "Created a chunk of size 396, which is longer than the specified 0\n",
      "Created a chunk of size 1891, which is longer than the specified 0\n",
      "Created a chunk of size 318, which is longer than the specified 0\n",
      "Created a chunk of size 717, which is longer than the specified 0\n",
      "Created a chunk of size 237, which is longer than the specified 0\n",
      "Created a chunk of size 273, which is longer than the specified 0\n",
      "Created a chunk of size 398, which is longer than the specified 0\n",
      "Created a chunk of size 255, which is longer than the specified 0\n",
      "Created a chunk of size 215, which is longer than the specified 0\n",
      "Created a chunk of size 220, which is longer than the specified 0\n",
      "Created a chunk of size 275, which is longer than the specified 0\n",
      "Created a chunk of size 3168, which is longer than the specified 0\n",
      "Created a chunk of size 267, which is longer than the specified 0\n",
      "Created a chunk of size 185, which is longer than the specified 0\n",
      "Created a chunk of size 240, which is longer than the specified 0\n",
      "Created a chunk of size 258, which is longer than the specified 0\n",
      "Created a chunk of size 263, which is longer than the specified 0\n",
      "Created a chunk of size 239, which is longer than the specified 0\n",
      "Created a chunk of size 1532, which is longer than the specified 0\n",
      "Created a chunk of size 228, which is longer than the specified 0\n",
      "Created a chunk of size 228, which is longer than the specified 0\n",
      "Created a chunk of size 381, which is longer than the specified 0\n",
      "Created a chunk of size 293, which is longer than the specified 0\n",
      "Created a chunk of size 178, which is longer than the specified 0\n",
      "Created a chunk of size 228, which is longer than the specified 0\n",
      "Created a chunk of size 236, which is longer than the specified 0\n",
      "Created a chunk of size 233, which is longer than the specified 0\n",
      "Created a chunk of size 213, which is longer than the specified 0\n",
      "Created a chunk of size 243, which is longer than the specified 0\n",
      "Created a chunk of size 223, which is longer than the specified 0\n",
      "Created a chunk of size 379, which is longer than the specified 0\n",
      "Created a chunk of size 330, which is longer than the specified 0\n",
      "Created a chunk of size 284, which is longer than the specified 0\n",
      "Created a chunk of size 344, which is longer than the specified 0\n",
      "Created a chunk of size 248, which is longer than the specified 0\n",
      "Created a chunk of size 313, which is longer than the specified 0\n",
      "Created a chunk of size 306, which is longer than the specified 0\n",
      "Created a chunk of size 290, which is longer than the specified 0\n",
      "Created a chunk of size 180, which is longer than the specified 0\n",
      "Created a chunk of size 236, which is longer than the specified 0\n",
      "Created a chunk of size 256, which is longer than the specified 0\n",
      "Created a chunk of size 230, which is longer than the specified 0\n",
      "Created a chunk of size 202, which is longer than the specified 0\n",
      "Created a chunk of size 242, which is longer than the specified 0\n",
      "Created a chunk of size 217, which is longer than the specified 0\n",
      "Created a chunk of size 222, which is longer than the specified 0\n",
      "Created a chunk of size 373, which is longer than the specified 0\n",
      "Created a chunk of size 431, which is longer than the specified 0\n",
      "Created a chunk of size 364, which is longer than the specified 0\n",
      "Created a chunk of size 337, which is longer than the specified 0\n",
      "Created a chunk of size 211, which is longer than the specified 0\n",
      "Created a chunk of size 251, which is longer than the specified 0\n",
      "Created a chunk of size 300, which is longer than the specified 0\n",
      "Created a chunk of size 240, which is longer than the specified 0\n",
      "Created a chunk of size 271, which is longer than the specified 0\n",
      "Created a chunk of size 407, which is longer than the specified 0\n",
      "Created a chunk of size 254, which is longer than the specified 0\n",
      "Created a chunk of size 246, which is longer than the specified 0\n",
      "Created a chunk of size 243, which is longer than the specified 0\n",
      "Created a chunk of size 278, which is longer than the specified 0\n",
      "Created a chunk of size 226, which is longer than the specified 0\n",
      "Created a chunk of size 263, which is longer than the specified 0\n",
      "Created a chunk of size 1588, which is longer than the specified 0\n",
      "Created a chunk of size 962, which is longer than the specified 0\n",
      "Created a chunk of size 225, which is longer than the specified 0\n",
      "Created a chunk of size 250, which is longer than the specified 0\n",
      "Created a chunk of size 324, which is longer than the specified 0\n",
      "Created a chunk of size 243, which is longer than the specified 0\n",
      "Created a chunk of size 445, which is longer than the specified 0\n",
      "Created a chunk of size 326, which is longer than the specified 0\n",
      "Created a chunk of size 416, which is longer than the specified 0\n",
      "Created a chunk of size 183, which is longer than the specified 0\n",
      "Created a chunk of size 451, which is longer than the specified 0\n",
      "Created a chunk of size 435, which is longer than the specified 0\n",
      "Created a chunk of size 229, which is longer than the specified 0\n",
      "Created a chunk of size 283, which is longer than the specified 0\n",
      "Created a chunk of size 226, which is longer than the specified 0\n",
      "Created a chunk of size 309, which is longer than the specified 0\n",
      "Created a chunk of size 226, which is longer than the specified 0\n",
      "Created a chunk of size 226, which is longer than the specified 0\n",
      "Created a chunk of size 347, which is longer than the specified 0\n",
      "Created a chunk of size 214, which is longer than the specified 0\n",
      "Created a chunk of size 220, which is longer than the specified 0\n",
      "Created a chunk of size 359, which is longer than the specified 0\n",
      "Created a chunk of size 331, which is longer than the specified 0\n",
      "Created a chunk of size 228, which is longer than the specified 0\n",
      "Created a chunk of size 1609, which is longer than the specified 0\n",
      "Created a chunk of size 210, which is longer than the specified 0\n",
      "Created a chunk of size 334, which is longer than the specified 0\n",
      "Created a chunk of size 236, which is longer than the specified 0\n",
      "Created a chunk of size 1623, which is longer than the specified 0\n",
      "Created a chunk of size 1419, which is longer than the specified 0\n",
      "Created a chunk of size 758, which is longer than the specified 0\n",
      "Created a chunk of size 714, which is longer than the specified 0\n",
      "Created a chunk of size 1114, which is longer than the specified 0\n",
      "Created a chunk of size 361, which is longer than the specified 0\n",
      "Created a chunk of size 308, which is longer than the specified 0\n",
      "Created a chunk of size 1128, which is longer than the specified 0\n",
      "Created a chunk of size 268, which is longer than the specified 0\n",
      "Created a chunk of size 679, which is longer than the specified 0\n",
      "Created a chunk of size 665, which is longer than the specified 0\n",
      "Created a chunk of size 1036, which is longer than the specified 0\n",
      "Created a chunk of size 1139, which is longer than the specified 0\n",
      "Created a chunk of size 1178, which is longer than the specified 0\n",
      "Created a chunk of size 1048, which is longer than the specified 0\n",
      "Created a chunk of size 246, which is longer than the specified 0\n",
      "Created a chunk of size 835, which is longer than the specified 0\n",
      "Created a chunk of size 1000, which is longer than the specified 0\n",
      "Created a chunk of size 589, which is longer than the specified 0\n",
      "Created a chunk of size 172, which is longer than the specified 0\n",
      "Created a chunk of size 473, which is longer than the specified 0\n",
      "Created a chunk of size 531, which is longer than the specified 0\n",
      "Created a chunk of size 579, which is longer than the specified 0\n",
      "Created a chunk of size 321, which is longer than the specified 0\n",
      "Created a chunk of size 209, which is longer than the specified 0\n",
      "Created a chunk of size 259, which is longer than the specified 0\n",
      "Created a chunk of size 284, which is longer than the specified 0\n",
      "Created a chunk of size 247, which is longer than the specified 0\n",
      "Created a chunk of size 255, which is longer than the specified 0\n",
      "Created a chunk of size 293, which is longer than the specified 0\n",
      "Created a chunk of size 234, which is longer than the specified 0\n",
      "Created a chunk of size 341, which is longer than the specified 0\n",
      "Created a chunk of size 257, which is longer than the specified 0\n",
      "Created a chunk of size 305, which is longer than the specified 0\n",
      "Created a chunk of size 255, which is longer than the specified 0\n",
      "Created a chunk of size 206, which is longer than the specified 0\n",
      "Created a chunk of size 287, which is longer than the specified 0\n",
      "Created a chunk of size 486, which is longer than the specified 0\n",
      "Created a chunk of size 458, which is longer than the specified 0\n",
      "Created a chunk of size 394, which is longer than the specified 0\n",
      "Created a chunk of size 219, which is longer than the specified 0\n",
      "Created a chunk of size 284, which is longer than the specified 0\n",
      "Created a chunk of size 670, which is longer than the specified 0\n",
      "Created a chunk of size 303, which is longer than the specified 0\n",
      "Created a chunk of size 293, which is longer than the specified 0\n",
      "Created a chunk of size 603, which is longer than the specified 0\n",
      "Created a chunk of size 272, which is longer than the specified 0\n",
      "Created a chunk of size 337, which is longer than the specified 0\n",
      "Created a chunk of size 259, which is longer than the specified 0\n",
      "Created a chunk of size 325, which is longer than the specified 0\n",
      "Created a chunk of size 207, which is longer than the specified 0\n",
      "Created a chunk of size 201, which is longer than the specified 0\n",
      "Created a chunk of size 252, which is longer than the specified 0\n",
      "Created a chunk of size 185, which is longer than the specified 0\n",
      "Created a chunk of size 211, which is longer than the specified 0\n",
      "Created a chunk of size 305, which is longer than the specified 0\n",
      "Created a chunk of size 256, which is longer than the specified 0\n",
      "Created a chunk of size 240, which is longer than the specified 0\n",
      "Created a chunk of size 276, which is longer than the specified 0\n",
      "Created a chunk of size 477, which is longer than the specified 0\n",
      "Created a chunk of size 269, which is longer than the specified 0\n",
      "Created a chunk of size 190, which is longer than the specified 0\n",
      "Created a chunk of size 269, which is longer than the specified 0\n",
      "Created a chunk of size 272, which is longer than the specified 0\n",
      "Created a chunk of size 970, which is longer than the specified 0\n",
      "Created a chunk of size 174, which is longer than the specified 0\n",
      "Created a chunk of size 497, which is longer than the specified 0\n",
      "Created a chunk of size 215, which is longer than the specified 0\n",
      "Created a chunk of size 1211, which is longer than the specified 0\n",
      "Created a chunk of size 333, which is longer than the specified 0\n",
      "Created a chunk of size 882, which is longer than the specified 0\n",
      "Created a chunk of size 245, which is longer than the specified 0\n",
      "Created a chunk of size 197, which is longer than the specified 0\n",
      "Created a chunk of size 846, which is longer than the specified 0\n",
      "Created a chunk of size 734, which is longer than the specified 0\n",
      "Created a chunk of size 231, which is longer than the specified 0\n",
      "Created a chunk of size 231, which is longer than the specified 0\n",
      "Created a chunk of size 171, which is longer than the specified 0\n",
      "Created a chunk of size 551, which is longer than the specified 0\n",
      "Created a chunk of size 614, which is longer than the specified 0\n",
      "Created a chunk of size 572, which is longer than the specified 0\n",
      "Created a chunk of size 285, which is longer than the specified 0\n",
      "Created a chunk of size 579, which is longer than the specified 0\n",
      "Created a chunk of size 346, which is longer than the specified 0\n",
      "Created a chunk of size 949, which is longer than the specified 0\n",
      "Created a chunk of size 395, which is longer than the specified 0\n",
      "Created a chunk of size 252, which is longer than the specified 0\n",
      "Created a chunk of size 402, which is longer than the specified 0\n",
      "Created a chunk of size 189, which is longer than the specified 0\n",
      "Created a chunk of size 293, which is longer than the specified 0\n",
      "Created a chunk of size 388, which is longer than the specified 0\n",
      "Created a chunk of size 387, which is longer than the specified 0\n",
      "Created a chunk of size 173, which is longer than the specified 0\n",
      "Created a chunk of size 246, which is longer than the specified 0\n",
      "Created a chunk of size 273, which is longer than the specified 0\n",
      "Created a chunk of size 401, which is longer than the specified 0\n",
      "Created a chunk of size 222, which is longer than the specified 0\n",
      "Created a chunk of size 265, which is longer than the specified 0\n",
      "Created a chunk of size 214, which is longer than the specified 0\n",
      "Created a chunk of size 251, which is longer than the specified 0\n",
      "Created a chunk of size 212, which is longer than the specified 0\n",
      "Created a chunk of size 160, which is longer than the specified 0\n",
      "Created a chunk of size 414, which is longer than the specified 0\n",
      "Created a chunk of size 256, which is longer than the specified 0\n",
      "Created a chunk of size 317, which is longer than the specified 0\n",
      "Created a chunk of size 313, which is longer than the specified 0\n",
      "Created a chunk of size 248, which is longer than the specified 0\n",
      "Created a chunk of size 202, which is longer than the specified 0\n",
      "Created a chunk of size 440, which is longer than the specified 0\n",
      "Created a chunk of size 275, which is longer than the specified 0\n",
      "Created a chunk of size 507, which is longer than the specified 0\n",
      "Created a chunk of size 258, which is longer than the specified 0\n",
      "Created a chunk of size 361, which is longer than the specified 0\n",
      "Created a chunk of size 245, which is longer than the specified 0\n",
      "Created a chunk of size 252, which is longer than the specified 0\n",
      "Created a chunk of size 304, which is longer than the specified 0\n",
      "Created a chunk of size 339, which is longer than the specified 0\n",
      "Created a chunk of size 401, which is longer than the specified 0\n",
      "Created a chunk of size 329, which is longer than the specified 0\n",
      "Created a chunk of size 248, which is longer than the specified 0\n",
      "Created a chunk of size 233, which is longer than the specified 0\n",
      "Created a chunk of size 316, which is longer than the specified 0\n",
      "Created a chunk of size 241, which is longer than the specified 0\n",
      "Created a chunk of size 342, which is longer than the specified 0\n",
      "Created a chunk of size 255, which is longer than the specified 0\n",
      "Created a chunk of size 273, which is longer than the specified 0\n",
      "Created a chunk of size 331, which is longer than the specified 0\n",
      "Created a chunk of size 304, which is longer than the specified 0\n",
      "Created a chunk of size 306, which is longer than the specified 0\n",
      "Created a chunk of size 207, which is longer than the specified 0\n",
      "Created a chunk of size 279, which is longer than the specified 0\n",
      "Created a chunk of size 226, which is longer than the specified 0\n",
      "Created a chunk of size 287, which is longer than the specified 0\n",
      "Created a chunk of size 226, which is longer than the specified 0\n",
      "Created a chunk of size 259, which is longer than the specified 0\n",
      "Created a chunk of size 184, which is longer than the specified 0\n",
      "Created a chunk of size 236, which is longer than the specified 0\n",
      "Created a chunk of size 318, which is longer than the specified 0\n",
      "Created a chunk of size 278, which is longer than the specified 0\n",
      "Created a chunk of size 336, which is longer than the specified 0\n",
      "Created a chunk of size 239, which is longer than the specified 0\n",
      "Created a chunk of size 239, which is longer than the specified 0\n",
      "Created a chunk of size 256, which is longer than the specified 0\n",
      "Created a chunk of size 457, which is longer than the specified 0\n",
      "Created a chunk of size 325, which is longer than the specified 0\n",
      "Created a chunk of size 222, which is longer than the specified 0\n",
      "Created a chunk of size 269, which is longer than the specified 0\n",
      "Created a chunk of size 274, which is longer than the specified 0\n",
      "Created a chunk of size 244, which is longer than the specified 0\n",
      "Created a chunk of size 238, which is longer than the specified 0\n",
      "Created a chunk of size 231, which is longer than the specified 0\n",
      "Created a chunk of size 253, which is longer than the specified 0\n",
      "Created a chunk of size 196, which is longer than the specified 0\n",
      "Created a chunk of size 237, which is longer than the specified 0\n",
      "Created a chunk of size 273, which is longer than the specified 0\n",
      "Created a chunk of size 1169, which is longer than the specified 0\n",
      "Created a chunk of size 245, which is longer than the specified 0\n",
      "Created a chunk of size 535, which is longer than the specified 0\n",
      "Created a chunk of size 238, which is longer than the specified 0\n",
      "Created a chunk of size 779, which is longer than the specified 0\n",
      "Created a chunk of size 353, which is longer than the specified 0\n",
      "Created a chunk of size 355, which is longer than the specified 0\n",
      "Created a chunk of size 511, which is longer than the specified 0\n",
      "Created a chunk of size 242, which is longer than the specified 0\n",
      "Created a chunk of size 227, which is longer than the specified 0\n",
      "Created a chunk of size 261, which is longer than the specified 0\n",
      "Created a chunk of size 214, which is longer than the specified 0\n",
      "Created a chunk of size 374, which is longer than the specified 0\n",
      "Created a chunk of size 842, which is longer than the specified 0\n",
      "Created a chunk of size 395, which is longer than the specified 0\n",
      "Created a chunk of size 203, which is longer than the specified 0\n",
      "Created a chunk of size 195, which is longer than the specified 0\n",
      "Created a chunk of size 250, which is longer than the specified 0\n",
      "Created a chunk of size 227, which is longer than the specified 0\n",
      "Created a chunk of size 155, which is longer than the specified 0\n",
      "Created a chunk of size 694, which is longer than the specified 0\n",
      "Created a chunk of size 218, which is longer than the specified 0\n",
      "Created a chunk of size 182, which is longer than the specified 0\n",
      "Created a chunk of size 161, which is longer than the specified 0\n",
      "Created a chunk of size 949, which is longer than the specified 0\n",
      "Created a chunk of size 318, which is longer than the specified 0\n",
      "Created a chunk of size 518, which is longer than the specified 0\n",
      "Created a chunk of size 653, which is longer than the specified 0\n",
      "Created a chunk of size 515, which is longer than the specified 0\n",
      "Created a chunk of size 675, which is longer than the specified 0\n",
      "Created a chunk of size 2034, which is longer than the specified 0\n",
      "Created a chunk of size 188, which is longer than the specified 0\n",
      "Created a chunk of size 721, which is longer than the specified 0\n",
      "Created a chunk of size 234, which is longer than the specified 0\n",
      "Created a chunk of size 992, which is longer than the specified 0\n",
      "Created a chunk of size 456, which is longer than the specified 0\n",
      "Created a chunk of size 266, which is longer than the specified 0\n",
      "Created a chunk of size 244, which is longer than the specified 0\n",
      "Created a chunk of size 266, which is longer than the specified 0\n",
      "Created a chunk of size 1115, which is longer than the specified 0\n",
      "Created a chunk of size 1436, which is longer than the specified 0\n",
      "Created a chunk of size 646, which is longer than the specified 0\n",
      "Created a chunk of size 223, which is longer than the specified 0\n",
      "Created a chunk of size 1113, which is longer than the specified 0\n",
      "Created a chunk of size 286, which is longer than the specified 0\n",
      "Created a chunk of size 257, which is longer than the specified 0\n",
      "Created a chunk of size 264, which is longer than the specified 0\n",
      "Created a chunk of size 260, which is longer than the specified 0\n",
      "Created a chunk of size 774, which is longer than the specified 0\n",
      "Created a chunk of size 925, which is longer than the specified 0\n",
      "Created a chunk of size 401, which is longer than the specified 0\n",
      "Created a chunk of size 691, which is longer than the specified 0\n",
      "Created a chunk of size 888, which is longer than the specified 0\n",
      "Created a chunk of size 848, which is longer than the specified 0\n",
      "Created a chunk of size 334, which is longer than the specified 0\n",
      "Created a chunk of size 874, which is longer than the specified 0\n",
      "Created a chunk of size 792, which is longer than the specified 0\n",
      "Created a chunk of size 845, which is longer than the specified 0\n",
      "Created a chunk of size 791, which is longer than the specified 0\n",
      "Created a chunk of size 655, which is longer than the specified 0\n",
      "Created a chunk of size 962, which is longer than the specified 0\n",
      "Created a chunk of size 251, which is longer than the specified 0\n",
      "Created a chunk of size 243, which is longer than the specified 0\n",
      "Created a chunk of size 226, which is longer than the specified 0\n",
      "Created a chunk of size 328, which is longer than the specified 0\n",
      "Created a chunk of size 203, which is longer than the specified 0\n",
      "Created a chunk of size 248, which is longer than the specified 0\n",
      "Created a chunk of size 224, which is longer than the specified 0\n",
      "Created a chunk of size 184, which is longer than the specified 0\n",
      "Created a chunk of size 182, which is longer than the specified 0\n",
      "Created a chunk of size 195, which is longer than the specified 0\n",
      "Created a chunk of size 401, which is longer than the specified 0\n",
      "Created a chunk of size 414, which is longer than the specified 0\n",
      "Created a chunk of size 230, which is longer than the specified 0\n",
      "Created a chunk of size 210, which is longer than the specified 0\n",
      "Created a chunk of size 206, which is longer than the specified 0\n",
      "Created a chunk of size 271, which is longer than the specified 0\n",
      "Created a chunk of size 203, which is longer than the specified 0\n",
      "Created a chunk of size 243, which is longer than the specified 0\n",
      "Created a chunk of size 248, which is longer than the specified 0\n",
      "Created a chunk of size 273, which is longer than the specified 0\n",
      "Created a chunk of size 243, which is longer than the specified 0\n",
      "Created a chunk of size 274, which is longer than the specified 0\n",
      "Created a chunk of size 293, which is longer than the specified 0\n",
      "Created a chunk of size 377, which is longer than the specified 0\n",
      "Created a chunk of size 338, which is longer than the specified 0\n",
      "Created a chunk of size 309, which is longer than the specified 0\n",
      "Created a chunk of size 269, which is longer than the specified 0\n",
      "Created a chunk of size 203, which is longer than the specified 0\n",
      "Created a chunk of size 404, which is longer than the specified 0\n",
      "Created a chunk of size 445, which is longer than the specified 0\n",
      "Created a chunk of size 202, which is longer than the specified 0\n",
      "Created a chunk of size 250, which is longer than the specified 0\n",
      "Created a chunk of size 180, which is longer than the specified 0\n",
      "Created a chunk of size 438, which is longer than the specified 0\n",
      "Created a chunk of size 333, which is longer than the specified 0\n",
      "Created a chunk of size 256, which is longer than the specified 0\n",
      "Created a chunk of size 285, which is longer than the specified 0\n",
      "Created a chunk of size 311, which is longer than the specified 0\n",
      "Created a chunk of size 433, which is longer than the specified 0\n",
      "Created a chunk of size 271, which is longer than the specified 0\n",
      "Created a chunk of size 278, which is longer than the specified 0\n",
      "Created a chunk of size 356, which is longer than the specified 0\n",
      "Created a chunk of size 303, which is longer than the specified 0\n",
      "Created a chunk of size 232, which is longer than the specified 0\n",
      "Created a chunk of size 241, which is longer than the specified 0\n",
      "Created a chunk of size 228, which is longer than the specified 0\n",
      "Created a chunk of size 270, which is longer than the specified 0\n",
      "Created a chunk of size 199, which is longer than the specified 0\n",
      "Created a chunk of size 212, which is longer than the specified 0\n",
      "Created a chunk of size 194, which is longer than the specified 0\n",
      "Created a chunk of size 166, which is longer than the specified 0\n",
      "Created a chunk of size 241, which is longer than the specified 0\n",
      "Created a chunk of size 232, which is longer than the specified 0\n",
      "Created a chunk of size 409, which is longer than the specified 0\n",
      "Created a chunk of size 228, which is longer than the specified 0\n",
      "Created a chunk of size 276, which is longer than the specified 0\n",
      "Created a chunk of size 175, which is longer than the specified 0\n",
      "Created a chunk of size 241, which is longer than the specified 0\n",
      "Created a chunk of size 197, which is longer than the specified 0\n",
      "Created a chunk of size 216, which is longer than the specified 0\n",
      "Created a chunk of size 166, which is longer than the specified 0\n",
      "Created a chunk of size 283, which is longer than the specified 0\n",
      "Created a chunk of size 188, which is longer than the specified 0\n",
      "Created a chunk of size 199, which is longer than the specified 0\n",
      "Created a chunk of size 238, which is longer than the specified 0\n",
      "Created a chunk of size 226, which is longer than the specified 0\n",
      "Created a chunk of size 191, which is longer than the specified 0\n",
      "Created a chunk of size 231, which is longer than the specified 0\n",
      "Created a chunk of size 321, which is longer than the specified 0\n",
      "Created a chunk of size 418, which is longer than the specified 0\n",
      "Created a chunk of size 264, which is longer than the specified 0\n",
      "Created a chunk of size 978, which is longer than the specified 0\n",
      "Created a chunk of size 1062, which is longer than the specified 0\n",
      "Created a chunk of size 559, which is longer than the specified 0\n",
      "Created a chunk of size 984, which is longer than the specified 0\n",
      "Created a chunk of size 234, which is longer than the specified 0\n",
      "Created a chunk of size 346, which is longer than the specified 0\n",
      "Created a chunk of size 264, which is longer than the specified 0\n",
      "Created a chunk of size 994, which is longer than the specified 0\n",
      "Created a chunk of size 417, which is longer than the specified 0\n",
      "Created a chunk of size 340, which is longer than the specified 0\n",
      "Created a chunk of size 215, which is longer than the specified 0\n",
      "Created a chunk of size 197, which is longer than the specified 0\n",
      "Created a chunk of size 289, which is longer than the specified 0\n",
      "Created a chunk of size 204, which is longer than the specified 0\n",
      "Created a chunk of size 254, which is longer than the specified 0\n",
      "Created a chunk of size 189, which is longer than the specified 0\n",
      "Created a chunk of size 234, which is longer than the specified 0\n",
      "Created a chunk of size 287, which is longer than the specified 0\n",
      "Created a chunk of size 236, which is longer than the specified 0\n",
      "Created a chunk of size 199, which is longer than the specified 0\n",
      "Created a chunk of size 216, which is longer than the specified 0\n",
      "Created a chunk of size 205, which is longer than the specified 0\n",
      "Created a chunk of size 460, which is longer than the specified 0\n",
      "Created a chunk of size 234, which is longer than the specified 0\n",
      "Created a chunk of size 246, which is longer than the specified 0\n",
      "Created a chunk of size 257, which is longer than the specified 0\n",
      "Created a chunk of size 237, which is longer than the specified 0\n",
      "Created a chunk of size 404, which is longer than the specified 0\n",
      "Created a chunk of size 694, which is longer than the specified 0\n",
      "Created a chunk of size 242, which is longer than the specified 0\n",
      "Created a chunk of size 253, which is longer than the specified 0\n",
      "Created a chunk of size 397, which is longer than the specified 0\n",
      "Created a chunk of size 269, which is longer than the specified 0\n",
      "Created a chunk of size 339, which is longer than the specified 0\n",
      "Created a chunk of size 235, which is longer than the specified 0\n",
      "Created a chunk of size 400, which is longer than the specified 0\n",
      "Created a chunk of size 307, which is longer than the specified 0\n",
      "Created a chunk of size 224, which is longer than the specified 0\n",
      "Created a chunk of size 180, which is longer than the specified 0\n",
      "Created a chunk of size 139, which is longer than the specified 0\n",
      "Created a chunk of size 249, which is longer than the specified 0\n",
      "Created a chunk of size 931, which is longer than the specified 0\n",
      "Created a chunk of size 225, which is longer than the specified 0\n",
      "Created a chunk of size 342, which is longer than the specified 0\n",
      "Created a chunk of size 241, which is longer than the specified 0\n",
      "Created a chunk of size 244, which is longer than the specified 0\n",
      "Created a chunk of size 205, which is longer than the specified 0\n",
      "Created a chunk of size 194, which is longer than the specified 0\n",
      "Created a chunk of size 253, which is longer than the specified 0\n",
      "Created a chunk of size 223, which is longer than the specified 0\n",
      "Created a chunk of size 326, which is longer than the specified 0\n",
      "Created a chunk of size 218, which is longer than the specified 0\n",
      "Created a chunk of size 255, which is longer than the specified 0\n",
      "Created a chunk of size 182, which is longer than the specified 0\n",
      "Created a chunk of size 239, which is longer than the specified 0\n",
      "Created a chunk of size 255, which is longer than the specified 0\n",
      "Created a chunk of size 327, which is longer than the specified 0\n",
      "Created a chunk of size 237, which is longer than the specified 0\n",
      "Created a chunk of size 226, which is longer than the specified 0\n",
      "Created a chunk of size 231, which is longer than the specified 0\n",
      "Created a chunk of size 206, which is longer than the specified 0\n",
      "Created a chunk of size 206, which is longer than the specified 0\n",
      "Created a chunk of size 265, which is longer than the specified 0\n",
      "Created a chunk of size 290, which is longer than the specified 0\n",
      "Created a chunk of size 292, which is longer than the specified 0\n",
      "Created a chunk of size 384, which is longer than the specified 0\n",
      "Created a chunk of size 316, which is longer than the specified 0\n",
      "Created a chunk of size 247, which is longer than the specified 0\n",
      "Created a chunk of size 347, which is longer than the specified 0\n",
      "Created a chunk of size 304, which is longer than the specified 0\n",
      "Created a chunk of size 280, which is longer than the specified 0\n",
      "Created a chunk of size 214, which is longer than the specified 0\n",
      "Created a chunk of size 243, which is longer than the specified 0\n",
      "Created a chunk of size 185, which is longer than the specified 0\n",
      "Created a chunk of size 686, which is longer than the specified 0\n",
      "Created a chunk of size 245, which is longer than the specified 0\n",
      "Created a chunk of size 219, which is longer than the specified 0\n",
      "Created a chunk of size 497, which is longer than the specified 0\n",
      "Created a chunk of size 169, which is longer than the specified 0\n",
      "Created a chunk of size 193, which is longer than the specified 0\n",
      "Created a chunk of size 243, which is longer than the specified 0\n",
      "Created a chunk of size 1471, which is longer than the specified 0\n",
      "Created a chunk of size 471, which is longer than the specified 0\n",
      "Created a chunk of size 1436, which is longer than the specified 0\n",
      "Created a chunk of size 409, which is longer than the specified 0\n",
      "Created a chunk of size 234, which is longer than the specified 0\n",
      "Created a chunk of size 291, which is longer than the specified 0\n",
      "Created a chunk of size 526, which is longer than the specified 0\n",
      "Created a chunk of size 271, which is longer than the specified 0\n",
      "Created a chunk of size 285, which is longer than the specified 0\n",
      "Created a chunk of size 214, which is longer than the specified 0\n",
      "Created a chunk of size 355, which is longer than the specified 0\n",
      "Created a chunk of size 233, which is longer than the specified 0\n",
      "Created a chunk of size 403, which is longer than the specified 0\n",
      "Created a chunk of size 188, which is longer than the specified 0\n",
      "Created a chunk of size 177, which is longer than the specified 0\n",
      "Created a chunk of size 170, which is longer than the specified 0\n",
      "Created a chunk of size 637, which is longer than the specified 0\n",
      "Created a chunk of size 302, which is longer than the specified 0\n",
      "Created a chunk of size 230, which is longer than the specified 0\n",
      "Created a chunk of size 190, which is longer than the specified 0\n",
      "Created a chunk of size 232, which is longer than the specified 0\n",
      "Created a chunk of size 331, which is longer than the specified 0\n",
      "Created a chunk of size 251, which is longer than the specified 0\n",
      "Created a chunk of size 278, which is longer than the specified 0\n",
      "Created a chunk of size 949, which is longer than the specified 0\n",
      "Created a chunk of size 269, which is longer than the specified 0\n",
      "Created a chunk of size 199, which is longer than the specified 0\n",
      "Created a chunk of size 449, which is longer than the specified 0\n",
      "Created a chunk of size 232, which is longer than the specified 0\n",
      "Created a chunk of size 384, which is longer than the specified 0\n",
      "Created a chunk of size 211, which is longer than the specified 0\n",
      "Created a chunk of size 233, which is longer than the specified 0\n",
      "Created a chunk of size 190, which is longer than the specified 0\n",
      "Created a chunk of size 252, which is longer than the specified 0\n",
      "Created a chunk of size 339, which is longer than the specified 0\n",
      "Created a chunk of size 265, which is longer than the specified 0\n",
      "Created a chunk of size 375, which is longer than the specified 0\n",
      "Created a chunk of size 343, which is longer than the specified 0\n",
      "Created a chunk of size 349, which is longer than the specified 0\n",
      "Created a chunk of size 291, which is longer than the specified 0\n",
      "Created a chunk of size 166, which is longer than the specified 0\n",
      "Created a chunk of size 728, which is longer than the specified 0\n",
      "Created a chunk of size 447, which is longer than the specified 0\n",
      "Created a chunk of size 251, which is longer than the specified 0\n",
      "Created a chunk of size 244, which is longer than the specified 0\n",
      "Created a chunk of size 297, which is longer than the specified 0\n",
      "Created a chunk of size 834, which is longer than the specified 0\n",
      "Created a chunk of size 344, which is longer than the specified 0\n",
      "Created a chunk of size 175, which is longer than the specified 0\n",
      "Created a chunk of size 288, which is longer than the specified 0\n",
      "Created a chunk of size 641, which is longer than the specified 0\n",
      "Created a chunk of size 503, which is longer than the specified 0\n",
      "Created a chunk of size 255, which is longer than the specified 0\n",
      "Created a chunk of size 458, which is longer than the specified 0\n",
      "Created a chunk of size 237, which is longer than the specified 0\n",
      "Created a chunk of size 1330, which is longer than the specified 0\n",
      "Created a chunk of size 168, which is longer than the specified 0\n",
      "Created a chunk of size 201, which is longer than the specified 0\n",
      "Created a chunk of size 270, which is longer than the specified 0\n",
      "Created a chunk of size 443, which is longer than the specified 0\n",
      "Created a chunk of size 160, which is longer than the specified 0\n",
      "Created a chunk of size 254, which is longer than the specified 0\n",
      "Created a chunk of size 1721, which is longer than the specified 0\n",
      "Created a chunk of size 246, which is longer than the specified 0\n",
      "Created a chunk of size 288, which is longer than the specified 0\n",
      "Created a chunk of size 164, which is longer than the specified 0\n",
      "Created a chunk of size 241, which is longer than the specified 0\n",
      "Created a chunk of size 218, which is longer than the specified 0\n",
      "Created a chunk of size 212, which is longer than the specified 0\n",
      "Created a chunk of size 196, which is longer than the specified 0\n",
      "Created a chunk of size 241, which is longer than the specified 0\n",
      "Created a chunk of size 250, which is longer than the specified 0\n",
      "Created a chunk of size 238, which is longer than the specified 0\n",
      "Created a chunk of size 284, which is longer than the specified 0\n",
      "Created a chunk of size 240, which is longer than the specified 0\n",
      "Created a chunk of size 245, which is longer than the specified 0\n",
      "Created a chunk of size 236, which is longer than the specified 0\n",
      "Created a chunk of size 239, which is longer than the specified 0\n",
      "Created a chunk of size 176, which is longer than the specified 0\n",
      "Created a chunk of size 248, which is longer than the specified 0\n",
      "Created a chunk of size 279, which is longer than the specified 0\n",
      "Created a chunk of size 218, which is longer than the specified 0\n",
      "Created a chunk of size 455, which is longer than the specified 0\n",
      "Created a chunk of size 233, which is longer than the specified 0\n",
      "Created a chunk of size 261, which is longer than the specified 0\n",
      "Created a chunk of size 275, which is longer than the specified 0\n",
      "Created a chunk of size 264, which is longer than the specified 0\n",
      "Created a chunk of size 242, which is longer than the specified 0\n",
      "Created a chunk of size 204, which is longer than the specified 0\n",
      "Created a chunk of size 203, which is longer than the specified 0\n",
      "Created a chunk of size 157, which is longer than the specified 0\n",
      "Created a chunk of size 246, which is longer than the specified 0\n",
      "Created a chunk of size 203, which is longer than the specified 0\n",
      "Created a chunk of size 247, which is longer than the specified 0\n",
      "Created a chunk of size 311, which is longer than the specified 0\n",
      "Created a chunk of size 238, which is longer than the specified 0\n",
      "Created a chunk of size 235, which is longer than the specified 0\n",
      "Created a chunk of size 372, which is longer than the specified 0\n",
      "Created a chunk of size 234, which is longer than the specified 0\n",
      "Created a chunk of size 212, which is longer than the specified 0\n",
      "Created a chunk of size 285, which is longer than the specified 0\n",
      "Created a chunk of size 192, which is longer than the specified 0\n",
      "Created a chunk of size 217, which is longer than the specified 0\n",
      "Created a chunk of size 321, which is longer than the specified 0\n",
      "Created a chunk of size 268, which is longer than the specified 0\n",
      "Created a chunk of size 199, which is longer than the specified 0\n",
      "Created a chunk of size 221, which is longer than the specified 0\n",
      "Created a chunk of size 316, which is longer than the specified 0\n",
      "Created a chunk of size 230, which is longer than the specified 0\n",
      "Created a chunk of size 258, which is longer than the specified 0\n",
      "Created a chunk of size 268, which is longer than the specified 0\n",
      "Created a chunk of size 307, which is longer than the specified 0\n",
      "Created a chunk of size 222, which is longer than the specified 0\n",
      "Created a chunk of size 257, which is longer than the specified 0\n",
      "Created a chunk of size 314, which is longer than the specified 0\n",
      "Created a chunk of size 209, which is longer than the specified 0\n",
      "Created a chunk of size 209, which is longer than the specified 0\n",
      "Created a chunk of size 279, which is longer than the specified 0\n",
      "Created a chunk of size 246, which is longer than the specified 0\n",
      "Created a chunk of size 197, which is longer than the specified 0\n",
      "Created a chunk of size 270, which is longer than the specified 0\n",
      "Created a chunk of size 246, which is longer than the specified 0\n",
      "Created a chunk of size 326, which is longer than the specified 0\n",
      "Created a chunk of size 215, which is longer than the specified 0\n",
      "Created a chunk of size 414, which is longer than the specified 0\n",
      "Created a chunk of size 283, which is longer than the specified 0\n",
      "Created a chunk of size 262, which is longer than the specified 0\n",
      "Created a chunk of size 215, which is longer than the specified 0\n",
      "Created a chunk of size 205, which is longer than the specified 0\n",
      "Created a chunk of size 317, which is longer than the specified 0\n",
      "Created a chunk of size 263, which is longer than the specified 0\n",
      "Created a chunk of size 212, which is longer than the specified 0\n",
      "Created a chunk of size 257, which is longer than the specified 0\n",
      "Created a chunk of size 239, which is longer than the specified 0\n",
      "Created a chunk of size 268, which is longer than the specified 0\n",
      "Created a chunk of size 356, which is longer than the specified 0\n",
      "Created a chunk of size 299, which is longer than the specified 0\n",
      "Created a chunk of size 312, which is longer than the specified 0\n",
      "Created a chunk of size 244, which is longer than the specified 0\n",
      "Created a chunk of size 259, which is longer than the specified 0\n",
      "Created a chunk of size 220, which is longer than the specified 0\n",
      "Created a chunk of size 252, which is longer than the specified 0\n",
      "Created a chunk of size 272, which is longer than the specified 0\n",
      "Created a chunk of size 251, which is longer than the specified 0\n",
      "Created a chunk of size 261, which is longer than the specified 0\n",
      "Created a chunk of size 240, which is longer than the specified 0\n",
      "Created a chunk of size 284, which is longer than the specified 0\n",
      "Created a chunk of size 263, which is longer than the specified 0\n",
      "Created a chunk of size 374, which is longer than the specified 0\n",
      "Created a chunk of size 199, which is longer than the specified 0\n",
      "Created a chunk of size 215, which is longer than the specified 0\n",
      "Created a chunk of size 952, which is longer than the specified 0\n",
      "Created a chunk of size 188, which is longer than the specified 0\n",
      "Created a chunk of size 1530, which is longer than the specified 0\n",
      "Created a chunk of size 656, which is longer than the specified 0\n",
      "Created a chunk of size 204, which is longer than the specified 0\n",
      "Created a chunk of size 214, which is longer than the specified 0\n",
      "Created a chunk of size 985, which is longer than the specified 0\n",
      "Created a chunk of size 177, which is longer than the specified 0\n",
      "Created a chunk of size 226, which is longer than the specified 0\n",
      "Created a chunk of size 305, which is longer than the specified 0\n",
      "Created a chunk of size 266, which is longer than the specified 0\n",
      "Created a chunk of size 179, which is longer than the specified 0\n",
      "Created a chunk of size 245, which is longer than the specified 0\n",
      "Created a chunk of size 1651, which is longer than the specified 0\n",
      "Created a chunk of size 278, which is longer than the specified 0\n",
      "Created a chunk of size 306, which is longer than the specified 0\n",
      "Created a chunk of size 190, which is longer than the specified 0\n",
      "Created a chunk of size 178, which is longer than the specified 0\n",
      "Created a chunk of size 232, which is longer than the specified 0\n",
      "Created a chunk of size 213, which is longer than the specified 0\n",
      "Created a chunk of size 205, which is longer than the specified 0\n",
      "Created a chunk of size 234, which is longer than the specified 0\n",
      "Created a chunk of size 151, which is longer than the specified 0\n",
      "Created a chunk of size 248, which is longer than the specified 0\n",
      "Created a chunk of size 196, which is longer than the specified 0\n",
      "Created a chunk of size 267, which is longer than the specified 0\n",
      "Created a chunk of size 313, which is longer than the specified 0\n",
      "Created a chunk of size 809, which is longer than the specified 0\n",
      "Created a chunk of size 695, which is longer than the specified 0\n",
      "Created a chunk of size 232, which is longer than the specified 0\n",
      "Created a chunk of size 1579, which is longer than the specified 0\n",
      "Created a chunk of size 325, which is longer than the specified 0\n",
      "Created a chunk of size 215, which is longer than the specified 0\n",
      "Created a chunk of size 199, which is longer than the specified 0\n",
      "Created a chunk of size 171, which is longer than the specified 0\n",
      "Created a chunk of size 198, which is longer than the specified 0\n",
      "Created a chunk of size 236, which is longer than the specified 0\n",
      "Created a chunk of size 234, which is longer than the specified 0\n",
      "Created a chunk of size 196, which is longer than the specified 0\n",
      "Created a chunk of size 1646, which is longer than the specified 0\n",
      "Created a chunk of size 185, which is longer than the specified 0\n",
      "Created a chunk of size 234, which is longer than the specified 0\n",
      "Created a chunk of size 170, which is longer than the specified 0\n",
      "Created a chunk of size 271, which is longer than the specified 0\n",
      "Created a chunk of size 179, which is longer than the specified 0\n",
      "Created a chunk of size 180, which is longer than the specified 0\n",
      "Created a chunk of size 182, which is longer than the specified 0\n",
      "Created a chunk of size 1687, which is longer than the specified 0\n",
      "Created a chunk of size 187, which is longer than the specified 0\n",
      "Created a chunk of size 161, which is longer than the specified 0\n",
      "Created a chunk of size 160, which is longer than the specified 0\n",
      "Created a chunk of size 199, which is longer than the specified 0\n",
      "Created a chunk of size 205, which is longer than the specified 0\n",
      "Created a chunk of size 600, which is longer than the specified 0\n",
      "Created a chunk of size 242, which is longer than the specified 0\n",
      "Created a chunk of size 152, which is longer than the specified 0\n",
      "Created a chunk of size 211, which is longer than the specified 0\n",
      "Created a chunk of size 275, which is longer than the specified 0\n",
      "Created a chunk of size 263, which is longer than the specified 0\n",
      "Created a chunk of size 191, which is longer than the specified 0\n",
      "Created a chunk of size 169, which is longer than the specified 0\n",
      "Created a chunk of size 180, which is longer than the specified 0\n",
      "Created a chunk of size 216, which is longer than the specified 0\n",
      "Created a chunk of size 178, which is longer than the specified 0\n",
      "Created a chunk of size 217, which is longer than the specified 0\n",
      "Created a chunk of size 410, which is longer than the specified 0\n",
      "Created a chunk of size 529, which is longer than the specified 0\n",
      "Created a chunk of size 673, which is longer than the specified 0\n",
      "Created a chunk of size 325, which is longer than the specified 0\n",
      "Created a chunk of size 358, which is longer than the specified 0\n",
      "Created a chunk of size 282, which is longer than the specified 0\n",
      "Created a chunk of size 185, which is longer than the specified 0\n",
      "Created a chunk of size 221, which is longer than the specified 0\n",
      "Created a chunk of size 206, which is longer than the specified 0\n",
      "Created a chunk of size 242, which is longer than the specified 0\n",
      "Created a chunk of size 242, which is longer than the specified 0\n",
      "Created a chunk of size 401, which is longer than the specified 0\n",
      "Created a chunk of size 169, which is longer than the specified 0\n",
      "Created a chunk of size 264, which is longer than the specified 0\n",
      "Created a chunk of size 249, which is longer than the specified 0\n",
      "Created a chunk of size 220, which is longer than the specified 0\n",
      "Created a chunk of size 231, which is longer than the specified 0\n",
      "Created a chunk of size 421, which is longer than the specified 0\n",
      "Created a chunk of size 246, which is longer than the specified 0\n",
      "Created a chunk of size 228, which is longer than the specified 0\n",
      "Created a chunk of size 225, which is longer than the specified 0\n",
      "Created a chunk of size 202, which is longer than the specified 0\n",
      "Created a chunk of size 195, which is longer than the specified 0\n",
      "Created a chunk of size 215, which is longer than the specified 0\n",
      "Created a chunk of size 255, which is longer than the specified 0\n",
      "Created a chunk of size 209, which is longer than the specified 0\n",
      "Created a chunk of size 248, which is longer than the specified 0\n",
      "Created a chunk of size 277, which is longer than the specified 0\n",
      "Created a chunk of size 253, which is longer than the specified 0\n",
      "Created a chunk of size 249, which is longer than the specified 0\n",
      "Created a chunk of size 165, which is longer than the specified 0\n",
      "Created a chunk of size 155, which is longer than the specified 0\n",
      "Created a chunk of size 214, which is longer than the specified 0\n",
      "Created a chunk of size 287, which is longer than the specified 0\n",
      "Created a chunk of size 249, which is longer than the specified 0\n",
      "Created a chunk of size 271, which is longer than the specified 0\n",
      "Created a chunk of size 248, which is longer than the specified 0\n",
      "Created a chunk of size 291, which is longer than the specified 0\n",
      "Created a chunk of size 237, which is longer than the specified 0\n",
      "Created a chunk of size 184, which is longer than the specified 0\n",
      "Created a chunk of size 152, which is longer than the specified 0\n",
      "Created a chunk of size 181, which is longer than the specified 0\n",
      "Created a chunk of size 194, which is longer than the specified 0\n",
      "Created a chunk of size 391, which is longer than the specified 0\n",
      "Created a chunk of size 241, which is longer than the specified 0\n",
      "Created a chunk of size 142, which is longer than the specified 0\n",
      "Created a chunk of size 173, which is longer than the specified 0\n",
      "Created a chunk of size 181, which is longer than the specified 0\n",
      "Created a chunk of size 189, which is longer than the specified 0\n",
      "Created a chunk of size 193, which is longer than the specified 0\n",
      "Created a chunk of size 286, which is longer than the specified 0\n",
      "Created a chunk of size 249, which is longer than the specified 0\n",
      "Created a chunk of size 211, which is longer than the specified 0\n",
      "Created a chunk of size 250, which is longer than the specified 0\n",
      "Created a chunk of size 229, which is longer than the specified 0\n",
      "Created a chunk of size 166, which is longer than the specified 0\n",
      "Created a chunk of size 272, which is longer than the specified 0\n",
      "Created a chunk of size 236, which is longer than the specified 0\n",
      "Created a chunk of size 782, which is longer than the specified 0\n",
      "Created a chunk of size 238, which is longer than the specified 0\n",
      "Created a chunk of size 221, which is longer than the specified 0\n",
      "Created a chunk of size 260, which is longer than the specified 0\n",
      "Created a chunk of size 165, which is longer than the specified 0\n",
      "Created a chunk of size 212, which is longer than the specified 0\n",
      "Created a chunk of size 207, which is longer than the specified 0\n",
      "Created a chunk of size 278, which is longer than the specified 0\n",
      "Created a chunk of size 205, which is longer than the specified 0\n",
      "Created a chunk of size 256, which is longer than the specified 0\n",
      "Created a chunk of size 270, which is longer than the specified 0\n",
      "Created a chunk of size 290, which is longer than the specified 0\n",
      "Created a chunk of size 176, which is longer than the specified 0\n",
      "Created a chunk of size 231, which is longer than the specified 0\n",
      "Created a chunk of size 250, which is longer than the specified 0\n",
      "Created a chunk of size 278, which is longer than the specified 0\n",
      "Created a chunk of size 400, which is longer than the specified 0\n",
      "Created a chunk of size 233, which is longer than the specified 0\n",
      "Created a chunk of size 363, which is longer than the specified 0\n",
      "Created a chunk of size 300, which is longer than the specified 0\n",
      "Created a chunk of size 253, which is longer than the specified 0\n",
      "Created a chunk of size 303, which is longer than the specified 0\n",
      "Created a chunk of size 330, which is longer than the specified 0\n",
      "Created a chunk of size 238, which is longer than the specified 0\n",
      "Created a chunk of size 192, which is longer than the specified 0\n",
      "Created a chunk of size 215, which is longer than the specified 0\n",
      "Created a chunk of size 227, which is longer than the specified 0\n",
      "Created a chunk of size 169, which is longer than the specified 0\n",
      "Created a chunk of size 219, which is longer than the specified 0\n",
      "Created a chunk of size 212, which is longer than the specified 0\n",
      "Created a chunk of size 233, which is longer than the specified 0\n",
      "Created a chunk of size 290, which is longer than the specified 0\n",
      "Created a chunk of size 165, which is longer than the specified 0\n",
      "Created a chunk of size 289, which is longer than the specified 0\n",
      "Created a chunk of size 289, which is longer than the specified 0\n",
      "Created a chunk of size 207, which is longer than the specified 0\n",
      "Created a chunk of size 215, which is longer than the specified 0\n",
      "Created a chunk of size 757, which is longer than the specified 0\n",
      "Created a chunk of size 235, which is longer than the specified 0\n",
      "Created a chunk of size 420, which is longer than the specified 0\n",
      "Created a chunk of size 573, which is longer than the specified 0\n",
      "Created a chunk of size 247, which is longer than the specified 0\n",
      "Created a chunk of size 179, which is longer than the specified 0\n",
      "Created a chunk of size 852, which is longer than the specified 0\n",
      "Created a chunk of size 184, which is longer than the specified 0\n",
      "Created a chunk of size 187, which is longer than the specified 0\n",
      "Created a chunk of size 251, which is longer than the specified 0\n",
      "Created a chunk of size 2031, which is longer than the specified 0\n",
      "Created a chunk of size 336, which is longer than the specified 0\n",
      "Created a chunk of size 243, which is longer than the specified 0\n",
      "Created a chunk of size 264, which is longer than the specified 0\n",
      "Created a chunk of size 263, which is longer than the specified 0\n",
      "Created a chunk of size 957, which is longer than the specified 0\n",
      "Created a chunk of size 214, which is longer than the specified 0\n",
      "Created a chunk of size 832, which is longer than the specified 0\n",
      "Created a chunk of size 832, which is longer than the specified 0\n",
      "Created a chunk of size 1107, which is longer than the specified 0\n",
      "Created a chunk of size 423, which is longer than the specified 0\n",
      "Created a chunk of size 180, which is longer than the specified 0\n",
      "Created a chunk of size 868, which is longer than the specified 0\n",
      "Created a chunk of size 1049, which is longer than the specified 0\n",
      "Created a chunk of size 248, which is longer than the specified 0\n",
      "Created a chunk of size 415, which is longer than the specified 0\n",
      "Created a chunk of size 479, which is longer than the specified 0\n",
      "Created a chunk of size 500, which is longer than the specified 0\n",
      "Created a chunk of size 492, which is longer than the specified 0\n",
      "Created a chunk of size 853, which is longer than the specified 0\n",
      "Created a chunk of size 880, which is longer than the specified 0\n",
      "Created a chunk of size 649, which is longer than the specified 0\n",
      "Created a chunk of size 563, which is longer than the specified 0\n",
      "Created a chunk of size 207, which is longer than the specified 0\n",
      "Created a chunk of size 241, which is longer than the specified 0\n",
      "Created a chunk of size 291, which is longer than the specified 0\n",
      "Created a chunk of size 706, which is longer than the specified 0\n",
      "Created a chunk of size 1118, which is longer than the specified 0\n",
      "Created a chunk of size 545, which is longer than the specified 0\n",
      "Created a chunk of size 297, which is longer than the specified 0\n",
      "Created a chunk of size 1089, which is longer than the specified 0\n",
      "Created a chunk of size 1103, which is longer than the specified 0\n",
      "Created a chunk of size 236, which is longer than the specified 0\n",
      "Created a chunk of size 1130, which is longer than the specified 0\n",
      "Created a chunk of size 753, which is longer than the specified 0\n",
      "Created a chunk of size 1338, which is longer than the specified 0\n",
      "Created a chunk of size 218, which is longer than the specified 0\n",
      "Created a chunk of size 195, which is longer than the specified 0\n",
      "Created a chunk of size 664, which is longer than the specified 0\n",
      "Created a chunk of size 861, which is longer than the specified 0\n",
      "Created a chunk of size 478, which is longer than the specified 0\n",
      "Created a chunk of size 478, which is longer than the specified 0\n",
      "Created a chunk of size 1080, which is longer than the specified 0\n",
      "Created a chunk of size 177, which is longer than the specified 0\n",
      "Created a chunk of size 286, which is longer than the specified 0\n",
      "Created a chunk of size 779, which is longer than the specified 0\n",
      "Created a chunk of size 629, which is longer than the specified 0\n",
      "Created a chunk of size 1163, which is longer than the specified 0\n",
      "Created a chunk of size 266, which is longer than the specified 0\n",
      "Created a chunk of size 731, which is longer than the specified 0\n",
      "Created a chunk of size 1003, which is longer than the specified 0\n",
      "Created a chunk of size 879, which is longer than the specified 0\n",
      "Created a chunk of size 369, which is longer than the specified 0\n",
      "Created a chunk of size 251, which is longer than the specified 0\n",
      "Created a chunk of size 269, which is longer than the specified 0\n",
      "Created a chunk of size 173, which is longer than the specified 0\n",
      "Created a chunk of size 206, which is longer than the specified 0\n",
      "Created a chunk of size 242, which is longer than the specified 0\n",
      "Created a chunk of size 147, which is longer than the specified 0\n",
      "Created a chunk of size 818, which is longer than the specified 0\n",
      "Created a chunk of size 238, which is longer than the specified 0\n",
      "Created a chunk of size 321, which is longer than the specified 0\n",
      "Created a chunk of size 230, which is longer than the specified 0\n",
      "Created a chunk of size 253, which is longer than the specified 0\n",
      "Created a chunk of size 208, which is longer than the specified 0\n",
      "Created a chunk of size 261, which is longer than the specified 0\n",
      "Created a chunk of size 240, which is longer than the specified 0\n",
      "Created a chunk of size 346, which is longer than the specified 0\n",
      "Created a chunk of size 242, which is longer than the specified 0\n",
      "Created a chunk of size 312, which is longer than the specified 0\n",
      "Created a chunk of size 374, which is longer than the specified 0\n",
      "Created a chunk of size 1085, which is longer than the specified 0\n",
      "Created a chunk of size 242, which is longer than the specified 0\n",
      "Created a chunk of size 187, which is longer than the specified 0\n",
      "Created a chunk of size 258, which is longer than the specified 0\n",
      "Created a chunk of size 633, which is longer than the specified 0\n",
      "Created a chunk of size 195, which is longer than the specified 0\n",
      "Created a chunk of size 199, which is longer than the specified 0\n",
      "Created a chunk of size 592, which is longer than the specified 0\n",
      "Created a chunk of size 274, which is longer than the specified 0\n",
      "Created a chunk of size 246, which is longer than the specified 0\n",
      "Created a chunk of size 709, which is longer than the specified 0\n",
      "Created a chunk of size 306, which is longer than the specified 0\n",
      "Created a chunk of size 281, which is longer than the specified 0\n",
      "Created a chunk of size 262, which is longer than the specified 0\n",
      "Created a chunk of size 199, which is longer than the specified 0\n",
      "Created a chunk of size 271, which is longer than the specified 0\n",
      "Created a chunk of size 184, which is longer than the specified 0\n",
      "Created a chunk of size 1003, which is longer than the specified 0\n",
      "Created a chunk of size 258, which is longer than the specified 0\n",
      "Created a chunk of size 180, which is longer than the specified 0\n",
      "Created a chunk of size 188, which is longer than the specified 0\n",
      "Created a chunk of size 211, which is longer than the specified 0\n",
      "Created a chunk of size 176, which is longer than the specified 0\n",
      "Created a chunk of size 234, which is longer than the specified 0\n",
      "Created a chunk of size 243, which is longer than the specified 0\n",
      "Created a chunk of size 182, which is longer than the specified 0\n",
      "Created a chunk of size 239, which is longer than the specified 0\n",
      "Created a chunk of size 281, which is longer than the specified 0\n",
      "Created a chunk of size 376, which is longer than the specified 0\n",
      "Created a chunk of size 176, which is longer than the specified 0\n",
      "Created a chunk of size 259, which is longer than the specified 0\n",
      "Created a chunk of size 282, which is longer than the specified 0\n",
      "Created a chunk of size 247, which is longer than the specified 0\n",
      "Created a chunk of size 240, which is longer than the specified 0\n",
      "Created a chunk of size 305, which is longer than the specified 0\n",
      "Created a chunk of size 194, which is longer than the specified 0\n",
      "Created a chunk of size 195, which is longer than the specified 0\n",
      "Created a chunk of size 452, which is longer than the specified 0\n",
      "Created a chunk of size 177, which is longer than the specified 0\n",
      "Created a chunk of size 275, which is longer than the specified 0\n",
      "Created a chunk of size 174, which is longer than the specified 0\n",
      "Created a chunk of size 203, which is longer than the specified 0\n",
      "Created a chunk of size 338, which is longer than the specified 0\n",
      "Created a chunk of size 303, which is longer than the specified 0\n",
      "Created a chunk of size 280, which is longer than the specified 0\n",
      "Created a chunk of size 244, which is longer than the specified 0\n",
      "Created a chunk of size 309, which is longer than the specified 0\n",
      "Created a chunk of size 181, which is longer than the specified 0\n",
      "Created a chunk of size 278, which is longer than the specified 0\n",
      "Created a chunk of size 264, which is longer than the specified 0\n",
      "Created a chunk of size 210, which is longer than the specified 0\n",
      "Created a chunk of size 203, which is longer than the specified 0\n",
      "Created a chunk of size 288, which is longer than the specified 0\n",
      "Created a chunk of size 221, which is longer than the specified 0\n",
      "Created a chunk of size 304, which is longer than the specified 0\n",
      "Created a chunk of size 329, which is longer than the specified 0\n",
      "Created a chunk of size 247, which is longer than the specified 0\n",
      "Created a chunk of size 263, which is longer than the specified 0\n",
      "Created a chunk of size 323, which is longer than the specified 0\n",
      "Created a chunk of size 296, which is longer than the specified 0\n",
      "Created a chunk of size 378, which is longer than the specified 0\n",
      "Created a chunk of size 288, which is longer than the specified 0\n",
      "Created a chunk of size 317, which is longer than the specified 0\n",
      "Created a chunk of size 223, which is longer than the specified 0\n",
      "Created a chunk of size 245, which is longer than the specified 0\n",
      "Created a chunk of size 217, which is longer than the specified 0\n",
      "Created a chunk of size 215, which is longer than the specified 0\n",
      "Created a chunk of size 272, which is longer than the specified 0\n",
      "Created a chunk of size 276, which is longer than the specified 0\n",
      "Created a chunk of size 268, which is longer than the specified 0\n",
      "Created a chunk of size 206, which is longer than the specified 0\n",
      "Created a chunk of size 238, which is longer than the specified 0\n",
      "Created a chunk of size 164, which is longer than the specified 0\n",
      "Created a chunk of size 224, which is longer than the specified 0\n",
      "Created a chunk of size 287, which is longer than the specified 0\n",
      "Created a chunk of size 196, which is longer than the specified 0\n",
      "Created a chunk of size 186, which is longer than the specified 0\n",
      "Created a chunk of size 275, which is longer than the specified 0\n",
      "Created a chunk of size 233, which is longer than the specified 0\n",
      "Created a chunk of size 219, which is longer than the specified 0\n",
      "Created a chunk of size 198, which is longer than the specified 0\n",
      "Created a chunk of size 222, which is longer than the specified 0\n",
      "Created a chunk of size 246, which is longer than the specified 0\n",
      "Created a chunk of size 210, which is longer than the specified 0\n",
      "Created a chunk of size 252, which is longer than the specified 0\n",
      "Created a chunk of size 236, which is longer than the specified 0\n",
      "Created a chunk of size 308, which is longer than the specified 0\n",
      "Created a chunk of size 332, which is longer than the specified 0\n",
      "Created a chunk of size 247, which is longer than the specified 0\n",
      "Created a chunk of size 210, which is longer than the specified 0\n",
      "Created a chunk of size 245, which is longer than the specified 0\n",
      "Created a chunk of size 202, which is longer than the specified 0\n",
      "Created a chunk of size 228, which is longer than the specified 0\n",
      "Created a chunk of size 195, which is longer than the specified 0\n",
      "Created a chunk of size 197, which is longer than the specified 0\n",
      "Created a chunk of size 184, which is longer than the specified 0\n",
      "Created a chunk of size 192, which is longer than the specified 0\n",
      "Created a chunk of size 248, which is longer than the specified 0\n",
      "Created a chunk of size 204, which is longer than the specified 0\n",
      "Created a chunk of size 446, which is longer than the specified 0\n",
      "Created a chunk of size 208, which is longer than the specified 0\n",
      "Created a chunk of size 304, which is longer than the specified 0\n",
      "Created a chunk of size 172, which is longer than the specified 0\n",
      "Created a chunk of size 219, which is longer than the specified 0\n",
      "Created a chunk of size 208, which is longer than the specified 0\n",
      "Created a chunk of size 212, which is longer than the specified 0\n",
      "Created a chunk of size 199, which is longer than the specified 0\n",
      "Created a chunk of size 205, which is longer than the specified 0\n",
      "Created a chunk of size 226, which is longer than the specified 0\n",
      "Created a chunk of size 232, which is longer than the specified 0\n",
      "Created a chunk of size 213, which is longer than the specified 0\n",
      "Created a chunk of size 325, which is longer than the specified 0\n",
      "Created a chunk of size 178, which is longer than the specified 0\n",
      "Created a chunk of size 290, which is longer than the specified 0\n",
      "Created a chunk of size 212, which is longer than the specified 0\n",
      "Created a chunk of size 235, which is longer than the specified 0\n",
      "Created a chunk of size 379, which is longer than the specified 0\n",
      "Created a chunk of size 251, which is longer than the specified 0\n",
      "Created a chunk of size 926, which is longer than the specified 0\n",
      "Created a chunk of size 239, which is longer than the specified 0\n",
      "Created a chunk of size 1226, which is longer than the specified 0\n",
      "Created a chunk of size 932, which is longer than the specified 0\n",
      "Created a chunk of size 898, which is longer than the specified 0\n",
      "Created a chunk of size 204, which is longer than the specified 0\n",
      "Created a chunk of size 412, which is longer than the specified 0\n",
      "Created a chunk of size 1235, which is longer than the specified 0\n",
      "Created a chunk of size 2940, which is longer than the specified 0\n",
      "Created a chunk of size 537, which is longer than the specified 0\n",
      "Created a chunk of size 370, which is longer than the specified 0\n",
      "Created a chunk of size 310, which is longer than the specified 0\n",
      "Created a chunk of size 638, which is longer than the specified 0\n",
      "Created a chunk of size 265, which is longer than the specified 0\n",
      "Created a chunk of size 1118, which is longer than the specified 0\n",
      "Created a chunk of size 168, which is longer than the specified 0\n",
      "Created a chunk of size 653, which is longer than the specified 0\n",
      "Created a chunk of size 1490, which is longer than the specified 0\n",
      "Created a chunk of size 1157, which is longer than the specified 0\n",
      "Created a chunk of size 1208, which is longer than the specified 0\n",
      "Created a chunk of size 1489, which is longer than the specified 0\n",
      "Created a chunk of size 409, which is longer than the specified 0\n",
      "Created a chunk of size 249, which is longer than the specified 0\n",
      "Created a chunk of size 1086, which is longer than the specified 0\n",
      "Created a chunk of size 1802, which is longer than the specified 0\n",
      "Created a chunk of size 1595, which is longer than the specified 0\n",
      "Created a chunk of size 1030, which is longer than the specified 0\n",
      "Created a chunk of size 1361, which is longer than the specified 0\n",
      "Created a chunk of size 1643, which is longer than the specified 0\n",
      "Created a chunk of size 457, which is longer than the specified 0\n",
      "Created a chunk of size 1382, which is longer than the specified 0\n",
      "Created a chunk of size 814, which is longer than the specified 0\n",
      "Created a chunk of size 1763, which is longer than the specified 0\n",
      "Created a chunk of size 911, which is longer than the specified 0\n",
      "Created a chunk of size 1971, which is longer than the specified 0\n",
      "Created a chunk of size 365, which is longer than the specified 0\n",
      "Created a chunk of size 1240, which is longer than the specified 0\n",
      "Created a chunk of size 801, which is longer than the specified 0\n",
      "Created a chunk of size 192, which is longer than the specified 0\n",
      "Created a chunk of size 153, which is longer than the specified 0\n",
      "Created a chunk of size 478, which is longer than the specified 0\n",
      "Created a chunk of size 1119, which is longer than the specified 0\n",
      "Created a chunk of size 1051, which is longer than the specified 0\n",
      "Created a chunk of size 376, which is longer than the specified 0\n",
      "Created a chunk of size 206, which is longer than the specified 0\n",
      "Created a chunk of size 378, which is longer than the specified 0\n",
      "Created a chunk of size 365, which is longer than the specified 0\n",
      "Created a chunk of size 406, which is longer than the specified 0\n",
      "Created a chunk of size 1006, which is longer than the specified 0\n",
      "Created a chunk of size 156, which is longer than the specified 0\n",
      "Created a chunk of size 173, which is longer than the specified 0\n",
      "Created a chunk of size 252, which is longer than the specified 0\n",
      "Created a chunk of size 201, which is longer than the specified 0\n",
      "Created a chunk of size 331, which is longer than the specified 0\n",
      "Created a chunk of size 306, which is longer than the specified 0\n",
      "Created a chunk of size 346, which is longer than the specified 0\n",
      "Created a chunk of size 228, which is longer than the specified 0\n",
      "Created a chunk of size 231, which is longer than the specified 0\n",
      "Created a chunk of size 457, which is longer than the specified 0\n",
      "Created a chunk of size 169, which is longer than the specified 0\n",
      "Created a chunk of size 1119, which is longer than the specified 0\n",
      "Created a chunk of size 191, which is longer than the specified 0\n",
      "Created a chunk of size 186, which is longer than the specified 0\n",
      "Created a chunk of size 394, which is longer than the specified 0\n",
      "Created a chunk of size 218, which is longer than the specified 0\n",
      "Created a chunk of size 515, which is longer than the specified 0\n",
      "Created a chunk of size 333, which is longer than the specified 0\n",
      "Created a chunk of size 182, which is longer than the specified 0\n",
      "Created a chunk of size 223, which is longer than the specified 0\n",
      "Created a chunk of size 235, which is longer than the specified 0\n",
      "Created a chunk of size 190, which is longer than the specified 0\n",
      "Created a chunk of size 672, which is longer than the specified 0\n",
      "Created a chunk of size 382, which is longer than the specified 0\n",
      "Created a chunk of size 308, which is longer than the specified 0\n",
      "Created a chunk of size 167, which is longer than the specified 0\n",
      "Created a chunk of size 356, which is longer than the specified 0\n",
      "Created a chunk of size 1127, which is longer than the specified 0\n",
      "Created a chunk of size 371, which is longer than the specified 0\n",
      "Created a chunk of size 241, which is longer than the specified 0\n",
      "Created a chunk of size 204, which is longer than the specified 0\n",
      "Created a chunk of size 1037, which is longer than the specified 0\n",
      "Created a chunk of size 1280, which is longer than the specified 0\n",
      "Created a chunk of size 200, which is longer than the specified 0\n",
      "Created a chunk of size 1475, which is longer than the specified 0\n",
      "Created a chunk of size 218, which is longer than the specified 0\n",
      "Created a chunk of size 266, which is longer than the specified 0\n",
      "Created a chunk of size 297, which is longer than the specified 0\n",
      "Created a chunk of size 168, which is longer than the specified 0\n",
      "Created a chunk of size 158, which is longer than the specified 0\n",
      "Created a chunk of size 272, which is longer than the specified 0\n",
      "Created a chunk of size 223, which is longer than the specified 0\n",
      "Created a chunk of size 204, which is longer than the specified 0\n",
      "Created a chunk of size 248, which is longer than the specified 0\n",
      "Created a chunk of size 164, which is longer than the specified 0\n",
      "Created a chunk of size 164, which is longer than the specified 0\n",
      "Created a chunk of size 238, which is longer than the specified 0\n",
      "Created a chunk of size 269, which is longer than the specified 0\n",
      "Created a chunk of size 232, which is longer than the specified 0\n",
      "Created a chunk of size 211, which is longer than the specified 0\n",
      "Created a chunk of size 324, which is longer than the specified 0\n",
      "Created a chunk of size 241, which is longer than the specified 0\n",
      "Created a chunk of size 680, which is longer than the specified 0\n",
      "Created a chunk of size 245, which is longer than the specified 0\n",
      "Created a chunk of size 241, which is longer than the specified 0\n",
      "Created a chunk of size 258, which is longer than the specified 0\n",
      "Created a chunk of size 1268, which is longer than the specified 0\n",
      "Created a chunk of size 224, which is longer than the specified 0\n",
      "Created a chunk of size 202, which is longer than the specified 0\n",
      "Created a chunk of size 177, which is longer than the specified 0\n",
      "Created a chunk of size 214, which is longer than the specified 0\n",
      "Created a chunk of size 245, which is longer than the specified 0\n",
      "Created a chunk of size 213, which is longer than the specified 0\n",
      "Created a chunk of size 297, which is longer than the specified 0\n",
      "Created a chunk of size 207, which is longer than the specified 0\n",
      "Created a chunk of size 400, which is longer than the specified 0\n",
      "Created a chunk of size 1219, which is longer than the specified 0\n",
      "Created a chunk of size 215, which is longer than the specified 0\n",
      "Created a chunk of size 166, which is longer than the specified 0\n",
      "Created a chunk of size 186, which is longer than the specified 0\n",
      "Created a chunk of size 404, which is longer than the specified 0\n",
      "Created a chunk of size 364, which is longer than the specified 0\n",
      "Created a chunk of size 209, which is longer than the specified 0\n",
      "Created a chunk of size 258, which is longer than the specified 0\n",
      "Created a chunk of size 900, which is longer than the specified 0\n",
      "Created a chunk of size 1003, which is longer than the specified 0\n",
      "Created a chunk of size 376, which is longer than the specified 0\n",
      "Created a chunk of size 618, which is longer than the specified 0\n",
      "Created a chunk of size 826, which is longer than the specified 0\n",
      "Created a chunk of size 201, which is longer than the specified 0\n",
      "Created a chunk of size 507, which is longer than the specified 0\n",
      "Created a chunk of size 1045, which is longer than the specified 0\n",
      "Created a chunk of size 217, which is longer than the specified 0\n",
      "Created a chunk of size 267, which is longer than the specified 0\n",
      "Created a chunk of size 168, which is longer than the specified 0\n",
      "Created a chunk of size 790, which is longer than the specified 0\n",
      "Created a chunk of size 207, which is longer than the specified 0\n",
      "Created a chunk of size 857, which is longer than the specified 0\n",
      "Created a chunk of size 245, which is longer than the specified 0\n",
      "Created a chunk of size 366, which is longer than the specified 0\n",
      "Created a chunk of size 526, which is longer than the specified 0\n",
      "Created a chunk of size 1052, which is longer than the specified 0\n",
      "Created a chunk of size 906, which is longer than the specified 0\n",
      "Created a chunk of size 177, which is longer than the specified 0\n",
      "Created a chunk of size 767, which is longer than the specified 0\n",
      "Created a chunk of size 751, which is longer than the specified 0\n",
      "Created a chunk of size 1017, which is longer than the specified 0\n",
      "Created a chunk of size 167, which is longer than the specified 0\n",
      "Created a chunk of size 806, which is longer than the specified 0\n",
      "Created a chunk of size 176, which is longer than the specified 0\n",
      "Created a chunk of size 294, which is longer than the specified 0\n",
      "Created a chunk of size 567, which is longer than the specified 0\n",
      "Created a chunk of size 828, which is longer than the specified 0\n",
      "Created a chunk of size 557, which is longer than the specified 0\n",
      "Created a chunk of size 388, which is longer than the specified 0\n",
      "Created a chunk of size 626, which is longer than the specified 0\n",
      "Created a chunk of size 471, which is longer than the specified 0\n",
      "Created a chunk of size 394, which is longer than the specified 0\n",
      "Created a chunk of size 706, which is longer than the specified 0\n",
      "Created a chunk of size 465, which is longer than the specified 0\n",
      "Created a chunk of size 215, which is longer than the specified 0\n",
      "Created a chunk of size 273, which is longer than the specified 0\n",
      "Created a chunk of size 214, which is longer than the specified 0\n",
      "Created a chunk of size 246, which is longer than the specified 0\n",
      "Created a chunk of size 205, which is longer than the specified 0\n",
      "Created a chunk of size 373, which is longer than the specified 0\n",
      "Created a chunk of size 662, which is longer than the specified 0\n",
      "Created a chunk of size 908, which is longer than the specified 0\n",
      "Created a chunk of size 760, which is longer than the specified 0\n",
      "Created a chunk of size 470, which is longer than the specified 0\n",
      "Created a chunk of size 856, which is longer than the specified 0\n",
      "Created a chunk of size 187, which is longer than the specified 0\n",
      "Created a chunk of size 267, which is longer than the specified 0\n",
      "Created a chunk of size 970, which is longer than the specified 0\n",
      "Created a chunk of size 1177, which is longer than the specified 0\n",
      "Created a chunk of size 537, which is longer than the specified 0\n",
      "Created a chunk of size 464, which is longer than the specified 0\n",
      "Created a chunk of size 559, which is longer than the specified 0\n",
      "Created a chunk of size 347, which is longer than the specified 0\n",
      "Created a chunk of size 1246, which is longer than the specified 0\n",
      "Created a chunk of size 905, which is longer than the specified 0\n",
      "Created a chunk of size 598, which is longer than the specified 0\n",
      "Created a chunk of size 615, which is longer than the specified 0\n",
      "Created a chunk of size 591, which is longer than the specified 0\n",
      "Created a chunk of size 1049, which is longer than the specified 0\n",
      "Created a chunk of size 418, which is longer than the specified 0\n",
      "Created a chunk of size 1125, which is longer than the specified 0\n",
      "Created a chunk of size 261, which is longer than the specified 0\n",
      "Created a chunk of size 651, which is longer than the specified 0\n",
      "Created a chunk of size 1127, which is longer than the specified 0\n",
      "Created a chunk of size 553, which is longer than the specified 0\n",
      "Created a chunk of size 768, which is longer than the specified 0\n",
      "Created a chunk of size 783, which is longer than the specified 0\n",
      "Created a chunk of size 266, which is longer than the specified 0\n",
      "Created a chunk of size 1025, which is longer than the specified 0\n",
      "Created a chunk of size 312, which is longer than the specified 0\n",
      "Created a chunk of size 281, which is longer than the specified 0\n",
      "Created a chunk of size 387, which is longer than the specified 0\n",
      "Created a chunk of size 632, which is longer than the specified 0\n",
      "Created a chunk of size 882, which is longer than the specified 0\n",
      "Created a chunk of size 474, which is longer than the specified 0\n",
      "Created a chunk of size 215, which is longer than the specified 0\n",
      "Created a chunk of size 190, which is longer than the specified 0\n",
      "Created a chunk of size 317, which is longer than the specified 0\n",
      "Created a chunk of size 194, which is longer than the specified 0\n",
      "Created a chunk of size 323, which is longer than the specified 0\n",
      "Created a chunk of size 234, which is longer than the specified 0\n",
      "Created a chunk of size 365, which is longer than the specified 0\n",
      "Created a chunk of size 155, which is longer than the specified 0\n",
      "Created a chunk of size 262, which is longer than the specified 0\n",
      "Created a chunk of size 196, which is longer than the specified 0\n",
      "Created a chunk of size 145, which is longer than the specified 0\n",
      "Created a chunk of size 242, which is longer than the specified 0\n",
      "Created a chunk of size 499, which is longer than the specified 0\n",
      "Created a chunk of size 258, which is longer than the specified 0\n",
      "Created a chunk of size 246, which is longer than the specified 0\n",
      "Created a chunk of size 170, which is longer than the specified 0\n",
      "Created a chunk of size 206, which is longer than the specified 0\n",
      "Created a chunk of size 207, which is longer than the specified 0\n",
      "Created a chunk of size 236, which is longer than the specified 0\n",
      "Created a chunk of size 212, which is longer than the specified 0\n",
      "Created a chunk of size 307, which is longer than the specified 0\n",
      "Created a chunk of size 231, which is longer than the specified 0\n",
      "Created a chunk of size 192, which is longer than the specified 0\n",
      "Created a chunk of size 258, which is longer than the specified 0\n",
      "Created a chunk of size 172, which is longer than the specified 0\n",
      "Created a chunk of size 733, which is longer than the specified 0\n",
      "Created a chunk of size 230, which is longer than the specified 0\n",
      "Created a chunk of size 171, which is longer than the specified 0\n",
      "Created a chunk of size 188, which is longer than the specified 0\n",
      "Created a chunk of size 162, which is longer than the specified 0\n",
      "Created a chunk of size 164, which is longer than the specified 0\n",
      "Created a chunk of size 237, which is longer than the specified 0\n",
      "Created a chunk of size 241, which is longer than the specified 0\n",
      "Created a chunk of size 215, which is longer than the specified 0\n",
      "Created a chunk of size 185, which is longer than the specified 0\n",
      "Created a chunk of size 1290, which is longer than the specified 0\n",
      "Created a chunk of size 1091, which is longer than the specified 0\n",
      "Created a chunk of size 237, which is longer than the specified 0\n",
      "Created a chunk of size 269, which is longer than the specified 0\n",
      "Created a chunk of size 539, which is longer than the specified 0\n",
      "Created a chunk of size 213, which is longer than the specified 0\n",
      "Created a chunk of size 172, which is longer than the specified 0\n",
      "Created a chunk of size 260, which is longer than the specified 0\n",
      "Created a chunk of size 242, which is longer than the specified 0\n",
      "Created a chunk of size 245, which is longer than the specified 0\n",
      "Created a chunk of size 213, which is longer than the specified 0\n",
      "Created a chunk of size 608, which is longer than the specified 0\n",
      "Created a chunk of size 172, which is longer than the specified 0\n",
      "Created a chunk of size 194, which is longer than the specified 0\n",
      "Created a chunk of size 203, which is longer than the specified 0\n",
      "Created a chunk of size 255, which is longer than the specified 0\n",
      "Created a chunk of size 264, which is longer than the specified 0\n",
      "Created a chunk of size 300, which is longer than the specified 0\n",
      "Created a chunk of size 224, which is longer than the specified 0\n",
      "Created a chunk of size 203, which is longer than the specified 0\n",
      "Created a chunk of size 189, which is longer than the specified 0\n",
      "Created a chunk of size 328, which is longer than the specified 0\n",
      "Created a chunk of size 213, which is longer than the specified 0\n",
      "Created a chunk of size 226, which is longer than the specified 0\n",
      "Created a chunk of size 264, which is longer than the specified 0\n",
      "Created a chunk of size 268, which is longer than the specified 0\n",
      "Created a chunk of size 264, which is longer than the specified 0\n",
      "Created a chunk of size 192, which is longer than the specified 0\n",
      "Created a chunk of size 226, which is longer than the specified 0\n",
      "Created a chunk of size 307, which is longer than the specified 0\n",
      "Created a chunk of size 383, which is longer than the specified 0\n",
      "Created a chunk of size 327, which is longer than the specified 0\n",
      "Created a chunk of size 202, which is longer than the specified 0\n",
      "Created a chunk of size 249, which is longer than the specified 0\n",
      "Created a chunk of size 703, which is longer than the specified 0\n",
      "Created a chunk of size 301, which is longer than the specified 0\n",
      "Created a chunk of size 155, which is longer than the specified 0\n",
      "Created a chunk of size 218, which is longer than the specified 0\n",
      "Created a chunk of size 207, which is longer than the specified 0\n",
      "Created a chunk of size 520, which is longer than the specified 0\n",
      "Created a chunk of size 244, which is longer than the specified 0\n",
      "Created a chunk of size 245, which is longer than the specified 0\n",
      "Created a chunk of size 229, which is longer than the specified 0\n",
      "Created a chunk of size 175, which is longer than the specified 0\n",
      "Created a chunk of size 191, which is longer than the specified 0\n",
      "Created a chunk of size 183, which is longer than the specified 0\n",
      "Created a chunk of size 172, which is longer than the specified 0\n",
      "Created a chunk of size 194, which is longer than the specified 0\n",
      "Created a chunk of size 267, which is longer than the specified 0\n",
      "Created a chunk of size 248, which is longer than the specified 0\n",
      "Created a chunk of size 213, which is longer than the specified 0\n",
      "Created a chunk of size 212, which is longer than the specified 0\n",
      "Created a chunk of size 211, which is longer than the specified 0\n",
      "Created a chunk of size 287, which is longer than the specified 0\n",
      "Created a chunk of size 243, which is longer than the specified 0\n",
      "Created a chunk of size 236, which is longer than the specified 0\n",
      "Created a chunk of size 217, which is longer than the specified 0\n",
      "Created a chunk of size 208, which is longer than the specified 0\n",
      "Created a chunk of size 199, which is longer than the specified 0\n",
      "Created a chunk of size 195, which is longer than the specified 0\n",
      "Created a chunk of size 230, which is longer than the specified 0\n",
      "Created a chunk of size 284, which is longer than the specified 0\n",
      "Created a chunk of size 148, which is longer than the specified 0\n",
      "Created a chunk of size 233, which is longer than the specified 0\n",
      "Created a chunk of size 250, which is longer than the specified 0\n",
      "Created a chunk of size 232, which is longer than the specified 0\n",
      "Created a chunk of size 269, which is longer than the specified 0\n",
      "Created a chunk of size 226, which is longer than the specified 0\n",
      "Created a chunk of size 216, which is longer than the specified 0\n",
      "Created a chunk of size 243, which is longer than the specified 0\n",
      "Created a chunk of size 279, which is longer than the specified 0\n",
      "Created a chunk of size 264, which is longer than the specified 0\n",
      "Created a chunk of size 288, which is longer than the specified 0\n",
      "Created a chunk of size 254, which is longer than the specified 0\n",
      "Created a chunk of size 225, which is longer than the specified 0\n",
      "Created a chunk of size 254, which is longer than the specified 0\n",
      "Created a chunk of size 315, which is longer than the specified 0\n",
      "Created a chunk of size 337, which is longer than the specified 0\n",
      "Created a chunk of size 369, which is longer than the specified 0\n",
      "Created a chunk of size 269, which is longer than the specified 0\n",
      "Created a chunk of size 325, which is longer than the specified 0\n",
      "Created a chunk of size 235, which is longer than the specified 0\n",
      "Created a chunk of size 246, which is longer than the specified 0\n",
      "Created a chunk of size 247, which is longer than the specified 0\n",
      "Created a chunk of size 245, which is longer than the specified 0\n",
      "Created a chunk of size 229, which is longer than the specified 0\n",
      "Created a chunk of size 366, which is longer than the specified 0\n",
      "Created a chunk of size 351, which is longer than the specified 0\n",
      "Created a chunk of size 325, which is longer than the specified 0\n",
      "Created a chunk of size 355, which is longer than the specified 0\n",
      "Created a chunk of size 236, which is longer than the specified 0\n",
      "Created a chunk of size 227, which is longer than the specified 0\n",
      "Created a chunk of size 286, which is longer than the specified 0\n",
      "Created a chunk of size 236, which is longer than the specified 0\n",
      "Created a chunk of size 337, which is longer than the specified 0\n",
      "Created a chunk of size 214, which is longer than the specified 0\n",
      "Created a chunk of size 270, which is longer than the specified 0\n",
      "Created a chunk of size 316, which is longer than the specified 0\n",
      "Created a chunk of size 200, which is longer than the specified 0\n",
      "Created a chunk of size 237, which is longer than the specified 0\n",
      "Created a chunk of size 1564, which is longer than the specified 0\n",
      "Created a chunk of size 242, which is longer than the specified 0\n",
      "Created a chunk of size 358, which is longer than the specified 0\n",
      "Created a chunk of size 250, which is longer than the specified 0\n",
      "Created a chunk of size 305, which is longer than the specified 0\n",
      "Created a chunk of size 251, which is longer than the specified 0\n",
      "Created a chunk of size 1149, which is longer than the specified 0\n",
      "Created a chunk of size 245, which is longer than the specified 0\n",
      "Created a chunk of size 661, which is longer than the specified 0\n",
      "Created a chunk of size 1214, which is longer than the specified 0\n",
      "Created a chunk of size 1215, which is longer than the specified 0\n",
      "Created a chunk of size 1066, which is longer than the specified 0\n",
      "Created a chunk of size 713, which is longer than the specified 0\n",
      "Created a chunk of size 382, which is longer than the specified 0\n",
      "Created a chunk of size 1081, which is longer than the specified 0\n",
      "Created a chunk of size 750, which is longer than the specified 0\n",
      "Created a chunk of size 215, which is longer than the specified 0\n",
      "Created a chunk of size 190, which is longer than the specified 0\n",
      "Created a chunk of size 228, which is longer than the specified 0\n",
      "Created a chunk of size 546, which is longer than the specified 0\n",
      "Created a chunk of size 302, which is longer than the specified 0\n",
      "Created a chunk of size 307, which is longer than the specified 0\n",
      "Created a chunk of size 293, which is longer than the specified 0\n",
      "Created a chunk of size 857, which is longer than the specified 0\n",
      "Created a chunk of size 313, which is longer than the specified 0\n",
      "Created a chunk of size 345, which is longer than the specified 0\n",
      "Created a chunk of size 478, which is longer than the specified 0\n",
      "Created a chunk of size 269, which is longer than the specified 0\n",
      "Created a chunk of size 203, which is longer than the specified 0\n",
      "Created a chunk of size 310, which is longer than the specified 0\n",
      "Created a chunk of size 1042, which is longer than the specified 0\n",
      "Created a chunk of size 202, which is longer than the specified 0\n",
      "Created a chunk of size 709, which is longer than the specified 0\n",
      "Created a chunk of size 254, which is longer than the specified 0\n",
      "Created a chunk of size 192, which is longer than the specified 0\n",
      "Created a chunk of size 487, which is longer than the specified 0\n",
      "Created a chunk of size 554, which is longer than the specified 0\n",
      "Created a chunk of size 1255, which is longer than the specified 0\n",
      "Created a chunk of size 167, which is longer than the specified 0\n",
      "Created a chunk of size 438, which is longer than the specified 0\n",
      "Created a chunk of size 692, which is longer than the specified 0\n",
      "Created a chunk of size 419, which is longer than the specified 0\n",
      "Created a chunk of size 555, which is longer than the specified 0\n",
      "Created a chunk of size 442, which is longer than the specified 0\n",
      "Created a chunk of size 1173, which is longer than the specified 0\n",
      "Created a chunk of size 421, which is longer than the specified 0\n",
      "Created a chunk of size 474, which is longer than the specified 0\n",
      "Created a chunk of size 766, which is longer than the specified 0\n",
      "Created a chunk of size 842, which is longer than the specified 0\n",
      "Created a chunk of size 294, which is longer than the specified 0\n",
      "Created a chunk of size 305, which is longer than the specified 0\n",
      "Created a chunk of size 491, which is longer than the specified 0\n",
      "Created a chunk of size 585, which is longer than the specified 0\n",
      "Created a chunk of size 666, which is longer than the specified 0\n",
      "Created a chunk of size 875, which is longer than the specified 0\n",
      "Created a chunk of size 699, which is longer than the specified 0\n",
      "Created a chunk of size 650, which is longer than the specified 0\n",
      "Created a chunk of size 674, which is longer than the specified 0\n",
      "Created a chunk of size 478, which is longer than the specified 0\n",
      "Created a chunk of size 519, which is longer than the specified 0\n",
      "Created a chunk of size 630, which is longer than the specified 0\n",
      "Created a chunk of size 195, which is longer than the specified 0\n",
      "Created a chunk of size 194, which is longer than the specified 0\n",
      "Created a chunk of size 605, which is longer than the specified 0\n",
      "Created a chunk of size 594, which is longer than the specified 0\n",
      "Created a chunk of size 446, which is longer than the specified 0\n",
      "Created a chunk of size 286, which is longer than the specified 0\n",
      "Created a chunk of size 279, which is longer than the specified 0\n",
      "Created a chunk of size 598, which is longer than the specified 0\n",
      "Created a chunk of size 174, which is longer than the specified 0\n",
      "Created a chunk of size 1075, which is longer than the specified 0\n",
      "Created a chunk of size 213, which is longer than the specified 0\n",
      "Created a chunk of size 181, which is longer than the specified 0\n",
      "Created a chunk of size 186, which is longer than the specified 0\n",
      "Created a chunk of size 183, which is longer than the specified 0\n",
      "Created a chunk of size 198, which is longer than the specified 0\n",
      "Created a chunk of size 217, which is longer than the specified 0\n",
      "Created a chunk of size 173, which is longer than the specified 0\n",
      "Created a chunk of size 180, which is longer than the specified 0\n",
      "Created a chunk of size 156, which is longer than the specified 0\n",
      "Created a chunk of size 207, which is longer than the specified 0\n",
      "Created a chunk of size 218, which is longer than the specified 0\n",
      "Created a chunk of size 232, which is longer than the specified 0\n",
      "Created a chunk of size 183, which is longer than the specified 0\n",
      "Created a chunk of size 606, which is longer than the specified 0\n",
      "Created a chunk of size 1263, which is longer than the specified 0\n",
      "Created a chunk of size 392, which is longer than the specified 0\n",
      "Created a chunk of size 197, which is longer than the specified 0\n",
      "Created a chunk of size 147, which is longer than the specified 0\n",
      "Created a chunk of size 216, which is longer than the specified 0\n",
      "Created a chunk of size 328, which is longer than the specified 0\n",
      "Created a chunk of size 1620, which is longer than the specified 0\n",
      "Created a chunk of size 175, which is longer than the specified 0\n",
      "Created a chunk of size 708, which is longer than the specified 0\n",
      "Created a chunk of size 279, which is longer than the specified 0\n",
      "Created a chunk of size 264, which is longer than the specified 0\n",
      "Created a chunk of size 213, which is longer than the specified 0\n",
      "Created a chunk of size 707, which is longer than the specified 0\n",
      "Created a chunk of size 199, which is longer than the specified 0\n",
      "Created a chunk of size 627, which is longer than the specified 0\n",
      "Created a chunk of size 994, which is longer than the specified 0\n",
      "Created a chunk of size 840, which is longer than the specified 0\n",
      "Created a chunk of size 797, which is longer than the specified 0\n",
      "Created a chunk of size 191, which is longer than the specified 0\n",
      "Created a chunk of size 451, which is longer than the specified 0\n",
      "Created a chunk of size 247, which is longer than the specified 0\n",
      "Created a chunk of size 1061, which is longer than the specified 0\n",
      "Created a chunk of size 1579, which is longer than the specified 0\n",
      "Created a chunk of size 331, which is longer than the specified 0\n",
      "Created a chunk of size 188, which is longer than the specified 0\n",
      "Created a chunk of size 200, which is longer than the specified 0\n",
      "Created a chunk of size 637, which is longer than the specified 0\n",
      "Created a chunk of size 231, which is longer than the specified 0\n",
      "Created a chunk of size 662, which is longer than the specified 0\n",
      "Created a chunk of size 764, which is longer than the specified 0\n",
      "Created a chunk of size 192, which is longer than the specified 0\n",
      "Created a chunk of size 259, which is longer than the specified 0\n",
      "Created a chunk of size 339, which is longer than the specified 0\n",
      "Created a chunk of size 230, which is longer than the specified 0\n",
      "Created a chunk of size 672, which is longer than the specified 0\n",
      "Created a chunk of size 220, which is longer than the specified 0\n",
      "Created a chunk of size 207, which is longer than the specified 0\n",
      "Created a chunk of size 151, which is longer than the specified 0\n",
      "Created a chunk of size 139, which is longer than the specified 0\n",
      "Created a chunk of size 226, which is longer than the specified 0\n",
      "Created a chunk of size 372, which is longer than the specified 0\n",
      "Created a chunk of size 253, which is longer than the specified 0\n",
      "Created a chunk of size 299, which is longer than the specified 0\n",
      "Created a chunk of size 227, which is longer than the specified 0\n",
      "Created a chunk of size 256, which is longer than the specified 0\n",
      "Created a chunk of size 256, which is longer than the specified 0\n",
      "Created a chunk of size 253, which is longer than the specified 0\n",
      "Created a chunk of size 229, which is longer than the specified 0\n",
      "Created a chunk of size 390, which is longer than the specified 0\n",
      "Created a chunk of size 192, which is longer than the specified 0\n",
      "Created a chunk of size 254, which is longer than the specified 0\n",
      "Created a chunk of size 1041, which is longer than the specified 0\n",
      "Created a chunk of size 395, which is longer than the specified 0\n",
      "Created a chunk of size 478, which is longer than the specified 0\n",
      "Created a chunk of size 250, which is longer than the specified 0\n",
      "Created a chunk of size 174, which is longer than the specified 0\n",
      "Created a chunk of size 261, which is longer than the specified 0\n",
      "Created a chunk of size 240, which is longer than the specified 0\n",
      "Created a chunk of size 275, which is longer than the specified 0\n",
      "Created a chunk of size 202, which is longer than the specified 0\n",
      "Created a chunk of size 194, which is longer than the specified 0\n",
      "Created a chunk of size 225, which is longer than the specified 0\n",
      "Created a chunk of size 288, which is longer than the specified 0\n",
      "Created a chunk of size 235, which is longer than the specified 0\n",
      "Created a chunk of size 250, which is longer than the specified 0\n",
      "Created a chunk of size 384, which is longer than the specified 0\n",
      "Created a chunk of size 267, which is longer than the specified 0\n",
      "Created a chunk of size 201, which is longer than the specified 0\n",
      "Created a chunk of size 190, which is longer than the specified 0\n",
      "Created a chunk of size 325, which is longer than the specified 0\n",
      "Created a chunk of size 317, which is longer than the specified 0\n",
      "Created a chunk of size 198, which is longer than the specified 0\n",
      "Created a chunk of size 692, which is longer than the specified 0\n",
      "Created a chunk of size 265, which is longer than the specified 0\n",
      "Created a chunk of size 827, which is longer than the specified 0\n",
      "Created a chunk of size 192, which is longer than the specified 0\n",
      "Created a chunk of size 392, which is longer than the specified 0\n",
      "Created a chunk of size 641, which is longer than the specified 0\n",
      "Created a chunk of size 1045, which is longer than the specified 0\n",
      "Created a chunk of size 707, which is longer than the specified 0\n",
      "Created a chunk of size 334, which is longer than the specified 0\n",
      "Created a chunk of size 323, which is longer than the specified 0\n",
      "Created a chunk of size 389, which is longer than the specified 0\n",
      "Created a chunk of size 370, which is longer than the specified 0\n",
      "Created a chunk of size 259, which is longer than the specified 0\n",
      "Created a chunk of size 318, which is longer than the specified 0\n",
      "Created a chunk of size 250, which is longer than the specified 0\n",
      "Created a chunk of size 1450, which is longer than the specified 0\n",
      "Created a chunk of size 341, which is longer than the specified 0\n",
      "Created a chunk of size 312, which is longer than the specified 0\n",
      "Created a chunk of size 495, which is longer than the specified 0\n",
      "Created a chunk of size 234, which is longer than the specified 0\n",
      "Created a chunk of size 229, which is longer than the specified 0\n",
      "Created a chunk of size 240, which is longer than the specified 0\n",
      "Created a chunk of size 1443, which is longer than the specified 0\n",
      "Created a chunk of size 1285, which is longer than the specified 0\n",
      "Created a chunk of size 941, which is longer than the specified 0\n",
      "Created a chunk of size 201, which is longer than the specified 0\n",
      "Created a chunk of size 224, which is longer than the specified 0\n",
      "Created a chunk of size 684, which is longer than the specified 0\n",
      "Created a chunk of size 800, which is longer than the specified 0\n",
      "Created a chunk of size 205, which is longer than the specified 0\n",
      "Created a chunk of size 278, which is longer than the specified 0\n",
      "Created a chunk of size 197, which is longer than the specified 0\n",
      "Created a chunk of size 857, which is longer than the specified 0\n",
      "Created a chunk of size 516, which is longer than the specified 0\n",
      "Created a chunk of size 238, which is longer than the specified 0\n",
      "Created a chunk of size 179, which is longer than the specified 0\n",
      "Created a chunk of size 331, which is longer than the specified 0\n",
      "Created a chunk of size 230, which is longer than the specified 0\n",
      "Created a chunk of size 164, which is longer than the specified 0\n",
      "Created a chunk of size 200, which is longer than the specified 0\n",
      "Created a chunk of size 236, which is longer than the specified 0\n",
      "Created a chunk of size 475, which is longer than the specified 0\n",
      "Created a chunk of size 1082, which is longer than the specified 0\n",
      "Created a chunk of size 310, which is longer than the specified 0\n",
      "Created a chunk of size 197, which is longer than the specified 0\n",
      "Created a chunk of size 418, which is longer than the specified 0\n",
      "Created a chunk of size 178, which is longer than the specified 0\n",
      "Created a chunk of size 208, which is longer than the specified 0\n",
      "Created a chunk of size 1006, which is longer than the specified 0\n",
      "Created a chunk of size 1309, which is longer than the specified 0\n",
      "Created a chunk of size 202, which is longer than the specified 0\n",
      "Created a chunk of size 886, which is longer than the specified 0\n",
      "Created a chunk of size 809, which is longer than the specified 0\n",
      "Created a chunk of size 1126, which is longer than the specified 0\n",
      "Created a chunk of size 1158, which is longer than the specified 0\n",
      "Created a chunk of size 282, which is longer than the specified 0\n",
      "Created a chunk of size 176, which is longer than the specified 0\n",
      "Created a chunk of size 260, which is longer than the specified 0\n",
      "Created a chunk of size 224, which is longer than the specified 0\n",
      "Created a chunk of size 539, which is longer than the specified 0\n",
      "Created a chunk of size 191, which is longer than the specified 0\n",
      "Created a chunk of size 190, which is longer than the specified 0\n",
      "Created a chunk of size 216, which is longer than the specified 0\n",
      "Created a chunk of size 243, which is longer than the specified 0\n",
      "Created a chunk of size 171, which is longer than the specified 0\n",
      "Created a chunk of size 178, which is longer than the specified 0\n",
      "Created a chunk of size 312, which is longer than the specified 0\n",
      "Created a chunk of size 639, which is longer than the specified 0\n",
      "Created a chunk of size 164, which is longer than the specified 0\n",
      "Created a chunk of size 243, which is longer than the specified 0\n",
      "Created a chunk of size 299, which is longer than the specified 0\n",
      "Created a chunk of size 245, which is longer than the specified 0\n",
      "Created a chunk of size 224, which is longer than the specified 0\n",
      "Created a chunk of size 781, which is longer than the specified 0\n",
      "Created a chunk of size 380, which is longer than the specified 0\n",
      "Created a chunk of size 160, which is longer than the specified 0\n",
      "Created a chunk of size 249, which is longer than the specified 0\n",
      "Created a chunk of size 245, which is longer than the specified 0\n",
      "Created a chunk of size 242, which is longer than the specified 0\n",
      "Created a chunk of size 246, which is longer than the specified 0\n",
      "Created a chunk of size 256, which is longer than the specified 0\n",
      "Created a chunk of size 332, which is longer than the specified 0\n",
      "Created a chunk of size 224, which is longer than the specified 0\n",
      "Created a chunk of size 244, which is longer than the specified 0\n",
      "Created a chunk of size 221, which is longer than the specified 0\n",
      "Created a chunk of size 259, which is longer than the specified 0\n",
      "Created a chunk of size 1922, which is longer than the specified 0\n",
      "Created a chunk of size 495, which is longer than the specified 0\n",
      "Created a chunk of size 214, which is longer than the specified 0\n",
      "Created a chunk of size 361, which is longer than the specified 0\n",
      "Created a chunk of size 733, which is longer than the specified 0\n",
      "Created a chunk of size 1912, which is longer than the specified 0\n",
      "Created a chunk of size 401, which is longer than the specified 0\n",
      "Created a chunk of size 271, which is longer than the specified 0\n",
      "Created a chunk of size 259, which is longer than the specified 0\n",
      "Created a chunk of size 253, which is longer than the specified 0\n",
      "Created a chunk of size 199, which is longer than the specified 0\n",
      "Created a chunk of size 1200, which is longer than the specified 0\n",
      "Created a chunk of size 1166, which is longer than the specified 0\n",
      "Created a chunk of size 2146, which is longer than the specified 0\n",
      "Created a chunk of size 315, which is longer than the specified 0\n",
      "Created a chunk of size 2490, which is longer than the specified 0\n",
      "Created a chunk of size 349, which is longer than the specified 0\n",
      "Created a chunk of size 261, which is longer than the specified 0\n",
      "Created a chunk of size 246, which is longer than the specified 0\n",
      "Created a chunk of size 1373, which is longer than the specified 0\n",
      "Created a chunk of size 910, which is longer than the specified 0\n",
      "Created a chunk of size 195, which is longer than the specified 0\n",
      "Created a chunk of size 257, which is longer than the specified 0\n",
      "Created a chunk of size 214, which is longer than the specified 0\n",
      "Created a chunk of size 1475, which is longer than the specified 0\n",
      "Created a chunk of size 285, which is longer than the specified 0\n",
      "Created a chunk of size 841, which is longer than the specified 0\n",
      "Created a chunk of size 270, which is longer than the specified 0\n",
      "Created a chunk of size 341, which is longer than the specified 0\n",
      "Created a chunk of size 225, which is longer than the specified 0\n",
      "Created a chunk of size 204, which is longer than the specified 0\n",
      "Created a chunk of size 269, which is longer than the specified 0\n",
      "Created a chunk of size 193, which is longer than the specified 0\n",
      "Created a chunk of size 334, which is longer than the specified 0\n",
      "Created a chunk of size 180, which is longer than the specified 0\n",
      "Created a chunk of size 174, which is longer than the specified 0\n",
      "Created a chunk of size 173, which is longer than the specified 0\n",
      "Created a chunk of size 250, which is longer than the specified 0\n",
      "Created a chunk of size 218, which is longer than the specified 0\n",
      "Created a chunk of size 215, which is longer than the specified 0\n",
      "Created a chunk of size 170, which is longer than the specified 0\n",
      "Created a chunk of size 198, which is longer than the specified 0\n",
      "Created a chunk of size 198, which is longer than the specified 0\n",
      "Created a chunk of size 191, which is longer than the specified 0\n",
      "Created a chunk of size 204, which is longer than the specified 0\n",
      "Created a chunk of size 245, which is longer than the specified 0\n",
      "Created a chunk of size 181, which is longer than the specified 0\n",
      "Created a chunk of size 272, which is longer than the specified 0\n",
      "Created a chunk of size 189, which is longer than the specified 0\n",
      "Created a chunk of size 270, which is longer than the specified 0\n",
      "Created a chunk of size 199, which is longer than the specified 0\n",
      "Created a chunk of size 640, which is longer than the specified 0\n",
      "Created a chunk of size 177, which is longer than the specified 0\n",
      "Created a chunk of size 303, which is longer than the specified 0\n",
      "Created a chunk of size 729, which is longer than the specified 0\n",
      "Created a chunk of size 231, which is longer than the specified 0\n",
      "Created a chunk of size 232, which is longer than the specified 0\n",
      "Created a chunk of size 238, which is longer than the specified 0\n",
      "Created a chunk of size 245, which is longer than the specified 0\n",
      "Created a chunk of size 351, which is longer than the specified 0\n",
      "Created a chunk of size 261, which is longer than the specified 0\n",
      "Created a chunk of size 234, which is longer than the specified 0\n",
      "Created a chunk of size 389, which is longer than the specified 0\n",
      "Created a chunk of size 180, which is longer than the specified 0\n",
      "Created a chunk of size 238, which is longer than the specified 0\n",
      "Created a chunk of size 231, which is longer than the specified 0\n",
      "Created a chunk of size 156, which is longer than the specified 0\n",
      "Created a chunk of size 239, which is longer than the specified 0\n",
      "Created a chunk of size 749, which is longer than the specified 0\n",
      "Created a chunk of size 352, which is longer than the specified 0\n",
      "Created a chunk of size 259, which is longer than the specified 0\n",
      "Created a chunk of size 738, which is longer than the specified 0\n",
      "Created a chunk of size 213, which is longer than the specified 0\n",
      "Created a chunk of size 257, which is longer than the specified 0\n",
      "Created a chunk of size 169, which is longer than the specified 0\n",
      "Created a chunk of size 145, which is longer than the specified 0\n",
      "Created a chunk of size 300, which is longer than the specified 0\n",
      "Created a chunk of size 221, which is longer than the specified 0\n",
      "Created a chunk of size 202, which is longer than the specified 0\n",
      "Created a chunk of size 319, which is longer than the specified 0\n",
      "Created a chunk of size 191, which is longer than the specified 0\n",
      "Created a chunk of size 207, which is longer than the specified 0\n",
      "Created a chunk of size 260, which is longer than the specified 0\n",
      "Created a chunk of size 241, which is longer than the specified 0\n",
      "Created a chunk of size 1965, which is longer than the specified 0\n",
      "Created a chunk of size 263, which is longer than the specified 0\n",
      "Created a chunk of size 231, which is longer than the specified 0\n",
      "Created a chunk of size 208, which is longer than the specified 0\n",
      "Created a chunk of size 268, which is longer than the specified 0\n",
      "Created a chunk of size 296, which is longer than the specified 0\n",
      "Created a chunk of size 248, which is longer than the specified 0\n",
      "Created a chunk of size 239, which is longer than the specified 0\n",
      "Created a chunk of size 237, which is longer than the specified 0\n",
      "Created a chunk of size 253, which is longer than the specified 0\n",
      "Created a chunk of size 259, which is longer than the specified 0\n",
      "Created a chunk of size 193, which is longer than the specified 0\n",
      "Created a chunk of size 213, which is longer than the specified 0\n",
      "Created a chunk of size 194, which is longer than the specified 0\n",
      "Created a chunk of size 186, which is longer than the specified 0\n",
      "Created a chunk of size 249, which is longer than the specified 0\n",
      "Created a chunk of size 150, which is longer than the specified 0\n",
      "Created a chunk of size 219, which is longer than the specified 0\n",
      "Created a chunk of size 177, which is longer than the specified 0\n",
      "Created a chunk of size 624, which is longer than the specified 0\n",
      "Created a chunk of size 1621, which is longer than the specified 0\n",
      "Created a chunk of size 215, which is longer than the specified 0\n",
      "Created a chunk of size 606, which is longer than the specified 0\n",
      "Created a chunk of size 757, which is longer than the specified 0\n",
      "Created a chunk of size 3784, which is longer than the specified 0\n",
      "Created a chunk of size 180, which is longer than the specified 0\n",
      "Created a chunk of size 663, which is longer than the specified 0\n",
      "Created a chunk of size 715, which is longer than the specified 0\n",
      "Created a chunk of size 1055, which is longer than the specified 0\n",
      "Created a chunk of size 179, which is longer than the specified 0\n",
      "Created a chunk of size 616, which is longer than the specified 0\n",
      "Created a chunk of size 193, which is longer than the specified 0\n",
      "Created a chunk of size 725, which is longer than the specified 0\n",
      "Created a chunk of size 571, which is longer than the specified 0\n",
      "Created a chunk of size 191, which is longer than the specified 0\n",
      "Created a chunk of size 434, which is longer than the specified 0\n",
      "Created a chunk of size 452, which is longer than the specified 0\n",
      "Created a chunk of size 467, which is longer than the specified 0\n",
      "Created a chunk of size 276, which is longer than the specified 0\n",
      "Created a chunk of size 1446, which is longer than the specified 0\n",
      "Created a chunk of size 210, which is longer than the specified 0\n",
      "Created a chunk of size 610, which is longer than the specified 0\n",
      "Created a chunk of size 283, which is longer than the specified 0\n",
      "Created a chunk of size 172, which is longer than the specified 0\n",
      "Created a chunk of size 168, which is longer than the specified 0\n",
      "Created a chunk of size 193, which is longer than the specified 0\n",
      "Created a chunk of size 928, which is longer than the specified 0\n",
      "Created a chunk of size 334, which is longer than the specified 0\n",
      "Created a chunk of size 183, which is longer than the specified 0\n",
      "Created a chunk of size 203, which is longer than the specified 0\n",
      "Created a chunk of size 1098, which is longer than the specified 0\n",
      "Created a chunk of size 213, which is longer than the specified 0\n",
      "Created a chunk of size 989, which is longer than the specified 0\n",
      "Created a chunk of size 310, which is longer than the specified 0\n",
      "Created a chunk of size 1199, which is longer than the specified 0\n",
      "Created a chunk of size 725, which is longer than the specified 0\n",
      "Created a chunk of size 218, which is longer than the specified 0\n",
      "Created a chunk of size 234, which is longer than the specified 0\n",
      "Created a chunk of size 1492, which is longer than the specified 0\n",
      "Created a chunk of size 2702, which is longer than the specified 0\n",
      "Created a chunk of size 5836, which is longer than the specified 0\n",
      "Created a chunk of size 1709, which is longer than the specified 0\n",
      "Created a chunk of size 1678, which is longer than the specified 0\n",
      "Created a chunk of size 681, which is longer than the specified 0\n",
      "Created a chunk of size 793, which is longer than the specified 0\n",
      "Created a chunk of size 268, which is longer than the specified 0\n",
      "Created a chunk of size 175, which is longer than the specified 0\n",
      "Created a chunk of size 1808, which is longer than the specified 0\n",
      "Created a chunk of size 1171, which is longer than the specified 0\n",
      "Created a chunk of size 1739, which is longer than the specified 0\n",
      "Created a chunk of size 548, which is longer than the specified 0\n",
      "Created a chunk of size 666, which is longer than the specified 0\n",
      "Created a chunk of size 1616, which is longer than the specified 0\n",
      "Created a chunk of size 643, which is longer than the specified 0\n",
      "Created a chunk of size 1477, which is longer than the specified 0\n",
      "Created a chunk of size 1348, which is longer than the specified 0\n",
      "Created a chunk of size 401, which is longer than the specified 0\n",
      "Created a chunk of size 1441, which is longer than the specified 0\n",
      "Created a chunk of size 1866, which is longer than the specified 0\n",
      "Created a chunk of size 1464, which is longer than the specified 0\n",
      "Created a chunk of size 1277, which is longer than the specified 0\n",
      "Created a chunk of size 359, which is longer than the specified 0\n",
      "Created a chunk of size 220, which is longer than the specified 0\n",
      "Created a chunk of size 219, which is longer than the specified 0\n",
      "Created a chunk of size 632, which is longer than the specified 0\n",
      "Created a chunk of size 606, which is longer than the specified 0\n",
      "Created a chunk of size 694, which is longer than the specified 0\n",
      "Created a chunk of size 180, which is longer than the specified 0\n",
      "Created a chunk of size 239, which is longer than the specified 0\n",
      "Created a chunk of size 640, which is longer than the specified 0\n",
      "Created a chunk of size 997, which is longer than the specified 0\n",
      "Created a chunk of size 174, which is longer than the specified 0\n",
      "Created a chunk of size 185, which is longer than the specified 0\n",
      "Created a chunk of size 218, which is longer than the specified 0\n",
      "Created a chunk of size 314, which is longer than the specified 0\n",
      "Created a chunk of size 315, which is longer than the specified 0\n",
      "Created a chunk of size 1086, which is longer than the specified 0\n",
      "Created a chunk of size 209, which is longer than the specified 0\n",
      "Created a chunk of size 192, which is longer than the specified 0\n",
      "Created a chunk of size 147, which is longer than the specified 0\n",
      "Created a chunk of size 206, which is longer than the specified 0\n",
      "Created a chunk of size 267, which is longer than the specified 0\n",
      "Created a chunk of size 907, which is longer than the specified 0\n",
      "Created a chunk of size 199, which is longer than the specified 0\n",
      "Created a chunk of size 210, which is longer than the specified 0\n",
      "Created a chunk of size 561, which is longer than the specified 0\n",
      "Created a chunk of size 759, which is longer than the specified 0\n",
      "Created a chunk of size 168, which is longer than the specified 0\n",
      "Created a chunk of size 948, which is longer than the specified 0\n",
      "Created a chunk of size 664, which is longer than the specified 0\n",
      "Created a chunk of size 1016, which is longer than the specified 0\n",
      "Created a chunk of size 223, which is longer than the specified 0\n",
      "Created a chunk of size 363, which is longer than the specified 0\n",
      "Created a chunk of size 1756, which is longer than the specified 0\n",
      "Created a chunk of size 514, which is longer than the specified 0\n",
      "Created a chunk of size 492, which is longer than the specified 0\n",
      "Created a chunk of size 347, which is longer than the specified 0\n",
      "Created a chunk of size 1555, which is longer than the specified 0\n",
      "Created a chunk of size 1122, which is longer than the specified 0\n",
      "Created a chunk of size 245, which is longer than the specified 0\n",
      "Created a chunk of size 1960, which is longer than the specified 0\n",
      "Created a chunk of size 2075, which is longer than the specified 0\n",
      "Created a chunk of size 243, which is longer than the specified 0\n",
      "Created a chunk of size 461, which is longer than the specified 0\n",
      "Created a chunk of size 1482, which is longer than the specified 0\n",
      "Created a chunk of size 211, which is longer than the specified 0\n",
      "Created a chunk of size 735, which is longer than the specified 0\n",
      "Created a chunk of size 169, which is longer than the specified 0\n",
      "Created a chunk of size 191, which is longer than the specified 0\n",
      "Created a chunk of size 640, which is longer than the specified 0\n",
      "Created a chunk of size 254, which is longer than the specified 0\n",
      "Created a chunk of size 228, which is longer than the specified 0\n",
      "Created a chunk of size 904, which is longer than the specified 0\n",
      "Created a chunk of size 453, which is longer than the specified 0\n",
      "Created a chunk of size 548, which is longer than the specified 0\n",
      "Created a chunk of size 596, which is longer than the specified 0\n",
      "Created a chunk of size 311, which is longer than the specified 0\n",
      "Created a chunk of size 609, which is longer than the specified 0\n",
      "Created a chunk of size 239, which is longer than the specified 0\n",
      "Created a chunk of size 200, which is longer than the specified 0\n",
      "Created a chunk of size 270, which is longer than the specified 0\n",
      "Created a chunk of size 252, which is longer than the specified 0\n",
      "Created a chunk of size 956, which is longer than the specified 0\n",
      "Created a chunk of size 996, which is longer than the specified 0\n",
      "Created a chunk of size 283, which is longer than the specified 0\n",
      "Created a chunk of size 281, which is longer than the specified 0\n",
      "Created a chunk of size 804, which is longer than the specified 0\n",
      "Created a chunk of size 1469, which is longer than the specified 0\n",
      "Created a chunk of size 416, which is longer than the specified 0\n",
      "Created a chunk of size 298, which is longer than the specified 0\n",
      "Created a chunk of size 498, which is longer than the specified 0\n",
      "Created a chunk of size 759, which is longer than the specified 0\n",
      "Created a chunk of size 207, which is longer than the specified 0\n",
      "Created a chunk of size 212, which is longer than the specified 0\n",
      "Created a chunk of size 221, which is longer than the specified 0\n",
      "Created a chunk of size 250, which is longer than the specified 0\n",
      "Created a chunk of size 187, which is longer than the specified 0\n",
      "Created a chunk of size 340, which is longer than the specified 0\n",
      "Created a chunk of size 695, which is longer than the specified 0\n",
      "Created a chunk of size 750, which is longer than the specified 0\n",
      "Created a chunk of size 304, which is longer than the specified 0\n",
      "Created a chunk of size 180, which is longer than the specified 0\n",
      "Created a chunk of size 193, which is longer than the specified 0\n",
      "Created a chunk of size 1370, which is longer than the specified 0\n",
      "Created a chunk of size 922, which is longer than the specified 0\n",
      "Created a chunk of size 1381, which is longer than the specified 0\n",
      "Created a chunk of size 1105, which is longer than the specified 0\n",
      "Created a chunk of size 920, which is longer than the specified 0\n",
      "Created a chunk of size 749, which is longer than the specified 0\n",
      "Created a chunk of size 175, which is longer than the specified 0\n",
      "Created a chunk of size 151, which is longer than the specified 0\n",
      "Created a chunk of size 210, which is longer than the specified 0\n",
      "Created a chunk of size 515, which is longer than the specified 0\n",
      "Created a chunk of size 263, which is longer than the specified 0\n",
      "Created a chunk of size 219, which is longer than the specified 0\n",
      "Created a chunk of size 790, which is longer than the specified 0\n",
      "Created a chunk of size 186, which is longer than the specified 0\n",
      "Created a chunk of size 256, which is longer than the specified 0\n",
      "Created a chunk of size 245, which is longer than the specified 0\n",
      "Created a chunk of size 261, which is longer than the specified 0\n",
      "Created a chunk of size 1345, which is longer than the specified 0\n",
      "Created a chunk of size 224, which is longer than the specified 0\n",
      "Created a chunk of size 234, which is longer than the specified 0\n",
      "Created a chunk of size 235, which is longer than the specified 0\n",
      "Created a chunk of size 200, which is longer than the specified 0\n",
      "Created a chunk of size 373, which is longer than the specified 0\n",
      "Created a chunk of size 900, which is longer than the specified 0\n",
      "Created a chunk of size 252, which is longer than the specified 0\n",
      "Created a chunk of size 163, which is longer than the specified 0\n",
      "Created a chunk of size 446, which is longer than the specified 0\n",
      "Created a chunk of size 637, which is longer than the specified 0\n",
      "Created a chunk of size 210, which is longer than the specified 0\n",
      "Created a chunk of size 1144, which is longer than the specified 0\n",
      "Created a chunk of size 1099, which is longer than the specified 0\n",
      "Created a chunk of size 188, which is longer than the specified 0\n",
      "Created a chunk of size 249, which is longer than the specified 0\n",
      "Created a chunk of size 944, which is longer than the specified 0\n",
      "Created a chunk of size 1171, which is longer than the specified 0\n",
      "Created a chunk of size 443, which is longer than the specified 0\n",
      "Created a chunk of size 1343, which is longer than the specified 0\n",
      "Created a chunk of size 818, which is longer than the specified 0\n",
      "Created a chunk of size 245, which is longer than the specified 0\n",
      "Created a chunk of size 179, which is longer than the specified 0\n",
      "Created a chunk of size 235, which is longer than the specified 0\n",
      "Created a chunk of size 381, which is longer than the specified 0\n",
      "Created a chunk of size 1456, which is longer than the specified 0\n",
      "Created a chunk of size 252, which is longer than the specified 0\n",
      "Created a chunk of size 254, which is longer than the specified 0\n",
      "Created a chunk of size 245, which is longer than the specified 0\n",
      "Created a chunk of size 1010, which is longer than the specified 0\n",
      "Created a chunk of size 332, which is longer than the specified 0\n",
      "Created a chunk of size 332, which is longer than the specified 0\n",
      "Created a chunk of size 195, which is longer than the specified 0\n",
      "Created a chunk of size 448, which is longer than the specified 0\n",
      "Created a chunk of size 293, which is longer than the specified 0\n",
      "Created a chunk of size 755, which is longer than the specified 0\n",
      "Created a chunk of size 2002, which is longer than the specified 0\n",
      "Created a chunk of size 238, which is longer than the specified 0\n",
      "Created a chunk of size 1853, which is longer than the specified 0\n",
      "Created a chunk of size 263, which is longer than the specified 0\n",
      "Created a chunk of size 194, which is longer than the specified 0\n",
      "Created a chunk of size 311, which is longer than the specified 0\n",
      "Created a chunk of size 1141, which is longer than the specified 0\n",
      "Created a chunk of size 1362, which is longer than the specified 0\n",
      "Created a chunk of size 269, which is longer than the specified 0\n",
      "Created a chunk of size 353, which is longer than the specified 0\n",
      "Created a chunk of size 1581, which is longer than the specified 0\n",
      "Created a chunk of size 1201, which is longer than the specified 0\n",
      "Created a chunk of size 481, which is longer than the specified 0\n",
      "Created a chunk of size 1510, which is longer than the specified 0\n",
      "Created a chunk of size 268, which is longer than the specified 0\n",
      "Created a chunk of size 1480, which is longer than the specified 0\n",
      "Created a chunk of size 241, which is longer than the specified 0\n",
      "Created a chunk of size 229, which is longer than the specified 0\n",
      "Created a chunk of size 258, which is longer than the specified 0\n",
      "Created a chunk of size 290, which is longer than the specified 0\n",
      "Created a chunk of size 386, which is longer than the specified 0\n",
      "Created a chunk of size 1326, which is longer than the specified 0\n",
      "Created a chunk of size 243, which is longer than the specified 0\n",
      "Created a chunk of size 897, which is longer than the specified 0\n",
      "Created a chunk of size 212, which is longer than the specified 0\n",
      "Created a chunk of size 809, which is longer than the specified 0\n",
      "Created a chunk of size 268, which is longer than the specified 0\n",
      "Created a chunk of size 226, which is longer than the specified 0\n",
      "Created a chunk of size 366, which is longer than the specified 0\n",
      "Created a chunk of size 299, which is longer than the specified 0\n",
      "Created a chunk of size 217, which is longer than the specified 0\n",
      "Created a chunk of size 242, which is longer than the specified 0\n",
      "Created a chunk of size 1307, which is longer than the specified 0\n",
      "Created a chunk of size 311, which is longer than the specified 0\n",
      "Created a chunk of size 283, which is longer than the specified 0\n",
      "Created a chunk of size 770, which is longer than the specified 0\n",
      "Created a chunk of size 223, which is longer than the specified 0\n",
      "Created a chunk of size 885, which is longer than the specified 0\n",
      "Created a chunk of size 245, which is longer than the specified 0\n",
      "Created a chunk of size 184, which is longer than the specified 0\n",
      "Created a chunk of size 293, which is longer than the specified 0\n",
      "Created a chunk of size 243, which is longer than the specified 0\n",
      "Created a chunk of size 247, which is longer than the specified 0\n",
      "Created a chunk of size 492, which is longer than the specified 0\n",
      "Created a chunk of size 337, which is longer than the specified 0\n",
      "Created a chunk of size 1191, which is longer than the specified 0\n",
      "Created a chunk of size 248, which is longer than the specified 0\n",
      "Created a chunk of size 994, which is longer than the specified 0\n",
      "Created a chunk of size 250, which is longer than the specified 0\n",
      "Created a chunk of size 224, which is longer than the specified 0\n",
      "Created a chunk of size 325, which is longer than the specified 0\n",
      "Created a chunk of size 271, which is longer than the specified 0\n",
      "Created a chunk of size 587, which is longer than the specified 0\n",
      "Created a chunk of size 724, which is longer than the specified 0\n",
      "Created a chunk of size 832, which is longer than the specified 0\n",
      "Created a chunk of size 742, which is longer than the specified 0\n",
      "Created a chunk of size 996, which is longer than the specified 0\n",
      "Created a chunk of size 285, which is longer than the specified 0\n",
      "Created a chunk of size 395, which is longer than the specified 0\n",
      "Created a chunk of size 350, which is longer than the specified 0\n",
      "Created a chunk of size 231, which is longer than the specified 0\n",
      "Created a chunk of size 273, which is longer than the specified 0\n",
      "Created a chunk of size 323, which is longer than the specified 0\n",
      "Created a chunk of size 168, which is longer than the specified 0\n",
      "Created a chunk of size 328, which is longer than the specified 0\n",
      "Created a chunk of size 450, which is longer than the specified 0\n",
      "Created a chunk of size 219, which is longer than the specified 0\n",
      "Created a chunk of size 1431, which is longer than the specified 0\n",
      "Created a chunk of size 1077, which is longer than the specified 0\n",
      "Created a chunk of size 226, which is longer than the specified 0\n",
      "Created a chunk of size 334, which is longer than the specified 0\n",
      "Created a chunk of size 1038, which is longer than the specified 0\n",
      "Created a chunk of size 235, which is longer than the specified 0\n",
      "Created a chunk of size 297, which is longer than the specified 0\n",
      "Created a chunk of size 1110, which is longer than the specified 0\n",
      "Created a chunk of size 1314, which is longer than the specified 0\n",
      "Created a chunk of size 958, which is longer than the specified 0\n",
      "Created a chunk of size 220, which is longer than the specified 0\n",
      "Created a chunk of size 310, which is longer than the specified 0\n",
      "Created a chunk of size 239, which is longer than the specified 0\n",
      "Created a chunk of size 1415, which is longer than the specified 0\n",
      "Created a chunk of size 1863, which is longer than the specified 0\n",
      "Created a chunk of size 1379, which is longer than the specified 0\n",
      "Created a chunk of size 198, which is longer than the specified 0\n",
      "Created a chunk of size 516, which is longer than the specified 0\n",
      "Created a chunk of size 501, which is longer than the specified 0\n",
      "Created a chunk of size 1519, which is longer than the specified 0\n",
      "Created a chunk of size 199, which is longer than the specified 0\n",
      "Created a chunk of size 269, which is longer than the specified 0\n",
      "Created a chunk of size 1078, which is longer than the specified 0\n",
      "Created a chunk of size 255, which is longer than the specified 0\n",
      "Created a chunk of size 226, which is longer than the specified 0\n",
      "Created a chunk of size 216, which is longer than the specified 0\n",
      "Created a chunk of size 239, which is longer than the specified 0\n",
      "Created a chunk of size 299, which is longer than the specified 0\n",
      "Created a chunk of size 1432, which is longer than the specified 0\n",
      "Created a chunk of size 759, which is longer than the specified 0\n",
      "Created a chunk of size 1246, which is longer than the specified 0\n",
      "Created a chunk of size 1549, which is longer than the specified 0\n",
      "Created a chunk of size 739, which is longer than the specified 0\n",
      "Created a chunk of size 1064, which is longer than the specified 0\n",
      "Created a chunk of size 235, which is longer than the specified 0\n",
      "Created a chunk of size 234, which is longer than the specified 0\n",
      "Created a chunk of size 223, which is longer than the specified 0\n",
      "Created a chunk of size 564, which is longer than the specified 0\n",
      "Created a chunk of size 465, which is longer than the specified 0\n",
      "Created a chunk of size 592, which is longer than the specified 0\n",
      "Created a chunk of size 289, which is longer than the specified 0\n",
      "Created a chunk of size 416, which is longer than the specified 0\n",
      "Created a chunk of size 221, which is longer than the specified 0\n",
      "Created a chunk of size 165, which is longer than the specified 0\n",
      "Created a chunk of size 252, which is longer than the specified 0\n",
      "Created a chunk of size 531, which is longer than the specified 0\n",
      "Created a chunk of size 1172, which is longer than the specified 0\n",
      "Created a chunk of size 1094, which is longer than the specified 0\n",
      "Created a chunk of size 815, which is longer than the specified 0\n",
      "Created a chunk of size 2082, which is longer than the specified 0\n",
      "Created a chunk of size 362, which is longer than the specified 0\n",
      "Created a chunk of size 271, which is longer than the specified 0\n",
      "Created a chunk of size 291, which is longer than the specified 0\n",
      "Created a chunk of size 594, which is longer than the specified 0\n",
      "Created a chunk of size 702, which is longer than the specified 0\n",
      "Created a chunk of size 604, which is longer than the specified 0\n",
      "Created a chunk of size 576, which is longer than the specified 0\n",
      "Created a chunk of size 829, which is longer than the specified 0\n",
      "Created a chunk of size 788, which is longer than the specified 0\n",
      "Created a chunk of size 797, which is longer than the specified 0\n",
      "Created a chunk of size 164, which is longer than the specified 0\n",
      "Created a chunk of size 855, which is longer than the specified 0\n",
      "Created a chunk of size 766, which is longer than the specified 0\n",
      "Created a chunk of size 164, which is longer than the specified 0\n",
      "Created a chunk of size 297, which is longer than the specified 0\n",
      "Created a chunk of size 568, which is longer than the specified 0\n",
      "Created a chunk of size 400, which is longer than the specified 0\n",
      "Created a chunk of size 557, which is longer than the specified 0\n",
      "Created a chunk of size 230, which is longer than the specified 0\n",
      "Created a chunk of size 196, which is longer than the specified 0\n",
      "Created a chunk of size 138, which is longer than the specified 0\n",
      "Created a chunk of size 487, which is longer than the specified 0\n",
      "Created a chunk of size 225, which is longer than the specified 0\n",
      "Created a chunk of size 311, which is longer than the specified 0\n",
      "Created a chunk of size 478, which is longer than the specified 0\n",
      "Created a chunk of size 621, which is longer than the specified 0\n",
      "Created a chunk of size 354, which is longer than the specified 0\n",
      "Created a chunk of size 553, which is longer than the specified 0\n",
      "Created a chunk of size 682, which is longer than the specified 0\n",
      "Created a chunk of size 1248, which is longer than the specified 0\n",
      "Created a chunk of size 209, which is longer than the specified 0\n",
      "Created a chunk of size 197, which is longer than the specified 0\n",
      "Created a chunk of size 650, which is longer than the specified 0\n",
      "Created a chunk of size 237, which is longer than the specified 0\n",
      "Created a chunk of size 369, which is longer than the specified 0\n",
      "Created a chunk of size 197, which is longer than the specified 0\n",
      "Created a chunk of size 306, which is longer than the specified 0\n",
      "Created a chunk of size 804, which is longer than the specified 0\n",
      "Created a chunk of size 357, which is longer than the specified 0\n",
      "Created a chunk of size 2297, which is longer than the specified 0\n",
      "Created a chunk of size 243, which is longer than the specified 0\n",
      "Created a chunk of size 303, which is longer than the specified 0\n",
      "Created a chunk of size 265, which is longer than the specified 0\n",
      "Created a chunk of size 901, which is longer than the specified 0\n",
      "Created a chunk of size 310, which is longer than the specified 0\n",
      "Created a chunk of size 604, which is longer than the specified 0\n",
      "Created a chunk of size 270, which is longer than the specified 0\n",
      "Created a chunk of size 988, which is longer than the specified 0\n",
      "Created a chunk of size 754, which is longer than the specified 0\n",
      "Created a chunk of size 275, which is longer than the specified 0\n",
      "Created a chunk of size 267, which is longer than the specified 0\n",
      "Created a chunk of size 778, which is longer than the specified 0\n",
      "Created a chunk of size 992, which is longer than the specified 0\n",
      "Created a chunk of size 780, which is longer than the specified 0\n",
      "Created a chunk of size 978, which is longer than the specified 0\n",
      "Created a chunk of size 984, which is longer than the specified 0\n",
      "Created a chunk of size 589, which is longer than the specified 0\n",
      "Created a chunk of size 703, which is longer than the specified 0\n",
      "Created a chunk of size 433, which is longer than the specified 0\n",
      "Created a chunk of size 690, which is longer than the specified 0\n",
      "Created a chunk of size 2071, which is longer than the specified 0\n",
      "Created a chunk of size 859, which is longer than the specified 0\n",
      "Created a chunk of size 628, which is longer than the specified 0\n",
      "Created a chunk of size 452, which is longer than the specified 0\n",
      "Created a chunk of size 349, which is longer than the specified 0\n",
      "Created a chunk of size 747, which is longer than the specified 0\n",
      "Created a chunk of size 692, which is longer than the specified 0\n",
      "Created a chunk of size 549, which is longer than the specified 0\n",
      "Created a chunk of size 620, which is longer than the specified 0\n",
      "Created a chunk of size 388, which is longer than the specified 0\n",
      "Created a chunk of size 876, which is longer than the specified 0\n",
      "Created a chunk of size 210, which is longer than the specified 0\n",
      "Created a chunk of size 235, which is longer than the specified 0\n",
      "Created a chunk of size 253, which is longer than the specified 0\n",
      "Created a chunk of size 849, which is longer than the specified 0\n",
      "Created a chunk of size 549, which is longer than the specified 0\n",
      "Created a chunk of size 363, which is longer than the specified 0\n",
      "Created a chunk of size 914, which is longer than the specified 0\n",
      "Created a chunk of size 522, which is longer than the specified 0\n",
      "Created a chunk of size 706, which is longer than the specified 0\n",
      "Created a chunk of size 315, which is longer than the specified 0\n",
      "Created a chunk of size 986, which is longer than the specified 0\n",
      "Created a chunk of size 1067, which is longer than the specified 0\n",
      "Created a chunk of size 793, which is longer than the specified 0\n",
      "Created a chunk of size 734, which is longer than the specified 0\n",
      "Created a chunk of size 772, which is longer than the specified 0\n",
      "Created a chunk of size 384, which is longer than the specified 0\n",
      "Created a chunk of size 537, which is longer than the specified 0\n",
      "Created a chunk of size 694, which is longer than the specified 0\n",
      "Created a chunk of size 760, which is longer than the specified 0\n",
      "Created a chunk of size 976, which is longer than the specified 0\n",
      "Created a chunk of size 176, which is longer than the specified 0\n",
      "Created a chunk of size 245, which is longer than the specified 0\n",
      "Created a chunk of size 356, which is longer than the specified 0\n",
      "Created a chunk of size 317, which is longer than the specified 0\n",
      "Created a chunk of size 251, which is longer than the specified 0\n",
      "Created a chunk of size 214, which is longer than the specified 0\n",
      "Created a chunk of size 233, which is longer than the specified 0\n",
      "Created a chunk of size 245, which is longer than the specified 0\n",
      "Created a chunk of size 233, which is longer than the specified 0\n",
      "Created a chunk of size 325, which is longer than the specified 0\n",
      "Created a chunk of size 170, which is longer than the specified 0\n",
      "Created a chunk of size 278, which is longer than the specified 0\n",
      "Created a chunk of size 224, which is longer than the specified 0\n",
      "Created a chunk of size 428, which is longer than the specified 0\n",
      "Created a chunk of size 241, which is longer than the specified 0\n",
      "Created a chunk of size 428, which is longer than the specified 0\n",
      "Created a chunk of size 261, which is longer than the specified 0\n",
      "Created a chunk of size 207, which is longer than the specified 0\n",
      "Created a chunk of size 237, which is longer than the specified 0\n",
      "Created a chunk of size 286, which is longer than the specified 0\n",
      "Created a chunk of size 1428, which is longer than the specified 0\n",
      "Created a chunk of size 213, which is longer than the specified 0\n",
      "Created a chunk of size 662, which is longer than the specified 0\n",
      "Created a chunk of size 207, which is longer than the specified 0\n",
      "Created a chunk of size 1017, which is longer than the specified 0\n",
      "Created a chunk of size 219, which is longer than the specified 0\n",
      "Created a chunk of size 167, which is longer than the specified 0\n",
      "Created a chunk of size 978, which is longer than the specified 0\n",
      "Created a chunk of size 218, which is longer than the specified 0\n",
      "Created a chunk of size 306, which is longer than the specified 0\n",
      "Created a chunk of size 451, which is longer than the specified 0\n",
      "Created a chunk of size 247, which is longer than the specified 0\n",
      "Created a chunk of size 794, which is longer than the specified 0\n",
      "Created a chunk of size 423, which is longer than the specified 0\n",
      "Created a chunk of size 728, which is longer than the specified 0\n",
      "Created a chunk of size 184, which is longer than the specified 0\n",
      "Created a chunk of size 286, which is longer than the specified 0\n",
      "Created a chunk of size 530, which is longer than the specified 0\n",
      "Created a chunk of size 185, which is longer than the specified 0\n",
      "Created a chunk of size 241, which is longer than the specified 0\n",
      "Created a chunk of size 159, which is longer than the specified 0\n",
      "Created a chunk of size 246, which is longer than the specified 0\n",
      "Created a chunk of size 210, which is longer than the specified 0\n",
      "Created a chunk of size 313, which is longer than the specified 0\n",
      "Created a chunk of size 251, which is longer than the specified 0\n",
      "Created a chunk of size 285, which is longer than the specified 0\n",
      "Created a chunk of size 257, which is longer than the specified 0\n",
      "Created a chunk of size 242, which is longer than the specified 0\n",
      "Created a chunk of size 229, which is longer than the specified 0\n",
      "Created a chunk of size 255, which is longer than the specified 0\n",
      "Created a chunk of size 262, which is longer than the specified 0\n",
      "Created a chunk of size 468, which is longer than the specified 0\n",
      "Created a chunk of size 420, which is longer than the specified 0\n",
      "Created a chunk of size 209, which is longer than the specified 0\n",
      "Created a chunk of size 173, which is longer than the specified 0\n",
      "Created a chunk of size 230, which is longer than the specified 0\n",
      "Created a chunk of size 1739, which is longer than the specified 0\n",
      "Created a chunk of size 1086, which is longer than the specified 0\n",
      "Created a chunk of size 264, which is longer than the specified 0\n",
      "Created a chunk of size 1261, which is longer than the specified 0\n",
      "Created a chunk of size 2021, which is longer than the specified 0\n",
      "Created a chunk of size 1077, which is longer than the specified 0\n",
      "Created a chunk of size 2022, which is longer than the specified 0\n",
      "Created a chunk of size 996, which is longer than the specified 0\n",
      "Created a chunk of size 166, which is longer than the specified 0\n",
      "Created a chunk of size 1267, which is longer than the specified 0\n",
      "Created a chunk of size 1294, which is longer than the specified 0\n",
      "Created a chunk of size 1250, which is longer than the specified 0\n",
      "Created a chunk of size 1143, which is longer than the specified 0\n",
      "Created a chunk of size 1406, which is longer than the specified 0\n",
      "Created a chunk of size 1395, which is longer than the specified 0\n",
      "Created a chunk of size 1533, which is longer than the specified 0\n",
      "Created a chunk of size 1344, which is longer than the specified 0\n",
      "Created a chunk of size 1435, which is longer than the specified 0\n",
      "Created a chunk of size 1145, which is longer than the specified 0\n",
      "Created a chunk of size 1219, which is longer than the specified 0\n",
      "Created a chunk of size 1321, which is longer than the specified 0\n",
      "Created a chunk of size 1442, which is longer than the specified 0\n",
      "Created a chunk of size 262, which is longer than the specified 0\n",
      "Created a chunk of size 261, which is longer than the specified 0\n",
      "Created a chunk of size 358, which is longer than the specified 0\n",
      "Created a chunk of size 308, which is longer than the specified 0\n",
      "Created a chunk of size 306, which is longer than the specified 0\n",
      "Created a chunk of size 596, which is longer than the specified 0\n",
      "Created a chunk of size 762, which is longer than the specified 0\n",
      "Created a chunk of size 248, which is longer than the specified 0\n",
      "Created a chunk of size 269, which is longer than the specified 0\n",
      "Created a chunk of size 338, which is longer than the specified 0\n",
      "Created a chunk of size 244, which is longer than the specified 0\n",
      "Created a chunk of size 358, which is longer than the specified 0\n",
      "Created a chunk of size 358, which is longer than the specified 0\n",
      "Created a chunk of size 362, which is longer than the specified 0\n",
      "Created a chunk of size 377, which is longer than the specified 0\n",
      "Created a chunk of size 1625, which is longer than the specified 0\n",
      "Created a chunk of size 901, which is longer than the specified 0\n",
      "Created a chunk of size 302, which is longer than the specified 0\n",
      "Created a chunk of size 417, which is longer than the specified 0\n",
      "Created a chunk of size 266, which is longer than the specified 0\n",
      "Created a chunk of size 247, which is longer than the specified 0\n",
      "Created a chunk of size 246, which is longer than the specified 0\n",
      "Created a chunk of size 218, which is longer than the specified 0\n",
      "Created a chunk of size 243, which is longer than the specified 0\n",
      "Created a chunk of size 300, which is longer than the specified 0\n",
      "Created a chunk of size 1162, which is longer than the specified 0\n",
      "Created a chunk of size 180, which is longer than the specified 0\n",
      "Created a chunk of size 310, which is longer than the specified 0\n",
      "Created a chunk of size 277, which is longer than the specified 0\n",
      "Created a chunk of size 254, which is longer than the specified 0\n",
      "Created a chunk of size 264, which is longer than the specified 0\n",
      "Created a chunk of size 314, which is longer than the specified 0\n",
      "Created a chunk of size 262, which is longer than the specified 0\n",
      "Created a chunk of size 176, which is longer than the specified 0\n",
      "Created a chunk of size 209, which is longer than the specified 0\n",
      "Created a chunk of size 253, which is longer than the specified 0\n",
      "Created a chunk of size 971, which is longer than the specified 0\n",
      "Created a chunk of size 298, which is longer than the specified 0\n",
      "Created a chunk of size 1333, which is longer than the specified 0\n",
      "Created a chunk of size 1154, which is longer than the specified 0\n",
      "Created a chunk of size 2372, which is longer than the specified 0\n",
      "Created a chunk of size 374, which is longer than the specified 0\n",
      "Created a chunk of size 631, which is longer than the specified 0\n",
      "Created a chunk of size 294, which is longer than the specified 0\n",
      "Created a chunk of size 862, which is longer than the specified 0\n",
      "Created a chunk of size 183, which is longer than the specified 0\n",
      "Created a chunk of size 295, which is longer than the specified 0\n",
      "Created a chunk of size 301, which is longer than the specified 0\n",
      "Created a chunk of size 193, which is longer than the specified 0\n",
      "Created a chunk of size 266, which is longer than the specified 0\n",
      "Created a chunk of size 593, which is longer than the specified 0\n",
      "Created a chunk of size 278, which is longer than the specified 0\n",
      "Created a chunk of size 209, which is longer than the specified 0\n",
      "Created a chunk of size 227, which is longer than the specified 0\n",
      "Created a chunk of size 230, which is longer than the specified 0\n",
      "Created a chunk of size 289, which is longer than the specified 0\n",
      "Created a chunk of size 343, which is longer than the specified 0\n",
      "Created a chunk of size 270, which is longer than the specified 0\n",
      "Created a chunk of size 270, which is longer than the specified 0\n",
      "Created a chunk of size 1679, which is longer than the specified 0\n",
      "Created a chunk of size 373, which is longer than the specified 0\n",
      "Created a chunk of size 247, which is longer than the specified 0\n",
      "Created a chunk of size 229, which is longer than the specified 0\n",
      "Created a chunk of size 257, which is longer than the specified 0\n",
      "Created a chunk of size 342, which is longer than the specified 0\n",
      "Created a chunk of size 214, which is longer than the specified 0\n",
      "Created a chunk of size 236, which is longer than the specified 0\n",
      "Created a chunk of size 222, which is longer than the specified 0\n",
      "Created a chunk of size 309, which is longer than the specified 0\n",
      "Created a chunk of size 382, which is longer than the specified 0\n",
      "Created a chunk of size 321, which is longer than the specified 0\n",
      "Created a chunk of size 280, which is longer than the specified 0\n",
      "Created a chunk of size 250, which is longer than the specified 0\n",
      "Created a chunk of size 256, which is longer than the specified 0\n",
      "Created a chunk of size 395, which is longer than the specified 0\n",
      "Created a chunk of size 310, which is longer than the specified 0\n",
      "Created a chunk of size 996, which is longer than the specified 0\n",
      "Created a chunk of size 1107, which is longer than the specified 0\n",
      "Created a chunk of size 1193, which is longer than the specified 0\n",
      "Created a chunk of size 236, which is longer than the specified 0\n",
      "Created a chunk of size 211, which is longer than the specified 0\n",
      "Created a chunk of size 269, which is longer than the specified 0\n",
      "Created a chunk of size 210, which is longer than the specified 0\n",
      "Created a chunk of size 293, which is longer than the specified 0\n",
      "Created a chunk of size 281, which is longer than the specified 0\n",
      "Created a chunk of size 257, which is longer than the specified 0\n",
      "Created a chunk of size 749, which is longer than the specified 0\n",
      "Created a chunk of size 217, which is longer than the specified 0\n",
      "Created a chunk of size 255, which is longer than the specified 0\n",
      "Created a chunk of size 271, which is longer than the specified 0\n",
      "Created a chunk of size 222, which is longer than the specified 0\n",
      "Created a chunk of size 374, which is longer than the specified 0\n",
      "Created a chunk of size 197, which is longer than the specified 0\n",
      "Created a chunk of size 197, which is longer than the specified 0\n",
      "Created a chunk of size 197, which is longer than the specified 0\n",
      "Created a chunk of size 200, which is longer than the specified 0\n",
      "Created a chunk of size 322, which is longer than the specified 0\n",
      "Created a chunk of size 236, which is longer than the specified 0\n",
      "Created a chunk of size 905, which is longer than the specified 0\n",
      "Created a chunk of size 714, which is longer than the specified 0\n",
      "Created a chunk of size 1334, which is longer than the specified 0\n",
      "Created a chunk of size 914, which is longer than the specified 0\n",
      "Created a chunk of size 191, which is longer than the specified 0\n",
      "Created a chunk of size 605, which is longer than the specified 0\n",
      "Created a chunk of size 1307, which is longer than the specified 0\n",
      "Created a chunk of size 378, which is longer than the specified 0\n",
      "Created a chunk of size 1144, which is longer than the specified 0\n",
      "Created a chunk of size 225, which is longer than the specified 0\n",
      "Created a chunk of size 343, which is longer than the specified 0\n",
      "Created a chunk of size 218, which is longer than the specified 0\n",
      "Created a chunk of size 316, which is longer than the specified 0\n",
      "Created a chunk of size 243, which is longer than the specified 0\n",
      "Created a chunk of size 211, which is longer than the specified 0\n",
      "Created a chunk of size 305, which is longer than the specified 0\n",
      "Created a chunk of size 241, which is longer than the specified 0\n",
      "Created a chunk of size 156, which is longer than the specified 0\n",
      "Created a chunk of size 244, which is longer than the specified 0\n",
      "Created a chunk of size 1053, which is longer than the specified 0\n",
      "Created a chunk of size 304, which is longer than the specified 0\n",
      "Created a chunk of size 208, which is longer than the specified 0\n",
      "Created a chunk of size 927, which is longer than the specified 0\n",
      "Created a chunk of size 347, which is longer than the specified 0\n",
      "Created a chunk of size 279, which is longer than the specified 0\n",
      "Created a chunk of size 265, which is longer than the specified 0\n",
      "Created a chunk of size 261, which is longer than the specified 0\n",
      "Created a chunk of size 342, which is longer than the specified 0\n",
      "Created a chunk of size 333, which is longer than the specified 0\n",
      "Created a chunk of size 270, which is longer than the specified 0\n",
      "Created a chunk of size 466, which is longer than the specified 0\n",
      "Created a chunk of size 277, which is longer than the specified 0\n",
      "Created a chunk of size 405, which is longer than the specified 0\n",
      "Created a chunk of size 413, which is longer than the specified 0\n",
      "Created a chunk of size 407, which is longer than the specified 0\n",
      "Created a chunk of size 297, which is longer than the specified 0\n",
      "Created a chunk of size 477, which is longer than the specified 0\n",
      "Created a chunk of size 302, which is longer than the specified 0\n",
      "Created a chunk of size 417, which is longer than the specified 0\n",
      "Created a chunk of size 654, which is longer than the specified 0\n",
      "Created a chunk of size 770, which is longer than the specified 0\n",
      "Created a chunk of size 554, which is longer than the specified 0\n",
      "Created a chunk of size 492, which is longer than the specified 0\n",
      "Created a chunk of size 223, which is longer than the specified 0\n",
      "Created a chunk of size 191, which is longer than the specified 0\n",
      "Created a chunk of size 241, which is longer than the specified 0\n",
      "Created a chunk of size 230, which is longer than the specified 0\n",
      "Created a chunk of size 360, which is longer than the specified 0\n",
      "Created a chunk of size 451, which is longer than the specified 0\n",
      "Created a chunk of size 269, which is longer than the specified 0\n",
      "Created a chunk of size 244, which is longer than the specified 0\n",
      "Created a chunk of size 261, which is longer than the specified 0\n",
      "Created a chunk of size 186, which is longer than the specified 0\n",
      "Created a chunk of size 872, which is longer than the specified 0\n",
      "Created a chunk of size 260, which is longer than the specified 0\n",
      "Created a chunk of size 646, which is longer than the specified 0\n",
      "Created a chunk of size 1015, which is longer than the specified 0\n",
      "Created a chunk of size 189, which is longer than the specified 0\n",
      "Created a chunk of size 520, which is longer than the specified 0\n",
      "Created a chunk of size 332, which is longer than the specified 0\n",
      "Created a chunk of size 636, which is longer than the specified 0\n",
      "Created a chunk of size 1060, which is longer than the specified 0\n",
      "Created a chunk of size 299, which is longer than the specified 0\n",
      "Created a chunk of size 237, which is longer than the specified 0\n",
      "Created a chunk of size 302, which is longer than the specified 0\n",
      "Created a chunk of size 316, which is longer than the specified 0\n",
      "Created a chunk of size 217, which is longer than the specified 0\n",
      "Created a chunk of size 175, which is longer than the specified 0\n",
      "Created a chunk of size 174, which is longer than the specified 0\n",
      "Created a chunk of size 330, which is longer than the specified 0\n",
      "Created a chunk of size 185, which is longer than the specified 0\n",
      "Created a chunk of size 207, which is longer than the specified 0\n",
      "Created a chunk of size 238, which is longer than the specified 0\n",
      "Created a chunk of size 1162, which is longer than the specified 0\n",
      "Created a chunk of size 539, which is longer than the specified 0\n",
      "Created a chunk of size 978, which is longer than the specified 0\n",
      "Created a chunk of size 780, which is longer than the specified 0\n",
      "Created a chunk of size 816, which is longer than the specified 0\n",
      "Created a chunk of size 1069, which is longer than the specified 0\n",
      "Created a chunk of size 217, which is longer than the specified 0\n",
      "Created a chunk of size 212, which is longer than the specified 0\n",
      "Created a chunk of size 241, which is longer than the specified 0\n",
      "Created a chunk of size 192, which is longer than the specified 0\n",
      "Created a chunk of size 166, which is longer than the specified 0\n",
      "Created a chunk of size 288, which is longer than the specified 0\n",
      "Created a chunk of size 362, which is longer than the specified 0\n",
      "Created a chunk of size 230, which is longer than the specified 0\n",
      "Created a chunk of size 586, which is longer than the specified 0\n",
      "Created a chunk of size 279, which is longer than the specified 0\n",
      "Created a chunk of size 372, which is longer than the specified 0\n",
      "Created a chunk of size 352, which is longer than the specified 0\n",
      "Created a chunk of size 286, which is longer than the specified 0\n",
      "Created a chunk of size 1981, which is longer than the specified 0\n",
      "Created a chunk of size 290, which is longer than the specified 0\n",
      "Created a chunk of size 980, which is longer than the specified 0\n",
      "Created a chunk of size 842, which is longer than the specified 0\n",
      "Created a chunk of size 314, which is longer than the specified 0\n",
      "Created a chunk of size 445, which is longer than the specified 0\n",
      "Created a chunk of size 344, which is longer than the specified 0\n",
      "Created a chunk of size 186, which is longer than the specified 0\n",
      "Created a chunk of size 163, which is longer than the specified 0\n",
      "Created a chunk of size 209, which is longer than the specified 0\n",
      "Created a chunk of size 240, which is longer than the specified 0\n",
      "Created a chunk of size 215, which is longer than the specified 0\n",
      "Created a chunk of size 275, which is longer than the specified 0\n",
      "Created a chunk of size 282, which is longer than the specified 0\n",
      "Created a chunk of size 1106, which is longer than the specified 0\n",
      "Created a chunk of size 247, which is longer than the specified 0\n",
      "Created a chunk of size 207, which is longer than the specified 0\n",
      "Created a chunk of size 500, which is longer than the specified 0\n",
      "Created a chunk of size 278, which is longer than the specified 0\n",
      "Created a chunk of size 245, which is longer than the specified 0\n",
      "Created a chunk of size 211, which is longer than the specified 0\n",
      "Created a chunk of size 182, which is longer than the specified 0\n",
      "Created a chunk of size 277, which is longer than the specified 0\n",
      "Created a chunk of size 864, which is longer than the specified 0\n",
      "Created a chunk of size 178, which is longer than the specified 0\n",
      "Created a chunk of size 383, which is longer than the specified 0\n",
      "Created a chunk of size 296, which is longer than the specified 0\n",
      "Created a chunk of size 681, which is longer than the specified 0\n",
      "Created a chunk of size 392, which is longer than the specified 0\n",
      "Created a chunk of size 1627, which is longer than the specified 0\n",
      "Created a chunk of size 603, which is longer than the specified 0\n",
      "Created a chunk of size 918, which is longer than the specified 0\n",
      "Created a chunk of size 283, which is longer than the specified 0\n",
      "Created a chunk of size 1297, which is longer than the specified 0\n",
      "Created a chunk of size 934, which is longer than the specified 0\n",
      "Created a chunk of size 220, which is longer than the specified 0\n",
      "Created a chunk of size 1745, which is longer than the specified 0\n",
      "Created a chunk of size 1070, which is longer than the specified 0\n",
      "Created a chunk of size 348, which is longer than the specified 0\n",
      "Created a chunk of size 156, which is longer than the specified 0\n",
      "Created a chunk of size 252, which is longer than the specified 0\n",
      "Created a chunk of size 228, which is longer than the specified 0\n",
      "Created a chunk of size 243, which is longer than the specified 0\n",
      "Created a chunk of size 915, which is longer than the specified 0\n",
      "Created a chunk of size 1086, which is longer than the specified 0\n",
      "Created a chunk of size 1024, which is longer than the specified 0\n",
      "Created a chunk of size 165, which is longer than the specified 0\n",
      "Created a chunk of size 198, which is longer than the specified 0\n",
      "Created a chunk of size 195, which is longer than the specified 0\n",
      "Created a chunk of size 264, which is longer than the specified 0\n",
      "Created a chunk of size 189, which is longer than the specified 0\n",
      "Created a chunk of size 1201, which is longer than the specified 0\n",
      "Created a chunk of size 369, which is longer than the specified 0\n",
      "Created a chunk of size 196, which is longer than the specified 0\n",
      "Created a chunk of size 867, which is longer than the specified 0\n",
      "Created a chunk of size 214, which is longer than the specified 0\n",
      "Created a chunk of size 244, which is longer than the specified 0\n",
      "Created a chunk of size 242, which is longer than the specified 0\n",
      "Created a chunk of size 309, which is longer than the specified 0\n",
      "Created a chunk of size 359, which is longer than the specified 0\n",
      "Created a chunk of size 269, which is longer than the specified 0\n",
      "Created a chunk of size 344, which is longer than the specified 0\n",
      "Created a chunk of size 261, which is longer than the specified 0\n",
      "Created a chunk of size 162, which is longer than the specified 0\n",
      "Created a chunk of size 210, which is longer than the specified 0\n",
      "Created a chunk of size 161, which is longer than the specified 0\n",
      "Created a chunk of size 370, which is longer than the specified 0\n",
      "Created a chunk of size 174, which is longer than the specified 0\n",
      "Created a chunk of size 1722, which is longer than the specified 0\n",
      "Created a chunk of size 1057, which is longer than the specified 0\n",
      "Created a chunk of size 362, which is longer than the specified 0\n",
      "Created a chunk of size 383, which is longer than the specified 0\n",
      "Created a chunk of size 1528, which is longer than the specified 0\n",
      "Created a chunk of size 876, which is longer than the specified 0\n",
      "Created a chunk of size 311, which is longer than the specified 0\n",
      "Created a chunk of size 263, which is longer than the specified 0\n",
      "Created a chunk of size 264, which is longer than the specified 0\n",
      "Created a chunk of size 580, which is longer than the specified 0\n",
      "Created a chunk of size 869, which is longer than the specified 0\n",
      "Created a chunk of size 239, which is longer than the specified 0\n",
      "Created a chunk of size 256, which is longer than the specified 0\n",
      "Created a chunk of size 1032, which is longer than the specified 0\n",
      "Created a chunk of size 976, which is longer than the specified 0\n",
      "Created a chunk of size 297, which is longer than the specified 0\n",
      "Created a chunk of size 477, which is longer than the specified 0\n",
      "Created a chunk of size 295, which is longer than the specified 0\n",
      "Created a chunk of size 214, which is longer than the specified 0\n",
      "Created a chunk of size 241, which is longer than the specified 0\n",
      "Created a chunk of size 378, which is longer than the specified 0\n",
      "Created a chunk of size 323, which is longer than the specified 0\n",
      "Created a chunk of size 295, which is longer than the specified 0\n",
      "Created a chunk of size 577, which is longer than the specified 0\n",
      "Created a chunk of size 754, which is longer than the specified 0\n",
      "Created a chunk of size 365, which is longer than the specified 0\n",
      "Created a chunk of size 191, which is longer than the specified 0\n",
      "Created a chunk of size 1327, which is longer than the specified 0\n",
      "Created a chunk of size 249, which is longer than the specified 0\n",
      "Created a chunk of size 199, which is longer than the specified 0\n",
      "Created a chunk of size 269, which is longer than the specified 0\n",
      "Created a chunk of size 269, which is longer than the specified 0\n",
      "Created a chunk of size 585, which is longer than the specified 0\n",
      "Created a chunk of size 579, which is longer than the specified 0\n",
      "Created a chunk of size 195, which is longer than the specified 0\n",
      "Created a chunk of size 159, which is longer than the specified 0\n",
      "Created a chunk of size 865, which is longer than the specified 0\n",
      "Created a chunk of size 265, which is longer than the specified 0\n",
      "Created a chunk of size 299, which is longer than the specified 0\n",
      "Created a chunk of size 767, which is longer than the specified 0\n",
      "Created a chunk of size 527, which is longer than the specified 0\n",
      "Created a chunk of size 1001, which is longer than the specified 0\n",
      "Created a chunk of size 1174, which is longer than the specified 0\n",
      "Created a chunk of size 861, which is longer than the specified 0\n",
      "Created a chunk of size 310, which is longer than the specified 0\n",
      "Created a chunk of size 231, which is longer than the specified 0\n",
      "Created a chunk of size 235, which is longer than the specified 0\n",
      "Created a chunk of size 221, which is longer than the specified 0\n",
      "Created a chunk of size 399, which is longer than the specified 0\n",
      "Created a chunk of size 181, which is longer than the specified 0\n",
      "Created a chunk of size 683, which is longer than the specified 0\n",
      "Created a chunk of size 475, which is longer than the specified 0\n",
      "Created a chunk of size 1382, which is longer than the specified 0\n",
      "Created a chunk of size 311, which is longer than the specified 0\n",
      "Created a chunk of size 182, which is longer than the specified 0\n",
      "Created a chunk of size 251, which is longer than the specified 0\n",
      "Created a chunk of size 366, which is longer than the specified 0\n",
      "Created a chunk of size 299, which is longer than the specified 0\n",
      "Created a chunk of size 166, which is longer than the specified 0\n",
      "Created a chunk of size 430, which is longer than the specified 0\n",
      "Created a chunk of size 177, which is longer than the specified 0\n",
      "Created a chunk of size 200, which is longer than the specified 0\n",
      "Created a chunk of size 784, which is longer than the specified 0\n",
      "Created a chunk of size 426, which is longer than the specified 0\n",
      "Created a chunk of size 776, which is longer than the specified 0\n",
      "Created a chunk of size 355, which is longer than the specified 0\n",
      "Created a chunk of size 194, which is longer than the specified 0\n",
      "Created a chunk of size 842, which is longer than the specified 0\n",
      "Created a chunk of size 995, which is longer than the specified 0\n",
      "Created a chunk of size 327, which is longer than the specified 0\n",
      "Created a chunk of size 197, which is longer than the specified 0\n",
      "Created a chunk of size 301, which is longer than the specified 0\n",
      "Created a chunk of size 219, which is longer than the specified 0\n",
      "Created a chunk of size 448, which is longer than the specified 0\n",
      "Created a chunk of size 179, which is longer than the specified 0\n",
      "Created a chunk of size 279, which is longer than the specified 0\n",
      "Created a chunk of size 332, which is longer than the specified 0\n",
      "Created a chunk of size 193, which is longer than the specified 0\n",
      "Created a chunk of size 299, which is longer than the specified 0\n",
      "Created a chunk of size 277, which is longer than the specified 0\n",
      "Created a chunk of size 2351, which is longer than the specified 0\n",
      "Created a chunk of size 199, which is longer than the specified 0\n",
      "Created a chunk of size 377, which is longer than the specified 0\n",
      "Created a chunk of size 224, which is longer than the specified 0\n",
      "Created a chunk of size 465, which is longer than the specified 0\n",
      "Created a chunk of size 546, which is longer than the specified 0\n",
      "Created a chunk of size 283, which is longer than the specified 0\n",
      "Created a chunk of size 237, which is longer than the specified 0\n",
      "Created a chunk of size 241, which is longer than the specified 0\n",
      "Created a chunk of size 277, which is longer than the specified 0\n",
      "Created a chunk of size 195, which is longer than the specified 0\n",
      "Created a chunk of size 205, which is longer than the specified 0\n",
      "Created a chunk of size 210, which is longer than the specified 0\n",
      "Created a chunk of size 250, which is longer than the specified 0\n",
      "Created a chunk of size 879, which is longer than the specified 0\n",
      "Created a chunk of size 901, which is longer than the specified 0\n",
      "Created a chunk of size 380, which is longer than the specified 0\n",
      "Created a chunk of size 197, which is longer than the specified 0\n",
      "Created a chunk of size 326, which is longer than the specified 0\n",
      "Created a chunk of size 226, which is longer than the specified 0\n",
      "Created a chunk of size 210, which is longer than the specified 0\n",
      "Created a chunk of size 348, which is longer than the specified 0\n",
      "Created a chunk of size 263, which is longer than the specified 0\n",
      "Created a chunk of size 221, which is longer than the specified 0\n",
      "Created a chunk of size 260, which is longer than the specified 0\n",
      "Created a chunk of size 217, which is longer than the specified 0\n",
      "Created a chunk of size 386, which is longer than the specified 0\n",
      "Created a chunk of size 195, which is longer than the specified 0\n",
      "Created a chunk of size 250, which is longer than the specified 0\n",
      "Created a chunk of size 307, which is longer than the specified 0\n",
      "Created a chunk of size 267, which is longer than the specified 0\n",
      "Created a chunk of size 302, which is longer than the specified 0\n",
      "Created a chunk of size 237, which is longer than the specified 0\n",
      "Created a chunk of size 240, which is longer than the specified 0\n",
      "Created a chunk of size 277, which is longer than the specified 0\n",
      "Created a chunk of size 203, which is longer than the specified 0\n",
      "Created a chunk of size 228, which is longer than the specified 0\n",
      "Created a chunk of size 217, which is longer than the specified 0\n",
      "Created a chunk of size 438, which is longer than the specified 0\n",
      "Created a chunk of size 340, which is longer than the specified 0\n",
      "Created a chunk of size 353, which is longer than the specified 0\n",
      "Created a chunk of size 354, which is longer than the specified 0\n",
      "Created a chunk of size 272, which is longer than the specified 0\n",
      "Created a chunk of size 210, which is longer than the specified 0\n",
      "Created a chunk of size 272, which is longer than the specified 0\n",
      "Created a chunk of size 275, which is longer than the specified 0\n",
      "Created a chunk of size 303, which is longer than the specified 0\n",
      "Created a chunk of size 266, which is longer than the specified 0\n",
      "Created a chunk of size 232, which is longer than the specified 0\n",
      "Created a chunk of size 289, which is longer than the specified 0\n",
      "Created a chunk of size 273, which is longer than the specified 0\n",
      "Created a chunk of size 243, which is longer than the specified 0\n",
      "Created a chunk of size 239, which is longer than the specified 0\n",
      "Created a chunk of size 264, which is longer than the specified 0\n",
      "Created a chunk of size 390, which is longer than the specified 0\n",
      "Created a chunk of size 350, which is longer than the specified 0\n",
      "Created a chunk of size 295, which is longer than the specified 0\n",
      "Created a chunk of size 208, which is longer than the specified 0\n",
      "Created a chunk of size 204, which is longer than the specified 0\n",
      "Created a chunk of size 384, which is longer than the specified 0\n",
      "Created a chunk of size 1850, which is longer than the specified 0\n",
      "Created a chunk of size 1280, which is longer than the specified 0\n",
      "Created a chunk of size 886, which is longer than the specified 0\n",
      "Created a chunk of size 1392, which is longer than the specified 0\n",
      "Created a chunk of size 979, which is longer than the specified 0\n",
      "Created a chunk of size 1432, which is longer than the specified 0\n",
      "Created a chunk of size 348, which is longer than the specified 0\n",
      "Created a chunk of size 233, which is longer than the specified 0\n",
      "Created a chunk of size 200, which is longer than the specified 0\n",
      "Created a chunk of size 228, which is longer than the specified 0\n",
      "Created a chunk of size 776, which is longer than the specified 0\n",
      "Created a chunk of size 727, which is longer than the specified 0\n",
      "Created a chunk of size 362, which is longer than the specified 0\n",
      "Created a chunk of size 284, which is longer than the specified 0\n",
      "Created a chunk of size 178, which is longer than the specified 0\n",
      "Created a chunk of size 1526, which is longer than the specified 0\n",
      "Created a chunk of size 351, which is longer than the specified 0\n",
      "Created a chunk of size 1193, which is longer than the specified 0\n",
      "Created a chunk of size 1186, which is longer than the specified 0\n",
      "Created a chunk of size 1299, which is longer than the specified 0\n",
      "Created a chunk of size 252, which is longer than the specified 0\n",
      "Created a chunk of size 340, which is longer than the specified 0\n",
      "Created a chunk of size 310, which is longer than the specified 0\n",
      "Created a chunk of size 260, which is longer than the specified 0\n",
      "Created a chunk of size 260, which is longer than the specified 0\n",
      "Created a chunk of size 293, which is longer than the specified 0\n",
      "Created a chunk of size 264, which is longer than the specified 0\n",
      "Created a chunk of size 311, which is longer than the specified 0\n",
      "Created a chunk of size 1093, which is longer than the specified 0\n",
      "Created a chunk of size 1097, which is longer than the specified 0\n",
      "Created a chunk of size 305, which is longer than the specified 0\n",
      "Created a chunk of size 953, which is longer than the specified 0\n",
      "Created a chunk of size 1069, which is longer than the specified 0\n",
      "Created a chunk of size 1100, which is longer than the specified 0\n",
      "Created a chunk of size 1262, which is longer than the specified 0\n",
      "Created a chunk of size 917, which is longer than the specified 0\n",
      "Created a chunk of size 1222, which is longer than the specified 0\n",
      "Created a chunk of size 1034, which is longer than the specified 0\n",
      "Created a chunk of size 1283, which is longer than the specified 0\n",
      "Created a chunk of size 1328, which is longer than the specified 0\n",
      "Created a chunk of size 402, which is longer than the specified 0\n",
      "Created a chunk of size 342, which is longer than the specified 0\n",
      "Created a chunk of size 262, which is longer than the specified 0\n",
      "Created a chunk of size 262, which is longer than the specified 0\n",
      "Created a chunk of size 262, which is longer than the specified 0\n",
      "Created a chunk of size 262, which is longer than the specified 0\n",
      "Created a chunk of size 262, which is longer than the specified 0\n",
      "Created a chunk of size 261, which is longer than the specified 0\n",
      "Created a chunk of size 262, which is longer than the specified 0\n",
      "Created a chunk of size 260, which is longer than the specified 0\n",
      "Created a chunk of size 418, which is longer than the specified 0\n",
      "Created a chunk of size 1789, which is longer than the specified 0\n",
      "Created a chunk of size 216, which is longer than the specified 0\n",
      "Created a chunk of size 269, which is longer than the specified 0\n",
      "Created a chunk of size 221, which is longer than the specified 0\n",
      "Created a chunk of size 288, which is longer than the specified 0\n",
      "Created a chunk of size 148, which is longer than the specified 0\n",
      "Created a chunk of size 176, which is longer than the specified 0\n",
      "Created a chunk of size 242, which is longer than the specified 0\n",
      "Created a chunk of size 225, which is longer than the specified 0\n",
      "Created a chunk of size 211, which is longer than the specified 0\n",
      "Created a chunk of size 294, which is longer than the specified 0\n",
      "Created a chunk of size 1476, which is longer than the specified 0\n",
      "Created a chunk of size 254, which is longer than the specified 0\n",
      "Created a chunk of size 394, which is longer than the specified 0\n",
      "Created a chunk of size 861, which is longer than the specified 0\n",
      "Created a chunk of size 915, which is longer than the specified 0\n",
      "Created a chunk of size 861, which is longer than the specified 0\n",
      "Created a chunk of size 222, which is longer than the specified 0\n",
      "Created a chunk of size 466, which is longer than the specified 0\n",
      "Created a chunk of size 925, which is longer than the specified 0\n",
      "Created a chunk of size 686, which is longer than the specified 0\n",
      "Created a chunk of size 466, which is longer than the specified 0\n",
      "Created a chunk of size 1654, which is longer than the specified 0\n",
      "Created a chunk of size 936, which is longer than the specified 0\n",
      "Created a chunk of size 281, which is longer than the specified 0\n",
      "Created a chunk of size 374, which is longer than the specified 0\n",
      "Created a chunk of size 347, which is longer than the specified 0\n",
      "Created a chunk of size 359, which is longer than the specified 0\n",
      "Created a chunk of size 195, which is longer than the specified 0\n",
      "Created a chunk of size 293, which is longer than the specified 0\n",
      "Created a chunk of size 542, which is longer than the specified 0\n",
      "Created a chunk of size 195, which is longer than the specified 0\n",
      "Created a chunk of size 264, which is longer than the specified 0\n",
      "Created a chunk of size 1354, which is longer than the specified 0\n",
      "Created a chunk of size 1060, which is longer than the specified 0\n",
      "Created a chunk of size 677, which is longer than the specified 0\n",
      "Created a chunk of size 229, which is longer than the specified 0\n",
      "Created a chunk of size 260, which is longer than the specified 0\n",
      "Created a chunk of size 229, which is longer than the specified 0\n",
      "Created a chunk of size 167, which is longer than the specified 0\n",
      "Created a chunk of size 352, which is longer than the specified 0\n",
      "Created a chunk of size 170, which is longer than the specified 0\n",
      "Created a chunk of size 343, which is longer than the specified 0\n",
      "Created a chunk of size 185, which is longer than the specified 0\n",
      "Created a chunk of size 423, which is longer than the specified 0\n",
      "Created a chunk of size 259, which is longer than the specified 0\n",
      "Created a chunk of size 299, which is longer than the specified 0\n",
      "Created a chunk of size 162, which is longer than the specified 0\n",
      "Created a chunk of size 166, which is longer than the specified 0\n",
      "Created a chunk of size 261, which is longer than the specified 0\n",
      "Created a chunk of size 232, which is longer than the specified 0\n",
      "Created a chunk of size 239, which is longer than the specified 0\n",
      "Created a chunk of size 291, which is longer than the specified 0\n",
      "Created a chunk of size 171, which is longer than the specified 0\n",
      "Created a chunk of size 289, which is longer than the specified 0\n",
      "Created a chunk of size 197, which is longer than the specified 0\n",
      "Created a chunk of size 149, which is longer than the specified 0\n",
      "Created a chunk of size 232, which is longer than the specified 0\n",
      "Created a chunk of size 379, which is longer than the specified 0\n",
      "Created a chunk of size 168, which is longer than the specified 0\n",
      "Created a chunk of size 184, which is longer than the specified 0\n",
      "Created a chunk of size 181, which is longer than the specified 0\n",
      "Created a chunk of size 163, which is longer than the specified 0\n",
      "Created a chunk of size 224, which is longer than the specified 0\n",
      "Created a chunk of size 193, which is longer than the specified 0\n",
      "Created a chunk of size 197, which is longer than the specified 0\n",
      "Created a chunk of size 326, which is longer than the specified 0\n",
      "Created a chunk of size 276, which is longer than the specified 0\n",
      "Created a chunk of size 276, which is longer than the specified 0\n",
      "Created a chunk of size 234, which is longer than the specified 0\n",
      "Created a chunk of size 236, which is longer than the specified 0\n",
      "Created a chunk of size 729, which is longer than the specified 0\n",
      "Created a chunk of size 187, which is longer than the specified 0\n",
      "Created a chunk of size 204, which is longer than the specified 0\n",
      "Created a chunk of size 661, which is longer than the specified 0\n",
      "Created a chunk of size 204, which is longer than the specified 0\n",
      "Created a chunk of size 569, which is longer than the specified 0\n",
      "Created a chunk of size 221, which is longer than the specified 0\n",
      "Created a chunk of size 545, which is longer than the specified 0\n",
      "Created a chunk of size 238, which is longer than the specified 0\n",
      "Created a chunk of size 187, which is longer than the specified 0\n",
      "Created a chunk of size 935, which is longer than the specified 0\n",
      "Created a chunk of size 302, which is longer than the specified 0\n",
      "Created a chunk of size 403, which is longer than the specified 0\n",
      "Created a chunk of size 339, which is longer than the specified 0\n",
      "Created a chunk of size 177, which is longer than the specified 0\n",
      "Created a chunk of size 229, which is longer than the specified 0\n",
      "Created a chunk of size 364, which is longer than the specified 0\n",
      "Created a chunk of size 368, which is longer than the specified 0\n",
      "Created a chunk of size 235, which is longer than the specified 0\n",
      "Created a chunk of size 215, which is longer than the specified 0\n",
      "Created a chunk of size 245, which is longer than the specified 0\n",
      "Created a chunk of size 586, which is longer than the specified 0\n",
      "Created a chunk of size 622, which is longer than the specified 0\n",
      "Created a chunk of size 441, which is longer than the specified 0\n",
      "Created a chunk of size 239, which is longer than the specified 0\n",
      "Created a chunk of size 380, which is longer than the specified 0\n",
      "Created a chunk of size 365, which is longer than the specified 0\n",
      "Created a chunk of size 340, which is longer than the specified 0\n",
      "Created a chunk of size 353, which is longer than the specified 0\n",
      "Created a chunk of size 188, which is longer than the specified 0\n",
      "Created a chunk of size 243, which is longer than the specified 0\n",
      "Created a chunk of size 424, which is longer than the specified 0\n",
      "Created a chunk of size 192, which is longer than the specified 0\n",
      "Created a chunk of size 267, which is longer than the specified 0\n",
      "Created a chunk of size 1363, which is longer than the specified 0\n",
      "Created a chunk of size 269, which is longer than the specified 0\n",
      "Created a chunk of size 197, which is longer than the specified 0\n",
      "Created a chunk of size 294, which is longer than the specified 0\n",
      "Created a chunk of size 534, which is longer than the specified 0\n",
      "Created a chunk of size 196, which is longer than the specified 0\n",
      "Created a chunk of size 448, which is longer than the specified 0\n",
      "Created a chunk of size 354, which is longer than the specified 0\n",
      "Created a chunk of size 662, which is longer than the specified 0\n",
      "Created a chunk of size 2350, which is longer than the specified 0\n",
      "Created a chunk of size 247, which is longer than the specified 0\n",
      "Created a chunk of size 194, which is longer than the specified 0\n",
      "Created a chunk of size 982, which is longer than the specified 0\n",
      "Created a chunk of size 514, which is longer than the specified 0\n",
      "Created a chunk of size 376, which is longer than the specified 0\n",
      "Created a chunk of size 882, which is longer than the specified 0\n",
      "Created a chunk of size 993, which is longer than the specified 0\n",
      "Created a chunk of size 194, which is longer than the specified 0\n",
      "Created a chunk of size 1174, which is longer than the specified 0\n",
      "Created a chunk of size 961, which is longer than the specified 0\n",
      "Created a chunk of size 721, which is longer than the specified 0\n",
      "Created a chunk of size 246, which is longer than the specified 0\n",
      "Created a chunk of size 240, which is longer than the specified 0\n",
      "Created a chunk of size 283, which is longer than the specified 0\n",
      "Created a chunk of size 386, which is longer than the specified 0\n",
      "Created a chunk of size 1650, which is longer than the specified 0\n",
      "Created a chunk of size 163, which is longer than the specified 0\n",
      "Created a chunk of size 303, which is longer than the specified 0\n",
      "Created a chunk of size 193, which is longer than the specified 0\n",
      "Created a chunk of size 192, which is longer than the specified 0\n",
      "Created a chunk of size 165, which is longer than the specified 0\n",
      "Created a chunk of size 370, which is longer than the specified 0\n",
      "Created a chunk of size 250, which is longer than the specified 0\n",
      "Created a chunk of size 241, which is longer than the specified 0\n",
      "Created a chunk of size 273, which is longer than the specified 0\n",
      "Created a chunk of size 244, which is longer than the specified 0\n",
      "Created a chunk of size 268, which is longer than the specified 0\n",
      "Created a chunk of size 233, which is longer than the specified 0\n",
      "Created a chunk of size 173, which is longer than the specified 0\n",
      "Created a chunk of size 269, which is longer than the specified 0\n",
      "Created a chunk of size 206, which is longer than the specified 0\n",
      "Created a chunk of size 904, which is longer than the specified 0\n",
      "Created a chunk of size 1042, which is longer than the specified 0\n",
      "Created a chunk of size 549, which is longer than the specified 0\n",
      "Created a chunk of size 221, which is longer than the specified 0\n",
      "Created a chunk of size 157, which is longer than the specified 0\n",
      "Created a chunk of size 1528, which is longer than the specified 0\n",
      "Created a chunk of size 1995, which is longer than the specified 0\n",
      "Created a chunk of size 252, which is longer than the specified 0\n",
      "Created a chunk of size 252, which is longer than the specified 0\n",
      "Created a chunk of size 247, which is longer than the specified 0\n",
      "Created a chunk of size 290, which is longer than the specified 0\n",
      "Created a chunk of size 988, which is longer than the specified 0\n",
      "Created a chunk of size 294, which is longer than the specified 0\n",
      "Created a chunk of size 473, which is longer than the specified 0\n",
      "Created a chunk of size 169, which is longer than the specified 0\n",
      "Created a chunk of size 549, which is longer than the specified 0\n",
      "Created a chunk of size 217, which is longer than the specified 0\n",
      "Created a chunk of size 828, which is longer than the specified 0\n",
      "Created a chunk of size 856, which is longer than the specified 0\n",
      "Created a chunk of size 1025, which is longer than the specified 0\n",
      "Created a chunk of size 535, which is longer than the specified 0\n",
      "Created a chunk of size 939, which is longer than the specified 0\n",
      "Created a chunk of size 1352, which is longer than the specified 0\n",
      "Created a chunk of size 1400, which is longer than the specified 0\n",
      "Created a chunk of size 824, which is longer than the specified 0\n",
      "Created a chunk of size 272, which is longer than the specified 0\n",
      "Created a chunk of size 605, which is longer than the specified 0\n",
      "Created a chunk of size 1745, which is longer than the specified 0\n",
      "Created a chunk of size 155, which is longer than the specified 0\n",
      "Created a chunk of size 196, which is longer than the specified 0\n",
      "Created a chunk of size 323, which is longer than the specified 0\n",
      "Created a chunk of size 236, which is longer than the specified 0\n",
      "Created a chunk of size 533, which is longer than the specified 0\n",
      "Created a chunk of size 547, which is longer than the specified 0\n",
      "Created a chunk of size 242, which is longer than the specified 0\n",
      "Created a chunk of size 242, which is longer than the specified 0\n",
      "Created a chunk of size 176, which is longer than the specified 0\n",
      "Created a chunk of size 383, which is longer than the specified 0\n",
      "Created a chunk of size 495, which is longer than the specified 0\n",
      "Created a chunk of size 186, which is longer than the specified 0\n",
      "Created a chunk of size 871, which is longer than the specified 0\n",
      "Created a chunk of size 2334, which is longer than the specified 0\n",
      "Created a chunk of size 2946, which is longer than the specified 0\n",
      "Created a chunk of size 198, which is longer than the specified 0\n",
      "Created a chunk of size 270, which is longer than the specified 0\n",
      "Created a chunk of size 804, which is longer than the specified 0\n",
      "Created a chunk of size 710, which is longer than the specified 0\n",
      "Created a chunk of size 3243, which is longer than the specified 0\n",
      "Created a chunk of size 2780, which is longer than the specified 0\n",
      "Created a chunk of size 207, which is longer than the specified 0\n",
      "Created a chunk of size 256, which is longer than the specified 0\n",
      "Created a chunk of size 627, which is longer than the specified 0\n",
      "Created a chunk of size 672, which is longer than the specified 0\n",
      "Created a chunk of size 175, which is longer than the specified 0\n",
      "Created a chunk of size 186, which is longer than the specified 0\n",
      "Created a chunk of size 736, which is longer than the specified 0\n",
      "Created a chunk of size 515, which is longer than the specified 0\n",
      "Created a chunk of size 887, which is longer than the specified 0\n",
      "Created a chunk of size 195, which is longer than the specified 0\n",
      "Created a chunk of size 178, which is longer than the specified 0\n",
      "Created a chunk of size 393, which is longer than the specified 0\n",
      "Created a chunk of size 908, which is longer than the specified 0\n",
      "Created a chunk of size 187, which is longer than the specified 0\n",
      "Created a chunk of size 1309, which is longer than the specified 0\n",
      "Created a chunk of size 1127, which is longer than the specified 0\n",
      "Created a chunk of size 1117, which is longer than the specified 0\n",
      "Created a chunk of size 495, which is longer than the specified 0\n",
      "Created a chunk of size 1194, which is longer than the specified 0\n",
      "Created a chunk of size 361, which is longer than the specified 0\n",
      "Created a chunk of size 726, which is longer than the specified 0\n",
      "Created a chunk of size 386, which is longer than the specified 0\n",
      "Created a chunk of size 832, which is longer than the specified 0\n",
      "Created a chunk of size 803, which is longer than the specified 0\n",
      "Created a chunk of size 200, which is longer than the specified 0\n",
      "Created a chunk of size 223, which is longer than the specified 0\n",
      "Created a chunk of size 251, which is longer than the specified 0\n",
      "Created a chunk of size 890, which is longer than the specified 0\n",
      "Created a chunk of size 210, which is longer than the specified 0\n",
      "Created a chunk of size 361, which is longer than the specified 0\n",
      "Created a chunk of size 309, which is longer than the specified 0\n",
      "Created a chunk of size 273, which is longer than the specified 0\n",
      "Created a chunk of size 560, which is longer than the specified 0\n",
      "Created a chunk of size 2085, which is longer than the specified 0\n",
      "Created a chunk of size 1897, which is longer than the specified 0\n",
      "Created a chunk of size 439, which is longer than the specified 0\n",
      "Created a chunk of size 669, which is longer than the specified 0\n",
      "Created a chunk of size 875, which is longer than the specified 0\n",
      "Created a chunk of size 2018, which is longer than the specified 0\n",
      "Created a chunk of size 764, which is longer than the specified 0\n",
      "Created a chunk of size 176, which is longer than the specified 0\n",
      "Created a chunk of size 880, which is longer than the specified 0\n",
      "Created a chunk of size 1096, which is longer than the specified 0\n",
      "Created a chunk of size 1132, which is longer than the specified 0\n",
      "Created a chunk of size 415, which is longer than the specified 0\n",
      "Created a chunk of size 428, which is longer than the specified 0\n",
      "Created a chunk of size 343, which is longer than the specified 0\n",
      "Created a chunk of size 367, which is longer than the specified 0\n",
      "Created a chunk of size 282, which is longer than the specified 0\n",
      "Created a chunk of size 227, which is longer than the specified 0\n",
      "Created a chunk of size 248, which is longer than the specified 0\n",
      "Created a chunk of size 283, which is longer than the specified 0\n",
      "Created a chunk of size 229, which is longer than the specified 0\n",
      "Created a chunk of size 261, which is longer than the specified 0\n",
      "Created a chunk of size 303, which is longer than the specified 0\n",
      "Created a chunk of size 247, which is longer than the specified 0\n",
      "Created a chunk of size 244, which is longer than the specified 0\n",
      "Created a chunk of size 378, which is longer than the specified 0\n",
      "Created a chunk of size 248, which is longer than the specified 0\n",
      "Created a chunk of size 241, which is longer than the specified 0\n",
      "Created a chunk of size 207, which is longer than the specified 0\n",
      "Created a chunk of size 248, which is longer than the specified 0\n",
      "Created a chunk of size 233, which is longer than the specified 0\n",
      "Created a chunk of size 313, which is longer than the specified 0\n",
      "Created a chunk of size 345, which is longer than the specified 0\n",
      "Created a chunk of size 269, which is longer than the specified 0\n",
      "Created a chunk of size 253, which is longer than the specified 0\n",
      "Created a chunk of size 226, which is longer than the specified 0\n",
      "Created a chunk of size 279, which is longer than the specified 0\n",
      "Created a chunk of size 331, which is longer than the specified 0\n",
      "Created a chunk of size 218, which is longer than the specified 0\n",
      "Created a chunk of size 435, which is longer than the specified 0\n",
      "Created a chunk of size 379, which is longer than the specified 0\n",
      "Created a chunk of size 270, which is longer than the specified 0\n",
      "Created a chunk of size 254, which is longer than the specified 0\n",
      "Created a chunk of size 258, which is longer than the specified 0\n",
      "Created a chunk of size 212, which is longer than the specified 0\n",
      "Created a chunk of size 232, which is longer than the specified 0\n",
      "Created a chunk of size 296, which is longer than the specified 0\n",
      "Created a chunk of size 289, which is longer than the specified 0\n",
      "Created a chunk of size 252, which is longer than the specified 0\n",
      "Created a chunk of size 251, which is longer than the specified 0\n",
      "Created a chunk of size 266, which is longer than the specified 0\n",
      "Created a chunk of size 277, which is longer than the specified 0\n",
      "Created a chunk of size 270, which is longer than the specified 0\n",
      "Created a chunk of size 202, which is longer than the specified 0\n",
      "Created a chunk of size 229, which is longer than the specified 0\n",
      "Created a chunk of size 368, which is longer than the specified 0\n",
      "Created a chunk of size 229, which is longer than the specified 0\n",
      "Created a chunk of size 252, which is longer than the specified 0\n",
      "Created a chunk of size 214, which is longer than the specified 0\n",
      "Created a chunk of size 224, which is longer than the specified 0\n",
      "Created a chunk of size 255, which is longer than the specified 0\n",
      "Created a chunk of size 300, which is longer than the specified 0\n",
      "Created a chunk of size 279, which is longer than the specified 0\n",
      "Created a chunk of size 349, which is longer than the specified 0\n",
      "Created a chunk of size 369, which is longer than the specified 0\n",
      "Created a chunk of size 352, which is longer than the specified 0\n",
      "Created a chunk of size 271, which is longer than the specified 0\n",
      "Created a chunk of size 444, which is longer than the specified 0\n",
      "Created a chunk of size 188, which is longer than the specified 0\n",
      "Created a chunk of size 336, which is longer than the specified 0\n",
      "Created a chunk of size 226, which is longer than the specified 0\n",
      "Created a chunk of size 188, which is longer than the specified 0\n",
      "Created a chunk of size 392, which is longer than the specified 0\n",
      "Created a chunk of size 247, which is longer than the specified 0\n",
      "Created a chunk of size 205, which is longer than the specified 0\n",
      "Created a chunk of size 388, which is longer than the specified 0\n",
      "Created a chunk of size 395, which is longer than the specified 0\n",
      "Created a chunk of size 230, which is longer than the specified 0\n",
      "Created a chunk of size 952, which is longer than the specified 0\n",
      "Created a chunk of size 308, which is longer than the specified 0\n",
      "Created a chunk of size 311, which is longer than the specified 0\n",
      "Created a chunk of size 242, which is longer than the specified 0\n",
      "Created a chunk of size 226, which is longer than the specified 0\n",
      "Created a chunk of size 435, which is longer than the specified 0\n",
      "Created a chunk of size 360, which is longer than the specified 0\n",
      "Created a chunk of size 397, which is longer than the specified 0\n",
      "Created a chunk of size 335, which is longer than the specified 0\n",
      "Created a chunk of size 405, which is longer than the specified 0\n",
      "Created a chunk of size 435, which is longer than the specified 0\n",
      "Created a chunk of size 170, which is longer than the specified 0\n",
      "Created a chunk of size 276, which is longer than the specified 0\n",
      "Created a chunk of size 286, which is longer than the specified 0\n",
      "Created a chunk of size 293, which is longer than the specified 0\n",
      "Created a chunk of size 331, which is longer than the specified 0\n",
      "Created a chunk of size 230, which is longer than the specified 0\n",
      "Created a chunk of size 233, which is longer than the specified 0\n",
      "Created a chunk of size 243, which is longer than the specified 0\n",
      "Created a chunk of size 243, which is longer than the specified 0\n",
      "Created a chunk of size 368, which is longer than the specified 0\n",
      "Created a chunk of size 249, which is longer than the specified 0\n",
      "Created a chunk of size 271, which is longer than the specified 0\n",
      "Created a chunk of size 211, which is longer than the specified 0\n",
      "Created a chunk of size 388, which is longer than the specified 0\n",
      "Created a chunk of size 267, which is longer than the specified 0\n",
      "Created a chunk of size 293, which is longer than the specified 0\n",
      "Created a chunk of size 243, which is longer than the specified 0\n",
      "Created a chunk of size 376, which is longer than the specified 0\n",
      "Created a chunk of size 247, which is longer than the specified 0\n",
      "Created a chunk of size 249, which is longer than the specified 0\n",
      "Created a chunk of size 232, which is longer than the specified 0\n",
      "Created a chunk of size 233, which is longer than the specified 0\n",
      "Created a chunk of size 211, which is longer than the specified 0\n",
      "Created a chunk of size 212, which is longer than the specified 0\n",
      "Created a chunk of size 253, which is longer than the specified 0\n",
      "Created a chunk of size 309, which is longer than the specified 0\n",
      "Created a chunk of size 165, which is longer than the specified 0\n",
      "Created a chunk of size 328, which is longer than the specified 0\n",
      "Created a chunk of size 268, which is longer than the specified 0\n",
      "Created a chunk of size 403, which is longer than the specified 0\n",
      "Created a chunk of size 192, which is longer than the specified 0\n",
      "Created a chunk of size 386, which is longer than the specified 0\n",
      "Created a chunk of size 238, which is longer than the specified 0\n",
      "Created a chunk of size 474, which is longer than the specified 0\n",
      "Created a chunk of size 352, which is longer than the specified 0\n",
      "Created a chunk of size 248, which is longer than the specified 0\n",
      "Created a chunk of size 220, which is longer than the specified 0\n",
      "Created a chunk of size 247, which is longer than the specified 0\n",
      "Created a chunk of size 187, which is longer than the specified 0\n",
      "Created a chunk of size 601, which is longer than the specified 0\n",
      "Created a chunk of size 254, which is longer than the specified 0\n",
      "Created a chunk of size 189, which is longer than the specified 0\n",
      "Created a chunk of size 240, which is longer than the specified 0\n",
      "Created a chunk of size 375, which is longer than the specified 0\n",
      "Created a chunk of size 277, which is longer than the specified 0\n",
      "Created a chunk of size 844, which is longer than the specified 0\n",
      "Created a chunk of size 1933, which is longer than the specified 0\n",
      "Created a chunk of size 259, which is longer than the specified 0\n",
      "Created a chunk of size 337, which is longer than the specified 0\n",
      "Created a chunk of size 323, which is longer than the specified 0\n",
      "Created a chunk of size 176, which is longer than the specified 0\n",
      "Created a chunk of size 999, which is longer than the specified 0\n",
      "Created a chunk of size 206, which is longer than the specified 0\n",
      "Created a chunk of size 157, which is longer than the specified 0\n",
      "Created a chunk of size 202, which is longer than the specified 0\n",
      "Created a chunk of size 243, which is longer than the specified 0\n",
      "Created a chunk of size 155, which is longer than the specified 0\n",
      "Created a chunk of size 185, which is longer than the specified 0\n",
      "Created a chunk of size 166, which is longer than the specified 0\n",
      "Created a chunk of size 192, which is longer than the specified 0\n",
      "Created a chunk of size 1365, which is longer than the specified 0\n",
      "Created a chunk of size 237, which is longer than the specified 0\n",
      "Created a chunk of size 212, which is longer than the specified 0\n",
      "Created a chunk of size 242, which is longer than the specified 0\n",
      "Created a chunk of size 1751, which is longer than the specified 0\n",
      "Created a chunk of size 631, which is longer than the specified 0\n",
      "Created a chunk of size 1025, which is longer than the specified 0\n",
      "Created a chunk of size 973, which is longer than the specified 0\n",
      "Created a chunk of size 584, which is longer than the specified 0\n",
      "Created a chunk of size 707, which is longer than the specified 0\n",
      "Created a chunk of size 838, which is longer than the specified 0\n",
      "Created a chunk of size 892, which is longer than the specified 0\n",
      "Created a chunk of size 509, which is longer than the specified 0\n",
      "Created a chunk of size 916, which is longer than the specified 0\n",
      "Created a chunk of size 935, which is longer than the specified 0\n",
      "Created a chunk of size 181, which is longer than the specified 0\n",
      "Created a chunk of size 428, which is longer than the specified 0\n",
      "Created a chunk of size 507, which is longer than the specified 0\n",
      "Created a chunk of size 439, which is longer than the specified 0\n",
      "Created a chunk of size 439, which is longer than the specified 0\n",
      "Created a chunk of size 439, which is longer than the specified 0\n",
      "Created a chunk of size 439, which is longer than the specified 0\n",
      "Created a chunk of size 439, which is longer than the specified 0\n",
      "Created a chunk of size 439, which is longer than the specified 0\n",
      "Created a chunk of size 290, which is longer than the specified 0\n",
      "Created a chunk of size 176, which is longer than the specified 0\n",
      "Created a chunk of size 176, which is longer than the specified 0\n",
      "Created a chunk of size 476, which is longer than the specified 0\n",
      "Created a chunk of size 968, which is longer than the specified 0\n",
      "Created a chunk of size 674, which is longer than the specified 0\n",
      "Created a chunk of size 2713, which is longer than the specified 0\n",
      "Created a chunk of size 2278, which is longer than the specified 0\n",
      "Created a chunk of size 255, which is longer than the specified 0\n",
      "Created a chunk of size 187, which is longer than the specified 0\n",
      "Created a chunk of size 207, which is longer than the specified 0\n",
      "Created a chunk of size 252, which is longer than the specified 0\n",
      "Created a chunk of size 229, which is longer than the specified 0\n",
      "Created a chunk of size 436, which is longer than the specified 0\n",
      "Created a chunk of size 436, which is longer than the specified 0\n",
      "Created a chunk of size 1204, which is longer than the specified 0\n",
      "Created a chunk of size 879, which is longer than the specified 0\n",
      "Created a chunk of size 1123, which is longer than the specified 0\n",
      "Created a chunk of size 381, which is longer than the specified 0\n",
      "Created a chunk of size 352, which is longer than the specified 0\n",
      "Created a chunk of size 166, which is longer than the specified 0\n",
      "Created a chunk of size 510, which is longer than the specified 0\n",
      "Created a chunk of size 377, which is longer than the specified 0\n",
      "Created a chunk of size 1435, which is longer than the specified 0\n",
      "Created a chunk of size 256, which is longer than the specified 0\n",
      "Created a chunk of size 388, which is longer than the specified 0\n",
      "Created a chunk of size 1055, which is longer than the specified 0\n",
      "Created a chunk of size 1340, which is longer than the specified 0\n",
      "Created a chunk of size 241, which is longer than the specified 0\n",
      "Created a chunk of size 1006, which is longer than the specified 0\n",
      "Created a chunk of size 883, which is longer than the specified 0\n",
      "Created a chunk of size 255, which is longer than the specified 0\n",
      "Created a chunk of size 235, which is longer than the specified 0\n",
      "Created a chunk of size 693, which is longer than the specified 0\n",
      "Created a chunk of size 293, which is longer than the specified 0\n",
      "Created a chunk of size 610, which is longer than the specified 0\n",
      "Created a chunk of size 199, which is longer than the specified 0\n",
      "Created a chunk of size 275, which is longer than the specified 0\n",
      "Created a chunk of size 317, which is longer than the specified 0\n",
      "Created a chunk of size 960, which is longer than the specified 0\n",
      "Created a chunk of size 299, which is longer than the specified 0\n",
      "Created a chunk of size 231, which is longer than the specified 0\n",
      "Created a chunk of size 734, which is longer than the specified 0\n",
      "Created a chunk of size 188, which is longer than the specified 0\n",
      "Created a chunk of size 609, which is longer than the specified 0\n",
      "Created a chunk of size 268, which is longer than the specified 0\n",
      "Created a chunk of size 891, which is longer than the specified 0\n",
      "Created a chunk of size 1137, which is longer than the specified 0\n",
      "Created a chunk of size 206, which is longer than the specified 0\n",
      "Created a chunk of size 179, which is longer than the specified 0\n",
      "Created a chunk of size 2051, which is longer than the specified 0\n",
      "Created a chunk of size 641, which is longer than the specified 0\n",
      "Created a chunk of size 244, which is longer than the specified 0\n",
      "Created a chunk of size 341, which is longer than the specified 0\n",
      "Created a chunk of size 539, which is longer than the specified 0\n",
      "Created a chunk of size 1305, which is longer than the specified 0\n",
      "Created a chunk of size 2014, which is longer than the specified 0\n",
      "Created a chunk of size 226, which is longer than the specified 0\n",
      "Created a chunk of size 264, which is longer than the specified 0\n",
      "Created a chunk of size 182, which is longer than the specified 0\n",
      "Created a chunk of size 726, which is longer than the specified 0\n",
      "Created a chunk of size 244, which is longer than the specified 0\n",
      "Created a chunk of size 633, which is longer than the specified 0\n",
      "Created a chunk of size 580, which is longer than the specified 0\n",
      "Created a chunk of size 928, which is longer than the specified 0\n",
      "Created a chunk of size 341, which is longer than the specified 0\n",
      "Created a chunk of size 617, which is longer than the specified 0\n",
      "Created a chunk of size 264, which is longer than the specified 0\n",
      "Created a chunk of size 569, which is longer than the specified 0\n",
      "Created a chunk of size 599, which is longer than the specified 0\n",
      "Created a chunk of size 352, which is longer than the specified 0\n",
      "Created a chunk of size 354, which is longer than the specified 0\n",
      "Created a chunk of size 273, which is longer than the specified 0\n",
      "Created a chunk of size 341, which is longer than the specified 0\n",
      "Created a chunk of size 452, which is longer than the specified 0\n",
      "Created a chunk of size 768, which is longer than the specified 0\n",
      "Created a chunk of size 325, which is longer than the specified 0\n",
      "Created a chunk of size 1045, which is longer than the specified 0\n",
      "Created a chunk of size 271, which is longer than the specified 0\n",
      "Created a chunk of size 255, which is longer than the specified 0\n",
      "Created a chunk of size 298, which is longer than the specified 0\n",
      "Created a chunk of size 355, which is longer than the specified 0\n",
      "Created a chunk of size 554, which is longer than the specified 0\n",
      "Created a chunk of size 362, which is longer than the specified 0\n",
      "Created a chunk of size 253, which is longer than the specified 0\n",
      "Created a chunk of size 364, which is longer than the specified 0\n",
      "Created a chunk of size 702, which is longer than the specified 0\n",
      "Created a chunk of size 224, which is longer than the specified 0\n",
      "Created a chunk of size 842, which is longer than the specified 0\n",
      "Created a chunk of size 462, which is longer than the specified 0\n",
      "Created a chunk of size 268, which is longer than the specified 0\n",
      "Created a chunk of size 1002, which is longer than the specified 0\n",
      "Created a chunk of size 1273, which is longer than the specified 0\n",
      "Created a chunk of size 865, which is longer than the specified 0\n",
      "Created a chunk of size 906, which is longer than the specified 0\n",
      "Created a chunk of size 924, which is longer than the specified 0\n",
      "Created a chunk of size 204, which is longer than the specified 0\n",
      "Created a chunk of size 360, which is longer than the specified 0\n",
      "Created a chunk of size 282, which is longer than the specified 0\n",
      "Created a chunk of size 290, which is longer than the specified 0\n",
      "Created a chunk of size 260, which is longer than the specified 0\n",
      "Created a chunk of size 258, which is longer than the specified 0\n",
      "Created a chunk of size 224, which is longer than the specified 0\n",
      "Created a chunk of size 249, which is longer than the specified 0\n",
      "Created a chunk of size 675, which is longer than the specified 0\n",
      "Created a chunk of size 834, which is longer than the specified 0\n",
      "Created a chunk of size 901, which is longer than the specified 0\n",
      "Created a chunk of size 544, which is longer than the specified 0\n",
      "Created a chunk of size 300, which is longer than the specified 0\n",
      "Created a chunk of size 414, which is longer than the specified 0\n",
      "Created a chunk of size 249, which is longer than the specified 0\n",
      "Created a chunk of size 189, which is longer than the specified 0\n",
      "Created a chunk of size 539, which is longer than the specified 0\n",
      "Created a chunk of size 714, which is longer than the specified 0\n",
      "Created a chunk of size 398, which is longer than the specified 0\n",
      "Created a chunk of size 190, which is longer than the specified 0\n",
      "Created a chunk of size 1360, which is longer than the specified 0\n",
      "Created a chunk of size 1731, which is longer than the specified 0\n",
      "Created a chunk of size 730, which is longer than the specified 0\n",
      "Created a chunk of size 317, which is longer than the specified 0\n",
      "Created a chunk of size 1054, which is longer than the specified 0\n",
      "Created a chunk of size 374, which is longer than the specified 0\n",
      "Created a chunk of size 239, which is longer than the specified 0\n",
      "Created a chunk of size 218, which is longer than the specified 0\n",
      "Created a chunk of size 468, which is longer than the specified 0\n",
      "Created a chunk of size 282, which is longer than the specified 0\n",
      "Created a chunk of size 236, which is longer than the specified 0\n",
      "Created a chunk of size 313, which is longer than the specified 0\n",
      "Created a chunk of size 2067, which is longer than the specified 0\n",
      "Created a chunk of size 189, which is longer than the specified 0\n",
      "Created a chunk of size 1326, which is longer than the specified 0\n",
      "Created a chunk of size 814, which is longer than the specified 0\n",
      "Created a chunk of size 292, which is longer than the specified 0\n",
      "Created a chunk of size 1030, which is longer than the specified 0\n",
      "Created a chunk of size 1127, which is longer than the specified 0\n",
      "Created a chunk of size 268, which is longer than the specified 0\n",
      "Created a chunk of size 222, which is longer than the specified 0\n",
      "Created a chunk of size 194, which is longer than the specified 0\n",
      "Created a chunk of size 220, which is longer than the specified 0\n",
      "Created a chunk of size 164, which is longer than the specified 0\n",
      "Created a chunk of size 246, which is longer than the specified 0\n",
      "Created a chunk of size 189, which is longer than the specified 0\n",
      "Created a chunk of size 247, which is longer than the specified 0\n",
      "Created a chunk of size 456, which is longer than the specified 0\n",
      "Created a chunk of size 178, which is longer than the specified 0\n",
      "Created a chunk of size 227, which is longer than the specified 0\n",
      "Created a chunk of size 594, which is longer than the specified 0\n",
      "Created a chunk of size 226, which is longer than the specified 0\n",
      "Created a chunk of size 637, which is longer than the specified 0\n",
      "Created a chunk of size 473, which is longer than the specified 0\n",
      "Created a chunk of size 365, which is longer than the specified 0\n",
      "Created a chunk of size 615, which is longer than the specified 0\n",
      "Created a chunk of size 370, which is longer than the specified 0\n",
      "Created a chunk of size 175, which is longer than the specified 0\n",
      "Created a chunk of size 723, which is longer than the specified 0\n",
      "Created a chunk of size 254, which is longer than the specified 0\n",
      "Created a chunk of size 328, which is longer than the specified 0\n",
      "Created a chunk of size 258, which is longer than the specified 0\n",
      "Created a chunk of size 420, which is longer than the specified 0\n",
      "Created a chunk of size 976, which is longer than the specified 0\n",
      "Created a chunk of size 1165, which is longer than the specified 0\n",
      "Created a chunk of size 1352, which is longer than the specified 0\n",
      "Created a chunk of size 1180, which is longer than the specified 0\n",
      "Created a chunk of size 693, which is longer than the specified 0\n",
      "Created a chunk of size 246, which is longer than the specified 0\n",
      "Created a chunk of size 691, which is longer than the specified 0\n",
      "Created a chunk of size 399, which is longer than the specified 0\n",
      "Created a chunk of size 652, which is longer than the specified 0\n",
      "Created a chunk of size 1012, which is longer than the specified 0\n",
      "Created a chunk of size 1055, which is longer than the specified 0\n",
      "Created a chunk of size 254, which is longer than the specified 0\n",
      "Created a chunk of size 1169, which is longer than the specified 0\n",
      "Created a chunk of size 320, which is longer than the specified 0\n",
      "Created a chunk of size 276, which is longer than the specified 0\n",
      "Created a chunk of size 938, which is longer than the specified 0\n",
      "Created a chunk of size 259, which is longer than the specified 0\n",
      "Created a chunk of size 185, which is longer than the specified 0\n",
      "Created a chunk of size 654, which is longer than the specified 0\n",
      "Created a chunk of size 520, which is longer than the specified 0\n",
      "Created a chunk of size 401, which is longer than the specified 0\n",
      "Created a chunk of size 815, which is longer than the specified 0\n",
      "Created a chunk of size 246, which is longer than the specified 0\n",
      "Created a chunk of size 872, which is longer than the specified 0\n",
      "Created a chunk of size 1079, which is longer than the specified 0\n",
      "Created a chunk of size 454, which is longer than the specified 0\n",
      "Created a chunk of size 312, which is longer than the specified 0\n",
      "Created a chunk of size 1903, which is longer than the specified 0\n",
      "Created a chunk of size 988, which is longer than the specified 0\n",
      "Created a chunk of size 305, which is longer than the specified 0\n",
      "Created a chunk of size 1310, which is longer than the specified 0\n",
      "Created a chunk of size 429, which is longer than the specified 0\n",
      "Created a chunk of size 963, which is longer than the specified 0\n",
      "Created a chunk of size 217, which is longer than the specified 0\n",
      "Created a chunk of size 421, which is longer than the specified 0\n",
      "Created a chunk of size 438, which is longer than the specified 0\n",
      "Created a chunk of size 364, which is longer than the specified 0\n",
      "Created a chunk of size 626, which is longer than the specified 0\n",
      "Created a chunk of size 616, which is longer than the specified 0\n",
      "Created a chunk of size 1621, which is longer than the specified 0\n",
      "Created a chunk of size 366, which is longer than the specified 0\n",
      "Created a chunk of size 458, which is longer than the specified 0\n",
      "Created a chunk of size 993, which is longer than the specified 0\n",
      "Created a chunk of size 871, which is longer than the specified 0\n",
      "Created a chunk of size 1163, which is longer than the specified 0\n",
      "Created a chunk of size 181, which is longer than the specified 0\n",
      "Created a chunk of size 255, which is longer than the specified 0\n",
      "Created a chunk of size 402, which is longer than the specified 0\n",
      "Created a chunk of size 574, which is longer than the specified 0\n",
      "Created a chunk of size 244, which is longer than the specified 0\n",
      "Created a chunk of size 401, which is longer than the specified 0\n",
      "Created a chunk of size 204, which is longer than the specified 0\n",
      "Created a chunk of size 585, which is longer than the specified 0\n",
      "Created a chunk of size 232, which is longer than the specified 0\n",
      "Created a chunk of size 218, which is longer than the specified 0\n",
      "Created a chunk of size 418, which is longer than the specified 0\n",
      "Created a chunk of size 969, which is longer than the specified 0\n",
      "Created a chunk of size 986, which is longer than the specified 0\n",
      "Created a chunk of size 1283, which is longer than the specified 0\n",
      "Created a chunk of size 619, which is longer than the specified 0\n",
      "Created a chunk of size 282, which is longer than the specified 0\n",
      "Created a chunk of size 208, which is longer than the specified 0\n",
      "Created a chunk of size 340, which is longer than the specified 0\n",
      "Created a chunk of size 438, which is longer than the specified 0\n",
      "Created a chunk of size 532, which is longer than the specified 0\n",
      "Created a chunk of size 334, which is longer than the specified 0\n",
      "Created a chunk of size 1475, which is longer than the specified 0\n",
      "Created a chunk of size 302, which is longer than the specified 0\n",
      "Created a chunk of size 606, which is longer than the specified 0\n",
      "Created a chunk of size 556, which is longer than the specified 0\n",
      "Created a chunk of size 240, which is longer than the specified 0\n",
      "Created a chunk of size 230, which is longer than the specified 0\n",
      "Created a chunk of size 313, which is longer than the specified 0\n",
      "Created a chunk of size 192, which is longer than the specified 0\n",
      "Created a chunk of size 183, which is longer than the specified 0\n",
      "Created a chunk of size 236, which is longer than the specified 0\n",
      "Created a chunk of size 240, which is longer than the specified 0\n",
      "Created a chunk of size 272, which is longer than the specified 0\n",
      "Created a chunk of size 296, which is longer than the specified 0\n",
      "Created a chunk of size 564, which is longer than the specified 0\n",
      "Created a chunk of size 568, which is longer than the specified 0\n",
      "Created a chunk of size 364, which is longer than the specified 0\n",
      "Created a chunk of size 204, which is longer than the specified 0\n",
      "Created a chunk of size 231, which is longer than the specified 0\n",
      "Created a chunk of size 256, which is longer than the specified 0\n",
      "Created a chunk of size 214, which is longer than the specified 0\n",
      "Created a chunk of size 232, which is longer than the specified 0\n",
      "Created a chunk of size 277, which is longer than the specified 0\n",
      "Created a chunk of size 1144, which is longer than the specified 0\n",
      "Created a chunk of size 304, which is longer than the specified 0\n",
      "Created a chunk of size 289, which is longer than the specified 0\n",
      "Created a chunk of size 485, which is longer than the specified 0\n",
      "Created a chunk of size 182, which is longer than the specified 0\n",
      "Created a chunk of size 162, which is longer than the specified 0\n",
      "Created a chunk of size 460, which is longer than the specified 0\n",
      "Created a chunk of size 380, which is longer than the specified 0\n",
      "Created a chunk of size 1772, which is longer than the specified 0\n",
      "Created a chunk of size 1502, which is longer than the specified 0\n",
      "Created a chunk of size 345, which is longer than the specified 0\n",
      "Created a chunk of size 242, which is longer than the specified 0\n",
      "Created a chunk of size 170, which is longer than the specified 0\n",
      "Created a chunk of size 562, which is longer than the specified 0\n",
      "Created a chunk of size 443, which is longer than the specified 0\n",
      "Created a chunk of size 358, which is longer than the specified 0\n",
      "Created a chunk of size 421, which is longer than the specified 0\n",
      "Created a chunk of size 192, which is longer than the specified 0\n",
      "Created a chunk of size 222, which is longer than the specified 0\n",
      "Created a chunk of size 416, which is longer than the specified 0\n",
      "Created a chunk of size 187, which is longer than the specified 0\n",
      "Created a chunk of size 250, which is longer than the specified 0\n",
      "Created a chunk of size 197, which is longer than the specified 0\n",
      "Created a chunk of size 252, which is longer than the specified 0\n",
      "Created a chunk of size 325, which is longer than the specified 0\n",
      "Created a chunk of size 1544, which is longer than the specified 0\n",
      "Created a chunk of size 202, which is longer than the specified 0\n",
      "Created a chunk of size 2855, which is longer than the specified 0\n",
      "Created a chunk of size 600, which is longer than the specified 0\n",
      "Created a chunk of size 566, which is longer than the specified 0\n",
      "Created a chunk of size 213, which is longer than the specified 0\n",
      "Created a chunk of size 711, which is longer than the specified 0\n",
      "Created a chunk of size 418, which is longer than the specified 0\n",
      "Created a chunk of size 1090, which is longer than the specified 0\n",
      "Created a chunk of size 963, which is longer than the specified 0\n",
      "Created a chunk of size 1132, which is longer than the specified 0\n",
      "Created a chunk of size 282, which is longer than the specified 0\n",
      "Created a chunk of size 225, which is longer than the specified 0\n",
      "Created a chunk of size 208, which is longer than the specified 0\n",
      "Created a chunk of size 209, which is longer than the specified 0\n",
      "Created a chunk of size 224, which is longer than the specified 0\n",
      "Created a chunk of size 762, which is longer than the specified 0\n",
      "Created a chunk of size 1197, which is longer than the specified 0\n",
      "Created a chunk of size 173, which is longer than the specified 0\n",
      "Created a chunk of size 1172, which is longer than the specified 0\n",
      "Created a chunk of size 961, which is longer than the specified 0\n",
      "Created a chunk of size 1214, which is longer than the specified 0\n",
      "Created a chunk of size 357, which is longer than the specified 0\n",
      "Created a chunk of size 966, which is longer than the specified 0\n",
      "Created a chunk of size 881, which is longer than the specified 0\n",
      "Created a chunk of size 342, which is longer than the specified 0\n",
      "Created a chunk of size 366, which is longer than the specified 0\n",
      "Created a chunk of size 355, which is longer than the specified 0\n",
      "Created a chunk of size 230, which is longer than the specified 0\n",
      "Created a chunk of size 258, which is longer than the specified 0\n",
      "Created a chunk of size 258, which is longer than the specified 0\n",
      "Created a chunk of size 264, which is longer than the specified 0\n",
      "Created a chunk of size 276, which is longer than the specified 0\n",
      "Created a chunk of size 289, which is longer than the specified 0\n",
      "Created a chunk of size 1002, which is longer than the specified 0\n",
      "Created a chunk of size 232, which is longer than the specified 0\n",
      "Created a chunk of size 246, which is longer than the specified 0\n",
      "Created a chunk of size 236, which is longer than the specified 0\n",
      "Created a chunk of size 404, which is longer than the specified 0\n",
      "Created a chunk of size 395, which is longer than the specified 0\n",
      "Created a chunk of size 182, which is longer than the specified 0\n",
      "Created a chunk of size 203, which is longer than the specified 0\n",
      "Created a chunk of size 1472, which is longer than the specified 0\n",
      "Created a chunk of size 1471, which is longer than the specified 0\n",
      "Created a chunk of size 247, which is longer than the specified 0\n",
      "Created a chunk of size 283, which is longer than the specified 0\n",
      "Created a chunk of size 241, which is longer than the specified 0\n",
      "Created a chunk of size 301, which is longer than the specified 0\n",
      "Created a chunk of size 285, which is longer than the specified 0\n",
      "Created a chunk of size 303, which is longer than the specified 0\n",
      "Created a chunk of size 212, which is longer than the specified 0\n",
      "Created a chunk of size 294, which is longer than the specified 0\n",
      "Created a chunk of size 885, which is longer than the specified 0\n",
      "Created a chunk of size 179, which is longer than the specified 0\n",
      "Created a chunk of size 309, which is longer than the specified 0\n",
      "Created a chunk of size 283, which is longer than the specified 0\n",
      "Created a chunk of size 520, which is longer than the specified 0\n",
      "Created a chunk of size 499, which is longer than the specified 0\n",
      "Created a chunk of size 275, which is longer than the specified 0\n",
      "Created a chunk of size 1215, which is longer than the specified 0\n",
      "Created a chunk of size 201, which is longer than the specified 0\n",
      "Created a chunk of size 318, which is longer than the specified 0\n",
      "Created a chunk of size 161, which is longer than the specified 0\n",
      "Created a chunk of size 223, which is longer than the specified 0\n",
      "Created a chunk of size 222, which is longer than the specified 0\n",
      "Created a chunk of size 943, which is longer than the specified 0\n",
      "Created a chunk of size 237, which is longer than the specified 0\n",
      "Created a chunk of size 176, which is longer than the specified 0\n",
      "Created a chunk of size 176, which is longer than the specified 0\n",
      "Created a chunk of size 1862, which is longer than the specified 0\n",
      "Created a chunk of size 422, which is longer than the specified 0\n",
      "Created a chunk of size 254, which is longer than the specified 0\n",
      "Created a chunk of size 1525, which is longer than the specified 0\n",
      "Created a chunk of size 260, which is longer than the specified 0\n",
      "Created a chunk of size 255, which is longer than the specified 0\n",
      "Created a chunk of size 198, which is longer than the specified 0\n",
      "Created a chunk of size 1016, which is longer than the specified 0\n",
      "Created a chunk of size 1385, which is longer than the specified 0\n",
      "Created a chunk of size 434, which is longer than the specified 0\n",
      "Created a chunk of size 284, which is longer than the specified 0\n",
      "Created a chunk of size 234, which is longer than the specified 0\n",
      "Created a chunk of size 359, which is longer than the specified 0\n",
      "Created a chunk of size 1452, which is longer than the specified 0\n",
      "Created a chunk of size 179, which is longer than the specified 0\n",
      "Created a chunk of size 1165, which is longer than the specified 0\n",
      "Created a chunk of size 927, which is longer than the specified 0\n",
      "Created a chunk of size 233, which is longer than the specified 0\n",
      "Created a chunk of size 881, which is longer than the specified 0\n",
      "Created a chunk of size 499, which is longer than the specified 0\n",
      "Created a chunk of size 813, which is longer than the specified 0\n",
      "Created a chunk of size 945, which is longer than the specified 0\n",
      "Created a chunk of size 299, which is longer than the specified 0\n",
      "Created a chunk of size 195, which is longer than the specified 0\n",
      "Created a chunk of size 246, which is longer than the specified 0\n",
      "Created a chunk of size 204, which is longer than the specified 0\n",
      "Created a chunk of size 1003, which is longer than the specified 0\n",
      "Created a chunk of size 1360, which is longer than the specified 0\n",
      "Created a chunk of size 923, which is longer than the specified 0\n",
      "Created a chunk of size 264, which is longer than the specified 0\n",
      "Created a chunk of size 213, which is longer than the specified 0\n",
      "Created a chunk of size 1341, which is longer than the specified 0\n",
      "Created a chunk of size 834, which is longer than the specified 0\n",
      "Created a chunk of size 530, which is longer than the specified 0\n",
      "Created a chunk of size 1050, which is longer than the specified 0\n",
      "Created a chunk of size 570, which is longer than the specified 0\n",
      "Created a chunk of size 184, which is longer than the specified 0\n",
      "Created a chunk of size 187, which is longer than the specified 0\n",
      "Created a chunk of size 229, which is longer than the specified 0\n",
      "Created a chunk of size 244, which is longer than the specified 0\n",
      "Created a chunk of size 168, which is longer than the specified 0\n",
      "Created a chunk of size 206, which is longer than the specified 0\n",
      "Created a chunk of size 224, which is longer than the specified 0\n",
      "Created a chunk of size 183, which is longer than the specified 0\n",
      "Created a chunk of size 1338, which is longer than the specified 0\n",
      "Created a chunk of size 496, which is longer than the specified 0\n",
      "Created a chunk of size 313, which is longer than the specified 0\n",
      "Created a chunk of size 1601, which is longer than the specified 0\n",
      "Created a chunk of size 1057, which is longer than the specified 0\n",
      "Created a chunk of size 142, which is longer than the specified 0\n",
      "Created a chunk of size 351, which is longer than the specified 0\n",
      "Created a chunk of size 1267, which is longer than the specified 0\n",
      "Created a chunk of size 201, which is longer than the specified 0\n",
      "Created a chunk of size 215, which is longer than the specified 0\n",
      "Created a chunk of size 404, which is longer than the specified 0\n",
      "Created a chunk of size 204, which is longer than the specified 0\n",
      "Created a chunk of size 296, which is longer than the specified 0\n",
      "Created a chunk of size 262, which is longer than the specified 0\n",
      "Created a chunk of size 769, which is longer than the specified 0\n",
      "Created a chunk of size 1026, which is longer than the specified 0\n",
      "Created a chunk of size 206, which is longer than the specified 0\n",
      "Created a chunk of size 527, which is longer than the specified 0\n",
      "Created a chunk of size 305, which is longer than the specified 0\n",
      "Created a chunk of size 227, which is longer than the specified 0\n",
      "Created a chunk of size 726, which is longer than the specified 0\n",
      "Created a chunk of size 675, which is longer than the specified 0\n",
      "Created a chunk of size 823, which is longer than the specified 0\n",
      "Created a chunk of size 383, which is longer than the specified 0\n",
      "Created a chunk of size 831, which is longer than the specified 0\n",
      "Created a chunk of size 572, which is longer than the specified 0\n",
      "Created a chunk of size 1036, which is longer than the specified 0\n",
      "Created a chunk of size 740, which is longer than the specified 0\n",
      "Created a chunk of size 573, which is longer than the specified 0\n",
      "Created a chunk of size 897, which is longer than the specified 0\n",
      "Created a chunk of size 1432, which is longer than the specified 0\n",
      "Created a chunk of size 873, which is longer than the specified 0\n",
      "Created a chunk of size 2869, which is longer than the specified 0\n",
      "Created a chunk of size 189, which is longer than the specified 0\n",
      "Created a chunk of size 242, which is longer than the specified 0\n",
      "Created a chunk of size 212, which is longer than the specified 0\n",
      "Created a chunk of size 211, which is longer than the specified 0\n",
      "Created a chunk of size 2347, which is longer than the specified 0\n",
      "Created a chunk of size 181, which is longer than the specified 0\n",
      "Created a chunk of size 180, which is longer than the specified 0\n",
      "Created a chunk of size 195, which is longer than the specified 0\n",
      "Created a chunk of size 528, which is longer than the specified 0\n",
      "Created a chunk of size 2451, which is longer than the specified 0\n",
      "Created a chunk of size 265, which is longer than the specified 0\n",
      "Created a chunk of size 192, which is longer than the specified 0\n",
      "Created a chunk of size 901, which is longer than the specified 0\n",
      "Created a chunk of size 375, which is longer than the specified 0\n",
      "Created a chunk of size 756, which is longer than the specified 0\n",
      "Created a chunk of size 393, which is longer than the specified 0\n",
      "Created a chunk of size 216, which is longer than the specified 0\n",
      "Created a chunk of size 299, which is longer than the specified 0\n",
      "Created a chunk of size 322, which is longer than the specified 0\n",
      "Created a chunk of size 294, which is longer than the specified 0\n",
      "Created a chunk of size 400, which is longer than the specified 0\n",
      "Created a chunk of size 196, which is longer than the specified 0\n",
      "Created a chunk of size 357, which is longer than the specified 0\n",
      "Created a chunk of size 289, which is longer than the specified 0\n",
      "Created a chunk of size 269, which is longer than the specified 0\n",
      "Created a chunk of size 229, which is longer than the specified 0\n",
      "Created a chunk of size 291, which is longer than the specified 0\n",
      "Created a chunk of size 248, which is longer than the specified 0\n",
      "Created a chunk of size 246, which is longer than the specified 0\n",
      "Created a chunk of size 295, which is longer than the specified 0\n",
      "Created a chunk of size 273, which is longer than the specified 0\n",
      "Created a chunk of size 1054, which is longer than the specified 0\n",
      "Created a chunk of size 366, which is longer than the specified 0\n",
      "Created a chunk of size 1510, which is longer than the specified 0\n",
      "Created a chunk of size 921, which is longer than the specified 0\n",
      "Created a chunk of size 1113, which is longer than the specified 0\n",
      "Created a chunk of size 1109, which is longer than the specified 0\n",
      "Created a chunk of size 770, which is longer than the specified 0\n",
      "Created a chunk of size 738, which is longer than the specified 0\n",
      "Created a chunk of size 258, which is longer than the specified 0\n",
      "Created a chunk of size 922, which is longer than the specified 0\n",
      "Created a chunk of size 721, which is longer than the specified 0\n",
      "Created a chunk of size 926, which is longer than the specified 0\n",
      "Created a chunk of size 630, which is longer than the specified 0\n",
      "Created a chunk of size 400, which is longer than the specified 0\n",
      "Created a chunk of size 170, which is longer than the specified 0\n",
      "Created a chunk of size 294, which is longer than the specified 0\n",
      "Created a chunk of size 239, which is longer than the specified 0\n",
      "Created a chunk of size 182, which is longer than the specified 0\n",
      "Created a chunk of size 1512, which is longer than the specified 0\n",
      "Created a chunk of size 212, which is longer than the specified 0\n",
      "Created a chunk of size 216, which is longer than the specified 0\n",
      "Created a chunk of size 271, which is longer than the specified 0\n",
      "Created a chunk of size 314, which is longer than the specified 0\n",
      "Created a chunk of size 341, which is longer than the specified 0\n",
      "Created a chunk of size 268, which is longer than the specified 0\n",
      "Created a chunk of size 257, which is longer than the specified 0\n",
      "Created a chunk of size 227, which is longer than the specified 0\n",
      "Created a chunk of size 1300, which is longer than the specified 0\n",
      "Created a chunk of size 229, which is longer than the specified 0\n",
      "Created a chunk of size 601, which is longer than the specified 0\n",
      "Created a chunk of size 374, which is longer than the specified 0\n",
      "Created a chunk of size 797, which is longer than the specified 0\n",
      "Created a chunk of size 431, which is longer than the specified 0\n",
      "Created a chunk of size 306, which is longer than the specified 0\n",
      "Created a chunk of size 431, which is longer than the specified 0\n",
      "Created a chunk of size 255, which is longer than the specified 0\n",
      "Created a chunk of size 839, which is longer than the specified 0\n",
      "Created a chunk of size 431, which is longer than the specified 0\n",
      "Created a chunk of size 205, which is longer than the specified 0\n",
      "Created a chunk of size 188, which is longer than the specified 0\n",
      "Created a chunk of size 306, which is longer than the specified 0\n",
      "Created a chunk of size 369, which is longer than the specified 0\n",
      "Created a chunk of size 186, which is longer than the specified 0\n",
      "Created a chunk of size 314, which is longer than the specified 0\n",
      "Created a chunk of size 797, which is longer than the specified 0\n",
      "Created a chunk of size 1134, which is longer than the specified 0\n",
      "Created a chunk of size 174, which is longer than the specified 0\n",
      "Created a chunk of size 508, which is longer than the specified 0\n",
      "Created a chunk of size 236, which is longer than the specified 0\n",
      "Created a chunk of size 288, which is longer than the specified 0\n",
      "Created a chunk of size 1348, which is longer than the specified 0\n",
      "Created a chunk of size 680, which is longer than the specified 0\n",
      "Created a chunk of size 579, which is longer than the specified 0\n",
      "Created a chunk of size 306, which is longer than the specified 0\n",
      "Created a chunk of size 954, which is longer than the specified 0\n",
      "Created a chunk of size 274, which is longer than the specified 0\n",
      "Created a chunk of size 683, which is longer than the specified 0\n",
      "Created a chunk of size 727, which is longer than the specified 0\n",
      "Created a chunk of size 656, which is longer than the specified 0\n",
      "Created a chunk of size 1084, which is longer than the specified 0\n",
      "Created a chunk of size 794, which is longer than the specified 0\n",
      "Created a chunk of size 798, which is longer than the specified 0\n",
      "Created a chunk of size 998, which is longer than the specified 0\n",
      "Created a chunk of size 960, which is longer than the specified 0\n",
      "Created a chunk of size 659, which is longer than the specified 0\n",
      "Created a chunk of size 231, which is longer than the specified 0\n",
      "Created a chunk of size 756, which is longer than the specified 0\n",
      "Created a chunk of size 283, which is longer than the specified 0\n",
      "Created a chunk of size 308, which is longer than the specified 0\n",
      "Created a chunk of size 509, which is longer than the specified 0\n",
      "Created a chunk of size 560, which is longer than the specified 0\n",
      "Created a chunk of size 241, which is longer than the specified 0\n",
      "Created a chunk of size 220, which is longer than the specified 0\n",
      "Created a chunk of size 502, which is longer than the specified 0\n",
      "Created a chunk of size 184, which is longer than the specified 0\n",
      "Created a chunk of size 206, which is longer than the specified 0\n",
      "Created a chunk of size 341, which is longer than the specified 0\n",
      "Created a chunk of size 269, which is longer than the specified 0\n",
      "Created a chunk of size 203, which is longer than the specified 0\n",
      "Created a chunk of size 189, which is longer than the specified 0\n",
      "Created a chunk of size 250, which is longer than the specified 0\n",
      "Created a chunk of size 670, which is longer than the specified 0\n",
      "Created a chunk of size 246, which is longer than the specified 0\n",
      "Created a chunk of size 670, which is longer than the specified 0\n",
      "Created a chunk of size 675, which is longer than the specified 0\n",
      "Created a chunk of size 174, which is longer than the specified 0\n",
      "Created a chunk of size 265, which is longer than the specified 0\n",
      "Created a chunk of size 856, which is longer than the specified 0\n",
      "Created a chunk of size 1108, which is longer than the specified 0\n",
      "Created a chunk of size 540, which is longer than the specified 0\n",
      "Created a chunk of size 232, which is longer than the specified 0\n",
      "Created a chunk of size 451, which is longer than the specified 0\n",
      "Created a chunk of size 981, which is longer than the specified 0\n",
      "Created a chunk of size 264, which is longer than the specified 0\n",
      "Created a chunk of size 238, which is longer than the specified 0\n",
      "Created a chunk of size 342, which is longer than the specified 0\n",
      "Created a chunk of size 1340, which is longer than the specified 0\n",
      "Created a chunk of size 163, which is longer than the specified 0\n",
      "Created a chunk of size 289, which is longer than the specified 0\n",
      "Created a chunk of size 761, which is longer than the specified 0\n",
      "Created a chunk of size 205, which is longer than the specified 0\n",
      "Created a chunk of size 419, which is longer than the specified 0\n",
      "Created a chunk of size 438, which is longer than the specified 0\n",
      "Created a chunk of size 200, which is longer than the specified 0\n",
      "Created a chunk of size 1298, which is longer than the specified 0\n",
      "Created a chunk of size 720, which is longer than the specified 0\n",
      "Created a chunk of size 235, which is longer than the specified 0\n",
      "Created a chunk of size 370, which is longer than the specified 0\n",
      "Created a chunk of size 1320, which is longer than the specified 0\n",
      "Created a chunk of size 1524, which is longer than the specified 0\n",
      "Created a chunk of size 1031, which is longer than the specified 0\n",
      "Created a chunk of size 705, which is longer than the specified 0\n",
      "Created a chunk of size 1255, which is longer than the specified 0\n",
      "Created a chunk of size 710, which is longer than the specified 0\n",
      "Created a chunk of size 1125, which is longer than the specified 0\n",
      "Created a chunk of size 181, which is longer than the specified 0\n",
      "Created a chunk of size 1293, which is longer than the specified 0\n",
      "Created a chunk of size 397, which is longer than the specified 0\n",
      "Created a chunk of size 238, which is longer than the specified 0\n",
      "Created a chunk of size 1041, which is longer than the specified 0\n",
      "Created a chunk of size 353, which is longer than the specified 0\n",
      "Created a chunk of size 500, which is longer than the specified 0\n",
      "Created a chunk of size 1150, which is longer than the specified 0\n",
      "Created a chunk of size 933, which is longer than the specified 0\n",
      "Created a chunk of size 661, which is longer than the specified 0\n",
      "Created a chunk of size 880, which is longer than the specified 0\n",
      "Created a chunk of size 888, which is longer than the specified 0\n",
      "Created a chunk of size 296, which is longer than the specified 0\n",
      "Created a chunk of size 570, which is longer than the specified 0\n",
      "Created a chunk of size 893, which is longer than the specified 0\n",
      "Created a chunk of size 528, which is longer than the specified 0\n",
      "Created a chunk of size 554, which is longer than the specified 0\n",
      "Created a chunk of size 909, which is longer than the specified 0\n",
      "Created a chunk of size 963, which is longer than the specified 0\n",
      "Created a chunk of size 868, which is longer than the specified 0\n",
      "Created a chunk of size 529, which is longer than the specified 0\n",
      "Created a chunk of size 406, which is longer than the specified 0\n",
      "Created a chunk of size 631, which is longer than the specified 0\n",
      "Created a chunk of size 349, which is longer than the specified 0\n",
      "Created a chunk of size 483, which is longer than the specified 0\n",
      "Created a chunk of size 510, which is longer than the specified 0\n",
      "Created a chunk of size 473, which is longer than the specified 0\n",
      "Created a chunk of size 343, which is longer than the specified 0\n",
      "Created a chunk of size 183, which is longer than the specified 0\n",
      "Created a chunk of size 649, which is longer than the specified 0\n",
      "Created a chunk of size 243, which is longer than the specified 0\n",
      "Created a chunk of size 461, which is longer than the specified 0\n",
      "Created a chunk of size 227, which is longer than the specified 0\n",
      "Created a chunk of size 209, which is longer than the specified 0\n",
      "Created a chunk of size 905, which is longer than the specified 0\n",
      "Created a chunk of size 294, which is longer than the specified 0\n",
      "Created a chunk of size 304, which is longer than the specified 0\n",
      "Created a chunk of size 304, which is longer than the specified 0\n",
      "Created a chunk of size 604, which is longer than the specified 0\n",
      "Created a chunk of size 565, which is longer than the specified 0\n",
      "Created a chunk of size 667, which is longer than the specified 0\n",
      "Created a chunk of size 525, which is longer than the specified 0\n",
      "Created a chunk of size 332, which is longer than the specified 0\n",
      "Created a chunk of size 308, which is longer than the specified 0\n",
      "Created a chunk of size 1155, which is longer than the specified 0\n",
      "Created a chunk of size 1350, which is longer than the specified 0\n",
      "Created a chunk of size 1403, which is longer than the specified 0\n",
      "Created a chunk of size 975, which is longer than the specified 0\n",
      "Created a chunk of size 411, which is longer than the specified 0\n",
      "Created a chunk of size 413, which is longer than the specified 0\n",
      "Created a chunk of size 282, which is longer than the specified 0\n",
      "Created a chunk of size 291, which is longer than the specified 0\n",
      "Created a chunk of size 580, which is longer than the specified 0\n",
      "Created a chunk of size 368, which is longer than the specified 0\n",
      "Created a chunk of size 637, which is longer than the specified 0\n",
      "Created a chunk of size 1898, which is longer than the specified 0\n",
      "Created a chunk of size 234, which is longer than the specified 0\n",
      "Created a chunk of size 385, which is longer than the specified 0\n",
      "Created a chunk of size 2149, which is longer than the specified 0\n",
      "Created a chunk of size 344, which is longer than the specified 0\n",
      "Created a chunk of size 325, which is longer than the specified 0\n",
      "Created a chunk of size 205, which is longer than the specified 0\n",
      "Created a chunk of size 275, which is longer than the specified 0\n",
      "Created a chunk of size 1417, which is longer than the specified 0\n",
      "Created a chunk of size 586, which is longer than the specified 0\n",
      "Created a chunk of size 973, which is longer than the specified 0\n",
      "Created a chunk of size 1419, which is longer than the specified 0\n",
      "Created a chunk of size 302, which is longer than the specified 0\n",
      "Created a chunk of size 170, which is longer than the specified 0\n",
      "Created a chunk of size 840, which is longer than the specified 0\n",
      "Created a chunk of size 1387, which is longer than the specified 0\n",
      "Created a chunk of size 486, which is longer than the specified 0\n",
      "Created a chunk of size 507, which is longer than the specified 0\n",
      "Created a chunk of size 1280, which is longer than the specified 0\n",
      "Created a chunk of size 1287, which is longer than the specified 0\n",
      "Created a chunk of size 189, which is longer than the specified 0\n",
      "Created a chunk of size 677, which is longer than the specified 0\n",
      "Created a chunk of size 465, which is longer than the specified 0\n",
      "Created a chunk of size 799, which is longer than the specified 0\n",
      "Created a chunk of size 1043, which is longer than the specified 0\n",
      "Created a chunk of size 416, which is longer than the specified 0\n",
      "Created a chunk of size 2742, which is longer than the specified 0\n",
      "Created a chunk of size 325, which is longer than the specified 0\n",
      "Created a chunk of size 866, which is longer than the specified 0\n",
      "Created a chunk of size 603, which is longer than the specified 0\n",
      "Created a chunk of size 404, which is longer than the specified 0\n",
      "Created a chunk of size 1182, which is longer than the specified 0\n",
      "Created a chunk of size 317, which is longer than the specified 0\n",
      "Created a chunk of size 654, which is longer than the specified 0\n",
      "Created a chunk of size 378, which is longer than the specified 0\n",
      "Created a chunk of size 1000, which is longer than the specified 0\n",
      "Created a chunk of size 234, which is longer than the specified 0\n",
      "Created a chunk of size 215, which is longer than the specified 0\n",
      "Created a chunk of size 295, which is longer than the specified 0\n",
      "Created a chunk of size 312, which is longer than the specified 0\n",
      "Created a chunk of size 796, which is longer than the specified 0\n",
      "Created a chunk of size 3938, which is longer than the specified 0\n",
      "Created a chunk of size 923, which is longer than the specified 0\n",
      "Created a chunk of size 695, which is longer than the specified 0\n",
      "Created a chunk of size 853, which is longer than the specified 0\n",
      "Created a chunk of size 928, which is longer than the specified 0\n",
      "Created a chunk of size 548, which is longer than the specified 0\n",
      "Created a chunk of size 1019, which is longer than the specified 0\n",
      "Created a chunk of size 395, which is longer than the specified 0\n",
      "Created a chunk of size 306, which is longer than the specified 0\n",
      "Created a chunk of size 262, which is longer than the specified 0\n",
      "Created a chunk of size 398, which is longer than the specified 0\n",
      "Created a chunk of size 332, which is longer than the specified 0\n",
      "Created a chunk of size 1108, which is longer than the specified 0\n",
      "Created a chunk of size 330, which is longer than the specified 0\n",
      "Created a chunk of size 244, which is longer than the specified 0\n",
      "Created a chunk of size 191, which is longer than the specified 0\n",
      "Created a chunk of size 365, which is longer than the specified 0\n",
      "Created a chunk of size 440, which is longer than the specified 0\n",
      "Created a chunk of size 1273, which is longer than the specified 0\n",
      "Created a chunk of size 299, which is longer than the specified 0\n",
      "Created a chunk of size 346, which is longer than the specified 0\n",
      "Created a chunk of size 1964, which is longer than the specified 0\n",
      "Created a chunk of size 540, which is longer than the specified 0\n",
      "Created a chunk of size 1529, which is longer than the specified 0\n",
      "Created a chunk of size 315, which is longer than the specified 0\n",
      "Created a chunk of size 342, which is longer than the specified 0\n",
      "Created a chunk of size 332, which is longer than the specified 0\n",
      "Created a chunk of size 251, which is longer than the specified 0\n",
      "Created a chunk of size 275, which is longer than the specified 0\n",
      "Created a chunk of size 189, which is longer than the specified 0\n",
      "Created a chunk of size 207, which is longer than the specified 0\n",
      "Created a chunk of size 375, which is longer than the specified 0\n",
      "Created a chunk of size 208, which is longer than the specified 0\n",
      "Created a chunk of size 273, which is longer than the specified 0\n",
      "Created a chunk of size 442, which is longer than the specified 0\n",
      "Created a chunk of size 183, which is longer than the specified 0\n",
      "Created a chunk of size 438, which is longer than the specified 0\n",
      "Created a chunk of size 167, which is longer than the specified 0\n",
      "Created a chunk of size 612, which is longer than the specified 0\n",
      "Created a chunk of size 268, which is longer than the specified 0\n",
      "Created a chunk of size 1302, which is longer than the specified 0\n",
      "Created a chunk of size 182, which is longer than the specified 0\n",
      "Created a chunk of size 292, which is longer than the specified 0\n",
      "Created a chunk of size 328, which is longer than the specified 0\n",
      "Created a chunk of size 519, which is longer than the specified 0\n",
      "Created a chunk of size 283, which is longer than the specified 0\n",
      "Created a chunk of size 999, which is longer than the specified 0\n",
      "Created a chunk of size 767, which is longer than the specified 0\n",
      "Created a chunk of size 291, which is longer than the specified 0\n",
      "Created a chunk of size 234, which is longer than the specified 0\n",
      "Created a chunk of size 561, which is longer than the specified 0\n",
      "Created a chunk of size 651, which is longer than the specified 0\n",
      "Created a chunk of size 224, which is longer than the specified 0\n",
      "Created a chunk of size 1048, which is longer than the specified 0\n",
      "Created a chunk of size 1272, which is longer than the specified 0\n",
      "Created a chunk of size 950, which is longer than the specified 0\n",
      "Created a chunk of size 451, which is longer than the specified 0\n",
      "Created a chunk of size 384, which is longer than the specified 0\n",
      "Created a chunk of size 682, which is longer than the specified 0\n",
      "Created a chunk of size 348, which is longer than the specified 0\n",
      "Created a chunk of size 584, which is longer than the specified 0\n",
      "Created a chunk of size 251, which is longer than the specified 0\n",
      "Created a chunk of size 195, which is longer than the specified 0\n",
      "Created a chunk of size 315, which is longer than the specified 0\n",
      "Created a chunk of size 308, which is longer than the specified 0\n",
      "Created a chunk of size 1655, which is longer than the specified 0\n",
      "Created a chunk of size 387, which is longer than the specified 0\n",
      "Created a chunk of size 763, which is longer than the specified 0\n",
      "Created a chunk of size 1032, which is longer than the specified 0\n"
     ]
    }
   ],
   "source": [
    "raw_documents = TextLoader(\"tagged_description.txt\").load()\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=0,\n",
    "    chunk_overlap=0,\n",
    "    length_function=len,\n",
    ")\n",
    "documents = text_splitter.split_documents(raw_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f66659a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'tagged_description.txt'}, page_content='9780002005883 A NOVEL THAT READERS and critics have been eagerly anticipating for over a decade, Gilead is an astonishingly imagined story of remarkable lives. John Ames is a preacher, the son of a preacher and the grandson (both maternal and paternal) of preachers. Itâ€™s 1956 in Gilead, Iowa, towards the end of the Reverend Amesâ€™s life, and he is absorbed in recording his familyâ€™s story, a legacy for the young son he will never see grow up. Haunted by his grandfatherâ€™s presence, John tells of the rift between his grandfather and his father: the elder, an angry visionary who fought for the abolitionist cause, and his son, an ardent pacifist. He is troubled, too, by his prodigal namesake, Jack (John Ames) Boughton, his best friendâ€™s lost son who returns to Gilead searching for forgiveness and redemption. Told in John Amesâ€™s joyous, rambling voice that finds beauty, humour and truth in the smallest of lifeâ€™s details, Gilead is a song of celebration and acceptance of the best and the worst the world has to offer. At its heart is a tale of the sacred bonds between fathers and sons, pitch-perfect in style and story, set to dazzle critics and readers alike.')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9f2a159",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_books = Chroma.from_documents(\n",
    "    documents,\n",
    "    embedding=OpenAIEmbeddings()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a61220f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='511c27fc-8b74-4e94-827c-fc7cb7346dc4', metadata={'source': 'tagged_description.txt'}, page_content='9780786808069 Children will discover the exciting world of their own backyard in this introduction to familiar animals from cats and dogs to bugs and frogs. The combination of photographs, illustrations, and fun facts make this an accessible and delightful learning experience.'),\n",
       " Document(id='cca748a5-c722-4de6-8ba1-b4599252be54', metadata={'source': 'tagged_description.txt'}, page_content=\"9780786808380 Introduce your babies to birds, cats, dogs, and babies through fine art, illustration, and photographs. These books are a rare opportunity to expose little ones to a range of images on a single subject, from simple child's drawings and abstract art to playful photos. A brief text accompanies each image, introducing the baby to some basic -- and sometimes playful -- information about the subjects.\"),\n",
       " Document(id='b7a52efe-e785-4ec2-af67-9e5a270ebc6d', metadata={'source': 'tagged_description.txt'}, page_content=\"9780786808397 Introduce your baby to birds, cats, dogs, and babies through fine art, illustration, and photographs. These books are a rare opportunity to exopse little ones to a range of images on a single subject, from simple child's drawings and abstract art to playful photos. A brief text accompanies each image, introducing baby to some basic -- and sometimes playful -- information about the subjects.\"),\n",
       " Document(id='102d154a-9ec1-4c18-92dd-3083d7d49c90', metadata={'source': 'tagged_description.txt'}, page_content=\"9780786808373 Introducing your baby to birds, cats, dogs, and babies through fine art, illsutration and photographs. These books are a rare opportunity to expose little ones to a range of images on a single subject, from simple child's drawings and abstract art to playful photos. A brief text accompanies each image, introducing baby to some basic -- and sometimes playful -- information on the subjects.\"),\n",
       " Document(id='7c772f83-843c-40ac-bc8b-024f422b277c', metadata={'source': 'tagged_description.txt'}, page_content=\"9780689861130 Children will love joining in and imitating the animal noises and sounds in this big, bold board book format, illustrated with Sandra Boynton's seriously silly signature animals.\"),\n",
       " Document(id='21641a30-9ab3-4df3-9b9b-e5ac9aba50de', metadata={'source': 'tagged_description.txt'}, page_content='9780789458209 Photographs and text explore the anatomy and life cycle of trees, examining the different kinds of bark, seeds, and leaves, the commercial processing of trees to make lumber, the creatures that live in trees, and other aspects.'),\n",
       " Document(id='78997809-f682-4b42-9863-9ffd8b413bda', metadata={'source': 'tagged_description.txt'}, page_content='9780786808717 A very special puddle sets Violet the mouse off on her latest nature discovery. It is through this puddle that Violet observes the effect rain has on the world around her. A Mylar puddle on the last page offers children a chance to see their reflection in a puddle, just like Violet!'),\n",
       " Document(id='a316ea81-d65d-41e1-86d1-af951966f891', metadata={'source': 'tagged_description.txt'}, page_content='9780786812912 In her first illustrated book for children, the Pulitzer Prizeâ€“winning author Toni Morrison introduces three feisty children who show grown-ups what it really means to be a kid.'),\n",
       " Document(id='7b5f52eb-ff3c-41c2-8e52-5f9aa63d31f8', metadata={'source': 'tagged_description.txt'}, page_content='\"9780067575208 First published more than three decades ago, this reissue of Rachel Carson\\'s award-winning classic brings her unique vision to a new generation of readers. Stunning new photographs by Nick Kelsh beautifully complement Carson\\'s intimate account of adventures with her young nephew, Roger, as they enjoy walks along the rocky coast of Maine and through dense forests and open fields, observing wildlife, strange plants, moonlight and storm clouds, and listening to the \"\"living music\"\" of insects in the underbrush. \"\"If a child is to keep alive his inborn sense of wonder.\"\" Writes Carson, \"\"he needs the companionship of at least one adult who can share it, rediscovering with him the joy, excitement and mystery of the world we live in.\"\" The Sense of Wonder is a refreshing antidote to indifference and a guide to capturing the simple power of discovery that Carson views as essential to life. In her insightful new introduction, Linda Lear remembers Rachel Carson\\'s groundbreaking achievements in the context of the legendary environmentalist\\'s personal commitment to introducing young and old to the miracles of nature. Kelsh\\'s lush photographs inspire sensual, tactile reactions: masses of leaves floating in a puddle are just waiting to be scooped up and examined more closely. An image of a narrow path through the trees evokes the earthy scent of the woods after a summer rain. Close-ups of mosses and miniature lichen fantasy-lands will spark innocent\\'as well as more jaded\\'imaginations. Like a curious child studying things underfoot and within reach, Kelsh\\'s camera is drawn to patterns in nature that too often elude hurried adults\\'a stand of beech trees in the springtime, patches of melting snow and the ripples from a pebble tossed into a slow-moving stream. The Sense of Wonder is a timeless volume that will be passed on from children to grandchildren, as treasured as the memory of an early-morning walk when the song of a whippoorwill was heard as if for the first time.\"'),\n",
       " Document(id='92fd0a0d-fb88-4c9f-806d-5c6cf95f5f9a', metadata={'source': 'tagged_description.txt'}, page_content='9780763620875 When Judy Moody gets serious about protecting the environment, her little brother Stink thinks she is overdoing it, but she manages to inspire her third grade class to undertake an award-winning, environment-saving project. Reprint.')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"A book to teach children about nature\"\n",
    "docs = db_books.similarity_search(query, k=10)\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f90b95f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isbn13</th>\n",
       "      <th>isbn10</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>categories</th>\n",
       "      <th>thumbnail</th>\n",
       "      <th>description</th>\n",
       "      <th>published_year</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>title_and_subtitle</th>\n",
       "      <th>tagged_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3747</th>\n",
       "      <td>9780786808069</td>\n",
       "      <td>0786808063</td>\n",
       "      <td>Baby Einstein: Neighborhood Animals</td>\n",
       "      <td>Marilyn Singer;Julie Aigner-Clark</td>\n",
       "      <td>Juvenile Fiction</td>\n",
       "      <td>http://books.google.com/books/content?id=X9a4P...</td>\n",
       "      <td>Children will discover the exciting world of t...</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>3.89</td>\n",
       "      <td>16.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>Baby Einstein: Neighborhood Animals</td>\n",
       "      <td>9780786808069 Children will discover the excit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             isbn13      isbn10                                title  \\\n",
       "3747  9780786808069  0786808063  Baby Einstein: Neighborhood Animals   \n",
       "\n",
       "                                authors        categories  \\\n",
       "3747  Marilyn Singer;Julie Aigner-Clark  Juvenile Fiction   \n",
       "\n",
       "                                              thumbnail  \\\n",
       "3747  http://books.google.com/books/content?id=X9a4P...   \n",
       "\n",
       "                                            description  published_year  \\\n",
       "3747  Children will discover the exciting world of t...          2001.0   \n",
       "\n",
       "      average_rating  num_pages  ratings_count  \\\n",
       "3747            3.89       16.0          180.0   \n",
       "\n",
       "                       title_and_subtitle  \\\n",
       "3747  Baby Einstein: Neighborhood Animals   \n",
       "\n",
       "                                     tagged_description  \n",
       "3747  9780786808069 Children will discover the excit...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books[books[\"isbn13\"] == int(docs[0].page_content.split()[0].strip())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26caec60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_semantic_recommmendations(\n",
    "        query: str,\n",
    "        top_k:int = 10,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Retrieve semantic recommendations based on a query.\n",
    "    \"\"\"\n",
    "    recs = db_books.similarity_search(query, k=50)\n",
    "    books_list = []\n",
    "    for i in range(0, len(recs)):\n",
    "        books_list.append(int(recs[i].page_content.strip('\"').split()[0]))\n",
    "\n",
    "\n",
    "    return books[books[\"isbn13\"].isin(books_list)].head(top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9c133ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isbn13</th>\n",
       "      <th>isbn10</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>categories</th>\n",
       "      <th>thumbnail</th>\n",
       "      <th>description</th>\n",
       "      <th>published_year</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>title_and_subtitle</th>\n",
       "      <th>tagged_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>9780060652920</td>\n",
       "      <td>0060652926</td>\n",
       "      <td>Mere Christianity</td>\n",
       "      <td>C. S. Lewis</td>\n",
       "      <td>Religion</td>\n",
       "      <td>http://books.google.com/books/content?id=LpHbX...</td>\n",
       "      <td>A forceful and accessible discussion of Christ...</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>4.32</td>\n",
       "      <td>227.0</td>\n",
       "      <td>7316.0</td>\n",
       "      <td>Mere Christianity</td>\n",
       "      <td>9780060652920 A forceful and accessible discus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>9780062508867</td>\n",
       "      <td>0062508865</td>\n",
       "      <td>Muhammad</td>\n",
       "      <td>Karen Armstrong</td>\n",
       "      <td>Biography &amp; Autobiography</td>\n",
       "      <td>http://books.google.com/books/content?id=FbDVD...</td>\n",
       "      <td>This vivid and detailed biography strips away ...</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>4.15</td>\n",
       "      <td>304.0</td>\n",
       "      <td>4795.0</td>\n",
       "      <td>Muhammad</td>\n",
       "      <td>9780062508867 This vivid and detailed biograph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>9780062700254</td>\n",
       "      <td>0062700251</td>\n",
       "      <td>Bulfinch's Mythology</td>\n",
       "      <td>Richard P. Martin</td>\n",
       "      <td>Reference</td>\n",
       "      <td>http://books.google.com/books/content?id=eev4u...</td>\n",
       "      <td>A beautiful gift edition of Thomas Bulfinch's ...</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>4.10</td>\n",
       "      <td>768.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>Bulfinch's Mythology:The Age of the Fable, The...</td>\n",
       "      <td>9780062700254 A beautiful gift edition of Thom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>9780140448948</td>\n",
       "      <td>0140448942</td>\n",
       "      <td>City of God</td>\n",
       "      <td>Augustine;Henry Scowcroft Bettenson;Gillian Ro...</td>\n",
       "      <td>History</td>\n",
       "      <td>http://books.google.com/books/content?id=SaznV...</td>\n",
       "      <td>One of the great cornerstones in the history o...</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1186.0</td>\n",
       "      <td>8508.0</td>\n",
       "      <td>City of God</td>\n",
       "      <td>9780140448948 One of the great cornerstones in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>9780141185910</td>\n",
       "      <td>0141185910</td>\n",
       "      <td>Go Tell it on the Mountain</td>\n",
       "      <td>James Baldwin</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>http://books.google.com/books/content?id=eyg78...</td>\n",
       "      <td>The story of the guilt, bitterness and spiritu...</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>4.01</td>\n",
       "      <td>256.0</td>\n",
       "      <td>33558.0</td>\n",
       "      <td>Go Tell it on the Mountain</td>\n",
       "      <td>9780141185910 The story of the guilt, bitterne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965</th>\n",
       "      <td>9780192833600</td>\n",
       "      <td>019283360X</td>\n",
       "      <td>The Canterbury Tales</td>\n",
       "      <td>Geoffrey Chaucer;David Wright</td>\n",
       "      <td>Poetry</td>\n",
       "      <td>http://books.google.com/books/content?id=5WkDQ...</td>\n",
       "      <td>Provides a modern verse translation of the sto...</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>3.49</td>\n",
       "      <td>465.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>The Canterbury Tales</td>\n",
       "      <td>9780192833600 Provides a modern verse translat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>9780300000894</td>\n",
       "      <td>0300000898</td>\n",
       "      <td>Psychoanalysis and Religion</td>\n",
       "      <td>Erich Fromm</td>\n",
       "      <td>Psychology</td>\n",
       "      <td>http://books.google.com/books/content?id=gtAgG...</td>\n",
       "      <td>A noted psychoanalyst assesses the modern issu...</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>4.04</td>\n",
       "      <td>126.0</td>\n",
       "      <td>822.0</td>\n",
       "      <td>Psychoanalysis and Religion</td>\n",
       "      <td>9780300000894 A noted psychoanalyst assesses t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164</th>\n",
       "      <td>9780310259664</td>\n",
       "      <td>0310259665</td>\n",
       "      <td>Journey into God's Word</td>\n",
       "      <td>J. Scott Duvall;J. Daniel Hays</td>\n",
       "      <td>Religion</td>\n",
       "      <td>http://books.google.com/books/content?id=Yg9xD...</td>\n",
       "      <td>Life is a journey, and like any journey, it re...</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>4.16</td>\n",
       "      <td>462.0</td>\n",
       "      <td>766.0</td>\n",
       "      <td>Journey into God's Word:Your Guide to Understa...</td>\n",
       "      <td>9780310259664 Life is a journey, and like any ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1165</th>\n",
       "      <td>9780310263456</td>\n",
       "      <td>031026345X</td>\n",
       "      <td>Velvet Elvis</td>\n",
       "      <td>Rob Bell</td>\n",
       "      <td>Religion</td>\n",
       "      <td>http://books.google.com/books/content?id=TLZO9...</td>\n",
       "      <td>A guide to living an authentic Christian life ...</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>3.78</td>\n",
       "      <td>194.0</td>\n",
       "      <td>19646.0</td>\n",
       "      <td>Velvet Elvis:Repainting the Christian Faith</td>\n",
       "      <td>9780310263456 A guide to living an authentic C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166</th>\n",
       "      <td>9780310264132</td>\n",
       "      <td>0310264138</td>\n",
       "      <td>Purpose Driven Life MM Camouflage Edition</td>\n",
       "      <td>Rick Warren, D.Min.;Zondervan Publishing</td>\n",
       "      <td>Christian life</td>\n",
       "      <td>http://books.google.com/books/content?id=2_zhA...</td>\n",
       "      <td>The #1 international bestseller! This 40-day s...</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>3.92</td>\n",
       "      <td>336.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Purpose Driven Life MM Camouflage Edition</td>\n",
       "      <td>9780310264132 The #1 international bestseller!...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             isbn13      isbn10                                      title  \\\n",
       "190   9780060652920  0060652926                          Mere Christianity   \n",
       "395   9780062508867  0062508865                                   Muhammad   \n",
       "400   9780062700254  0062700251                       Bulfinch's Mythology   \n",
       "697   9780140448948  0140448942                                City of God   \n",
       "761   9780141185910  0141185910                 Go Tell it on the Mountain   \n",
       "965   9780192833600  019283360X                       The Canterbury Tales   \n",
       "1117  9780300000894  0300000898                Psychoanalysis and Religion   \n",
       "1164  9780310259664  0310259665                    Journey into God's Word   \n",
       "1165  9780310263456  031026345X                               Velvet Elvis   \n",
       "1166  9780310264132  0310264138  Purpose Driven Life MM Camouflage Edition   \n",
       "\n",
       "                                                authors  \\\n",
       "190                                         C. S. Lewis   \n",
       "395                                     Karen Armstrong   \n",
       "400                                   Richard P. Martin   \n",
       "697   Augustine;Henry Scowcroft Bettenson;Gillian Ro...   \n",
       "761                                       James Baldwin   \n",
       "965                       Geoffrey Chaucer;David Wright   \n",
       "1117                                        Erich Fromm   \n",
       "1164                     J. Scott Duvall;J. Daniel Hays   \n",
       "1165                                           Rob Bell   \n",
       "1166           Rick Warren, D.Min.;Zondervan Publishing   \n",
       "\n",
       "                     categories  \\\n",
       "190                    Religion   \n",
       "395   Biography & Autobiography   \n",
       "400                   Reference   \n",
       "697                     History   \n",
       "761                     Fiction   \n",
       "965                      Poetry   \n",
       "1117                 Psychology   \n",
       "1164                   Religion   \n",
       "1165                   Religion   \n",
       "1166             Christian life   \n",
       "\n",
       "                                              thumbnail  \\\n",
       "190   http://books.google.com/books/content?id=LpHbX...   \n",
       "395   http://books.google.com/books/content?id=FbDVD...   \n",
       "400   http://books.google.com/books/content?id=eev4u...   \n",
       "697   http://books.google.com/books/content?id=SaznV...   \n",
       "761   http://books.google.com/books/content?id=eyg78...   \n",
       "965   http://books.google.com/books/content?id=5WkDQ...   \n",
       "1117  http://books.google.com/books/content?id=gtAgG...   \n",
       "1164  http://books.google.com/books/content?id=Yg9xD...   \n",
       "1165  http://books.google.com/books/content?id=TLZO9...   \n",
       "1166  http://books.google.com/books/content?id=2_zhA...   \n",
       "\n",
       "                                            description  published_year  \\\n",
       "190   A forceful and accessible discussion of Christ...          2001.0   \n",
       "395   This vivid and detailed biography strips away ...          1993.0   \n",
       "400   A beautiful gift edition of Thomas Bulfinch's ...          1991.0   \n",
       "697   One of the great cornerstones in the history o...          2003.0   \n",
       "761   The story of the guilt, bitterness and spiritu...          2001.0   \n",
       "965   Provides a modern verse translation of the sto...          1998.0   \n",
       "1117  A noted psychoanalyst assesses the modern issu...          1950.0   \n",
       "1164  Life is a journey, and like any journey, it re...          2005.0   \n",
       "1165  A guide to living an authentic Christian life ...          2005.0   \n",
       "1166  The #1 international bestseller! This 40-day s...          2004.0   \n",
       "\n",
       "      average_rating  num_pages  ratings_count  \\\n",
       "190             4.32      227.0         7316.0   \n",
       "395             4.15      304.0         4795.0   \n",
       "400             4.10      768.0           64.0   \n",
       "697             3.92     1186.0         8508.0   \n",
       "761             4.01      256.0        33558.0   \n",
       "965             3.49      465.0          249.0   \n",
       "1117            4.04      126.0          822.0   \n",
       "1164            4.16      462.0          766.0   \n",
       "1165            3.78      194.0        19646.0   \n",
       "1166            3.92      336.0           20.0   \n",
       "\n",
       "                                     title_and_subtitle  \\\n",
       "190                                   Mere Christianity   \n",
       "395                                            Muhammad   \n",
       "400   Bulfinch's Mythology:The Age of the Fable, The...   \n",
       "697                                         City of God   \n",
       "761                          Go Tell it on the Mountain   \n",
       "965                                The Canterbury Tales   \n",
       "1117                        Psychoanalysis and Religion   \n",
       "1164  Journey into God's Word:Your Guide to Understa...   \n",
       "1165        Velvet Elvis:Repainting the Christian Faith   \n",
       "1166          Purpose Driven Life MM Camouflage Edition   \n",
       "\n",
       "                                     tagged_description  \n",
       "190   9780060652920 A forceful and accessible discus...  \n",
       "395   9780062508867 This vivid and detailed biograph...  \n",
       "400   9780062700254 A beautiful gift edition of Thom...  \n",
       "697   9780140448948 One of the great cornerstones in...  \n",
       "761   9780141185910 The story of the guilt, bitterne...  \n",
       "965   9780192833600 Provides a modern verse translat...  \n",
       "1117  9780300000894 A noted psychoanalyst assesses t...  \n",
       "1164  9780310259664 Life is a journey, and like any ...  \n",
       "1165  9780310263456 A guide to living an authentic C...  \n",
       "1166  9780310264132 The #1 international bestseller!...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieve_semantic_recommmendations(\n",
    "    query=\"A book about God\",\n",
    "    top_k=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c198f870",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_mapping = {\n",
    "    'Fiction': 'Fiction',\n",
    "    'Juvenile Fiction': \"Children's Fiction\",\n",
    "    'Biogaphy & Autobiography': 'Nonfiction',\n",
    "    'History': 'Nonfiction',\n",
    "    'Literary Criticism': 'Nonfiction',\n",
    "    'Philosophy': 'Nonfiction',\n",
    "    'Religion': 'Nonfiction',\n",
    "    'Comics & Graphic Novels': \"Fiction\",\n",
    "    'Drama': \"Fiction\",\n",
    "    'Juvenile Nonfiction': \"Children's Nonfiction\",\n",
    "    'Poetry': \"Fiction\",\n",
    "    'Science': 'Nonfiction',\n",
    "}\n",
    "\n",
    "books[\"simple_categories\"] = books[\"categories\"].map(category_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9727ee95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isbn13</th>\n",
       "      <th>isbn10</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>categories</th>\n",
       "      <th>thumbnail</th>\n",
       "      <th>description</th>\n",
       "      <th>published_year</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>title_and_subtitle</th>\n",
       "      <th>tagged_description</th>\n",
       "      <th>simple_categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9780002005883</td>\n",
       "      <td>0002005883</td>\n",
       "      <td>Gilead</td>\n",
       "      <td>Marilynne Robinson</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>http://books.google.com/books/content?id=KQZCP...</td>\n",
       "      <td>A NOVEL THAT READERS and critics have been eag...</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>247.0</td>\n",
       "      <td>361.0</td>\n",
       "      <td>Gilead</td>\n",
       "      <td>9780002005883 A NOVEL THAT READERS and critics...</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9780002261982</td>\n",
       "      <td>0002261987</td>\n",
       "      <td>Spider's Web</td>\n",
       "      <td>Charles Osborne;Agatha Christie</td>\n",
       "      <td>Detective and mystery stories</td>\n",
       "      <td>http://books.google.com/books/content?id=gA5GP...</td>\n",
       "      <td>A new 'Christie for Christmas' -- a full-lengt...</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>3.83</td>\n",
       "      <td>241.0</td>\n",
       "      <td>5164.0</td>\n",
       "      <td>Spider's Web:A Novel</td>\n",
       "      <td>9780002261982 A new 'Christie for Christmas' -...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9780006178736</td>\n",
       "      <td>0006178731</td>\n",
       "      <td>Rage of angels</td>\n",
       "      <td>Sidney Sheldon</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>http://books.google.com/books/content?id=FKo2T...</td>\n",
       "      <td>A memorable, mesmerizing heroine Jennifer -- b...</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>3.93</td>\n",
       "      <td>512.0</td>\n",
       "      <td>29532.0</td>\n",
       "      <td>Rage of angels</td>\n",
       "      <td>9780006178736 A memorable, mesmerizing heroine...</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9780006280897</td>\n",
       "      <td>0006280897</td>\n",
       "      <td>The Four Loves</td>\n",
       "      <td>Clive Staples Lewis</td>\n",
       "      <td>Christian life</td>\n",
       "      <td>http://books.google.com/books/content?id=XhQ5X...</td>\n",
       "      <td>Lewis' work on the nature of love divides love...</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>4.15</td>\n",
       "      <td>170.0</td>\n",
       "      <td>33684.0</td>\n",
       "      <td>The Four Loves</td>\n",
       "      <td>9780006280897 Lewis' work on the nature of lov...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9780006280934</td>\n",
       "      <td>0006280935</td>\n",
       "      <td>The Problem of Pain</td>\n",
       "      <td>Clive Staples Lewis</td>\n",
       "      <td>Christian life</td>\n",
       "      <td>http://books.google.com/books/content?id=Kk-uV...</td>\n",
       "      <td>\"In The Problem of Pain, C.S. Lewis, one of th...</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>4.09</td>\n",
       "      <td>176.0</td>\n",
       "      <td>37569.0</td>\n",
       "      <td>The Problem of Pain</td>\n",
       "      <td>9780006280934 \"In The Problem of Pain, C.S. Le...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5192</th>\n",
       "      <td>9788172235222</td>\n",
       "      <td>8172235224</td>\n",
       "      <td>Mistaken Identity</td>\n",
       "      <td>Nayantara Sahgal</td>\n",
       "      <td>Indic fiction (English)</td>\n",
       "      <td>http://books.google.com/books/content?id=q-tKP...</td>\n",
       "      <td>On A Train Journey Home To North India After L...</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>2.93</td>\n",
       "      <td>324.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Mistaken Identity</td>\n",
       "      <td>9788172235222 On A Train Journey Home To North...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5193</th>\n",
       "      <td>9788173031014</td>\n",
       "      <td>8173031010</td>\n",
       "      <td>Journey to the East</td>\n",
       "      <td>Hermann Hesse</td>\n",
       "      <td>Adventure stories</td>\n",
       "      <td>http://books.google.com/books/content?id=rq6JP...</td>\n",
       "      <td>This book tells the tale of a man who goes on ...</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>3.70</td>\n",
       "      <td>175.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Journey to the East</td>\n",
       "      <td>9788173031014 This book tells the tale of a ma...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5194</th>\n",
       "      <td>9788179921623</td>\n",
       "      <td>817992162X</td>\n",
       "      <td>The Monk Who Sold His Ferrari: A Fable About F...</td>\n",
       "      <td>Robin Sharma</td>\n",
       "      <td>Health &amp; Fitness</td>\n",
       "      <td>http://books.google.com/books/content?id=c_7mf...</td>\n",
       "      <td>Wisdom to Create a Life of Passion, Purpose, a...</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>3.82</td>\n",
       "      <td>198.0</td>\n",
       "      <td>1568.0</td>\n",
       "      <td>The Monk Who Sold His Ferrari: A Fable About F...</td>\n",
       "      <td>9788179921623 Wisdom to Create a Life of Passi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5195</th>\n",
       "      <td>9788185300535</td>\n",
       "      <td>8185300534</td>\n",
       "      <td>I Am that</td>\n",
       "      <td>Sri Nisargadatta Maharaj;Sudhakar S. Dikshit</td>\n",
       "      <td>Philosophy</td>\n",
       "      <td>http://books.google.com/books/content?id=Fv_JP...</td>\n",
       "      <td>This collection of the timeless teachings of o...</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>4.51</td>\n",
       "      <td>531.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>I Am that:Talks with Sri Nisargadatta Maharaj</td>\n",
       "      <td>9788185300535 This collection of the timeless ...</td>\n",
       "      <td>Nonfiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5196</th>\n",
       "      <td>9789027712059</td>\n",
       "      <td>9027712050</td>\n",
       "      <td>The Berlin Phenomenology</td>\n",
       "      <td>Georg Wilhelm Friedrich Hegel</td>\n",
       "      <td>History</td>\n",
       "      <td>http://books.google.com/books/content?id=Vy7Sk...</td>\n",
       "      <td>Since the three volume edition ofHegel's Philo...</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>210.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The Berlin Phenomenology</td>\n",
       "      <td>9789027712059 Since the three volume edition o...</td>\n",
       "      <td>Nonfiction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5197 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             isbn13      isbn10  \\\n",
       "0     9780002005883  0002005883   \n",
       "1     9780002261982  0002261987   \n",
       "2     9780006178736  0006178731   \n",
       "3     9780006280897  0006280897   \n",
       "4     9780006280934  0006280935   \n",
       "...             ...         ...   \n",
       "5192  9788172235222  8172235224   \n",
       "5193  9788173031014  8173031010   \n",
       "5194  9788179921623  817992162X   \n",
       "5195  9788185300535  8185300534   \n",
       "5196  9789027712059  9027712050   \n",
       "\n",
       "                                                  title  \\\n",
       "0                                                Gilead   \n",
       "1                                          Spider's Web   \n",
       "2                                        Rage of angels   \n",
       "3                                        The Four Loves   \n",
       "4                                   The Problem of Pain   \n",
       "...                                                 ...   \n",
       "5192                                  Mistaken Identity   \n",
       "5193                                Journey to the East   \n",
       "5194  The Monk Who Sold His Ferrari: A Fable About F...   \n",
       "5195                                          I Am that   \n",
       "5196                           The Berlin Phenomenology   \n",
       "\n",
       "                                           authors  \\\n",
       "0                               Marilynne Robinson   \n",
       "1                  Charles Osborne;Agatha Christie   \n",
       "2                                   Sidney Sheldon   \n",
       "3                              Clive Staples Lewis   \n",
       "4                              Clive Staples Lewis   \n",
       "...                                            ...   \n",
       "5192                              Nayantara Sahgal   \n",
       "5193                                 Hermann Hesse   \n",
       "5194                                  Robin Sharma   \n",
       "5195  Sri Nisargadatta Maharaj;Sudhakar S. Dikshit   \n",
       "5196                 Georg Wilhelm Friedrich Hegel   \n",
       "\n",
       "                         categories  \\\n",
       "0                           Fiction   \n",
       "1     Detective and mystery stories   \n",
       "2                           Fiction   \n",
       "3                    Christian life   \n",
       "4                    Christian life   \n",
       "...                             ...   \n",
       "5192        Indic fiction (English)   \n",
       "5193              Adventure stories   \n",
       "5194               Health & Fitness   \n",
       "5195                     Philosophy   \n",
       "5196                        History   \n",
       "\n",
       "                                              thumbnail  \\\n",
       "0     http://books.google.com/books/content?id=KQZCP...   \n",
       "1     http://books.google.com/books/content?id=gA5GP...   \n",
       "2     http://books.google.com/books/content?id=FKo2T...   \n",
       "3     http://books.google.com/books/content?id=XhQ5X...   \n",
       "4     http://books.google.com/books/content?id=Kk-uV...   \n",
       "...                                                 ...   \n",
       "5192  http://books.google.com/books/content?id=q-tKP...   \n",
       "5193  http://books.google.com/books/content?id=rq6JP...   \n",
       "5194  http://books.google.com/books/content?id=c_7mf...   \n",
       "5195  http://books.google.com/books/content?id=Fv_JP...   \n",
       "5196  http://books.google.com/books/content?id=Vy7Sk...   \n",
       "\n",
       "                                            description  published_year  \\\n",
       "0     A NOVEL THAT READERS and critics have been eag...          2004.0   \n",
       "1     A new 'Christie for Christmas' -- a full-lengt...          2000.0   \n",
       "2     A memorable, mesmerizing heroine Jennifer -- b...          1993.0   \n",
       "3     Lewis' work on the nature of love divides love...          2002.0   \n",
       "4     \"In The Problem of Pain, C.S. Lewis, one of th...          2002.0   \n",
       "...                                                 ...             ...   \n",
       "5192  On A Train Journey Home To North India After L...          2003.0   \n",
       "5193  This book tells the tale of a man who goes on ...          2002.0   \n",
       "5194  Wisdom to Create a Life of Passion, Purpose, a...          2003.0   \n",
       "5195  This collection of the timeless teachings of o...          1999.0   \n",
       "5196  Since the three volume edition ofHegel's Philo...          1981.0   \n",
       "\n",
       "      average_rating  num_pages  ratings_count  \\\n",
       "0               3.85      247.0          361.0   \n",
       "1               3.83      241.0         5164.0   \n",
       "2               3.93      512.0        29532.0   \n",
       "3               4.15      170.0        33684.0   \n",
       "4               4.09      176.0        37569.0   \n",
       "...              ...        ...            ...   \n",
       "5192            2.93      324.0            0.0   \n",
       "5193            3.70      175.0           24.0   \n",
       "5194            3.82      198.0         1568.0   \n",
       "5195            4.51      531.0          104.0   \n",
       "5196            0.00      210.0            0.0   \n",
       "\n",
       "                                     title_and_subtitle  \\\n",
       "0                                                Gilead   \n",
       "1                                  Spider's Web:A Novel   \n",
       "2                                        Rage of angels   \n",
       "3                                        The Four Loves   \n",
       "4                                   The Problem of Pain   \n",
       "...                                                 ...   \n",
       "5192                                  Mistaken Identity   \n",
       "5193                                Journey to the East   \n",
       "5194  The Monk Who Sold His Ferrari: A Fable About F...   \n",
       "5195      I Am that:Talks with Sri Nisargadatta Maharaj   \n",
       "5196                           The Berlin Phenomenology   \n",
       "\n",
       "                                     tagged_description simple_categories  \n",
       "0     9780002005883 A NOVEL THAT READERS and critics...           Fiction  \n",
       "1     9780002261982 A new 'Christie for Christmas' -...               NaN  \n",
       "2     9780006178736 A memorable, mesmerizing heroine...           Fiction  \n",
       "3     9780006280897 Lewis' work on the nature of lov...               NaN  \n",
       "4     9780006280934 \"In The Problem of Pain, C.S. Le...               NaN  \n",
       "...                                                 ...               ...  \n",
       "5192  9788172235222 On A Train Journey Home To North...               NaN  \n",
       "5193  9788173031014 This book tells the tale of a ma...               NaN  \n",
       "5194  9788179921623 Wisdom to Create a Life of Passi...               NaN  \n",
       "5195  9788185300535 This collection of the timeless ...        Nonfiction  \n",
       "5196  9789027712059 Since the three volume edition o...        Nonfiction  \n",
       "\n",
       "[5197 rows x 14 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "380af657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isbn13</th>\n",
       "      <th>isbn10</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>categories</th>\n",
       "      <th>thumbnail</th>\n",
       "      <th>description</th>\n",
       "      <th>published_year</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>title_and_subtitle</th>\n",
       "      <th>tagged_description</th>\n",
       "      <th>simple_categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9780002005883</td>\n",
       "      <td>0002005883</td>\n",
       "      <td>Gilead</td>\n",
       "      <td>Marilynne Robinson</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>http://books.google.com/books/content?id=KQZCP...</td>\n",
       "      <td>A NOVEL THAT READERS and critics have been eag...</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>247.0</td>\n",
       "      <td>361.0</td>\n",
       "      <td>Gilead</td>\n",
       "      <td>9780002005883 A NOVEL THAT READERS and critics...</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9780006178736</td>\n",
       "      <td>0006178731</td>\n",
       "      <td>Rage of angels</td>\n",
       "      <td>Sidney Sheldon</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>http://books.google.com/books/content?id=FKo2T...</td>\n",
       "      <td>A memorable, mesmerizing heroine Jennifer -- b...</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>3.93</td>\n",
       "      <td>512.0</td>\n",
       "      <td>29532.0</td>\n",
       "      <td>Rage of angels</td>\n",
       "      <td>9780006178736 A memorable, mesmerizing heroine...</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9780006482079</td>\n",
       "      <td>0006482074</td>\n",
       "      <td>Warhost of Vastmark</td>\n",
       "      <td>Janny Wurts</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>http://books.google.com/books/content?id=uOL0f...</td>\n",
       "      <td>Tricked once more by his wily half-brother, Ly...</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>4.03</td>\n",
       "      <td>522.0</td>\n",
       "      <td>2966.0</td>\n",
       "      <td>Warhost of Vastmark</td>\n",
       "      <td>9780006482079 Tricked once more by his wily ha...</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>9780006646006</td>\n",
       "      <td>000664600X</td>\n",
       "      <td>Ocean Star Express</td>\n",
       "      <td>Mark Haddon;Peter Sutton</td>\n",
       "      <td>Juvenile Fiction</td>\n",
       "      <td>http://books.google.com/books/content?id=I2QZA...</td>\n",
       "      <td>Joe and his parents are enjoying a summer holi...</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>3.50</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Ocean Star Express</td>\n",
       "      <td>9780006646006 Joe and his parents are enjoying...</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>9780007121014</td>\n",
       "      <td>0007121016</td>\n",
       "      <td>Taken at the Flood</td>\n",
       "      <td>Agatha Christie</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>http://books.google.com/books/content?id=3gWlx...</td>\n",
       "      <td>A Few Weeks After Marrying An Attractive Young...</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>3.71</td>\n",
       "      <td>352.0</td>\n",
       "      <td>8852.0</td>\n",
       "      <td>Taken at the Flood</td>\n",
       "      <td>9780007121014 A Few Weeks After Marrying An At...</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5178</th>\n",
       "      <td>9781933648279</td>\n",
       "      <td>1933648279</td>\n",
       "      <td>Night Has a Thousand Eyes</td>\n",
       "      <td>Cornell Woolrich</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>http://books.google.com/books/content?id=3Gk6s...</td>\n",
       "      <td>\"Cornell Woolrich's novels define the essence ...</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>3.77</td>\n",
       "      <td>344.0</td>\n",
       "      <td>680.0</td>\n",
       "      <td>Night Has a Thousand Eyes</td>\n",
       "      <td>9781933648279 \"Cornell Woolrich's novels defin...</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5188</th>\n",
       "      <td>9784770028969</td>\n",
       "      <td>4770028962</td>\n",
       "      <td>Coin Locker Babies</td>\n",
       "      <td>æ‘ä¸Šé¾</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>http://books.google.com/books/content?id=87DJw...</td>\n",
       "      <td>Rescued from the lockers in which they were le...</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>3.75</td>\n",
       "      <td>393.0</td>\n",
       "      <td>5560.0</td>\n",
       "      <td>Coin Locker Babies</td>\n",
       "      <td>9784770028969 Rescued from the lockers in whic...</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5189</th>\n",
       "      <td>9788122200850</td>\n",
       "      <td>8122200850</td>\n",
       "      <td>Cry, the Peacock</td>\n",
       "      <td>Anita Desai</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>http://books.google.com/books/content?id=_QKwV...</td>\n",
       "      <td>This book is the story of a young girl obsesse...</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>3.22</td>\n",
       "      <td>218.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>Cry, the Peacock</td>\n",
       "      <td>9788122200850 This book is the story of a youn...</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5195</th>\n",
       "      <td>9788185300535</td>\n",
       "      <td>8185300534</td>\n",
       "      <td>I Am that</td>\n",
       "      <td>Sri Nisargadatta Maharaj;Sudhakar S. Dikshit</td>\n",
       "      <td>Philosophy</td>\n",
       "      <td>http://books.google.com/books/content?id=Fv_JP...</td>\n",
       "      <td>This collection of the timeless teachings of o...</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>4.51</td>\n",
       "      <td>531.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>I Am that:Talks with Sri Nisargadatta Maharaj</td>\n",
       "      <td>9788185300535 This collection of the timeless ...</td>\n",
       "      <td>Nonfiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5196</th>\n",
       "      <td>9789027712059</td>\n",
       "      <td>9027712050</td>\n",
       "      <td>The Berlin Phenomenology</td>\n",
       "      <td>Georg Wilhelm Friedrich Hegel</td>\n",
       "      <td>History</td>\n",
       "      <td>http://books.google.com/books/content?id=Vy7Sk...</td>\n",
       "      <td>Since the three volume edition ofHegel's Philo...</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>210.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The Berlin Phenomenology</td>\n",
       "      <td>9789027712059 Since the three volume edition o...</td>\n",
       "      <td>Nonfiction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3432 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             isbn13      isbn10                      title  \\\n",
       "0     9780002005883  0002005883                     Gilead   \n",
       "2     9780006178736  0006178731             Rage of angels   \n",
       "8     9780006482079  0006482074        Warhost of Vastmark   \n",
       "30    9780006646006  000664600X         Ocean Star Express   \n",
       "46    9780007121014  0007121016         Taken at the Flood   \n",
       "...             ...         ...                        ...   \n",
       "5178  9781933648279  1933648279  Night Has a Thousand Eyes   \n",
       "5188  9784770028969  4770028962         Coin Locker Babies   \n",
       "5189  9788122200850  8122200850           Cry, the Peacock   \n",
       "5195  9788185300535  8185300534                  I Am that   \n",
       "5196  9789027712059  9027712050   The Berlin Phenomenology   \n",
       "\n",
       "                                           authors        categories  \\\n",
       "0                               Marilynne Robinson           Fiction   \n",
       "2                                   Sidney Sheldon           Fiction   \n",
       "8                                      Janny Wurts           Fiction   \n",
       "30                        Mark Haddon;Peter Sutton  Juvenile Fiction   \n",
       "46                                 Agatha Christie           Fiction   \n",
       "...                                            ...               ...   \n",
       "5178                              Cornell Woolrich           Fiction   \n",
       "5188                                           æ‘ä¸Šé¾           Fiction   \n",
       "5189                                   Anita Desai           Fiction   \n",
       "5195  Sri Nisargadatta Maharaj;Sudhakar S. Dikshit        Philosophy   \n",
       "5196                 Georg Wilhelm Friedrich Hegel           History   \n",
       "\n",
       "                                              thumbnail  \\\n",
       "0     http://books.google.com/books/content?id=KQZCP...   \n",
       "2     http://books.google.com/books/content?id=FKo2T...   \n",
       "8     http://books.google.com/books/content?id=uOL0f...   \n",
       "30    http://books.google.com/books/content?id=I2QZA...   \n",
       "46    http://books.google.com/books/content?id=3gWlx...   \n",
       "...                                                 ...   \n",
       "5178  http://books.google.com/books/content?id=3Gk6s...   \n",
       "5188  http://books.google.com/books/content?id=87DJw...   \n",
       "5189  http://books.google.com/books/content?id=_QKwV...   \n",
       "5195  http://books.google.com/books/content?id=Fv_JP...   \n",
       "5196  http://books.google.com/books/content?id=Vy7Sk...   \n",
       "\n",
       "                                            description  published_year  \\\n",
       "0     A NOVEL THAT READERS and critics have been eag...          2004.0   \n",
       "2     A memorable, mesmerizing heroine Jennifer -- b...          1993.0   \n",
       "8     Tricked once more by his wily half-brother, Ly...          1995.0   \n",
       "30    Joe and his parents are enjoying a summer holi...          2002.0   \n",
       "46    A Few Weeks After Marrying An Attractive Young...          2002.0   \n",
       "...                                                 ...             ...   \n",
       "5178  \"Cornell Woolrich's novels define the essence ...          2007.0   \n",
       "5188  Rescued from the lockers in which they were le...          2002.0   \n",
       "5189  This book is the story of a young girl obsesse...          1980.0   \n",
       "5195  This collection of the timeless teachings of o...          1999.0   \n",
       "5196  Since the three volume edition ofHegel's Philo...          1981.0   \n",
       "\n",
       "      average_rating  num_pages  ratings_count  \\\n",
       "0               3.85      247.0          361.0   \n",
       "2               3.93      512.0        29532.0   \n",
       "8               4.03      522.0         2966.0   \n",
       "30              3.50       32.0            1.0   \n",
       "46              3.71      352.0         8852.0   \n",
       "...              ...        ...            ...   \n",
       "5178            3.77      344.0          680.0   \n",
       "5188            3.75      393.0         5560.0   \n",
       "5189            3.22      218.0          134.0   \n",
       "5195            4.51      531.0          104.0   \n",
       "5196            0.00      210.0            0.0   \n",
       "\n",
       "                                 title_and_subtitle  \\\n",
       "0                                            Gilead   \n",
       "2                                    Rage of angels   \n",
       "8                               Warhost of Vastmark   \n",
       "30                               Ocean Star Express   \n",
       "46                               Taken at the Flood   \n",
       "...                                             ...   \n",
       "5178                      Night Has a Thousand Eyes   \n",
       "5188                             Coin Locker Babies   \n",
       "5189                               Cry, the Peacock   \n",
       "5195  I Am that:Talks with Sri Nisargadatta Maharaj   \n",
       "5196                       The Berlin Phenomenology   \n",
       "\n",
       "                                     tagged_description   simple_categories  \n",
       "0     9780002005883 A NOVEL THAT READERS and critics...             Fiction  \n",
       "2     9780006178736 A memorable, mesmerizing heroine...             Fiction  \n",
       "8     9780006482079 Tricked once more by his wily ha...             Fiction  \n",
       "30    9780006646006 Joe and his parents are enjoying...  Children's Fiction  \n",
       "46    9780007121014 A Few Weeks After Marrying An At...             Fiction  \n",
       "...                                                 ...                 ...  \n",
       "5178  9781933648279 \"Cornell Woolrich's novels defin...             Fiction  \n",
       "5188  9784770028969 Rescued from the lockers in whic...             Fiction  \n",
       "5189  9788122200850 This book is the story of a youn...             Fiction  \n",
       "5195  9788185300535 This collection of the timeless ...          Nonfiction  \n",
       "5196  9789027712059 Since the three volume edition o...          Nonfiction  \n",
       "\n",
       "[3432 rows x 14 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books[~(books[\"simple_categories\"].isna())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62e1816f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab71b73d5308446b802b2de198941f14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7da7e7d67fd54a2295a051c54c110322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e3502c81b0e46f2b1081ccbcd028e9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "214f3a0bb99b4c9c90d47262f5e041ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c390248b6ae44a69f2003de3db3014a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps\n"
     ]
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "# Install PyTorch if not already installed\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "fiction_categories = [\"Fiction\", \"Nonfiction\"]\n",
    "\n",
    "pipe = pipeline(\"zero-shot-classification\", \n",
    "                model=\"facebook/bart-large-mnli\",\n",
    "                device=\"mps\"\n",
    "                )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ccefe5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = books.loc[books[\"simple_categories\"] == \"Fiction\", \"description\"].reset_index(drop=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47ca69b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'A NOVEL THAT READERS and critics have been eagerly anticipating for over a decade, Gilead is an astonishingly imagined story of remarkable lives. John Ames is a preacher, the son of a preacher and the grandson (both maternal and paternal) of preachers. Itâ€™s 1956 in Gilead, Iowa, towards the end of the Reverend Amesâ€™s life, and he is absorbed in recording his familyâ€™s story, a legacy for the young son he will never see grow up. Haunted by his grandfatherâ€™s presence, John tells of the rift between his grandfather and his father: the elder, an angry visionary who fought for the abolitionist cause, and his son, an ardent pacifist. He is troubled, too, by his prodigal namesake, Jack (John Ames) Boughton, his best friendâ€™s lost son who returns to Gilead searching for forgiveness and redemption. Told in John Amesâ€™s joyous, rambling voice that finds beauty, humour and truth in the smallest of lifeâ€™s details, Gilead is a song of celebration and acceptance of the best and the worst the world has to offer. At its heart is a tale of the sacred bonds between fathers and sons, pitch-perfect in style and story, set to dazzle critics and readers alike.',\n",
       " 'labels': ['Fiction', 'Nonfiction'],\n",
       " 'scores': [0.8438272476196289, 0.15617279708385468]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(sequence, fiction_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d77f6d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fiction'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "max_index = np.argmax(pipe(sequence, fiction_categories)[\"scores\"])\n",
    "max_label = pipe(sequence, fiction_categories)[\"labels\"][max_index]\n",
    "max_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64091878",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predictions(sequence, categories):\n",
    "    predictions = pipe(sequence, categories)\n",
    "    max_index = np.argmax(predictions[\"scores\"])\n",
    "    max_label = predictions[\"labels\"][max_index]\n",
    "    return max_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "20f4ef19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [01:57<00:00,  2.54it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [01:55<00:00,  2.59it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "actual_cats = []\n",
    "predicted_cats = []\n",
    "\n",
    "for i in tqdm(range(0, 300)):\n",
    "    sequence = books.loc[books[\"simple_categories\"] == \"Fiction\", \"description\"].reset_index(drop=True)[i]\n",
    "    actual_cats += [\"Fiction\"]\n",
    "    predicted_cats += [generate_predictions(sequence, fiction_categories)]\n",
    "\n",
    "for i in tqdm(range(0, 300)):\n",
    "    sequence = books.loc[books[\"simple_categories\"] == \"Nonfiction\", \"description\"].reset_index(drop=True)[i]\n",
    "    actual_cats += [\"Nonfiction\"]\n",
    "    predicted_cats += [generate_predictions(sequence, fiction_categories)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca7b9918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual_categories</th>\n",
       "      <th>predicted_categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fiction</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fiction</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fiction</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fiction</td>\n",
       "      <td>Nonfiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fiction</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>Nonfiction</td>\n",
       "      <td>Nonfiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>Nonfiction</td>\n",
       "      <td>Nonfiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>Nonfiction</td>\n",
       "      <td>Nonfiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>Nonfiction</td>\n",
       "      <td>Nonfiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>Nonfiction</td>\n",
       "      <td>Nonfiction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    actual_categories predicted_categories\n",
       "0             Fiction              Fiction\n",
       "1             Fiction              Fiction\n",
       "2             Fiction              Fiction\n",
       "3             Fiction           Nonfiction\n",
       "4             Fiction              Fiction\n",
       "..                ...                  ...\n",
       "595        Nonfiction           Nonfiction\n",
       "596        Nonfiction           Nonfiction\n",
       "597        Nonfiction           Nonfiction\n",
       "598        Nonfiction           Nonfiction\n",
       "599        Nonfiction           Nonfiction\n",
       "\n",
       "[600 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df = pd.DataFrame({\"actual_categories\": actual_cats,\n",
    "                              \"predicted_categories\": predicted_cats})\n",
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f13055db",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df[\"correct_prediction\"] = (\n",
    "    np.where(predictions_df[\"actual_categories\"] == predictions_df[\"predicted_categories\"], 1, 0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "df4eb86b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(78.33333333333333)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df[\"correct_prediction\"].sum() / len(predictions_df)\n",
    "predictions_df[\"correct_prediction\"].sum() / len(predictions_df) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f9f37ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1765/1765 [09:10<00:00,  3.21it/s]\n"
     ]
    }
   ],
   "source": [
    "isbns = []\n",
    "predicted_cats = []\n",
    "\n",
    "missing_cats = books.loc[books[\"simple_categories\"].isna(), [\"description\", \"isbn13\"]].reset_index(drop=True)\n",
    "\n",
    "for i in tqdm(range(0, len(missing_cats))):\n",
    "    sequence = missing_cats[\"description\"][i]\n",
    "    predicted_cats += [generate_predictions(sequence, fiction_categories)]\n",
    "    isbns += [missing_cats[\"isbn13\"][i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ffce33d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isbn13</th>\n",
       "      <th>predicted_categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9780002261982</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9780006280897</td>\n",
       "      <td>Nonfiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9780006280934</td>\n",
       "      <td>Nonfiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9780006380832</td>\n",
       "      <td>Nonfiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9780006470229</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1760</th>\n",
       "      <td>9788125026600</td>\n",
       "      <td>Nonfiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1761</th>\n",
       "      <td>9788171565641</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1762</th>\n",
       "      <td>9788172235222</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1763</th>\n",
       "      <td>9788173031014</td>\n",
       "      <td>Nonfiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764</th>\n",
       "      <td>9788179921623</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1765 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             isbn13 predicted_categories\n",
       "0     9780002261982              Fiction\n",
       "1     9780006280897           Nonfiction\n",
       "2     9780006280934           Nonfiction\n",
       "3     9780006380832           Nonfiction\n",
       "4     9780006470229              Fiction\n",
       "...             ...                  ...\n",
       "1760  9788125026600           Nonfiction\n",
       "1761  9788171565641              Fiction\n",
       "1762  9788172235222              Fiction\n",
       "1763  9788173031014           Nonfiction\n",
       "1764  9788179921623              Fiction\n",
       "\n",
       "[1765 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_predicted_df = pd.DataFrame({\"isbn13\": isbns, \"predicted_categories\": predicted_cats})\n",
    "missing_predicted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "25cdea1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isbn13</th>\n",
       "      <th>isbn10</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>categories</th>\n",
       "      <th>thumbnail</th>\n",
       "      <th>description</th>\n",
       "      <th>published_year</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>title_and_subtitle</th>\n",
       "      <th>tagged_description</th>\n",
       "      <th>simple_categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9780002005883</td>\n",
       "      <td>0002005883</td>\n",
       "      <td>Gilead</td>\n",
       "      <td>Marilynne Robinson</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>http://books.google.com/books/content?id=KQZCP...</td>\n",
       "      <td>A NOVEL THAT READERS and critics have been eag...</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>247.0</td>\n",
       "      <td>361.0</td>\n",
       "      <td>Gilead</td>\n",
       "      <td>9780002005883 A NOVEL THAT READERS and critics...</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9780002261982</td>\n",
       "      <td>0002261987</td>\n",
       "      <td>Spider's Web</td>\n",
       "      <td>Charles Osborne;Agatha Christie</td>\n",
       "      <td>Detective and mystery stories</td>\n",
       "      <td>http://books.google.com/books/content?id=gA5GP...</td>\n",
       "      <td>A new 'Christie for Christmas' -- a full-lengt...</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>3.83</td>\n",
       "      <td>241.0</td>\n",
       "      <td>5164.0</td>\n",
       "      <td>Spider's Web:A Novel</td>\n",
       "      <td>9780002261982 A new 'Christie for Christmas' -...</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9780006178736</td>\n",
       "      <td>0006178731</td>\n",
       "      <td>Rage of angels</td>\n",
       "      <td>Sidney Sheldon</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>http://books.google.com/books/content?id=FKo2T...</td>\n",
       "      <td>A memorable, mesmerizing heroine Jennifer -- b...</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>3.93</td>\n",
       "      <td>512.0</td>\n",
       "      <td>29532.0</td>\n",
       "      <td>Rage of angels</td>\n",
       "      <td>9780006178736 A memorable, mesmerizing heroine...</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9780006280897</td>\n",
       "      <td>0006280897</td>\n",
       "      <td>The Four Loves</td>\n",
       "      <td>Clive Staples Lewis</td>\n",
       "      <td>Christian life</td>\n",
       "      <td>http://books.google.com/books/content?id=XhQ5X...</td>\n",
       "      <td>Lewis' work on the nature of love divides love...</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>4.15</td>\n",
       "      <td>170.0</td>\n",
       "      <td>33684.0</td>\n",
       "      <td>The Four Loves</td>\n",
       "      <td>9780006280897 Lewis' work on the nature of lov...</td>\n",
       "      <td>Nonfiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9780006280934</td>\n",
       "      <td>0006280935</td>\n",
       "      <td>The Problem of Pain</td>\n",
       "      <td>Clive Staples Lewis</td>\n",
       "      <td>Christian life</td>\n",
       "      <td>http://books.google.com/books/content?id=Kk-uV...</td>\n",
       "      <td>\"In The Problem of Pain, C.S. Lewis, one of th...</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>4.09</td>\n",
       "      <td>176.0</td>\n",
       "      <td>37569.0</td>\n",
       "      <td>The Problem of Pain</td>\n",
       "      <td>9780006280934 \"In The Problem of Pain, C.S. Le...</td>\n",
       "      <td>Nonfiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5192</th>\n",
       "      <td>9788172235222</td>\n",
       "      <td>8172235224</td>\n",
       "      <td>Mistaken Identity</td>\n",
       "      <td>Nayantara Sahgal</td>\n",
       "      <td>Indic fiction (English)</td>\n",
       "      <td>http://books.google.com/books/content?id=q-tKP...</td>\n",
       "      <td>On A Train Journey Home To North India After L...</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>2.93</td>\n",
       "      <td>324.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Mistaken Identity</td>\n",
       "      <td>9788172235222 On A Train Journey Home To North...</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5193</th>\n",
       "      <td>9788173031014</td>\n",
       "      <td>8173031010</td>\n",
       "      <td>Journey to the East</td>\n",
       "      <td>Hermann Hesse</td>\n",
       "      <td>Adventure stories</td>\n",
       "      <td>http://books.google.com/books/content?id=rq6JP...</td>\n",
       "      <td>This book tells the tale of a man who goes on ...</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>3.70</td>\n",
       "      <td>175.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Journey to the East</td>\n",
       "      <td>9788173031014 This book tells the tale of a ma...</td>\n",
       "      <td>Nonfiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5194</th>\n",
       "      <td>9788179921623</td>\n",
       "      <td>817992162X</td>\n",
       "      <td>The Monk Who Sold His Ferrari: A Fable About F...</td>\n",
       "      <td>Robin Sharma</td>\n",
       "      <td>Health &amp; Fitness</td>\n",
       "      <td>http://books.google.com/books/content?id=c_7mf...</td>\n",
       "      <td>Wisdom to Create a Life of Passion, Purpose, a...</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>3.82</td>\n",
       "      <td>198.0</td>\n",
       "      <td>1568.0</td>\n",
       "      <td>The Monk Who Sold His Ferrari: A Fable About F...</td>\n",
       "      <td>9788179921623 Wisdom to Create a Life of Passi...</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5195</th>\n",
       "      <td>9788185300535</td>\n",
       "      <td>8185300534</td>\n",
       "      <td>I Am that</td>\n",
       "      <td>Sri Nisargadatta Maharaj;Sudhakar S. Dikshit</td>\n",
       "      <td>Philosophy</td>\n",
       "      <td>http://books.google.com/books/content?id=Fv_JP...</td>\n",
       "      <td>This collection of the timeless teachings of o...</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>4.51</td>\n",
       "      <td>531.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>I Am that:Talks with Sri Nisargadatta Maharaj</td>\n",
       "      <td>9788185300535 This collection of the timeless ...</td>\n",
       "      <td>Nonfiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5196</th>\n",
       "      <td>9789027712059</td>\n",
       "      <td>9027712050</td>\n",
       "      <td>The Berlin Phenomenology</td>\n",
       "      <td>Georg Wilhelm Friedrich Hegel</td>\n",
       "      <td>History</td>\n",
       "      <td>http://books.google.com/books/content?id=Vy7Sk...</td>\n",
       "      <td>Since the three volume edition ofHegel's Philo...</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>210.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The Berlin Phenomenology</td>\n",
       "      <td>9789027712059 Since the three volume edition o...</td>\n",
       "      <td>Nonfiction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5197 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             isbn13      isbn10  \\\n",
       "0     9780002005883  0002005883   \n",
       "1     9780002261982  0002261987   \n",
       "2     9780006178736  0006178731   \n",
       "3     9780006280897  0006280897   \n",
       "4     9780006280934  0006280935   \n",
       "...             ...         ...   \n",
       "5192  9788172235222  8172235224   \n",
       "5193  9788173031014  8173031010   \n",
       "5194  9788179921623  817992162X   \n",
       "5195  9788185300535  8185300534   \n",
       "5196  9789027712059  9027712050   \n",
       "\n",
       "                                                  title  \\\n",
       "0                                                Gilead   \n",
       "1                                          Spider's Web   \n",
       "2                                        Rage of angels   \n",
       "3                                        The Four Loves   \n",
       "4                                   The Problem of Pain   \n",
       "...                                                 ...   \n",
       "5192                                  Mistaken Identity   \n",
       "5193                                Journey to the East   \n",
       "5194  The Monk Who Sold His Ferrari: A Fable About F...   \n",
       "5195                                          I Am that   \n",
       "5196                           The Berlin Phenomenology   \n",
       "\n",
       "                                           authors  \\\n",
       "0                               Marilynne Robinson   \n",
       "1                  Charles Osborne;Agatha Christie   \n",
       "2                                   Sidney Sheldon   \n",
       "3                              Clive Staples Lewis   \n",
       "4                              Clive Staples Lewis   \n",
       "...                                            ...   \n",
       "5192                              Nayantara Sahgal   \n",
       "5193                                 Hermann Hesse   \n",
       "5194                                  Robin Sharma   \n",
       "5195  Sri Nisargadatta Maharaj;Sudhakar S. Dikshit   \n",
       "5196                 Georg Wilhelm Friedrich Hegel   \n",
       "\n",
       "                         categories  \\\n",
       "0                           Fiction   \n",
       "1     Detective and mystery stories   \n",
       "2                           Fiction   \n",
       "3                    Christian life   \n",
       "4                    Christian life   \n",
       "...                             ...   \n",
       "5192        Indic fiction (English)   \n",
       "5193              Adventure stories   \n",
       "5194               Health & Fitness   \n",
       "5195                     Philosophy   \n",
       "5196                        History   \n",
       "\n",
       "                                              thumbnail  \\\n",
       "0     http://books.google.com/books/content?id=KQZCP...   \n",
       "1     http://books.google.com/books/content?id=gA5GP...   \n",
       "2     http://books.google.com/books/content?id=FKo2T...   \n",
       "3     http://books.google.com/books/content?id=XhQ5X...   \n",
       "4     http://books.google.com/books/content?id=Kk-uV...   \n",
       "...                                                 ...   \n",
       "5192  http://books.google.com/books/content?id=q-tKP...   \n",
       "5193  http://books.google.com/books/content?id=rq6JP...   \n",
       "5194  http://books.google.com/books/content?id=c_7mf...   \n",
       "5195  http://books.google.com/books/content?id=Fv_JP...   \n",
       "5196  http://books.google.com/books/content?id=Vy7Sk...   \n",
       "\n",
       "                                            description  published_year  \\\n",
       "0     A NOVEL THAT READERS and critics have been eag...          2004.0   \n",
       "1     A new 'Christie for Christmas' -- a full-lengt...          2000.0   \n",
       "2     A memorable, mesmerizing heroine Jennifer -- b...          1993.0   \n",
       "3     Lewis' work on the nature of love divides love...          2002.0   \n",
       "4     \"In The Problem of Pain, C.S. Lewis, one of th...          2002.0   \n",
       "...                                                 ...             ...   \n",
       "5192  On A Train Journey Home To North India After L...          2003.0   \n",
       "5193  This book tells the tale of a man who goes on ...          2002.0   \n",
       "5194  Wisdom to Create a Life of Passion, Purpose, a...          2003.0   \n",
       "5195  This collection of the timeless teachings of o...          1999.0   \n",
       "5196  Since the three volume edition ofHegel's Philo...          1981.0   \n",
       "\n",
       "      average_rating  num_pages  ratings_count  \\\n",
       "0               3.85      247.0          361.0   \n",
       "1               3.83      241.0         5164.0   \n",
       "2               3.93      512.0        29532.0   \n",
       "3               4.15      170.0        33684.0   \n",
       "4               4.09      176.0        37569.0   \n",
       "...              ...        ...            ...   \n",
       "5192            2.93      324.0            0.0   \n",
       "5193            3.70      175.0           24.0   \n",
       "5194            3.82      198.0         1568.0   \n",
       "5195            4.51      531.0          104.0   \n",
       "5196            0.00      210.0            0.0   \n",
       "\n",
       "                                     title_and_subtitle  \\\n",
       "0                                                Gilead   \n",
       "1                                  Spider's Web:A Novel   \n",
       "2                                        Rage of angels   \n",
       "3                                        The Four Loves   \n",
       "4                                   The Problem of Pain   \n",
       "...                                                 ...   \n",
       "5192                                  Mistaken Identity   \n",
       "5193                                Journey to the East   \n",
       "5194  The Monk Who Sold His Ferrari: A Fable About F...   \n",
       "5195      I Am that:Talks with Sri Nisargadatta Maharaj   \n",
       "5196                           The Berlin Phenomenology   \n",
       "\n",
       "                                     tagged_description simple_categories  \n",
       "0     9780002005883 A NOVEL THAT READERS and critics...           Fiction  \n",
       "1     9780002261982 A new 'Christie for Christmas' -...           Fiction  \n",
       "2     9780006178736 A memorable, mesmerizing heroine...           Fiction  \n",
       "3     9780006280897 Lewis' work on the nature of lov...        Nonfiction  \n",
       "4     9780006280934 \"In The Problem of Pain, C.S. Le...        Nonfiction  \n",
       "...                                                 ...               ...  \n",
       "5192  9788172235222 On A Train Journey Home To North...           Fiction  \n",
       "5193  9788173031014 This book tells the tale of a ma...        Nonfiction  \n",
       "5194  9788179921623 Wisdom to Create a Life of Passi...           Fiction  \n",
       "5195  9788185300535 This collection of the timeless ...        Nonfiction  \n",
       "5196  9789027712059 Since the three volume edition o...        Nonfiction  \n",
       "\n",
       "[5197 rows x 14 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books = pd.merge(books, missing_predicted_df,on=\"isbn13\", how=\"left\")\n",
    "books[\"simple_categories\"] = np.where(\n",
    "    books[\"simple_categories\"].isna(),\n",
    "    books[\"predicted_categories\"],\n",
    "    books[\"simple_categories\"],\n",
    ")\n",
    "books = books.drop(columns=[\"predicted_categories\"])\n",
    "books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "362107e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isbn13</th>\n",
       "      <th>isbn10</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>categories</th>\n",
       "      <th>thumbnail</th>\n",
       "      <th>description</th>\n",
       "      <th>published_year</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>title_and_subtitle</th>\n",
       "      <th>tagged_description</th>\n",
       "      <th>simple_categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>9780099422341</td>\n",
       "      <td>0099422344</td>\n",
       "      <td>Yeats is Dead!</td>\n",
       "      <td>Joseph O'Connor</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>http://books.google.com/books/content?id=DrE3I...</td>\n",
       "      <td>In aid of Amnesty International, this is a bri...</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>3.39</td>\n",
       "      <td>298.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>Yeats is Dead!:A Novel by Fifteen Irish Writers</td>\n",
       "      <td>9780099422341 In aid of Amnesty International,...</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>9780099446729</td>\n",
       "      <td>0099446723</td>\n",
       "      <td>Blackwood Farm</td>\n",
       "      <td>Anne Rice</td>\n",
       "      <td>Horror</td>\n",
       "      <td>http://books.google.com/books/content?id=cIn8T...</td>\n",
       "      <td>Lestat Is Back, Saviour And Demon, Presiding O...</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>3.86</td>\n",
       "      <td>774.0</td>\n",
       "      <td>26145.0</td>\n",
       "      <td>Blackwood Farm</td>\n",
       "      <td>9780099446729 Lestat Is Back, Saviour And Demo...</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>9780140189223</td>\n",
       "      <td>014018922X</td>\n",
       "      <td>Six Characters in Search of an Author and Othe...</td>\n",
       "      <td>Luigi Pirandello</td>\n",
       "      <td>Drama</td>\n",
       "      <td>http://books.google.com/books/content?id=AU4Mc...</td>\n",
       "      <td>Accompanied by two additional plays, presents ...</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>3.95</td>\n",
       "      <td>224.0</td>\n",
       "      <td>2888.0</td>\n",
       "      <td>Six Characters in Search of an Author and Othe...</td>\n",
       "      <td>9780140189223 Accompanied by two additional pl...</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>9780140437911</td>\n",
       "      <td>0140437916</td>\n",
       "      <td>Saint Joan</td>\n",
       "      <td>George Bernard Shaw</td>\n",
       "      <td>Drama</td>\n",
       "      <td>http://books.google.com/books/content?id=9S6eV...</td>\n",
       "      <td>One of Shaw's most unusual and enduringly popu...</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>3.79</td>\n",
       "      <td>160.0</td>\n",
       "      <td>5789.0</td>\n",
       "      <td>Saint Joan</td>\n",
       "      <td>9780140437911 One of Shaw's most unusual and e...</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>9780140440935</td>\n",
       "      <td>0140440933</td>\n",
       "      <td>Faust</td>\n",
       "      <td>Johann Goethe</td>\n",
       "      <td>Drama</td>\n",
       "      <td>http://books.google.com/books/content?id=IYSxm...</td>\n",
       "      <td>A brief analysis of the development, style, an...</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>3.73</td>\n",
       "      <td>288.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>Faust</td>\n",
       "      <td>9780140440935 A brief analysis of the developm...</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4806</th>\n",
       "      <td>9781586638498</td>\n",
       "      <td>1586638491</td>\n",
       "      <td>The Tempest</td>\n",
       "      <td>William Shakespeare</td>\n",
       "      <td>Drama</td>\n",
       "      <td>http://books.google.com/books/content?id=ua7mx...</td>\n",
       "      <td>Presents the original text of Shakespeare's pl...</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>3.81</td>\n",
       "      <td>224.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>The Tempest</td>\n",
       "      <td>9781586638498 Presents the original text of Sh...</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4979</th>\n",
       "      <td>9781841494081</td>\n",
       "      <td>1841494089</td>\n",
       "      <td>The Darkness that Comes Before</td>\n",
       "      <td>R. Scott Bakker</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>http://books.google.com/books/content?id=BG8qG...</td>\n",
       "      <td>A score of centuries has passed since the Firs...</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>3.79</td>\n",
       "      <td>638.0</td>\n",
       "      <td>317.0</td>\n",
       "      <td>The Darkness that Comes Before</td>\n",
       "      <td>9781841494081 A score of centuries has passed ...</td>\n",
       "      <td>Nonfiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5027</th>\n",
       "      <td>9781854596017</td>\n",
       "      <td>1854596012</td>\n",
       "      <td>Abandonment</td>\n",
       "      <td>Kate Atkinson</td>\n",
       "      <td>Drama</td>\n",
       "      <td>http://books.google.com/books/content?id=dUrSI...</td>\n",
       "      <td>A play about love, death, identity and evoluti...</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>3.60</td>\n",
       "      <td>96.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>Abandonment</td>\n",
       "      <td>9781854596017 A play about love, death, identi...</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5127</th>\n",
       "      <td>9781904271062</td>\n",
       "      <td>1904271065</td>\n",
       "      <td>King Henry IV Part 2</td>\n",
       "      <td>William Shakespeare;A. R. Humphreys</td>\n",
       "      <td>Drama</td>\n",
       "      <td>http://books.google.com/books/content?id=AG4h-...</td>\n",
       "      <td>A. R. Humphreyswas Professor of English at Lei...</td>\n",
       "      <td>1967.0</td>\n",
       "      <td>3.80</td>\n",
       "      <td>336.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>King Henry IV Part 2:Second Series</td>\n",
       "      <td>9781904271062 A. R. Humphreyswas Professor of ...</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5128</th>\n",
       "      <td>9781904271550</td>\n",
       "      <td>1904271553</td>\n",
       "      <td>Hamlet: The Texts of 1603 and 1623</td>\n",
       "      <td>William Shakespeare</td>\n",
       "      <td>Drama</td>\n",
       "      <td>http://books.google.com/books/content?id=rGFlA...</td>\n",
       "      <td>This second volume gives readers the First Qua...</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>4.01</td>\n",
       "      <td>384.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Hamlet: The Texts of 1603 and 1623:Third Series</td>\n",
       "      <td>9781904271550 This second volume gives readers...</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             isbn13      isbn10  \\\n",
       "478   9780099422341  0099422344   \n",
       "491   9780099446729  0099446723   \n",
       "588   9780140189223  014018922X   \n",
       "656   9780140437911  0140437916   \n",
       "659   9780140440935  0140440933   \n",
       "...             ...         ...   \n",
       "4806  9781586638498  1586638491   \n",
       "4979  9781841494081  1841494089   \n",
       "5027  9781854596017  1854596012   \n",
       "5127  9781904271062  1904271065   \n",
       "5128  9781904271550  1904271553   \n",
       "\n",
       "                                                  title  \\\n",
       "478                                      Yeats is Dead!   \n",
       "491                                      Blackwood Farm   \n",
       "588   Six Characters in Search of an Author and Othe...   \n",
       "656                                          Saint Joan   \n",
       "659                                               Faust   \n",
       "...                                                 ...   \n",
       "4806                                        The Tempest   \n",
       "4979                     The Darkness that Comes Before   \n",
       "5027                                        Abandonment   \n",
       "5127                               King Henry IV Part 2   \n",
       "5128                 Hamlet: The Texts of 1603 and 1623   \n",
       "\n",
       "                                  authors categories  \\\n",
       "478                       Joseph O'Connor     Comedy   \n",
       "491                             Anne Rice     Horror   \n",
       "588                      Luigi Pirandello      Drama   \n",
       "656                   George Bernard Shaw      Drama   \n",
       "659                         Johann Goethe      Drama   \n",
       "...                                   ...        ...   \n",
       "4806                  William Shakespeare      Drama   \n",
       "4979                      R. Scott Bakker    Fantasy   \n",
       "5027                        Kate Atkinson      Drama   \n",
       "5127  William Shakespeare;A. R. Humphreys      Drama   \n",
       "5128                  William Shakespeare      Drama   \n",
       "\n",
       "                                              thumbnail  \\\n",
       "478   http://books.google.com/books/content?id=DrE3I...   \n",
       "491   http://books.google.com/books/content?id=cIn8T...   \n",
       "588   http://books.google.com/books/content?id=AU4Mc...   \n",
       "656   http://books.google.com/books/content?id=9S6eV...   \n",
       "659   http://books.google.com/books/content?id=IYSxm...   \n",
       "...                                                 ...   \n",
       "4806  http://books.google.com/books/content?id=ua7mx...   \n",
       "4979  http://books.google.com/books/content?id=BG8qG...   \n",
       "5027  http://books.google.com/books/content?id=dUrSI...   \n",
       "5127  http://books.google.com/books/content?id=AG4h-...   \n",
       "5128  http://books.google.com/books/content?id=rGFlA...   \n",
       "\n",
       "                                            description  published_year  \\\n",
       "478   In aid of Amnesty International, this is a bri...          2002.0   \n",
       "491   Lestat Is Back, Saviour And Demon, Presiding O...          2003.0   \n",
       "588   Accompanied by two additional plays, presents ...          1995.0   \n",
       "656   One of Shaw's most unusual and enduringly popu...          2003.0   \n",
       "659   A brief analysis of the development, style, an...          1959.0   \n",
       "...                                                 ...             ...   \n",
       "4806  Presents the original text of Shakespeare's pl...          2003.0   \n",
       "4979  A score of centuries has passed since the Firs...          2005.0   \n",
       "5027  A play about love, death, identity and evoluti...          2000.0   \n",
       "5127  A. R. Humphreyswas Professor of English at Lei...          1967.0   \n",
       "5128  This second volume gives readers the First Qua...          2006.0   \n",
       "\n",
       "      average_rating  num_pages  ratings_count  \\\n",
       "478             3.39      298.0           34.0   \n",
       "491             3.86      774.0        26145.0   \n",
       "588             3.95      224.0         2888.0   \n",
       "656             3.79      160.0         5789.0   \n",
       "659             3.73      288.0          120.0   \n",
       "...              ...        ...            ...   \n",
       "4806            3.81      224.0          438.0   \n",
       "4979            3.79      638.0          317.0   \n",
       "5027            3.60       96.0           78.0   \n",
       "5127            3.80      336.0          241.0   \n",
       "5128            4.01      384.0           16.0   \n",
       "\n",
       "                                     title_and_subtitle  \\\n",
       "478     Yeats is Dead!:A Novel by Fifteen Irish Writers   \n",
       "491                                      Blackwood Farm   \n",
       "588   Six Characters in Search of an Author and Othe...   \n",
       "656                                          Saint Joan   \n",
       "659                                               Faust   \n",
       "...                                                 ...   \n",
       "4806                                        The Tempest   \n",
       "4979                     The Darkness that Comes Before   \n",
       "5027                                        Abandonment   \n",
       "5127                 King Henry IV Part 2:Second Series   \n",
       "5128    Hamlet: The Texts of 1603 and 1623:Third Series   \n",
       "\n",
       "                                     tagged_description simple_categories  \n",
       "478   9780099422341 In aid of Amnesty International,...           Fiction  \n",
       "491   9780099446729 Lestat Is Back, Saviour And Demo...           Fiction  \n",
       "588   9780140189223 Accompanied by two additional pl...           Fiction  \n",
       "656   9780140437911 One of Shaw's most unusual and e...           Fiction  \n",
       "659   9780140440935 A brief analysis of the developm...           Fiction  \n",
       "...                                                 ...               ...  \n",
       "4806  9781586638498 Presents the original text of Sh...           Fiction  \n",
       "4979  9781841494081 A score of centuries has passed ...        Nonfiction  \n",
       "5027  9781854596017 A play about love, death, identi...           Fiction  \n",
       "5127  9781904271062 A. R. Humphreyswas Professor of ...           Fiction  \n",
       "5128  9781904271550 This second volume gives readers...           Fiction  \n",
       "\n",
       "[94 rows x 14 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books[books[\"categories\"].str.lower().isin([\n",
    "    \"romance\",\n",
    "    \"mystery\",\n",
    "    \"thriller\",\n",
    "    \"horror\",\n",
    "    \"fantasy\",\n",
    "    \"scifi\",\n",
    "    \"comedy\",\n",
    "    \"drama\",\n",
    "    \"historical\"\n",
    "    \"crime\"\n",
    "])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "769a21ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "books.to_csv(\"books_with_categories.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8965b490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mType:\u001b[39m        DataFrame\n",
      "\u001b[31mString form:\u001b[39m\n",
      "             isbn13 predicted_categories\n",
      "0     9780002261982              Fiction\n",
      "1     9780006280897           Nonfiction\n",
      "2     9780006280934           Nonfiction\n",
      "3     9780006380832           Nonfiction\n",
      "4     9780006470229              Fiction\n",
      "...             ...                  ...\n",
      "1760  9788125026600           Nonfiction\n",
      "1761  9788171565641              Fiction\n",
      "1762  9788172235222              Fiction\n",
      "1763  9788173031014           Nonfiction\n",
      "1764  9788179921623              Fiction\n",
      "\n",
      "[1765 rows x 2 columns]\n",
      "\u001b[31mLength:\u001b[39m      1765\n",
      "\u001b[31mFile:\u001b[39m        ~/BookRecommender/venv/lib/python3.11/site-packages/pandas/core/frame.py\n",
      "\u001b[31mSource:\u001b[39m     \n",
      "\u001b[38;5;28;01mclass\u001b[39;00m DataFrame(NDFrame, OpsMixin):\n",
      "    \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m    Two-dimensional, size-mutable, potentially heterogeneous tabular data.\u001b[39m\n",
      "\n",
      "\u001b[33m    Data structure also contains labeled axes (rows and columns).\u001b[39m\n",
      "\u001b[33m    Arithmetic operations align on both row and column labels. Can be\u001b[39m\n",
      "\u001b[33m    thought of as a dict-like container for Series objects. The primary\u001b[39m\n",
      "\u001b[33m    pandas data structure.\u001b[39m\n",
      "\n",
      "\u001b[33m    Parameters\u001b[39m\n",
      "\u001b[33m    ----------\u001b[39m\n",
      "\u001b[33m    data : ndarray (structured or homogeneous), Iterable, dict, or DataFrame\u001b[39m\n",
      "\u001b[33m        Dict can contain Series, arrays, constants, dataclass or list-like objects. If\u001b[39m\n",
      "\u001b[33m        data is a dict, column order follows insertion-order. If a dict contains Series\u001b[39m\n",
      "\u001b[33m        which have an index defined, it is aligned by its index. This alignment also\u001b[39m\n",
      "\u001b[33m        occurs if data is a Series or a DataFrame itself. Alignment is done on\u001b[39m\n",
      "\u001b[33m        Series/DataFrame inputs.\u001b[39m\n",
      "\n",
      "\u001b[33m        If data is a list of dicts, column order follows insertion-order.\u001b[39m\n",
      "\n",
      "\u001b[33m    index : Index or array-like\u001b[39m\n",
      "\u001b[33m        Index to use for resulting frame. Will default to RangeIndex if\u001b[39m\n",
      "\u001b[33m        no indexing information part of input data and no index provided.\u001b[39m\n",
      "\u001b[33m    columns : Index or array-like\u001b[39m\n",
      "\u001b[33m        Column labels to use for resulting frame when data does not have them,\u001b[39m\n",
      "\u001b[33m        defaulting to RangeIndex(0, 1, 2, ..., n). If data contains column labels,\u001b[39m\n",
      "\u001b[33m        will perform column selection instead.\u001b[39m\n",
      "\u001b[33m    dtype : dtype, default None\u001b[39m\n",
      "\u001b[33m        Data type to force. Only a single dtype is allowed. If None, infer.\u001b[39m\n",
      "\u001b[33m    copy : bool or None, default None\u001b[39m\n",
      "\u001b[33m        Copy data from inputs.\u001b[39m\n",
      "\u001b[33m        For dict data, the default of None behaves like ``copy=True``.  For DataFrame\u001b[39m\n",
      "\u001b[33m        or 2d ndarray input, the default of None behaves like ``copy=False``.\u001b[39m\n",
      "\u001b[33m        If data is a dict containing one or more Series (possibly of different dtypes),\u001b[39m\n",
      "\u001b[33m        ``copy=False`` will ensure that these inputs are not copied.\u001b[39m\n",
      "\n",
      "\u001b[33m        .. versionchanged:: 1.3.0\u001b[39m\n",
      "\n",
      "\u001b[33m    See Also\u001b[39m\n",
      "\u001b[33m    --------\u001b[39m\n",
      "\u001b[33m    DataFrame.from_records : Constructor from tuples, also record arrays.\u001b[39m\n",
      "\u001b[33m    DataFrame.from_dict : From dicts of Series, arrays, or dicts.\u001b[39m\n",
      "\u001b[33m    read_csv : Read a comma-separated values (csv) file into DataFrame.\u001b[39m\n",
      "\u001b[33m    read_table : Read general delimited file into DataFrame.\u001b[39m\n",
      "\u001b[33m    read_clipboard : Read text from clipboard into DataFrame.\u001b[39m\n",
      "\n",
      "\u001b[33m    Notes\u001b[39m\n",
      "\u001b[33m    -----\u001b[39m\n",
      "\u001b[33m    Please reference the :ref:`User Guide <basics.dataframe>` for more information.\u001b[39m\n",
      "\n",
      "\u001b[33m    Examples\u001b[39m\n",
      "\u001b[33m    --------\u001b[39m\n",
      "\u001b[33m    Constructing DataFrame from a dictionary.\u001b[39m\n",
      "\n",
      "\u001b[33m    >>> d = {'col1': [1, 2], 'col2': [3, 4]}\u001b[39m\n",
      "\u001b[33m    >>> df = pd.DataFrame(data=d)\u001b[39m\n",
      "\u001b[33m    >>> df\u001b[39m\n",
      "\u001b[33m       col1  col2\u001b[39m\n",
      "\u001b[33m    0     1     3\u001b[39m\n",
      "\u001b[33m    1     2     4\u001b[39m\n",
      "\n",
      "\u001b[33m    Notice that the inferred dtype is int64.\u001b[39m\n",
      "\n",
      "\u001b[33m    >>> df.dtypes\u001b[39m\n",
      "\u001b[33m    col1    int64\u001b[39m\n",
      "\u001b[33m    col2    int64\u001b[39m\n",
      "\u001b[33m    dtype: object\u001b[39m\n",
      "\n",
      "\u001b[33m    To enforce a single dtype:\u001b[39m\n",
      "\n",
      "\u001b[33m    >>> df = pd.DataFrame(data=d, dtype=np.int8)\u001b[39m\n",
      "\u001b[33m    >>> df.dtypes\u001b[39m\n",
      "\u001b[33m    col1    int8\u001b[39m\n",
      "\u001b[33m    col2    int8\u001b[39m\n",
      "\u001b[33m    dtype: object\u001b[39m\n",
      "\n",
      "\u001b[33m    Constructing DataFrame from a dictionary including Series:\u001b[39m\n",
      "\n",
      "\u001b[33m    >>> d = {'col1': [0, 1, 2, 3], 'col2': pd.Series([2, 3], index=[2, 3])}\u001b[39m\n",
      "\u001b[33m    >>> pd.DataFrame(data=d, index=[0, 1, 2, 3])\u001b[39m\n",
      "\u001b[33m       col1  col2\u001b[39m\n",
      "\u001b[33m    0     0   NaN\u001b[39m\n",
      "\u001b[33m    1     1   NaN\u001b[39m\n",
      "\u001b[33m    2     2   2.0\u001b[39m\n",
      "\u001b[33m    3     3   3.0\u001b[39m\n",
      "\n",
      "\u001b[33m    Constructing DataFrame from numpy ndarray:\u001b[39m\n",
      "\n",
      "\u001b[33m    >>> df2 = pd.DataFrame(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]),\u001b[39m\n",
      "\u001b[33m    ...                    columns=['a', 'b', 'c'])\u001b[39m\n",
      "\u001b[33m    >>> df2\u001b[39m\n",
      "\u001b[33m       a  b  c\u001b[39m\n",
      "\u001b[33m    0  1  2  3\u001b[39m\n",
      "\u001b[33m    1  4  5  6\u001b[39m\n",
      "\u001b[33m    2  7  8  9\u001b[39m\n",
      "\n",
      "\u001b[33m    Constructing DataFrame from a numpy ndarray that has labeled columns:\u001b[39m\n",
      "\n",
      "\u001b[33m    >>> data = np.array([(1, 2, 3), (4, 5, 6), (7, 8, 9)],\u001b[39m\n",
      "\u001b[33m    ...                 dtype=[(\"a\", \"i4\"), (\"b\", \"i4\"), (\"c\", \"i4\")])\u001b[39m\n",
      "\u001b[33m    >>> df3 = pd.DataFrame(data, columns=['c', 'a'])\u001b[39m\n",
      "\u001b[33m    ...\u001b[39m\n",
      "\u001b[33m    >>> df3\u001b[39m\n",
      "\u001b[33m       c  a\u001b[39m\n",
      "\u001b[33m    0  3  1\u001b[39m\n",
      "\u001b[33m    1  6  4\u001b[39m\n",
      "\u001b[33m    2  9  7\u001b[39m\n",
      "\n",
      "\u001b[33m    Constructing DataFrame from dataclass:\u001b[39m\n",
      "\n",
      "\u001b[33m    >>> from dataclasses import make_dataclass\u001b[39m\n",
      "\u001b[33m    >>> Point = make_dataclass(\"Point\", [(\"x\", int), (\"y\", int)])\u001b[39m\n",
      "\u001b[33m    >>> pd.DataFrame([Point(0, 0), Point(0, 3), Point(2, 3)])\u001b[39m\n",
      "\u001b[33m       x  y\u001b[39m\n",
      "\u001b[33m    0  0  0\u001b[39m\n",
      "\u001b[33m    1  0  3\u001b[39m\n",
      "\u001b[33m    2  2  3\u001b[39m\n",
      "\n",
      "\u001b[33m    Constructing DataFrame from Series/DataFrame:\u001b[39m\n",
      "\n",
      "\u001b[33m    >>> ser = pd.Series([1, 2, 3], index=[\"a\", \"b\", \"c\"])\u001b[39m\n",
      "\u001b[33m    >>> df = pd.DataFrame(data=ser, index=[\"a\", \"c\"])\u001b[39m\n",
      "\u001b[33m    >>> df\u001b[39m\n",
      "\u001b[33m       0\u001b[39m\n",
      "\u001b[33m    a  1\u001b[39m\n",
      "\u001b[33m    c  3\u001b[39m\n",
      "\n",
      "\u001b[33m    >>> df1 = pd.DataFrame([1, 2, 3], index=[\"a\", \"b\", \"c\"], columns=[\"x\"])\u001b[39m\n",
      "\u001b[33m    >>> df2 = pd.DataFrame(data=df1, index=[\"a\", \"c\"])\u001b[39m\n",
      "\u001b[33m    >>> df2\u001b[39m\n",
      "\u001b[33m       x\u001b[39m\n",
      "\u001b[33m    a  1\u001b[39m\n",
      "\u001b[33m    c  3\u001b[39m\n",
      "\u001b[33m    \"\"\"\u001b[39m\n",
      "\n",
      "    _internal_names_set = {\u001b[33m\"columns\"\u001b[39m, \u001b[33m\"index\"\u001b[39m} | NDFrame._internal_names_set\n",
      "    _typ = \u001b[33m\"dataframe\"\u001b[39m\n",
      "    _HANDLED_TYPES = (Series, Index, ExtensionArray, np.ndarray)\n",
      "    _accessors: set[str] = {\u001b[33m\"sparse\"\u001b[39m}\n",
      "    _hidden_attrs: frozenset[str] = NDFrame._hidden_attrs | frozenset([])\n",
      "    _mgr: BlockManager | ArrayManager\n",
      "\n",
      "    \u001b[38;5;66;03m# similar to __array_priority__, positions DataFrame before Series, Index,\u001b[39;00m\n",
      "    \u001b[38;5;66;03m#  and ExtensionArray.  Should NOT be overridden by subclasses.\u001b[39;00m\n",
      "    __pandas_priority__ = \u001b[32m4000\u001b[39m\n",
      "\n",
      "    @property\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m _constructor(self) -> Callable[..., DataFrame]:\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m _constructor_from_mgr(self, mgr, axes) -> DataFrame:\n",
      "        df = DataFrame._from_mgr(mgr, axes=axes)\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m type(self) \u001b[38;5;28;01mis\u001b[39;00m DataFrame:\n",
      "            \u001b[38;5;66;03m# This would also work `if self._constructor is DataFrame`, but\u001b[39;00m\n",
      "            \u001b[38;5;66;03m#  this check is slightly faster, benefiting the most-common case.\u001b[39;00m\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "\n",
      "        \u001b[38;5;28;01melif\u001b[39;00m type(self).__name__ == \u001b[33m\"GeoDataFrame\"\u001b[39m:\n",
      "            \u001b[38;5;66;03m# Shim until geopandas can override their _constructor_from_mgr\u001b[39;00m\n",
      "            \u001b[38;5;66;03m#  bc they have different behavior for Managers than for DataFrames\u001b[39;00m\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m self._constructor(mgr)\n",
      "\n",
      "        \u001b[38;5;66;03m# We assume that the subclass __init__ knows how to handle a\u001b[39;00m\n",
      "        \u001b[38;5;66;03m#  pd.DataFrame object.\u001b[39;00m\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m self._constructor(df)\n",
      "\n",
      "    _constructor_sliced: Callable[..., Series] = Series\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m _constructor_sliced_from_mgr(self, mgr, axes) -> Series:\n",
      "        ser = Series._from_mgr(mgr, axes)\n",
      "        ser._name = \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# caller is responsible for setting real name\u001b[39;00m\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m type(self) \u001b[38;5;28;01mis\u001b[39;00m DataFrame:\n",
      "            \u001b[38;5;66;03m# This would also work `if self._constructor_sliced is Series`, but\u001b[39;00m\n",
      "            \u001b[38;5;66;03m#  this check is slightly faster, benefiting the most-common case.\u001b[39;00m\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m ser\n",
      "\n",
      "        \u001b[38;5;66;03m# We assume that the subclass __init__ knows how to handle a\u001b[39;00m\n",
      "        \u001b[38;5;66;03m#  pd.Series object.\u001b[39;00m\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m self._constructor_sliced(ser)\n",
      "\n",
      "    \u001b[38;5;66;03m# ----------------------------------------------------------------------\u001b[39;00m\n",
      "    \u001b[38;5;66;03m# Constructors\u001b[39;00m\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m __init__(\n",
      "        self,\n",
      "        data=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        index: Axes | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        columns: Axes | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        dtype: Dtype | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        copy: bool | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        allow_mgr = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "            dtype = self._validate_dtype(dtype)\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m isinstance(data, DataFrame):\n",
      "            data = data._mgr\n",
      "            allow_mgr = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m copy:\n",
      "                \u001b[38;5;66;03m# if not copying data, ensure to still return a shallow copy\u001b[39;00m\n",
      "                \u001b[38;5;66;03m# to avoid the result sharing the same Manager\u001b[39;00m\n",
      "                data = data.copy(deep=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m isinstance(data, (BlockManager, ArrayManager)):\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m allow_mgr:\n",
      "                \u001b[38;5;66;03m# GH#52419\u001b[39;00m\n",
      "                warnings.warn(\n",
      "                    \u001b[33mf\"Passing a {type(data).__name__} to {type(self).__name__} \"\u001b[39m\n",
      "                    \u001b[33m\"is deprecated and will raise in a future version. \"\u001b[39m\n",
      "                    \u001b[33m\"Use public APIs instead.\"\u001b[39m,\n",
      "                    DeprecationWarning,\n",
      "                    stacklevel=\u001b[32m1\u001b[39m,  \u001b[38;5;66;03m# bump to 2 once pyarrow 15.0 is released with fix\u001b[39;00m\n",
      "                )\n",
      "\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m using_copy_on_write():\n",
      "                data = data.copy(deep=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "            \u001b[38;5;66;03m# first check if a Manager is passed without any other arguments\u001b[39;00m\n",
      "            \u001b[38;5;66;03m# -> use fastpath (without checking Manager type)\u001b[39;00m\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mand\u001b[39;00m columns \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mand\u001b[39;00m dtype \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mand\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m copy:\n",
      "                \u001b[38;5;66;03m# GH#33357 fastpath\u001b[39;00m\n",
      "                NDFrame.__init__(self, data)\n",
      "                \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\n",
      "        manager = _get_option(\u001b[33m\"mode.data_manager\"\u001b[39m, silent=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\n",
      "        is_pandas_object = isinstance(data, (Series, Index, ExtensionArray))\n",
      "        data_dtype = getattr(data, \u001b[33m\"dtype\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "        original_dtype = dtype\n",
      "\n",
      "        \u001b[38;5;66;03m# GH47215\u001b[39;00m\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m isinstance(index, set):\n",
      "            \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\u001b[33m\"index cannot be a set\"\u001b[39m)\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m isinstance(columns, set):\n",
      "            \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\u001b[33m\"columns cannot be a set\"\u001b[39m)\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m isinstance(data, dict):\n",
      "                \u001b[38;5;66;03m# retain pre-GH#38939 default behavior\u001b[39;00m\n",
      "                copy = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "            \u001b[38;5;28;01melif\u001b[39;00m (\n",
      "                manager == \u001b[33m\"array\"\u001b[39m\n",
      "                \u001b[38;5;28;01mand\u001b[39;00m isinstance(data, (np.ndarray, ExtensionArray))\n",
      "                \u001b[38;5;28;01mand\u001b[39;00m data.ndim == \u001b[32m2\u001b[39m\n",
      "            ):\n",
      "                \u001b[38;5;66;03m# INFO(ArrayManager) by default copy the 2D input array to get\u001b[39;00m\n",
      "                \u001b[38;5;66;03m# contiguous 1D arrays\u001b[39;00m\n",
      "                copy = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "            \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write() \u001b[38;5;28;01mand\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m isinstance(\n",
      "                data, (Index, DataFrame, Series)\n",
      "            ):\n",
      "                copy = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "            \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "                copy = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "            index = index \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m default_index(\u001b[32m0\u001b[39m)\n",
      "            columns = columns \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m default_index(\u001b[32m0\u001b[39m)\n",
      "            dtype = dtype \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m pandas_dtype(object)\n",
      "            data = []\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m isinstance(data, (BlockManager, ArrayManager)):\n",
      "            mgr = self._init_mgr(\n",
      "                data, axes={\u001b[33m\"index\"\u001b[39m: index, \u001b[33m\"columns\"\u001b[39m: columns}, dtype=dtype, copy=copy\n",
      "            )\n",
      "\n",
      "        \u001b[38;5;28;01melif\u001b[39;00m isinstance(data, dict):\n",
      "            \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n",
      "            mgr = dict_to_mgr(data, index, columns, dtype=dtype, copy=copy, typ=manager)\n",
      "        \u001b[38;5;28;01melif\u001b[39;00m isinstance(data, ma.MaskedArray):\n",
      "            \u001b[38;5;28;01mfrom\u001b[39;00m numpy.ma \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "\n",
      "            \u001b[38;5;66;03m# masked recarray\u001b[39;00m\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m isinstance(data, mrecords.MaskedRecords):\n",
      "                \u001b[38;5;28;01mraise\u001b[39;00m TypeError(\n",
      "                    \u001b[33m\"MaskedRecords are not supported. Pass \"\u001b[39m\n",
      "                    \u001b[33m\"{name: data[name] for name in data.dtype.names} \"\u001b[39m\n",
      "                    \u001b[33m\"instead\"\u001b[39m\n",
      "                )\n",
      "\n",
      "            \u001b[38;5;66;03m# a masked array\u001b[39;00m\n",
      "            data = sanitize_masked_array(data)\n",
      "            mgr = ndarray_to_mgr(\n",
      "                data,\n",
      "                index,\n",
      "                columns,\n",
      "                dtype=dtype,\n",
      "                copy=copy,\n",
      "                typ=manager,\n",
      "            )\n",
      "\n",
      "        \u001b[38;5;28;01melif\u001b[39;00m isinstance(data, (np.ndarray, Series, Index, ExtensionArray)):\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m data.dtype.names:\n",
      "                \u001b[38;5;66;03m# i.e. numpy structured array\u001b[39;00m\n",
      "                data = cast(np.ndarray, data)\n",
      "                mgr = rec_array_to_mgr(\n",
      "                    data,\n",
      "                    index,\n",
      "                    columns,\n",
      "                    dtype,\n",
      "                    copy,\n",
      "                    typ=manager,\n",
      "                )\n",
      "            \u001b[38;5;28;01melif\u001b[39;00m getattr(data, \u001b[33m\"name\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "                \u001b[38;5;66;03m# i.e. Series/Index with non-None name\u001b[39;00m\n",
      "                _copy = copy \u001b[38;5;28;01mif\u001b[39;00m using_copy_on_write() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "                mgr = dict_to_mgr(\n",
      "                    \u001b[38;5;66;03m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n",
      "                    \u001b[38;5;66;03m# attribute \"name\"\u001b[39;00m\n",
      "                    {data.name: data},  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n",
      "                    index,\n",
      "                    columns,\n",
      "                    dtype=dtype,\n",
      "                    typ=manager,\n",
      "                    copy=_copy,\n",
      "                )\n",
      "            \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "                mgr = ndarray_to_mgr(\n",
      "                    data,\n",
      "                    index,\n",
      "                    columns,\n",
      "                    dtype=dtype,\n",
      "                    copy=copy,\n",
      "                    typ=manager,\n",
      "                )\n",
      "\n",
      "        \u001b[38;5;66;03m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n",
      "        \u001b[38;5;28;01melif\u001b[39;00m is_list_like(data):\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m isinstance(data, abc.Sequence):\n",
      "                \u001b[38;5;28;01mif\u001b[39;00m hasattr(data, \u001b[33m\"__array__\"\u001b[39m):\n",
      "                    \u001b[38;5;66;03m# GH#44616 big perf improvement for e.g. pytorch tensor\u001b[39;00m\n",
      "                    data = np.asarray(data)\n",
      "                \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "                    data = list(data)\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m len(data) > \u001b[32m0\u001b[39m:\n",
      "                \u001b[38;5;28;01mif\u001b[39;00m is_dataclass(data[\u001b[32m0\u001b[39m]):\n",
      "                    data = dataclasses_to_dicts(data)\n",
      "                \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m isinstance(data, np.ndarray) \u001b[38;5;28;01mand\u001b[39;00m treat_as_nested(data):\n",
      "                    \u001b[38;5;66;03m# exclude ndarray as we may have cast it a few lines above\u001b[39;00m\n",
      "                    \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "                        columns = ensure_index(columns)\n",
      "                    arrays, columns, index = nested_data_to_arrays(\n",
      "                        \u001b[38;5;66;03m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[39;00m\n",
      "                        \u001b[38;5;66;03m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[39;00m\n",
      "                        data,\n",
      "                        columns,\n",
      "                        index,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "                        dtype,\n",
      "                    )\n",
      "                    mgr = arrays_to_mgr(\n",
      "                        arrays,\n",
      "                        columns,\n",
      "                        index,\n",
      "                        dtype=dtype,\n",
      "                        typ=manager,\n",
      "                    )\n",
      "                \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "                    mgr = ndarray_to_mgr(\n",
      "                        data,\n",
      "                        index,\n",
      "                        columns,\n",
      "                        dtype=dtype,\n",
      "                        copy=copy,\n",
      "                        typ=manager,\n",
      "                    )\n",
      "            \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "                mgr = dict_to_mgr(\n",
      "                    {},\n",
      "                    index,\n",
      "                    columns \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m default_index(\u001b[32m0\u001b[39m),\n",
      "                    dtype=dtype,\n",
      "                    typ=manager,\n",
      "                )\n",
      "        \u001b[38;5;66;03m# For data is scalar\u001b[39;00m\n",
      "        \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mor\u001b[39;00m columns \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "                \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\u001b[33m\"DataFrame constructor not properly called!\"\u001b[39m)\n",
      "\n",
      "            index = ensure_index(index)\n",
      "            columns = ensure_index(columns)\n",
      "\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m dtype:\n",
      "                dtype, _ = infer_dtype_from_scalar(data)\n",
      "\n",
      "            \u001b[38;5;66;03m# For data is a scalar extension dtype\u001b[39;00m\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m isinstance(dtype, ExtensionDtype):\n",
      "                \u001b[38;5;66;03m# TODO(EA2D): special case not needed with 2D EAs\u001b[39;00m\n",
      "\n",
      "                values = [\n",
      "                    construct_1d_arraylike_from_scalar(data, len(index), dtype)\n",
      "                    \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;28;01min\u001b[39;00m range(len(columns))\n",
      "                ]\n",
      "                mgr = arrays_to_mgr(values, columns, index, dtype=\u001b[38;5;28;01mNone\u001b[39;00m, typ=manager)\n",
      "            \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "                arr2d = construct_2d_arraylike_from_scalar(\n",
      "                    data,\n",
      "                    len(index),\n",
      "                    len(columns),\n",
      "                    dtype,\n",
      "                    copy,\n",
      "                )\n",
      "\n",
      "                mgr = ndarray_to_mgr(\n",
      "                    arr2d,\n",
      "                    index,\n",
      "                    columns,\n",
      "                    dtype=arr2d.dtype,\n",
      "                    copy=\u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "                    typ=manager,\n",
      "                )\n",
      "\n",
      "        \u001b[38;5;66;03m# ensure correct Manager type according to settings\u001b[39;00m\n",
      "        mgr = mgr_to_mgr(mgr, typ=manager)\n",
      "\n",
      "        NDFrame.__init__(self, mgr)\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m original_dtype \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mand\u001b[39;00m is_pandas_object \u001b[38;5;28;01mand\u001b[39;00m data_dtype == np.object_:\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m self.dtypes.iloc[\u001b[32m0\u001b[39m] != data_dtype:\n",
      "                warnings.warn(\n",
      "                    \u001b[33m\"Dtype inference on a pandas object \"\u001b[39m\n",
      "                    \u001b[33m\"(Series, Index, ExtensionArray) is deprecated. The DataFrame \"\u001b[39m\n",
      "                    \u001b[33m\"constructor will keep the original dtype in the future. \"\u001b[39m\n",
      "                    \u001b[33m\"Call `infer_objects` on the result to get the old \"\u001b[39m\n",
      "                    \u001b[33m\"behavior.\"\u001b[39m,\n",
      "                    FutureWarning,\n",
      "                    stacklevel=\u001b[32m2\u001b[39m,\n",
      "                )\n",
      "\n",
      "    \u001b[38;5;66;03m# ----------------------------------------------------------------------\u001b[39;00m\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m __dataframe__(\n",
      "        self, nan_as_null: bool = \u001b[38;5;28;01mFalse\u001b[39;00m, allow_copy: bool = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "    ) -> DataFrameXchg:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Return the dataframe interchange object implementing the interchange protocol.\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        nan_as_null : bool, default False\u001b[39m\n",
      "\u001b[33m            `nan_as_null` is DEPRECATED and has no effect. Please avoid using\u001b[39m\n",
      "\u001b[33m            it; it will be removed in a future release.\u001b[39m\n",
      "\u001b[33m        allow_copy : bool, default True\u001b[39m\n",
      "\u001b[33m            Whether to allow memory copying when exporting. If set to False\u001b[39m\n",
      "\u001b[33m            it would cause non-zero-copy exports to fail.\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        DataFrame interchange object\u001b[39m\n",
      "\u001b[33m            The object which consuming library can use to ingress the dataframe.\u001b[39m\n",
      "\n",
      "\u001b[33m        Notes\u001b[39m\n",
      "\u001b[33m        -----\u001b[39m\n",
      "\u001b[33m        Details on the interchange protocol:\u001b[39m\n",
      "\u001b[33m        https://data-apis.org/dataframe-protocol/latest/index.html\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        >>> df_not_necessarily_pandas = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})\u001b[39m\n",
      "\u001b[33m        >>> interchange_object = df_not_necessarily_pandas.__dataframe__()\u001b[39m\n",
      "\u001b[33m        >>> interchange_object.column_names()\u001b[39m\n",
      "\u001b[33m        Index(['A', 'B'], dtype='object')\u001b[39m\n",
      "\u001b[33m        >>> df_pandas = (pd.api.interchange.from_dataframe\u001b[39m\n",
      "\u001b[33m        ...              (interchange_object.select_columns_by_name(['A'])))\u001b[39m\n",
      "\u001b[33m        >>> df_pandas\u001b[39m\n",
      "\u001b[33m             A\u001b[39m\n",
      "\u001b[33m        0    1\u001b[39m\n",
      "\u001b[33m        1    2\u001b[39m\n",
      "\n",
      "\u001b[33m        These methods (``column_names``, ``select_columns_by_name``) should work\u001b[39m\n",
      "\u001b[33m        for any dataframe library which implements the interchange protocol.\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "\n",
      "        \u001b[38;5;28;01mfrom\u001b[39;00m pandas.core.interchange.dataframe \u001b[38;5;28;01mimport\u001b[39;00m PandasDataFrameXchg\n",
      "\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m PandasDataFrameXchg(self, allow_copy=allow_copy)\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m __dataframe_consortium_standard__(\n",
      "        self, *, api_version: str | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "    ) -> Any:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Provide entry point to the Consortium DataFrame Standard API.\u001b[39m\n",
      "\n",
      "\u001b[33m        This is developed and maintained outside of pandas.\u001b[39m\n",
      "\u001b[33m        Please report any issues to https://github.com/data-apis/dataframe-api-compat.\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        dataframe_api_compat = import_optional_dependency(\u001b[33m\"dataframe_api_compat\"\u001b[39m)\n",
      "        convert_to_standard_compliant_dataframe = (\n",
      "            dataframe_api_compat.pandas_standard.convert_to_standard_compliant_dataframe\n",
      "        )\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_standard_compliant_dataframe(self, api_version=api_version)\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m __arrow_c_stream__(self, requested_schema=\u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Export the pandas DataFrame as an Arrow C stream PyCapsule.\u001b[39m\n",
      "\n",
      "\u001b[33m        This relies on pyarrow to convert the pandas DataFrame to the Arrow\u001b[39m\n",
      "\u001b[33m        format (and follows the default behaviour of ``pyarrow.Table.from_pandas``\u001b[39m\n",
      "\u001b[33m        in its handling of the index, i.e. store the index as a column except\u001b[39m\n",
      "\u001b[33m        for RangeIndex).\u001b[39m\n",
      "\u001b[33m        This conversion is not necessarily zero-copy.\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        requested_schema : PyCapsule, default None\u001b[39m\n",
      "\u001b[33m            The schema to which the dataframe should be casted, passed as a\u001b[39m\n",
      "\u001b[33m            PyCapsule containing a C ArrowSchema representation of the\u001b[39m\n",
      "\u001b[33m            requested schema.\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        PyCapsule\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        pa = import_optional_dependency(\u001b[33m\"pyarrow\"\u001b[39m, min_version=\u001b[33m\"14.0.0\"\u001b[39m)\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m requested_schema \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "            requested_schema = pa.Schema._import_from_c_capsule(requested_schema)\n",
      "        table = pa.Table.from_pandas(self, schema=requested_schema)\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m table.__arrow_c_stream__()\n",
      "\n",
      "    \u001b[38;5;66;03m# ----------------------------------------------------------------------\u001b[39;00m\n",
      "\n",
      "    @property\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m axes(self) -> list[Index]:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Return a list representing the axes of the DataFrame.\u001b[39m\n",
      "\n",
      "\u001b[33m        It has the row axis labels and column axis labels as the only members.\u001b[39m\n",
      "\u001b[33m        They are returned in that order.\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})\u001b[39m\n",
      "\u001b[33m        >>> df.axes\u001b[39m\n",
      "\u001b[33m        [RangeIndex(start=0, stop=2, step=1), Index(['col1', 'col2'],\u001b[39m\n",
      "\u001b[33m        dtype='object')]\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m [self.index, self.columns]\n",
      "\n",
      "    @property\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m shape(self) -> tuple[int, int]:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Return a tuple representing the dimensionality of the DataFrame.\u001b[39m\n",
      "\n",
      "\u001b[33m        See Also\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        ndarray.shape : Tuple of array dimensions.\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})\u001b[39m\n",
      "\u001b[33m        >>> df.shape\u001b[39m\n",
      "\u001b[33m        (2, 2)\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4],\u001b[39m\n",
      "\u001b[33m        ...                    'col3': [5, 6]})\u001b[39m\n",
      "\u001b[33m        >>> df.shape\u001b[39m\n",
      "\u001b[33m        (2, 3)\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m len(self.index), len(self.columns)\n",
      "\n",
      "    @property\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m _is_homogeneous_type(self) -> bool:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Whether all the columns in a DataFrame have the same type.\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        bool\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        >>> DataFrame({\"A\": [1, 2], \"B\": [3, 4]})._is_homogeneous_type\u001b[39m\n",
      "\u001b[33m        True\u001b[39m\n",
      "\u001b[33m        >>> DataFrame({\"A\": [1, 2], \"B\": [3.0, 4.0]})._is_homogeneous_type\u001b[39m\n",
      "\u001b[33m        False\u001b[39m\n",
      "\n",
      "\u001b[33m        Items with the same type but different sizes are considered\u001b[39m\n",
      "\u001b[33m        different types.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> DataFrame({\u001b[39m\n",
      "\u001b[33m        ...    \"A\": np.array([1, 2], dtype=np.int32),\u001b[39m\n",
      "\u001b[33m        ...    \"B\": np.array([1, 2], dtype=np.int64)})._is_homogeneous_type\u001b[39m\n",
      "\u001b[33m        False\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;66;03m# The \"<\" part of \"<=\" here is for empty DataFrame cases\u001b[39;00m\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m len({arr.dtype \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;28;01min\u001b[39;00m self._mgr.arrays}) <= \u001b[32m1\u001b[39m\n",
      "\n",
      "    @property\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m _can_fast_transpose(self) -> bool:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Can we transpose this DataFrame without creating any new array objects.\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m isinstance(self._mgr, ArrayManager):\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "        blocks = self._mgr.blocks\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m len(blocks) != \u001b[32m1\u001b[39m:\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\n",
      "        dtype = blocks[\u001b[32m0\u001b[39m].dtype\n",
      "        \u001b[38;5;66;03m# TODO(EA2D) special case would be unnecessary with 2D EAs\u001b[39;00m\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m is_1d_only_ea_dtype(dtype)\n",
      "\n",
      "    @property\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m _values(self) -> np.ndarray | DatetimeArray | TimedeltaArray | PeriodArray:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Analogue to ._values that may return a 2D ExtensionArray.\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        mgr = self._mgr\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m isinstance(mgr, ArrayManager):\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m len(mgr.arrays) == \u001b[32m1\u001b[39m \u001b[38;5;28;01mand\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m is_1d_only_ea_dtype(mgr.arrays[\u001b[32m0\u001b[39m].dtype):\n",
      "                \u001b[38;5;66;03m# error: Item \"ExtensionArray\" of \"Union[ndarray, ExtensionArray]\"\u001b[39;00m\n",
      "                \u001b[38;5;66;03m# has no attribute \"reshape\"\u001b[39;00m\n",
      "                \u001b[38;5;28;01mreturn\u001b[39;00m mgr.arrays[\u001b[32m0\u001b[39m].reshape(-\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m ensure_wrapped_if_datetimelike(self.values)\n",
      "\n",
      "        blocks = mgr.blocks\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m len(blocks) != \u001b[32m1\u001b[39m:\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m ensure_wrapped_if_datetimelike(self.values)\n",
      "\n",
      "        arr = blocks[\u001b[32m0\u001b[39m].values\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m arr.ndim == \u001b[32m1\u001b[39m:\n",
      "            \u001b[38;5;66;03m# non-2D ExtensionArray\u001b[39;00m\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m self.values\n",
      "\n",
      "        \u001b[38;5;66;03m# more generally, whatever we allow in NDArrayBackedExtensionBlock\u001b[39;00m\n",
      "        arr = cast(\u001b[33m\"np.ndarray | DatetimeArray | TimedeltaArray | PeriodArray\"\u001b[39m, arr)\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m arr.T\n",
      "\n",
      "    \u001b[38;5;66;03m# ----------------------------------------------------------------------\u001b[39;00m\n",
      "    \u001b[38;5;66;03m# Rendering Methods\u001b[39;00m\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m _repr_fits_vertical_(self) -> bool:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Check length against max_rows.\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        max_rows = get_option(\u001b[33m\"display.max_rows\"\u001b[39m)\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m len(self) <= max_rows\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m _repr_fits_horizontal_(self) -> bool:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Check if full repr fits in horizontal boundaries imposed by the display\u001b[39m\n",
      "\u001b[33m        options width and max_columns.\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        width, height = console.get_console_size()\n",
      "        max_columns = get_option(\u001b[33m\"display.max_columns\"\u001b[39m)\n",
      "        nb_columns = len(self.columns)\n",
      "\n",
      "        \u001b[38;5;66;03m# exceed max columns\u001b[39;00m\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m (max_columns \u001b[38;5;28;01mand\u001b[39;00m nb_columns > max_columns) \u001b[38;5;28;01mor\u001b[39;00m (\n",
      "            width \u001b[38;5;28;01mand\u001b[39;00m nb_columns > (width // \u001b[32m2\u001b[39m)\n",
      "        ):\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\n",
      "        \u001b[38;5;66;03m# used by repr_html under IPython notebook or scripts ignore terminal\u001b[39;00m\n",
      "        \u001b[38;5;66;03m# dims\u001b[39;00m\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m width \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mor\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m console.in_interactive_session():\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m get_option(\u001b[33m\"display.width\"\u001b[39m) \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mor\u001b[39;00m console.in_ipython_frontend():\n",
      "            \u001b[38;5;66;03m# check at least the column row for excessive width\u001b[39;00m\n",
      "            max_rows = \u001b[32m1\u001b[39m\n",
      "        \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "            max_rows = get_option(\u001b[33m\"display.max_rows\"\u001b[39m)\n",
      "\n",
      "        \u001b[38;5;66;03m# when auto-detecting, so width=None and not in ipython front end\u001b[39;00m\n",
      "        \u001b[38;5;66;03m# check whether repr fits horizontal by actually checking\u001b[39;00m\n",
      "        \u001b[38;5;66;03m# the width of the rendered repr\u001b[39;00m\n",
      "        buf = StringIO()\n",
      "\n",
      "        \u001b[38;5;66;03m# only care about the stuff we'll actually print out\u001b[39;00m\n",
      "        \u001b[38;5;66;03m# and to_string on entire frame may be expensive\u001b[39;00m\n",
      "        d = self\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m max_rows \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# unlimited rows\u001b[39;00m\n",
      "            \u001b[38;5;66;03m# min of two, where one may be None\u001b[39;00m\n",
      "            d = d.iloc[: min(max_rows, len(d))]\n",
      "        \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\n",
      "        d.to_string(buf=buf)\n",
      "        value = buf.getvalue()\n",
      "        repr_width = max(len(line) \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;28;01min\u001b[39;00m value.split(\u001b[33m\"\\n\"\u001b[39m))\n",
      "\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m repr_width < width\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m _info_repr(self) -> bool:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        True if the repr should show the info view.\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        info_repr_option = get_option(\u001b[33m\"display.large_repr\"\u001b[39m) == \u001b[33m\"info\"\u001b[39m\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m info_repr_option \u001b[38;5;28;01mand\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m (\n",
      "            self._repr_fits_horizontal_() \u001b[38;5;28;01mand\u001b[39;00m self._repr_fits_vertical_()\n",
      "        )\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m __repr__(self) -> str:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Return a string representation for a particular DataFrame.\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m self._info_repr():\n",
      "            buf = StringIO()\n",
      "            self.info(buf=buf)\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m buf.getvalue()\n",
      "\n",
      "        repr_params = fmt.get_dataframe_repr_params()\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m self.to_string(**repr_params)\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m _repr_html_(self) -> str | \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Return a html representation for a particular DataFrame.\u001b[39m\n",
      "\n",
      "\u001b[33m        Mainly for IPython notebook.\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m self._info_repr():\n",
      "            buf = StringIO()\n",
      "            self.info(buf=buf)\n",
      "            \u001b[38;5;66;03m# need to escape the <class>, should be the first line.\u001b[39;00m\n",
      "            val = buf.getvalue().replace(\u001b[33m\"<\"\u001b[39m, \u001b[33mr\"&lt;\"\u001b[39m, \u001b[32m1\u001b[39m)\n",
      "            val = val.replace(\u001b[33m\">\"\u001b[39m, \u001b[33mr\"&gt;\"\u001b[39m, \u001b[32m1\u001b[39m)\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33mf\"<pre>{val}</pre>\"\u001b[39m\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m get_option(\u001b[33m\"display.notebook_repr_html\"\u001b[39m):\n",
      "            max_rows = get_option(\u001b[33m\"display.max_rows\"\u001b[39m)\n",
      "            min_rows = get_option(\u001b[33m\"display.min_rows\"\u001b[39m)\n",
      "            max_cols = get_option(\u001b[33m\"display.max_columns\"\u001b[39m)\n",
      "            show_dimensions = get_option(\u001b[33m\"display.show_dimensions\"\u001b[39m)\n",
      "\n",
      "            formatter = fmt.DataFrameFormatter(\n",
      "                self,\n",
      "                columns=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "                col_space=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "                na_rep=\u001b[33m\"NaN\"\u001b[39m,\n",
      "                formatters=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "                float_format=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "                sparsify=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "                justify=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "                index_names=\u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "                header=\u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "                index=\u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "                bold_rows=\u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "                escape=\u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "                max_rows=max_rows,\n",
      "                min_rows=min_rows,\n",
      "                max_cols=max_cols,\n",
      "                show_dimensions=show_dimensions,\n",
      "                decimal=\u001b[33m\".\"\u001b[39m,\n",
      "            )\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m fmt.DataFrameRenderer(formatter).to_html(notebook=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "        \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\n",
      "    @overload\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m to_string(\n",
      "        self,\n",
      "        buf: \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        columns: Axes | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        col_space: int | list[int] | dict[Hashable, int] | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        header: bool | SequenceNotStr[str] = ...,\n",
      "        index: bool = ...,\n",
      "        na_rep: str = ...,\n",
      "        formatters: fmt.FormattersType | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        float_format: fmt.FloatFormatType | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        sparsify: bool | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        index_names: bool = ...,\n",
      "        justify: str | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        max_rows: int | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        max_cols: int | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        show_dimensions: bool = ...,\n",
      "        decimal: str = ...,\n",
      "        line_width: int | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        min_rows: int | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        max_colwidth: int | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        encoding: str | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "    ) -> str:\n",
      "        ...\n",
      "\n",
      "    @overload\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m to_string(\n",
      "        self,\n",
      "        buf: FilePath | WriteBuffer[str],\n",
      "        columns: Axes | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        col_space: int | list[int] | dict[Hashable, int] | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        header: bool | SequenceNotStr[str] = ...,\n",
      "        index: bool = ...,\n",
      "        na_rep: str = ...,\n",
      "        formatters: fmt.FormattersType | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        float_format: fmt.FloatFormatType | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        sparsify: bool | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        index_names: bool = ...,\n",
      "        justify: str | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        max_rows: int | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        max_cols: int | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        show_dimensions: bool = ...,\n",
      "        decimal: str = ...,\n",
      "        line_width: int | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        min_rows: int | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        max_colwidth: int | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        encoding: str | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "    ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        ...\n",
      "\n",
      "    @deprecate_nonkeyword_arguments(\n",
      "        version=\u001b[33m\"3.0\"\u001b[39m, allowed_args=[\u001b[33m\"self\"\u001b[39m, \u001b[33m\"buf\"\u001b[39m], name=\u001b[33m\"to_string\"\u001b[39m\n",
      "    )\n",
      "    @Substitution(\n",
      "        header_type=\u001b[33m\"bool or list of str\"\u001b[39m,\n",
      "        header=\u001b[33m\"Write out the column names. If a list of columns \"\u001b[39m\n",
      "        \u001b[33m\"is given, it is assumed to be aliases for the \"\u001b[39m\n",
      "        \u001b[33m\"column names\"\u001b[39m,\n",
      "        col_space_type=\u001b[33m\"int, list or dict of int\"\u001b[39m,\n",
      "        col_space=\u001b[33m\"The minimum width of each column. If a list of ints is given \"\u001b[39m\n",
      "        \u001b[33m\"every integers corresponds with one column. If a dict is given, the key \"\u001b[39m\n",
      "        \u001b[33m\"references the column, while the value defines the space to use.\"\u001b[39m,\n",
      "    )\n",
      "    @Substitution(shared_params=fmt.common_docstring, returns=fmt.return_docstring)\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m to_string(\n",
      "        self,\n",
      "        buf: FilePath | WriteBuffer[str] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        columns: Axes | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        col_space: int | list[int] | dict[Hashable, int] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        header: bool | SequenceNotStr[str] = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "        index: bool = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "        na_rep: str = \u001b[33m\"NaN\"\u001b[39m,\n",
      "        formatters: fmt.FormattersType | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        float_format: fmt.FloatFormatType | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        sparsify: bool | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        index_names: bool = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "        justify: str | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        max_rows: int | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        max_cols: int | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        show_dimensions: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "        decimal: str = \u001b[33m\".\"\u001b[39m,\n",
      "        line_width: int | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        min_rows: int | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        max_colwidth: int | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        encoding: str | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    ) -> str | \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Render a DataFrame to a console-friendly tabular output.\u001b[39m\n",
      "\u001b[33m        %(shared_params)s\u001b[39m\n",
      "\u001b[33m        line_width : int, optional\u001b[39m\n",
      "\u001b[33m            Width to wrap a line in characters.\u001b[39m\n",
      "\u001b[33m        min_rows : int, optional\u001b[39m\n",
      "\u001b[33m            The number of rows to display in the console in a truncated repr\u001b[39m\n",
      "\u001b[33m            (when number of rows is above `max_rows`).\u001b[39m\n",
      "\u001b[33m        max_colwidth : int, optional\u001b[39m\n",
      "\u001b[33m            Max width to truncate each column in characters. By default, no limit.\u001b[39m\n",
      "\u001b[33m        encoding : str, default \"utf-8\"\u001b[39m\n",
      "\u001b[33m            Set character encoding.\u001b[39m\n",
      "\u001b[33m        %(returns)s\u001b[39m\n",
      "\u001b[33m        See Also\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        to_html : Convert DataFrame to HTML.\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        >>> d = {'col1': [1, 2, 3], 'col2': [4, 5, 6]}\u001b[39m\n",
      "\u001b[33m        >>> df = pd.DataFrame(d)\u001b[39m\n",
      "\u001b[33m        >>> print(df.to_string())\u001b[39m\n",
      "\u001b[33m           col1  col2\u001b[39m\n",
      "\u001b[33m        0     1     4\u001b[39m\n",
      "\u001b[33m        1     2     5\u001b[39m\n",
      "\u001b[33m        2     3     6\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;28;01mfrom\u001b[39;00m pandas \u001b[38;5;28;01mimport\u001b[39;00m option_context\n",
      "\n",
      "        \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[33m\"display.max_colwidth\"\u001b[39m, max_colwidth):\n",
      "            formatter = fmt.DataFrameFormatter(\n",
      "                self,\n",
      "                columns=columns,\n",
      "                col_space=col_space,\n",
      "                na_rep=na_rep,\n",
      "                formatters=formatters,\n",
      "                float_format=float_format,\n",
      "                sparsify=sparsify,\n",
      "                justify=justify,\n",
      "                index_names=index_names,\n",
      "                header=header,\n",
      "                index=index,\n",
      "                min_rows=min_rows,\n",
      "                max_rows=max_rows,\n",
      "                max_cols=max_cols,\n",
      "                show_dimensions=show_dimensions,\n",
      "                decimal=decimal,\n",
      "            )\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m fmt.DataFrameRenderer(formatter).to_string(\n",
      "                buf=buf,\n",
      "                encoding=encoding,\n",
      "                line_width=line_width,\n",
      "            )\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m _get_values_for_csv(\n",
      "        self,\n",
      "        *,\n",
      "        float_format: FloatFormatType | \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        date_format: str | \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        decimal: str,\n",
      "        na_rep: str,\n",
      "        quoting,  \u001b[38;5;66;03m# int csv.QUOTE_FOO from stdlib\u001b[39;00m\n",
      "    ) -> Self:\n",
      "        \u001b[38;5;66;03m# helper used by to_csv\u001b[39;00m\n",
      "        mgr = self._mgr.get_values_for_csv(\n",
      "            float_format=float_format,\n",
      "            date_format=date_format,\n",
      "            decimal=decimal,\n",
      "            na_rep=na_rep,\n",
      "            quoting=quoting,\n",
      "        )\n",
      "        \u001b[38;5;66;03m# error: Incompatible return value type (got \"DataFrame\", expected \"Self\")\u001b[39;00m\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m self._constructor_from_mgr(mgr, axes=mgr.axes)  \u001b[38;5;66;03m# type: ignore[return-value]\u001b[39;00m\n",
      "\n",
      "    \u001b[38;5;66;03m# ----------------------------------------------------------------------\u001b[39;00m\n",
      "\n",
      "    @property\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m style(self) -> Styler:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Returns a Styler object.\u001b[39m\n",
      "\n",
      "\u001b[33m        Contains methods for building a styled HTML representation of the DataFrame.\u001b[39m\n",
      "\n",
      "\u001b[33m        See Also\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        io.formats.style.Styler : Helps style a DataFrame or Series according to the\u001b[39m\n",
      "\u001b[33m            data with HTML and CSS.\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        >>> df = pd.DataFrame({'A': [1, 2, 3]})\u001b[39m\n",
      "\u001b[33m        >>> df.style  # doctest: +SKIP\u001b[39m\n",
      "\n",
      "\u001b[33m        Please see\u001b[39m\n",
      "\u001b[33m        `Table Visualization <../../user_guide/style.ipynb>`_ for more examples.\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;28;01mfrom\u001b[39;00m pandas.io.formats.style \u001b[38;5;28;01mimport\u001b[39;00m Styler\n",
      "\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m Styler(self)\n",
      "\n",
      "    _shared_docs[\n",
      "        \u001b[33m\"items\"\u001b[39m\n",
      "    ] = \u001b[33mr\"\"\"\u001b[39m\n",
      "\u001b[33m        Iterate over (column name, Series) pairs.\u001b[39m\n",
      "\n",
      "\u001b[33m        Iterates over the DataFrame columns, returning a tuple with\u001b[39m\n",
      "\u001b[33m        the column name and the content as a Series.\u001b[39m\n",
      "\n",
      "\u001b[33m        Yields\u001b[39m\n",
      "\u001b[33m        ------\u001b[39m\n",
      "\u001b[33m        label : object\u001b[39m\n",
      "\u001b[33m            The column names for the DataFrame being iterated over.\u001b[39m\n",
      "\u001b[33m        content : Series\u001b[39m\n",
      "\u001b[33m            The column entries belonging to each label, as a Series.\u001b[39m\n",
      "\n",
      "\u001b[33m        See Also\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        DataFrame.iterrows : Iterate over DataFrame rows as\u001b[39m\n",
      "\u001b[33m            (index, Series) pairs.\u001b[39m\n",
      "\u001b[33m        DataFrame.itertuples : Iterate over DataFrame rows as namedtuples\u001b[39m\n",
      "\u001b[33m            of the values.\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        >>> df = pd.DataFrame({'species': ['bear', 'bear', 'marsupial'],\u001b[39m\n",
      "\u001b[33m        ...                   'population': [1864, 22000, 80000]},\u001b[39m\n",
      "\u001b[33m        ...                   index=['panda', 'polar', 'koala'])\u001b[39m\n",
      "\u001b[33m        >>> df\u001b[39m\n",
      "\u001b[33m                species   population\u001b[39m\n",
      "\u001b[33m        panda   bear      1864\u001b[39m\n",
      "\u001b[33m        polar   bear      22000\u001b[39m\n",
      "\u001b[33m        koala   marsupial 80000\u001b[39m\n",
      "\u001b[33m        >>> for label, content in df.items():\u001b[39m\n",
      "\u001b[33m        ...     print(f'label: {label}')\u001b[39m\n",
      "\u001b[33m        ...     print(f'content: {content}', sep='\\n')\u001b[39m\n",
      "\u001b[33m        ...\u001b[39m\n",
      "\u001b[33m        label: species\u001b[39m\n",
      "\u001b[33m        content:\u001b[39m\n",
      "\u001b[33m        panda         bear\u001b[39m\n",
      "\u001b[33m        polar         bear\u001b[39m\n",
      "\u001b[33m        koala    marsupial\u001b[39m\n",
      "\u001b[33m        Name: species, dtype: object\u001b[39m\n",
      "\u001b[33m        label: population\u001b[39m\n",
      "\u001b[33m        content:\u001b[39m\n",
      "\u001b[33m        panda     1864\u001b[39m\n",
      "\u001b[33m        polar    22000\u001b[39m\n",
      "\u001b[33m        koala    80000\u001b[39m\n",
      "\u001b[33m        Name: population, dtype: int64\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "\n",
      "    @Appender(_shared_docs[\u001b[33m\"items\"\u001b[39m])\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m items(self) -> Iterable[tuple[Hashable, Series]]:\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m self.columns.is_unique \u001b[38;5;28;01mand\u001b[39;00m hasattr(self, \u001b[33m\"_item_cache\"\u001b[39m):\n",
      "            \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;28;01min\u001b[39;00m self.columns:\n",
      "                \u001b[38;5;28;01myield\u001b[39;00m k, self._get_item_cache(k)\n",
      "        \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "            \u001b[38;5;28;01mfor\u001b[39;00m i, k \u001b[38;5;28;01min\u001b[39;00m enumerate(self.columns):\n",
      "                \u001b[38;5;28;01myield\u001b[39;00m k, self._ixs(i, axis=\u001b[32m1\u001b[39m)\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m iterrows(self) -> Iterable[tuple[Hashable, Series]]:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Iterate over DataFrame rows as (index, Series) pairs.\u001b[39m\n",
      "\n",
      "\u001b[33m        Yields\u001b[39m\n",
      "\u001b[33m        ------\u001b[39m\n",
      "\u001b[33m        index : label or tuple of label\u001b[39m\n",
      "\u001b[33m            The index of the row. A tuple for a `MultiIndex`.\u001b[39m\n",
      "\u001b[33m        data : Series\u001b[39m\n",
      "\u001b[33m            The data of the row as a Series.\u001b[39m\n",
      "\n",
      "\u001b[33m        See Also\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        DataFrame.itertuples : Iterate over DataFrame rows as namedtuples of the values.\u001b[39m\n",
      "\u001b[33m        DataFrame.items : Iterate over (column name, Series) pairs.\u001b[39m\n",
      "\n",
      "\u001b[33m        Notes\u001b[39m\n",
      "\u001b[33m        -----\u001b[39m\n",
      "\u001b[33m        1. Because ``iterrows`` returns a Series for each row,\u001b[39m\n",
      "\u001b[33m           it does **not** preserve dtypes across the rows (dtypes are\u001b[39m\n",
      "\u001b[33m           preserved across columns for DataFrames).\u001b[39m\n",
      "\n",
      "\u001b[33m           To preserve dtypes while iterating over the rows, it is better\u001b[39m\n",
      "\u001b[33m           to use :meth:`itertuples` which returns namedtuples of the values\u001b[39m\n",
      "\u001b[33m           and which is generally faster than ``iterrows``.\u001b[39m\n",
      "\n",
      "\u001b[33m        2. You should **never modify** something you are iterating over.\u001b[39m\n",
      "\u001b[33m           This is not guaranteed to work in all cases. Depending on the\u001b[39m\n",
      "\u001b[33m           data types, the iterator returns a copy and not a view, and writing\u001b[39m\n",
      "\u001b[33m           to it will have no effect.\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df = pd.DataFrame([[1, 1.5]], columns=['int', 'float'])\u001b[39m\n",
      "\u001b[33m        >>> row = next(df.iterrows())[1]\u001b[39m\n",
      "\u001b[33m        >>> row\u001b[39m\n",
      "\u001b[33m        int      1.0\u001b[39m\n",
      "\u001b[33m        float    1.5\u001b[39m\n",
      "\u001b[33m        Name: 0, dtype: float64\u001b[39m\n",
      "\u001b[33m        >>> print(row['int'].dtype)\u001b[39m\n",
      "\u001b[33m        float64\u001b[39m\n",
      "\u001b[33m        >>> print(df['int'].dtype)\u001b[39m\n",
      "\u001b[33m        int64\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        columns = self.columns\n",
      "        klass = self._constructor_sliced\n",
      "        using_cow = using_copy_on_write()\n",
      "        \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;28;01min\u001b[39;00m zip(self.index, self.values):\n",
      "            s = klass(v, index=columns, name=k).__finalize__(self)\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m using_cow \u001b[38;5;28;01mand\u001b[39;00m self._mgr.is_single_block:\n",
      "                s._mgr.add_references(self._mgr)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "            \u001b[38;5;28;01myield\u001b[39;00m k, s\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m itertuples(\n",
      "        self, index: bool = \u001b[38;5;28;01mTrue\u001b[39;00m, name: str | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[33m\"Pandas\"\u001b[39m\n",
      "    ) -> Iterable[tuple[Any, ...]]:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Iterate over DataFrame rows as namedtuples.\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        index : bool, default True\u001b[39m\n",
      "\u001b[33m            If True, return the index as the first element of the tuple.\u001b[39m\n",
      "\u001b[33m        name : str or None, default \"Pandas\"\u001b[39m\n",
      "\u001b[33m            The name of the returned namedtuples or None to return regular\u001b[39m\n",
      "\u001b[33m            tuples.\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        iterator\u001b[39m\n",
      "\u001b[33m            An object to iterate over namedtuples for each row in the\u001b[39m\n",
      "\u001b[33m            DataFrame with the first field possibly being the index and\u001b[39m\n",
      "\u001b[33m            following fields being the column values.\u001b[39m\n",
      "\n",
      "\u001b[33m        See Also\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        DataFrame.iterrows : Iterate over DataFrame rows as (index, Series)\u001b[39m\n",
      "\u001b[33m            pairs.\u001b[39m\n",
      "\u001b[33m        DataFrame.items : Iterate over (column name, Series) pairs.\u001b[39m\n",
      "\n",
      "\u001b[33m        Notes\u001b[39m\n",
      "\u001b[33m        -----\u001b[39m\n",
      "\u001b[33m        The column names will be renamed to positional names if they are\u001b[39m\n",
      "\u001b[33m        invalid Python identifiers, repeated, or start with an underscore.\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        >>> df = pd.DataFrame({'num_legs': [4, 2], 'num_wings': [0, 2]},\u001b[39m\n",
      "\u001b[33m        ...                   index=['dog', 'hawk'])\u001b[39m\n",
      "\u001b[33m        >>> df\u001b[39m\n",
      "\u001b[33m              num_legs  num_wings\u001b[39m\n",
      "\u001b[33m        dog          4          0\u001b[39m\n",
      "\u001b[33m        hawk         2          2\u001b[39m\n",
      "\u001b[33m        >>> for row in df.itertuples():\u001b[39m\n",
      "\u001b[33m        ...     print(row)\u001b[39m\n",
      "\u001b[33m        ...\u001b[39m\n",
      "\u001b[33m        Pandas(Index='dog', num_legs=4, num_wings=0)\u001b[39m\n",
      "\u001b[33m        Pandas(Index='hawk', num_legs=2, num_wings=2)\u001b[39m\n",
      "\n",
      "\u001b[33m        By setting the `index` parameter to False we can remove the index\u001b[39m\n",
      "\u001b[33m        as the first element of the tuple:\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> for row in df.itertuples(index=False):\u001b[39m\n",
      "\u001b[33m        ...     print(row)\u001b[39m\n",
      "\u001b[33m        ...\u001b[39m\n",
      "\u001b[33m        Pandas(num_legs=4, num_wings=0)\u001b[39m\n",
      "\u001b[33m        Pandas(num_legs=2, num_wings=2)\u001b[39m\n",
      "\n",
      "\u001b[33m        With the `name` parameter set we set a custom name for the yielded\u001b[39m\n",
      "\u001b[33m        namedtuples:\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> for row in df.itertuples(name='Animal'):\u001b[39m\n",
      "\u001b[33m        ...     print(row)\u001b[39m\n",
      "\u001b[33m        ...\u001b[39m\n",
      "\u001b[33m        Animal(Index='dog', num_legs=4, num_wings=0)\u001b[39m\n",
      "\u001b[33m        Animal(Index='hawk', num_legs=2, num_wings=2)\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        arrays = []\n",
      "        fields = list(self.columns)\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m index:\n",
      "            arrays.append(self.index)\n",
      "            fields.insert(\u001b[32m0\u001b[39m, \u001b[33m\"Index\"\u001b[39m)\n",
      "\n",
      "        \u001b[38;5;66;03m# use integer indexing because of possible duplicate column names\u001b[39;00m\n",
      "        arrays.extend(self.iloc[:, k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;28;01min\u001b[39;00m range(len(self.columns)))\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "            \u001b[38;5;66;03m# https://github.com/python/mypy/issues/9046\u001b[39;00m\n",
      "            \u001b[38;5;66;03m# error: namedtuple() expects a string literal as the first argument\u001b[39;00m\n",
      "            itertuple = collections.namedtuple(  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "                name, fields, rename=\u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "            )\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m map(itertuple._make, zip(*arrays))\n",
      "\n",
      "        \u001b[38;5;66;03m# fallback to regular tuples\u001b[39;00m\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m zip(*arrays)\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m __len__(self) -> int:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Returns length of info axis, but here we use the index.\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m len(self.index)\n",
      "\n",
      "    @overload\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m dot(self, other: Series) -> Series:\n",
      "        ...\n",
      "\n",
      "    @overload\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m dot(self, other: DataFrame | Index | ArrayLike) -> DataFrame:\n",
      "        ...\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m dot(self, other: AnyArrayLike | DataFrame) -> DataFrame | Series:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Compute the matrix multiplication between the DataFrame and other.\u001b[39m\n",
      "\n",
      "\u001b[33m        This method computes the matrix product between the DataFrame and the\u001b[39m\n",
      "\u001b[33m        values of an other Series, DataFrame or a numpy array.\u001b[39m\n",
      "\n",
      "\u001b[33m        It can also be called using ``self @ other``.\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        other : Series, DataFrame or array-like\u001b[39m\n",
      "\u001b[33m            The other object to compute the matrix product with.\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        Series or DataFrame\u001b[39m\n",
      "\u001b[33m            If other is a Series, return the matrix product between self and\u001b[39m\n",
      "\u001b[33m            other as a Series. If other is a DataFrame or a numpy.array, return\u001b[39m\n",
      "\u001b[33m            the matrix product of self and other in a DataFrame of a np.array.\u001b[39m\n",
      "\n",
      "\u001b[33m        See Also\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        Series.dot: Similar method for Series.\u001b[39m\n",
      "\n",
      "\u001b[33m        Notes\u001b[39m\n",
      "\u001b[33m        -----\u001b[39m\n",
      "\u001b[33m        The dimensions of DataFrame and other must be compatible in order to\u001b[39m\n",
      "\u001b[33m        compute the matrix multiplication. In addition, the column names of\u001b[39m\n",
      "\u001b[33m        DataFrame and the index of other must contain the same values, as they\u001b[39m\n",
      "\u001b[33m        will be aligned prior to the multiplication.\u001b[39m\n",
      "\n",
      "\u001b[33m        The dot method for Series computes the inner product, instead of the\u001b[39m\n",
      "\u001b[33m        matrix product here.\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        Here we multiply a DataFrame with a Series.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df = pd.DataFrame([[0, 1, -2, -1], [1, 1, 1, 1]])\u001b[39m\n",
      "\u001b[33m        >>> s = pd.Series([1, 1, 2, 1])\u001b[39m\n",
      "\u001b[33m        >>> df.dot(s)\u001b[39m\n",
      "\u001b[33m        0    -4\u001b[39m\n",
      "\u001b[33m        1     5\u001b[39m\n",
      "\u001b[33m        dtype: int64\u001b[39m\n",
      "\n",
      "\u001b[33m        Here we multiply a DataFrame with another DataFrame.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> other = pd.DataFrame([[0, 1], [1, 2], [-1, -1], [2, 0]])\u001b[39m\n",
      "\u001b[33m        >>> df.dot(other)\u001b[39m\n",
      "\u001b[33m            0   1\u001b[39m\n",
      "\u001b[33m        0   1   4\u001b[39m\n",
      "\u001b[33m        1   2   2\u001b[39m\n",
      "\n",
      "\u001b[33m        Note that the dot method give the same result as @\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df @ other\u001b[39m\n",
      "\u001b[33m            0   1\u001b[39m\n",
      "\u001b[33m        0   1   4\u001b[39m\n",
      "\u001b[33m        1   2   2\u001b[39m\n",
      "\n",
      "\u001b[33m        The dot method works also if other is an np.array.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> arr = np.array([[0, 1], [1, 2], [-1, -1], [2, 0]])\u001b[39m\n",
      "\u001b[33m        >>> df.dot(arr)\u001b[39m\n",
      "\u001b[33m            0   1\u001b[39m\n",
      "\u001b[33m        0   1   4\u001b[39m\n",
      "\u001b[33m        1   2   2\u001b[39m\n",
      "\n",
      "\u001b[33m        Note how shuffling of the objects does not change the result.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> s2 = s.reindex([1, 0, 2, 3])\u001b[39m\n",
      "\u001b[33m        >>> df.dot(s2)\u001b[39m\n",
      "\u001b[33m        0    -4\u001b[39m\n",
      "\u001b[33m        1     5\u001b[39m\n",
      "\u001b[33m        dtype: int64\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m isinstance(other, (Series, DataFrame)):\n",
      "            common = self.columns.union(other.index)\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m len(common) > len(self.columns) \u001b[38;5;28;01mor\u001b[39;00m len(common) > len(other.index):\n",
      "                \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\u001b[33m\"matrices are not aligned\"\u001b[39m)\n",
      "\n",
      "            left = self.reindex(columns=common, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "            right = other.reindex(index=common, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "            lvals = left.values\n",
      "            rvals = right._values\n",
      "        \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "            left = self\n",
      "            lvals = self.values\n",
      "            rvals = np.asarray(other)\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m lvals.shape[\u001b[32m1\u001b[39m] != rvals.shape[\u001b[32m0\u001b[39m]:\n",
      "                \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\n",
      "                    \u001b[33mf\"Dot product shape mismatch, {lvals.shape} vs {rvals.shape}\"\u001b[39m\n",
      "                )\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m isinstance(other, DataFrame):\n",
      "            common_type = find_common_type(list(self.dtypes) + list(other.dtypes))\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m self._constructor(\n",
      "                np.dot(lvals, rvals),\n",
      "                index=left.index,\n",
      "                columns=other.columns,\n",
      "                copy=\u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "                dtype=common_type,\n",
      "            )\n",
      "        \u001b[38;5;28;01melif\u001b[39;00m isinstance(other, Series):\n",
      "            common_type = find_common_type(list(self.dtypes) + [other.dtypes])\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m self._constructor_sliced(\n",
      "                np.dot(lvals, rvals), index=left.index, copy=\u001b[38;5;28;01mFalse\u001b[39;00m, dtype=common_type\n",
      "            )\n",
      "        \u001b[38;5;28;01melif\u001b[39;00m isinstance(rvals, (np.ndarray, Index)):\n",
      "            result = np.dot(lvals, rvals)\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m result.ndim == \u001b[32m2\u001b[39m:\n",
      "                \u001b[38;5;28;01mreturn\u001b[39;00m self._constructor(result, index=left.index, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "            \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "                \u001b[38;5;28;01mreturn\u001b[39;00m self._constructor_sliced(result, index=left.index, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "        \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n",
      "            \u001b[38;5;28;01mraise\u001b[39;00m TypeError(\u001b[33mf\"unsupported type: {type(other)}\"\u001b[39m)\n",
      "\n",
      "    @overload\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m __matmul__(self, other: Series) -> Series:\n",
      "        ...\n",
      "\n",
      "    @overload\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m __matmul__(self, other: AnyArrayLike | DataFrame) -> DataFrame | Series:\n",
      "        ...\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m __matmul__(self, other: AnyArrayLike | DataFrame) -> DataFrame | Series:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Matrix multiplication using binary `@` operator.\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m self.dot(other)\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m __rmatmul__(self, other) -> DataFrame:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Matrix multiplication using binary `@` operator.\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m self.T.dot(np.transpose(other)).T\n",
      "        \u001b[38;5;28;01mexcept\u001b[39;00m ValueError \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"shape mismatch\"\u001b[39m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01min\u001b[39;00m str(err):\n",
      "                \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "            \u001b[38;5;66;03m# GH#21581 give exception message for original shapes\u001b[39;00m\n",
      "            msg = \u001b[33mf\"shapes {np.shape(other)} and {self.shape} not aligned\"\u001b[39m\n",
      "            \u001b[38;5;28;01mraise\u001b[39;00m ValueError(msg) \u001b[38;5;28;01mfrom\u001b[39;00m err\n",
      "\n",
      "    \u001b[38;5;66;03m# ----------------------------------------------------------------------\u001b[39;00m\n",
      "    \u001b[38;5;66;03m# IO methods (to / from other formats)\u001b[39;00m\n",
      "\n",
      "    @classmethod\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m from_dict(\n",
      "        cls,\n",
      "        data: dict,\n",
      "        orient: FromDictOrient = \u001b[33m\"columns\"\u001b[39m,\n",
      "        dtype: Dtype | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        columns: Axes | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    ) -> DataFrame:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Construct DataFrame from dict of array-like or dicts.\u001b[39m\n",
      "\n",
      "\u001b[33m        Creates DataFrame object from dictionary by columns or by index\u001b[39m\n",
      "\u001b[33m        allowing dtype specification.\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        data : dict\u001b[39m\n",
      "\u001b[33m            Of the form {field : array-like} or {field : dict}.\u001b[39m\n",
      "\u001b[33m        orient : {'columns', 'index', 'tight'}, default 'columns'\u001b[39m\n",
      "\u001b[33m            The \"orientation\" of the data. If the keys of the passed dict\u001b[39m\n",
      "\u001b[33m            should be the columns of the resulting DataFrame, pass 'columns'\u001b[39m\n",
      "\u001b[33m            (default). Otherwise if the keys should be rows, pass 'index'.\u001b[39m\n",
      "\u001b[33m            If 'tight', assume a dict with keys ['index', 'columns', 'data',\u001b[39m\n",
      "\u001b[33m            'index_names', 'column_names'].\u001b[39m\n",
      "\n",
      "\u001b[33m            .. versionadded:: 1.4.0\u001b[39m\n",
      "\u001b[33m               'tight' as an allowed value for the ``orient`` argument\u001b[39m\n",
      "\n",
      "\u001b[33m        dtype : dtype, default None\u001b[39m\n",
      "\u001b[33m            Data type to force after DataFrame construction, otherwise infer.\u001b[39m\n",
      "\u001b[33m        columns : list, default None\u001b[39m\n",
      "\u001b[33m            Column labels to use when ``orient='index'``. Raises a ValueError\u001b[39m\n",
      "\u001b[33m            if used with ``orient='columns'`` or ``orient='tight'``.\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        DataFrame\u001b[39m\n",
      "\n",
      "\u001b[33m        See Also\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        DataFrame.from_records : DataFrame from structured ndarray, sequence\u001b[39m\n",
      "\u001b[33m            of tuples or dicts, or DataFrame.\u001b[39m\n",
      "\u001b[33m        DataFrame : DataFrame object creation using constructor.\u001b[39m\n",
      "\u001b[33m        DataFrame.to_dict : Convert the DataFrame to a dictionary.\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        By default the keys of the dict become the DataFrame columns:\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> data = {'col_1': [3, 2, 1, 0], 'col_2': ['a', 'b', 'c', 'd']}\u001b[39m\n",
      "\u001b[33m        >>> pd.DataFrame.from_dict(data)\u001b[39m\n",
      "\u001b[33m           col_1 col_2\u001b[39m\n",
      "\u001b[33m        0      3     a\u001b[39m\n",
      "\u001b[33m        1      2     b\u001b[39m\n",
      "\u001b[33m        2      1     c\u001b[39m\n",
      "\u001b[33m        3      0     d\u001b[39m\n",
      "\n",
      "\u001b[33m        Specify ``orient='index'`` to create the DataFrame using dictionary\u001b[39m\n",
      "\u001b[33m        keys as rows:\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> data = {'row_1': [3, 2, 1, 0], 'row_2': ['a', 'b', 'c', 'd']}\u001b[39m\n",
      "\u001b[33m        >>> pd.DataFrame.from_dict(data, orient='index')\u001b[39m\n",
      "\u001b[33m               0  1  2  3\u001b[39m\n",
      "\u001b[33m        row_1  3  2  1  0\u001b[39m\n",
      "\u001b[33m        row_2  a  b  c  d\u001b[39m\n",
      "\n",
      "\u001b[33m        When using the 'index' orientation, the column names can be\u001b[39m\n",
      "\u001b[33m        specified manually:\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> pd.DataFrame.from_dict(data, orient='index',\u001b[39m\n",
      "\u001b[33m        ...                        columns=['A', 'B', 'C', 'D'])\u001b[39m\n",
      "\u001b[33m               A  B  C  D\u001b[39m\n",
      "\u001b[33m        row_1  3  2  1  0\u001b[39m\n",
      "\u001b[33m        row_2  a  b  c  d\u001b[39m\n",
      "\n",
      "\u001b[33m        Specify ``orient='tight'`` to create the DataFrame using a 'tight'\u001b[39m\n",
      "\u001b[33m        format:\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> data = {'index': [('a', 'b'), ('a', 'c')],\u001b[39m\n",
      "\u001b[33m        ...         'columns': [('x', 1), ('y', 2)],\u001b[39m\n",
      "\u001b[33m        ...         'data': [[1, 3], [2, 4]],\u001b[39m\n",
      "\u001b[33m        ...         'index_names': ['n1', 'n2'],\u001b[39m\n",
      "\u001b[33m        ...         'column_names': ['z1', 'z2']}\u001b[39m\n",
      "\u001b[33m        >>> pd.DataFrame.from_dict(data, orient='tight')\u001b[39m\n",
      "\u001b[33m        z1     x  y\u001b[39m\n",
      "\u001b[33m        z2     1  2\u001b[39m\n",
      "\u001b[33m        n1 n2\u001b[39m\n",
      "\u001b[33m        a  b   1  3\u001b[39m\n",
      "\u001b[33m           c   2  4\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        index = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "        orient = orient.lower()  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m orient == \u001b[33m\"index\"\u001b[39m:\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m len(data) > \u001b[32m0\u001b[39m:\n",
      "                \u001b[38;5;66;03m# TODO speed up Series case\u001b[39;00m\n",
      "                \u001b[38;5;28;01mif\u001b[39;00m isinstance(next(iter(data.values())), (Series, dict)):\n",
      "                    data = _from_nested_dict(data)\n",
      "                \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "                    index = list(data.keys())\n",
      "                    \u001b[38;5;66;03m# error: Incompatible types in assignment (expression has type\u001b[39;00m\n",
      "                    \u001b[38;5;66;03m# \"List[Any]\", variable has type \"Dict[Any, Any]\")\u001b[39;00m\n",
      "                    data = list(data.values())  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n",
      "        \u001b[38;5;28;01melif\u001b[39;00m orient \u001b[38;5;28;01min\u001b[39;00m (\u001b[33m\"columns\"\u001b[39m, \u001b[33m\"tight\"\u001b[39m):\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "                \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\u001b[33mf\"cannot use columns parameter with orient='{orient}'\"\u001b[39m)\n",
      "        \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n",
      "            \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\n",
      "                \u001b[33mf\"Expected 'index', 'columns' or 'tight' for orient parameter. \"\u001b[39m\n",
      "                \u001b[33mf\"Got '{orient}' instead\"\u001b[39m\n",
      "            )\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m orient != \u001b[33m\"tight\"\u001b[39m:\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m cls(data, index=index, columns=columns, dtype=dtype)\n",
      "        \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "            realdata = data[\u001b[33m\"data\"\u001b[39m]\n",
      "\n",
      "            \u001b[38;5;28;01mdef\u001b[39;00m create_index(indexlist, namelist):\n",
      "                index: Index\n",
      "                \u001b[38;5;28;01mif\u001b[39;00m len(namelist) > \u001b[32m1\u001b[39m:\n",
      "                    index = MultiIndex.from_tuples(indexlist, names=namelist)\n",
      "                \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "                    index = Index(indexlist, name=namelist[\u001b[32m0\u001b[39m])\n",
      "                \u001b[38;5;28;01mreturn\u001b[39;00m index\n",
      "\n",
      "            index = create_index(data[\u001b[33m\"index\"\u001b[39m], data[\u001b[33m\"index_names\"\u001b[39m])\n",
      "            columns = create_index(data[\u001b[33m\"columns\"\u001b[39m], data[\u001b[33m\"column_names\"\u001b[39m])\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m cls(realdata, index=index, columns=columns, dtype=dtype)\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m to_numpy(\n",
      "        self,\n",
      "        dtype: npt.DTypeLike | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        copy: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "        na_value: object = lib.no_default,\n",
      "    ) -> np.ndarray:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Convert the DataFrame to a NumPy array.\u001b[39m\n",
      "\n",
      "\u001b[33m        By default, the dtype of the returned array will be the common NumPy\u001b[39m\n",
      "\u001b[33m        dtype of all types in the DataFrame. For example, if the dtypes are\u001b[39m\n",
      "\u001b[33m        ``float16`` and ``float32``, the results dtype will be ``float32``.\u001b[39m\n",
      "\u001b[33m        This may require copying data and coercing values, which may be\u001b[39m\n",
      "\u001b[33m        expensive.\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        dtype : str or numpy.dtype, optional\u001b[39m\n",
      "\u001b[33m            The dtype to pass to :meth:`numpy.asarray`.\u001b[39m\n",
      "\u001b[33m        copy : bool, default False\u001b[39m\n",
      "\u001b[33m            Whether to ensure that the returned value is not a view on\u001b[39m\n",
      "\u001b[33m            another array. Note that ``copy=False`` does not *ensure* that\u001b[39m\n",
      "\u001b[33m            ``to_numpy()`` is no-copy. Rather, ``copy=True`` ensure that\u001b[39m\n",
      "\u001b[33m            a copy is made, even if not strictly necessary.\u001b[39m\n",
      "\u001b[33m        na_value : Any, optional\u001b[39m\n",
      "\u001b[33m            The value to use for missing values. The default value depends\u001b[39m\n",
      "\u001b[33m            on `dtype` and the dtypes of the DataFrame columns.\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        numpy.ndarray\u001b[39m\n",
      "\n",
      "\u001b[33m        See Also\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        Series.to_numpy : Similar method for Series.\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        >>> pd.DataFrame({\"A\": [1, 2], \"B\": [3, 4]}).to_numpy()\u001b[39m\n",
      "\u001b[33m        array([[1, 3],\u001b[39m\n",
      "\u001b[33m               [2, 4]])\u001b[39m\n",
      "\n",
      "\u001b[33m        With heterogeneous data, the lowest common type will have to\u001b[39m\n",
      "\u001b[33m        be used.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df = pd.DataFrame({\"A\": [1, 2], \"B\": [3.0, 4.5]})\u001b[39m\n",
      "\u001b[33m        >>> df.to_numpy()\u001b[39m\n",
      "\u001b[33m        array([[1. , 3. ],\u001b[39m\n",
      "\u001b[33m               [2. , 4.5]])\u001b[39m\n",
      "\n",
      "\u001b[33m        For a mix of numeric and non-numeric types, the output array will\u001b[39m\n",
      "\u001b[33m        have object dtype.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df['C'] = pd.date_range('2000', periods=2)\u001b[39m\n",
      "\u001b[33m        >>> df.to_numpy()\u001b[39m\n",
      "\u001b[33m        array([[1, 3.0, Timestamp('2000-01-01 00:00:00')],\u001b[39m\n",
      "\u001b[33m               [2, 4.5, Timestamp('2000-01-02 00:00:00')]], dtype=object)\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "            dtype = np.dtype(dtype)\n",
      "        result = self._mgr.as_array(dtype=dtype, copy=copy, na_value=na_value)\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m result.dtype \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m dtype:\n",
      "            result = np.asarray(result, dtype=dtype)\n",
      "\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m _create_data_for_split_and_tight_to_dict(\n",
      "        self, are_all_object_dtype_cols: bool, object_dtype_indices: list[int]\n",
      "    ) -> list:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Simple helper method to create data for to ``to_dict(orient=\"split\")`` and\u001b[39m\n",
      "\u001b[33m        ``to_dict(orient=\"tight\")`` to create the main output data\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m are_all_object_dtype_cols:\n",
      "            data = [\n",
      "                list(map(maybe_box_native, t))\n",
      "                \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;28;01min\u001b[39;00m self.itertuples(index=\u001b[38;5;28;01mFalse\u001b[39;00m, name=\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "            ]\n",
      "        \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "            data = [list(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;28;01min\u001b[39;00m self.itertuples(index=\u001b[38;5;28;01mFalse\u001b[39;00m, name=\u001b[38;5;28;01mNone\u001b[39;00m)]\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m object_dtype_indices:\n",
      "                \u001b[38;5;66;03m# If we have object_dtype_cols, apply maybe_box_naive after list\u001b[39;00m\n",
      "                \u001b[38;5;66;03m# comprehension for perf\u001b[39;00m\n",
      "                \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;28;01min\u001b[39;00m data:\n",
      "                    \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;28;01min\u001b[39;00m object_dtype_indices:\n",
      "                        row[i] = maybe_box_native(row[i])\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\n",
      "    @overload\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m to_dict(\n",
      "        self,\n",
      "        orient: Literal[\u001b[33m\"dict\"\u001b[39m, \u001b[33m\"list\"\u001b[39m, \u001b[33m\"series\"\u001b[39m, \u001b[33m\"split\"\u001b[39m, \u001b[33m\"tight\"\u001b[39m, \u001b[33m\"index\"\u001b[39m] = ...,\n",
      "        *,\n",
      "        into: type[MutableMappingT] | MutableMappingT,\n",
      "        index: bool = ...,\n",
      "    ) -> MutableMappingT:\n",
      "        ...\n",
      "\n",
      "    @overload\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m to_dict(\n",
      "        self,\n",
      "        orient: Literal[\u001b[33m\"records\"\u001b[39m],\n",
      "        *,\n",
      "        into: type[MutableMappingT] | MutableMappingT,\n",
      "        index: bool = ...,\n",
      "    ) -> list[MutableMappingT]:\n",
      "        ...\n",
      "\n",
      "    @overload\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m to_dict(\n",
      "        self,\n",
      "        orient: Literal[\u001b[33m\"dict\"\u001b[39m, \u001b[33m\"list\"\u001b[39m, \u001b[33m\"series\"\u001b[39m, \u001b[33m\"split\"\u001b[39m, \u001b[33m\"tight\"\u001b[39m, \u001b[33m\"index\"\u001b[39m] = ...,\n",
      "        *,\n",
      "        into: type[dict] = ...,\n",
      "        index: bool = ...,\n",
      "    ) -> dict:\n",
      "        ...\n",
      "\n",
      "    @overload\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m to_dict(\n",
      "        self,\n",
      "        orient: Literal[\u001b[33m\"records\"\u001b[39m],\n",
      "        *,\n",
      "        into: type[dict] = ...,\n",
      "        index: bool = ...,\n",
      "    ) -> list[dict]:\n",
      "        ...\n",
      "\n",
      "    \u001b[38;5;66;03m# error: Incompatible default for argument \"into\" (default has type \"type\u001b[39;00m\n",
      "    \u001b[38;5;66;03m# [dict[Any, Any]]\", argument has type \"type[MutableMappingT] | MutableMappingT\")\u001b[39;00m\n",
      "    @deprecate_nonkeyword_arguments(\n",
      "        version=\u001b[33m\"3.0\"\u001b[39m, allowed_args=[\u001b[33m\"self\"\u001b[39m, \u001b[33m\"orient\"\u001b[39m], name=\u001b[33m\"to_dict\"\u001b[39m\n",
      "    )\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m to_dict(\n",
      "        self,\n",
      "        orient: Literal[\n",
      "            \u001b[33m\"dict\"\u001b[39m, \u001b[33m\"list\"\u001b[39m, \u001b[33m\"series\"\u001b[39m, \u001b[33m\"split\"\u001b[39m, \u001b[33m\"tight\"\u001b[39m, \u001b[33m\"records\"\u001b[39m, \u001b[33m\"index\"\u001b[39m\n",
      "        ] = \u001b[33m\"dict\"\u001b[39m,\n",
      "        into: type[MutableMappingT]\n",
      "        | MutableMappingT = dict,  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n",
      "        index: bool = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "    ) -> MutableMappingT | list[MutableMappingT]:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Convert the DataFrame to a dictionary.\u001b[39m\n",
      "\n",
      "\u001b[33m        The type of the key-value pairs can be customized with the parameters\u001b[39m\n",
      "\u001b[33m        (see below).\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        orient : str {'dict', 'list', 'series', 'split', 'tight', 'records', 'index'}\u001b[39m\n",
      "\u001b[33m            Determines the type of the values of the dictionary.\u001b[39m\n",
      "\n",
      "\u001b[33m            - 'dict' (default) : dict like {column -> {index -> value}}\u001b[39m\n",
      "\u001b[33m            - 'list' : dict like {column -> [values]}\u001b[39m\n",
      "\u001b[33m            - 'series' : dict like {column -> Series(values)}\u001b[39m\n",
      "\u001b[33m            - 'split' : dict like\u001b[39m\n",
      "\u001b[33m              {'index' -> [index], 'columns' -> [columns], 'data' -> [values]}\u001b[39m\n",
      "\u001b[33m            - 'tight' : dict like\u001b[39m\n",
      "\u001b[33m              {'index' -> [index], 'columns' -> [columns], 'data' -> [values],\u001b[39m\n",
      "\u001b[33m              'index_names' -> [index.names], 'column_names' -> [column.names]}\u001b[39m\n",
      "\u001b[33m            - 'records' : list like\u001b[39m\n",
      "\u001b[33m              [{column -> value}, ... , {column -> value}]\u001b[39m\n",
      "\u001b[33m            - 'index' : dict like {index -> {column -> value}}\u001b[39m\n",
      "\n",
      "\u001b[33m            .. versionadded:: 1.4.0\u001b[39m\n",
      "\u001b[33m                'tight' as an allowed value for the ``orient`` argument\u001b[39m\n",
      "\n",
      "\u001b[33m        into : class, default dict\u001b[39m\n",
      "\u001b[33m            The collections.abc.MutableMapping subclass used for all Mappings\u001b[39m\n",
      "\u001b[33m            in the return value.  Can be the actual class or an empty\u001b[39m\n",
      "\u001b[33m            instance of the mapping type you want.  If you want a\u001b[39m\n",
      "\u001b[33m            collections.defaultdict, you must pass it initialized.\u001b[39m\n",
      "\n",
      "\u001b[33m        index : bool, default True\u001b[39m\n",
      "\u001b[33m            Whether to include the index item (and index_names item if `orient`\u001b[39m\n",
      "\u001b[33m            is 'tight') in the returned dictionary. Can only be ``False``\u001b[39m\n",
      "\u001b[33m            when `orient` is 'split' or 'tight'.\u001b[39m\n",
      "\n",
      "\u001b[33m            .. versionadded:: 2.0.0\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        dict, list or collections.abc.MutableMapping\u001b[39m\n",
      "\u001b[33m            Return a collections.abc.MutableMapping object representing the\u001b[39m\n",
      "\u001b[33m            DataFrame. The resulting transformation depends on the `orient`\u001b[39m\n",
      "\u001b[33m            parameter.\u001b[39m\n",
      "\n",
      "\u001b[33m        See Also\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        DataFrame.from_dict: Create a DataFrame from a dictionary.\u001b[39m\n",
      "\u001b[33m        DataFrame.to_json: Convert a DataFrame to JSON format.\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        >>> df = pd.DataFrame({'col1': [1, 2],\u001b[39m\n",
      "\u001b[33m        ...                    'col2': [0.5, 0.75]},\u001b[39m\n",
      "\u001b[33m        ...                   index=['row1', 'row2'])\u001b[39m\n",
      "\u001b[33m        >>> df\u001b[39m\n",
      "\u001b[33m              col1  col2\u001b[39m\n",
      "\u001b[33m        row1     1  0.50\u001b[39m\n",
      "\u001b[33m        row2     2  0.75\u001b[39m\n",
      "\u001b[33m        >>> df.to_dict()\u001b[39m\n",
      "\u001b[33m        {'col1': {'row1': 1, 'row2': 2}, 'col2': {'row1': 0.5, 'row2': 0.75}}\u001b[39m\n",
      "\n",
      "\u001b[33m        You can specify the return orientation.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.to_dict('series')\u001b[39m\n",
      "\u001b[33m        {'col1': row1    1\u001b[39m\n",
      "\u001b[33m                 row2    2\u001b[39m\n",
      "\u001b[33m        Name: col1, dtype: int64,\u001b[39m\n",
      "\u001b[33m        'col2': row1    0.50\u001b[39m\n",
      "\u001b[33m                row2    0.75\u001b[39m\n",
      "\u001b[33m        Name: col2, dtype: float64}\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.to_dict('split')\u001b[39m\n",
      "\u001b[33m        {'index': ['row1', 'row2'], 'columns': ['col1', 'col2'],\u001b[39m\n",
      "\u001b[33m         'data': [[1, 0.5], [2, 0.75]]}\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.to_dict('records')\u001b[39m\n",
      "\u001b[33m        [{'col1': 1, 'col2': 0.5}, {'col1': 2, 'col2': 0.75}]\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.to_dict('index')\u001b[39m\n",
      "\u001b[33m        {'row1': {'col1': 1, 'col2': 0.5}, 'row2': {'col1': 2, 'col2': 0.75}}\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.to_dict('tight')\u001b[39m\n",
      "\u001b[33m        {'index': ['row1', 'row2'], 'columns': ['col1', 'col2'],\u001b[39m\n",
      "\u001b[33m         'data': [[1, 0.5], [2, 0.75]], 'index_names': [None], 'column_names': [None]}\u001b[39m\n",
      "\n",
      "\u001b[33m        You can also specify the mapping type.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> from collections import OrderedDict, defaultdict\u001b[39m\n",
      "\u001b[33m        >>> df.to_dict(into=OrderedDict)\u001b[39m\n",
      "\u001b[33m        OrderedDict([('col1', OrderedDict([('row1', 1), ('row2', 2)])),\u001b[39m\n",
      "\u001b[33m                     ('col2', OrderedDict([('row1', 0.5), ('row2', 0.75)]))])\u001b[39m\n",
      "\n",
      "\u001b[33m        If you want a `defaultdict`, you need to initialize it:\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> dd = defaultdict(list)\u001b[39m\n",
      "\u001b[33m        >>> df.to_dict('records', into=dd)\u001b[39m\n",
      "\u001b[33m        [defaultdict(<class 'list'>, {'col1': 1, 'col2': 0.5}),\u001b[39m\n",
      "\u001b[33m         defaultdict(<class 'list'>, {'col1': 2, 'col2': 0.75})]\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;28;01mfrom\u001b[39;00m pandas.core.methods.to_dict \u001b[38;5;28;01mimport\u001b[39;00m to_dict\n",
      "\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m to_dict(self, orient, into=into, index=index)\n",
      "\n",
      "    @deprecate_nonkeyword_arguments(\n",
      "        version=\u001b[33m\"3.0\"\u001b[39m, allowed_args=[\u001b[33m\"self\"\u001b[39m, \u001b[33m\"destination_table\"\u001b[39m], name=\u001b[33m\"to_gbq\"\u001b[39m\n",
      "    )\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m to_gbq(\n",
      "        self,\n",
      "        destination_table: str,\n",
      "        project_id: str | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        chunksize: int | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        reauth: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "        if_exists: ToGbqIfexist = \u001b[33m\"fail\"\u001b[39m,\n",
      "        auth_local_webserver: bool = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "        table_schema: list[dict[str, str]] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        location: str | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        progress_bar: bool = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "        credentials=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Write a DataFrame to a Google BigQuery table.\u001b[39m\n",
      "\n",
      "\u001b[33m        .. deprecated:: 2.2.0\u001b[39m\n",
      "\n",
      "\u001b[33m           Please use ``pandas_gbq.to_gbq`` instead.\u001b[39m\n",
      "\n",
      "\u001b[33m        This function requires the `pandas-gbq package\u001b[39m\n",
      "\u001b[33m        <https://pandas-gbq.readthedocs.io>`__.\u001b[39m\n",
      "\n",
      "\u001b[33m        See the `How to authenticate with Google BigQuery\u001b[39m\n",
      "\u001b[33m        <https://pandas-gbq.readthedocs.io/en/latest/howto/authentication.html>`__\u001b[39m\n",
      "\u001b[33m        guide for authentication instructions.\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        destination_table : str\u001b[39m\n",
      "\u001b[33m            Name of table to be written, in the form ``dataset.tablename``.\u001b[39m\n",
      "\u001b[33m        project_id : str, optional\u001b[39m\n",
      "\u001b[33m            Google BigQuery Account project ID. Optional when available from\u001b[39m\n",
      "\u001b[33m            the environment.\u001b[39m\n",
      "\u001b[33m        chunksize : int, optional\u001b[39m\n",
      "\u001b[33m            Number of rows to be inserted in each chunk from the dataframe.\u001b[39m\n",
      "\u001b[33m            Set to ``None`` to load the whole dataframe at once.\u001b[39m\n",
      "\u001b[33m        reauth : bool, default False\u001b[39m\n",
      "\u001b[33m            Force Google BigQuery to re-authenticate the user. This is useful\u001b[39m\n",
      "\u001b[33m            if multiple accounts are used.\u001b[39m\n",
      "\u001b[33m        if_exists : str, default 'fail'\u001b[39m\n",
      "\u001b[33m            Behavior when the destination table exists. Value can be one of:\u001b[39m\n",
      "\n",
      "\u001b[33m            ``'fail'``\u001b[39m\n",
      "\u001b[33m                If table exists raise pandas_gbq.gbq.TableCreationError.\u001b[39m\n",
      "\u001b[33m            ``'replace'``\u001b[39m\n",
      "\u001b[33m                If table exists, drop it, recreate it, and insert data.\u001b[39m\n",
      "\u001b[33m            ``'append'``\u001b[39m\n",
      "\u001b[33m                If table exists, insert data. Create if does not exist.\u001b[39m\n",
      "\u001b[33m        auth_local_webserver : bool, default True\u001b[39m\n",
      "\u001b[33m            Use the `local webserver flow`_ instead of the `console flow`_\u001b[39m\n",
      "\u001b[33m            when getting user credentials.\u001b[39m\n",
      "\n",
      "\u001b[33m            .. _local webserver flow:\u001b[39m\n",
      "\u001b[33m                https://google-auth-oauthlib.readthedocs.io/en/latest/reference/google_auth_oauthlib.flow.html#google_auth_oauthlib.flow.InstalledAppFlow.run_local_server\u001b[39m\n",
      "\u001b[33m            .. _console flow:\u001b[39m\n",
      "\u001b[33m                https://google-auth-oauthlib.readthedocs.io/en/latest/reference/google_auth_oauthlib.flow.html#google_auth_oauthlib.flow.InstalledAppFlow.run_console\u001b[39m\n",
      "\n",
      "\u001b[33m            *New in version 0.2.0 of pandas-gbq*.\u001b[39m\n",
      "\n",
      "\u001b[33m            .. versionchanged:: 1.5.0\u001b[39m\n",
      "\u001b[33m               Default value is changed to ``True``. Google has deprecated the\u001b[39m\n",
      "\u001b[33m               ``auth_local_webserver = False`` `\"out of band\" (copy-paste)\u001b[39m\n",
      "\u001b[33m               flow\u001b[39m\n",
      "\u001b[33m               <https://developers.googleblog.com/2022/02/making-oauth-flows-safer.html?m=1#disallowed-oob>`_.\u001b[39m\n",
      "\u001b[33m        table_schema : list of dicts, optional\u001b[39m\n",
      "\u001b[33m            List of BigQuery table fields to which according DataFrame\u001b[39m\n",
      "\u001b[33m            columns conform to, e.g. ``[{'name': 'col1', 'type':\u001b[39m\n",
      "\u001b[33m            'STRING'},...]``. If schema is not provided, it will be\u001b[39m\n",
      "\u001b[33m            generated according to dtypes of DataFrame columns. See\u001b[39m\n",
      "\u001b[33m            BigQuery API documentation on available names of a field.\u001b[39m\n",
      "\n",
      "\u001b[33m            *New in version 0.3.1 of pandas-gbq*.\u001b[39m\n",
      "\u001b[33m        location : str, optional\u001b[39m\n",
      "\u001b[33m            Location where the load job should run. See the `BigQuery locations\u001b[39m\n",
      "\u001b[33m            documentation\u001b[39m\n",
      "\u001b[33m            <https://cloud.google.com/bigquery/docs/dataset-locations>`__ for a\u001b[39m\n",
      "\u001b[33m            list of available locations. The location must match that of the\u001b[39m\n",
      "\u001b[33m            target dataset.\u001b[39m\n",
      "\n",
      "\u001b[33m            *New in version 0.5.0 of pandas-gbq*.\u001b[39m\n",
      "\u001b[33m        progress_bar : bool, default True\u001b[39m\n",
      "\u001b[33m            Use the library `tqdm` to show the progress bar for the upload,\u001b[39m\n",
      "\u001b[33m            chunk by chunk.\u001b[39m\n",
      "\n",
      "\u001b[33m            *New in version 0.5.0 of pandas-gbq*.\u001b[39m\n",
      "\u001b[33m        credentials : google.auth.credentials.Credentials, optional\u001b[39m\n",
      "\u001b[33m            Credentials for accessing Google APIs. Use this parameter to\u001b[39m\n",
      "\u001b[33m            override default credentials, such as to use Compute Engine\u001b[39m\n",
      "\u001b[33m            :class:`google.auth.compute_engine.Credentials` or Service\u001b[39m\n",
      "\u001b[33m            Account :class:`google.oauth2.service_account.Credentials`\u001b[39m\n",
      "\u001b[33m            directly.\u001b[39m\n",
      "\n",
      "\u001b[33m            *New in version 0.8.0 of pandas-gbq*.\u001b[39m\n",
      "\n",
      "\u001b[33m        See Also\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        pandas_gbq.to_gbq : This function in the pandas-gbq library.\u001b[39m\n",
      "\u001b[33m        read_gbq : Read a DataFrame from Google BigQuery.\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        Example taken from `Google BigQuery documentation\u001b[39m\n",
      "\u001b[33m        <https://cloud.google.com/bigquery/docs/samples/bigquery-pandas-gbq-to-gbq-simple>`_\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> project_id = \"my-project\"\u001b[39m\n",
      "\u001b[33m        >>> table_id = 'my_dataset.my_table'\u001b[39m\n",
      "\u001b[33m        >>> df = pd.DataFrame({\u001b[39m\n",
      "\u001b[33m        ...                   \"my_string\": [\"a\", \"b\", \"c\"],\u001b[39m\n",
      "\u001b[33m        ...                   \"my_int64\": [1, 2, 3],\u001b[39m\n",
      "\u001b[33m        ...                   \"my_float64\": [4.0, 5.0, 6.0],\u001b[39m\n",
      "\u001b[33m        ...                   \"my_bool1\": [True, False, True],\u001b[39m\n",
      "\u001b[33m        ...                   \"my_bool2\": [False, True, False],\u001b[39m\n",
      "\u001b[33m        ...                   \"my_dates\": pd.date_range(\"now\", periods=3),\u001b[39m\n",
      "\u001b[33m        ...                   }\u001b[39m\n",
      "\u001b[33m        ...                   )\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.to_gbq(table_id, project_id=project_id)  # doctest: +SKIP\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;28;01mfrom\u001b[39;00m pandas.io \u001b[38;5;28;01mimport\u001b[39;00m gbq\n",
      "\n",
      "        gbq.to_gbq(\n",
      "            self,\n",
      "            destination_table,\n",
      "            project_id=project_id,\n",
      "            chunksize=chunksize,\n",
      "            reauth=reauth,\n",
      "            if_exists=if_exists,\n",
      "            auth_local_webserver=auth_local_webserver,\n",
      "            table_schema=table_schema,\n",
      "            location=location,\n",
      "            progress_bar=progress_bar,\n",
      "            credentials=credentials,\n",
      "        )\n",
      "\n",
      "    @classmethod\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m from_records(\n",
      "        cls,\n",
      "        data,\n",
      "        index=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        exclude=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        columns=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        coerce_float: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "        nrows: int | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    ) -> DataFrame:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Convert structured or record ndarray to DataFrame.\u001b[39m\n",
      "\n",
      "\u001b[33m        Creates a DataFrame object from a structured ndarray, sequence of\u001b[39m\n",
      "\u001b[33m        tuples or dicts, or DataFrame.\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        data : structured ndarray, sequence of tuples or dicts, or DataFrame\u001b[39m\n",
      "\u001b[33m            Structured input data.\u001b[39m\n",
      "\n",
      "\u001b[33m            .. deprecated:: 2.1.0\u001b[39m\n",
      "\u001b[33m                Passing a DataFrame is deprecated.\u001b[39m\n",
      "\u001b[33m        index : str, list of fields, array-like\u001b[39m\n",
      "\u001b[33m            Field of array to use as the index, alternately a specific set of\u001b[39m\n",
      "\u001b[33m            input labels to use.\u001b[39m\n",
      "\u001b[33m        exclude : sequence, default None\u001b[39m\n",
      "\u001b[33m            Columns or fields to exclude.\u001b[39m\n",
      "\u001b[33m        columns : sequence, default None\u001b[39m\n",
      "\u001b[33m            Column names to use. If the passed data do not have names\u001b[39m\n",
      "\u001b[33m            associated with them, this argument provides names for the\u001b[39m\n",
      "\u001b[33m            columns. Otherwise this argument indicates the order of the columns\u001b[39m\n",
      "\u001b[33m            in the result (any names not found in the data will become all-NA\u001b[39m\n",
      "\u001b[33m            columns).\u001b[39m\n",
      "\u001b[33m        coerce_float : bool, default False\u001b[39m\n",
      "\u001b[33m            Attempt to convert values of non-string, non-numeric objects (like\u001b[39m\n",
      "\u001b[33m            decimal.Decimal) to floating point, useful for SQL result sets.\u001b[39m\n",
      "\u001b[33m        nrows : int, default None\u001b[39m\n",
      "\u001b[33m            Number of rows to read if data is an iterator.\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        DataFrame\u001b[39m\n",
      "\n",
      "\u001b[33m        See Also\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        DataFrame.from_dict : DataFrame from dict of array-like or dicts.\u001b[39m\n",
      "\u001b[33m        DataFrame : DataFrame object creation using constructor.\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        Data can be provided as a structured ndarray:\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> data = np.array([(3, 'a'), (2, 'b'), (1, 'c'), (0, 'd')],\u001b[39m\n",
      "\u001b[33m        ...                 dtype=[('col_1', 'i4'), ('col_2', 'U1')])\u001b[39m\n",
      "\u001b[33m        >>> pd.DataFrame.from_records(data)\u001b[39m\n",
      "\u001b[33m           col_1 col_2\u001b[39m\n",
      "\u001b[33m        0      3     a\u001b[39m\n",
      "\u001b[33m        1      2     b\u001b[39m\n",
      "\u001b[33m        2      1     c\u001b[39m\n",
      "\u001b[33m        3      0     d\u001b[39m\n",
      "\n",
      "\u001b[33m        Data can be provided as a list of dicts:\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> data = [{'col_1': 3, 'col_2': 'a'},\u001b[39m\n",
      "\u001b[33m        ...         {'col_1': 2, 'col_2': 'b'},\u001b[39m\n",
      "\u001b[33m        ...         {'col_1': 1, 'col_2': 'c'},\u001b[39m\n",
      "\u001b[33m        ...         {'col_1': 0, 'col_2': 'd'}]\u001b[39m\n",
      "\u001b[33m        >>> pd.DataFrame.from_records(data)\u001b[39m\n",
      "\u001b[33m           col_1 col_2\u001b[39m\n",
      "\u001b[33m        0      3     a\u001b[39m\n",
      "\u001b[33m        1      2     b\u001b[39m\n",
      "\u001b[33m        2      1     c\u001b[39m\n",
      "\u001b[33m        3      0     d\u001b[39m\n",
      "\n",
      "\u001b[33m        Data can be provided as a list of tuples with corresponding columns:\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> data = [(3, 'a'), (2, 'b'), (1, 'c'), (0, 'd')]\u001b[39m\n",
      "\u001b[33m        >>> pd.DataFrame.from_records(data, columns=['col_1', 'col_2'])\u001b[39m\n",
      "\u001b[33m           col_1 col_2\u001b[39m\n",
      "\u001b[33m        0      3     a\u001b[39m\n",
      "\u001b[33m        1      2     b\u001b[39m\n",
      "\u001b[33m        2      1     c\u001b[39m\n",
      "\u001b[33m        3      0     d\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m isinstance(data, DataFrame):\n",
      "            warnings.warn(\n",
      "                \u001b[33m\"Passing a DataFrame to DataFrame.from_records is deprecated. Use \"\u001b[39m\n",
      "                \u001b[33m\"set_index and/or drop to modify the DataFrame instead.\"\u001b[39m,\n",
      "                FutureWarning,\n",
      "                stacklevel=find_stack_level(),\n",
      "            )\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "                \u001b[38;5;28;01mif\u001b[39;00m is_scalar(columns):\n",
      "                    columns = [columns]\n",
      "                data = data[columns]\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "                data = data.set_index(index)\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m exclude \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "                data = data.drop(columns=exclude)\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m data.copy(deep=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\n",
      "        result_index = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\n",
      "        \u001b[38;5;66;03m# Make a copy of the input columns so we can modify it\u001b[39;00m\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "            columns = ensure_index(columns)\n",
      "\n",
      "        \u001b[38;5;28;01mdef\u001b[39;00m maybe_reorder(\n",
      "            arrays: list[ArrayLike], arr_columns: Index, columns: Index, index\n",
      "        ) -> tuple[list[ArrayLike], Index, Index | \u001b[38;5;28;01mNone\u001b[39;00m]:\n",
      "            \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m            If our desired 'columns' do not match the data's pre-existing 'arr_columns',\u001b[39m\n",
      "\u001b[33m            we re-order our arrays.  This is like a pre-emptive (cheap) reindex.\u001b[39m\n",
      "\u001b[33m            \"\"\"\u001b[39m\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m len(arrays):\n",
      "                length = len(arrays[\u001b[32m0\u001b[39m])\n",
      "            \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "                length = \u001b[32m0\u001b[39m\n",
      "\n",
      "            result_index = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m len(arrays) == \u001b[32m0\u001b[39m \u001b[38;5;28;01mand\u001b[39;00m index \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mand\u001b[39;00m length == \u001b[32m0\u001b[39m:\n",
      "                result_index = default_index(\u001b[32m0\u001b[39m)\n",
      "\n",
      "            arrays, arr_columns = reorder_arrays(arrays, arr_columns, columns, length)\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m arrays, arr_columns, result_index\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m is_iterator(data):\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m nrows == \u001b[32m0\u001b[39m:\n",
      "                \u001b[38;5;28;01mreturn\u001b[39;00m cls()\n",
      "\n",
      "            \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "                first_row = next(data)\n",
      "            \u001b[38;5;28;01mexcept\u001b[39;00m StopIteration:\n",
      "                \u001b[38;5;28;01mreturn\u001b[39;00m cls(index=index, columns=columns)\n",
      "\n",
      "            dtype = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m hasattr(first_row, \u001b[33m\"dtype\"\u001b[39m) \u001b[38;5;28;01mand\u001b[39;00m first_row.dtype.names:\n",
      "                dtype = first_row.dtype\n",
      "\n",
      "            values = [first_row]\n",
      "\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m nrows \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "                values += data\n",
      "            \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "                values.extend(itertools.islice(data, nrows - \u001b[32m1\u001b[39m))\n",
      "\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "                data = np.array(values, dtype=dtype)\n",
      "            \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "                data = values\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m isinstance(data, dict):\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "                columns = arr_columns = ensure_index(sorted(data))\n",
      "                arrays = [data[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;28;01min\u001b[39;00m columns]\n",
      "            \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "                arrays = []\n",
      "                arr_columns_list = []\n",
      "                \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;28;01min\u001b[39;00m data.items():\n",
      "                    \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;28;01min\u001b[39;00m columns:\n",
      "                        arr_columns_list.append(k)\n",
      "                        arrays.append(v)\n",
      "\n",
      "                arr_columns = Index(arr_columns_list)\n",
      "                arrays, arr_columns, result_index = maybe_reorder(\n",
      "                    arrays, arr_columns, columns, index\n",
      "                )\n",
      "\n",
      "        \u001b[38;5;28;01melif\u001b[39;00m isinstance(data, np.ndarray):\n",
      "            arrays, columns = to_arrays(data, columns)\n",
      "            arr_columns = columns\n",
      "        \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "            arrays, arr_columns = to_arrays(data, columns)\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m coerce_float:\n",
      "                \u001b[38;5;28;01mfor\u001b[39;00m i, arr \u001b[38;5;28;01min\u001b[39;00m enumerate(arrays):\n",
      "                    \u001b[38;5;28;01mif\u001b[39;00m arr.dtype == object:\n",
      "                        \u001b[38;5;66;03m# error: Argument 1 to \"maybe_convert_objects\" has\u001b[39;00m\n",
      "                        \u001b[38;5;66;03m# incompatible type \"Union[ExtensionArray, ndarray]\";\u001b[39;00m\n",
      "                        \u001b[38;5;66;03m# expected \"ndarray\"\u001b[39;00m\n",
      "                        arrays[i] = lib.maybe_convert_objects(\n",
      "                            arr,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "                            try_float=\u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "                        )\n",
      "\n",
      "            arr_columns = ensure_index(arr_columns)\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "                columns = arr_columns\n",
      "            \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "                arrays, arr_columns, result_index = maybe_reorder(\n",
      "                    arrays, arr_columns, columns, index\n",
      "                )\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m exclude \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "            exclude = set()\n",
      "        \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "            exclude = set(exclude)\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m isinstance(index, str) \u001b[38;5;28;01mor\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m hasattr(index, \u001b[33m\"__iter__\"\u001b[39m):\n",
      "                i = columns.get_loc(index)\n",
      "                exclude.add(index)\n",
      "                \u001b[38;5;28;01mif\u001b[39;00m len(arrays) > \u001b[32m0\u001b[39m:\n",
      "                    result_index = Index(arrays[i], name=index)\n",
      "                \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "                    result_index = Index([], name=index)\n",
      "            \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "                \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "                    index_data = [arrays[arr_columns.get_loc(field)] \u001b[38;5;28;01mfor\u001b[39;00m field \u001b[38;5;28;01min\u001b[39;00m index]\n",
      "                \u001b[38;5;28;01mexcept\u001b[39;00m (KeyError, TypeError):\n",
      "                    \u001b[38;5;66;03m# raised by get_loc, see GH#29258\u001b[39;00m\n",
      "                    result_index = index\n",
      "                \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "                    result_index = ensure_index_from_sequences(index_data, names=index)\n",
      "                    exclude.update(index)\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m any(exclude):\n",
      "            arr_exclude = [x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;28;01min\u001b[39;00m exclude \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;28;01min\u001b[39;00m arr_columns]\n",
      "            to_remove = [arr_columns.get_loc(col) \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;28;01min\u001b[39;00m arr_exclude]\n",
      "            arrays = [v \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;28;01min\u001b[39;00m enumerate(arrays) \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01min\u001b[39;00m to_remove]\n",
      "\n",
      "            columns = columns.drop(exclude)\n",
      "\n",
      "        manager = _get_option(\u001b[33m\"mode.data_manager\"\u001b[39m, silent=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "        mgr = arrays_to_mgr(arrays, columns, result_index, typ=manager)\n",
      "\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m cls._from_mgr(mgr, axes=mgr.axes)\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m to_records(\n",
      "        self, index: bool = \u001b[38;5;28;01mTrue\u001b[39;00m, column_dtypes=\u001b[38;5;28;01mNone\u001b[39;00m, index_dtypes=\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "    ) -> np.rec.recarray:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Convert DataFrame to a NumPy record array.\u001b[39m\n",
      "\n",
      "\u001b[33m        Index will be included as the first field of the record array if\u001b[39m\n",
      "\u001b[33m        requested.\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        index : bool, default True\u001b[39m\n",
      "\u001b[33m            Include index in resulting record array, stored in 'index'\u001b[39m\n",
      "\u001b[33m            field or using the index label, if set.\u001b[39m\n",
      "\u001b[33m        column_dtypes : str, type, dict, default None\u001b[39m\n",
      "\u001b[33m            If a string or type, the data type to store all columns. If\u001b[39m\n",
      "\u001b[33m            a dictionary, a mapping of column names and indices (zero-indexed)\u001b[39m\n",
      "\u001b[33m            to specific data types.\u001b[39m\n",
      "\u001b[33m        index_dtypes : str, type, dict, default None\u001b[39m\n",
      "\u001b[33m            If a string or type, the data type to store all index levels. If\u001b[39m\n",
      "\u001b[33m            a dictionary, a mapping of index level names and indices\u001b[39m\n",
      "\u001b[33m            (zero-indexed) to specific data types.\u001b[39m\n",
      "\n",
      "\u001b[33m            This mapping is applied only if `index=True`.\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        numpy.rec.recarray\u001b[39m\n",
      "\u001b[33m            NumPy ndarray with the DataFrame labels as fields and each row\u001b[39m\n",
      "\u001b[33m            of the DataFrame as entries.\u001b[39m\n",
      "\n",
      "\u001b[33m        See Also\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        DataFrame.from_records: Convert structured or record ndarray\u001b[39m\n",
      "\u001b[33m            to DataFrame.\u001b[39m\n",
      "\u001b[33m        numpy.rec.recarray: An ndarray that allows field access using\u001b[39m\n",
      "\u001b[33m            attributes, analogous to typed columns in a\u001b[39m\n",
      "\u001b[33m            spreadsheet.\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        >>> df = pd.DataFrame({'A': [1, 2], 'B': [0.5, 0.75]},\u001b[39m\n",
      "\u001b[33m        ...                   index=['a', 'b'])\u001b[39m\n",
      "\u001b[33m        >>> df\u001b[39m\n",
      "\u001b[33m           A     B\u001b[39m\n",
      "\u001b[33m        a  1  0.50\u001b[39m\n",
      "\u001b[33m        b  2  0.75\u001b[39m\n",
      "\u001b[33m        >>> df.to_records()\u001b[39m\n",
      "\u001b[33m        rec.array([('a', 1, 0.5 ), ('b', 2, 0.75)],\u001b[39m\n",
      "\u001b[33m                  dtype=[('index', 'O'), ('A', '<i8'), ('B', '<f8')])\u001b[39m\n",
      "\n",
      "\u001b[33m        If the DataFrame index has no label then the recarray field name\u001b[39m\n",
      "\u001b[33m        is set to 'index'. If the index has a label then this is used as the\u001b[39m\n",
      "\u001b[33m        field name:\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.index = df.index.rename(\"I\")\u001b[39m\n",
      "\u001b[33m        >>> df.to_records()\u001b[39m\n",
      "\u001b[33m        rec.array([('a', 1, 0.5 ), ('b', 2, 0.75)],\u001b[39m\n",
      "\u001b[33m                  dtype=[('I', 'O'), ('A', '<i8'), ('B', '<f8')])\u001b[39m\n",
      "\n",
      "\u001b[33m        The index can be excluded from the record array:\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.to_records(index=False)\u001b[39m\n",
      "\u001b[33m        rec.array([(1, 0.5 ), (2, 0.75)],\u001b[39m\n",
      "\u001b[33m                  dtype=[('A', '<i8'), ('B', '<f8')])\u001b[39m\n",
      "\n",
      "\u001b[33m        Data types can be specified for the columns:\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.to_records(column_dtypes={\"A\": \"int32\"})\u001b[39m\n",
      "\u001b[33m        rec.array([('a', 1, 0.5 ), ('b', 2, 0.75)],\u001b[39m\n",
      "\u001b[33m                  dtype=[('I', 'O'), ('A', '<i4'), ('B', '<f8')])\u001b[39m\n",
      "\n",
      "\u001b[33m        As well as for the index:\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.to_records(index_dtypes=\"<S2\")\u001b[39m\n",
      "\u001b[33m        rec.array([(b'a', 1, 0.5 ), (b'b', 2, 0.75)],\u001b[39m\n",
      "\u001b[33m                  dtype=[('I', 'S2'), ('A', '<i8'), ('B', '<f8')])\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> index_dtypes = f\"<S{df.index.str.len().max()}\"\u001b[39m\n",
      "\u001b[33m        >>> df.to_records(index_dtypes=index_dtypes)\u001b[39m\n",
      "\u001b[33m        rec.array([(b'a', 1, 0.5 ), (b'b', 2, 0.75)],\u001b[39m\n",
      "\u001b[33m                  dtype=[('I', 'S1'), ('A', '<i8'), ('B', '<f8')])\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m index:\n",
      "            ix_vals = [\n",
      "                np.asarray(self.index.get_level_values(i))\n",
      "                \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;28;01min\u001b[39;00m range(self.index.nlevels)\n",
      "            ]\n",
      "\n",
      "            arrays = ix_vals + [\n",
      "                np.asarray(self.iloc[:, i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;28;01min\u001b[39;00m range(len(self.columns))\n",
      "            ]\n",
      "\n",
      "            index_names = list(self.index.names)\n",
      "\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m isinstance(self.index, MultiIndex):\n",
      "                index_names = com.fill_missing_names(index_names)\n",
      "            \u001b[38;5;28;01melif\u001b[39;00m index_names[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "                index_names = [\u001b[33m\"index\"\u001b[39m]\n",
      "\n",
      "            names = [str(name) \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;28;01min\u001b[39;00m itertools.chain(index_names, self.columns)]\n",
      "        \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "            arrays = [np.asarray(self.iloc[:, i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;28;01min\u001b[39;00m range(len(self.columns))]\n",
      "            names = [str(c) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;28;01min\u001b[39;00m self.columns]\n",
      "            index_names = []\n",
      "\n",
      "        index_len = len(index_names)\n",
      "        formats = []\n",
      "\n",
      "        \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;28;01min\u001b[39;00m enumerate(arrays):\n",
      "            index_int = i\n",
      "\n",
      "            \u001b[38;5;66;03m# When the names and arrays are collected, we\u001b[39;00m\n",
      "            \u001b[38;5;66;03m# first collect those in the DataFrame's index,\u001b[39;00m\n",
      "            \u001b[38;5;66;03m# followed by those in its columns.\u001b[39;00m\n",
      "            \u001b[38;5;66;03m#\u001b[39;00m\n",
      "            \u001b[38;5;66;03m# Thus, the total length of the array is:\u001b[39;00m\n",
      "            \u001b[38;5;66;03m# len(index_names) + len(DataFrame.columns).\u001b[39;00m\n",
      "            \u001b[38;5;66;03m#\u001b[39;00m\n",
      "            \u001b[38;5;66;03m# This check allows us to see whether we are\u001b[39;00m\n",
      "            \u001b[38;5;66;03m# handling a name / array in the index or column.\u001b[39;00m\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m index_int < index_len:\n",
      "                dtype_mapping = index_dtypes\n",
      "                name = index_names[index_int]\n",
      "            \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "                index_int -= index_len\n",
      "                dtype_mapping = column_dtypes\n",
      "                name = self.columns[index_int]\n",
      "\n",
      "            \u001b[38;5;66;03m# We have a dictionary, so we get the data type\u001b[39;00m\n",
      "            \u001b[38;5;66;03m# associated with the index or column (which can\u001b[39;00m\n",
      "            \u001b[38;5;66;03m# be denoted by its name in the DataFrame or its\u001b[39;00m\n",
      "            \u001b[38;5;66;03m# position in DataFrame's array of indices or\u001b[39;00m\n",
      "            \u001b[38;5;66;03m# columns, whichever is applicable.\u001b[39;00m\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m is_dict_like(dtype_mapping):\n",
      "                \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;28;01min\u001b[39;00m dtype_mapping:\n",
      "                    dtype_mapping = dtype_mapping[name]\n",
      "                \u001b[38;5;28;01melif\u001b[39;00m index_int \u001b[38;5;28;01min\u001b[39;00m dtype_mapping:\n",
      "                    dtype_mapping = dtype_mapping[index_int]\n",
      "                \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "                    dtype_mapping = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\n",
      "            \u001b[38;5;66;03m# If no mapping can be found, use the array's\u001b[39;00m\n",
      "            \u001b[38;5;66;03m# dtype attribute for formatting.\u001b[39;00m\n",
      "            \u001b[38;5;66;03m#\u001b[39;00m\n",
      "            \u001b[38;5;66;03m# A valid dtype must either be a type or\u001b[39;00m\n",
      "            \u001b[38;5;66;03m# string naming a type.\u001b[39;00m\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m dtype_mapping \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "                formats.append(v.dtype)\n",
      "            \u001b[38;5;28;01melif\u001b[39;00m isinstance(dtype_mapping, (type, np.dtype, str)):\n",
      "                \u001b[38;5;66;03m# error: Argument 1 to \"append\" of \"list\" has incompatible\u001b[39;00m\n",
      "                \u001b[38;5;66;03m# type \"Union[type, dtype[Any], str]\"; expected \"dtype[Any]\"\u001b[39;00m\n",
      "                formats.append(dtype_mapping)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "            \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "                element = \u001b[33m\"row\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i < index_len \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"column\"\u001b[39m\n",
      "                msg = \u001b[33mf\"Invalid dtype {dtype_mapping} specified for {element} {name}\"\u001b[39m\n",
      "                \u001b[38;5;28;01mraise\u001b[39;00m ValueError(msg)\n",
      "\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m np.rec.fromarrays(arrays, dtype={\u001b[33m\"names\"\u001b[39m: names, \u001b[33m\"formats\"\u001b[39m: formats})\n",
      "\n",
      "    @classmethod\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m _from_arrays(\n",
      "        cls,\n",
      "        arrays,\n",
      "        columns,\n",
      "        index,\n",
      "        dtype: Dtype | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        verify_integrity: bool = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "    ) -> Self:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Create DataFrame from a list of arrays corresponding to the columns.\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        arrays : list-like of arrays\u001b[39m\n",
      "\u001b[33m            Each array in the list corresponds to one column, in order.\u001b[39m\n",
      "\u001b[33m        columns : list-like, Index\u001b[39m\n",
      "\u001b[33m            The column names for the resulting DataFrame.\u001b[39m\n",
      "\u001b[33m        index : list-like, Index\u001b[39m\n",
      "\u001b[33m            The rows labels for the resulting DataFrame.\u001b[39m\n",
      "\u001b[33m        dtype : dtype, optional\u001b[39m\n",
      "\u001b[33m            Optional dtype to enforce for all arrays.\u001b[39m\n",
      "\u001b[33m        verify_integrity : bool, default True\u001b[39m\n",
      "\u001b[33m            Validate and homogenize all input. If set to False, it is assumed\u001b[39m\n",
      "\u001b[33m            that all elements of `arrays` are actual arrays how they will be\u001b[39m\n",
      "\u001b[33m            stored in a block (numpy ndarray or ExtensionArray), have the same\u001b[39m\n",
      "\u001b[33m            length as and are aligned with the index, and that `columns` and\u001b[39m\n",
      "\u001b[33m            `index` are ensured to be an Index object.\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        DataFrame\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "            dtype = pandas_dtype(dtype)\n",
      "\n",
      "        manager = _get_option(\u001b[33m\"mode.data_manager\"\u001b[39m, silent=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "        columns = ensure_index(columns)\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m len(columns) != len(arrays):\n",
      "            \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\u001b[33m\"len(columns) must match len(arrays)\"\u001b[39m)\n",
      "        mgr = arrays_to_mgr(\n",
      "            arrays,\n",
      "            columns,\n",
      "            index,\n",
      "            dtype=dtype,\n",
      "            verify_integrity=verify_integrity,\n",
      "            typ=manager,\n",
      "        )\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m cls._from_mgr(mgr, axes=mgr.axes)\n",
      "\n",
      "    @doc(\n",
      "        storage_options=_shared_docs[\u001b[33m\"storage_options\"\u001b[39m],\n",
      "        compression_options=_shared_docs[\u001b[33m\"compression_options\"\u001b[39m] % \u001b[33m\"path\"\u001b[39m,\n",
      "    )\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m to_stata(\n",
      "        self,\n",
      "        path: FilePath | WriteBuffer[bytes],\n",
      "        *,\n",
      "        convert_dates: dict[Hashable, str] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        write_index: bool = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "        byteorder: ToStataByteorder | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        time_stamp: datetime.datetime | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        data_label: str | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        variable_labels: dict[Hashable, str] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        version: int | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[32m114\u001b[39m,\n",
      "        convert_strl: Sequence[Hashable] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        compression: CompressionOptions = \u001b[33m\"infer\"\u001b[39m,\n",
      "        storage_options: StorageOptions | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        value_labels: dict[Hashable, dict[float, str]] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Export DataFrame object to Stata dta format.\u001b[39m\n",
      "\n",
      "\u001b[33m        Writes the DataFrame to a Stata dataset file.\u001b[39m\n",
      "\u001b[33m        \"dta\" files contain a Stata dataset.\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        path : str, path object, or buffer\u001b[39m\n",
      "\u001b[33m            String, path object (implementing ``os.PathLike[str]``), or file-like\u001b[39m\n",
      "\u001b[33m            object implementing a binary ``write()`` function.\u001b[39m\n",
      "\n",
      "\u001b[33m        convert_dates : dict\u001b[39m\n",
      "\u001b[33m            Dictionary mapping columns containing datetime types to stata\u001b[39m\n",
      "\u001b[33m            internal format to use when writing the dates. Options are 'tc',\u001b[39m\n",
      "\u001b[33m            'td', 'tm', 'tw', 'th', 'tq', 'ty'. Column can be either an integer\u001b[39m\n",
      "\u001b[33m            or a name. Datetime columns that do not have a conversion type\u001b[39m\n",
      "\u001b[33m            specified will be converted to 'tc'. Raises NotImplementedError if\u001b[39m\n",
      "\u001b[33m            a datetime column has timezone information.\u001b[39m\n",
      "\u001b[33m        write_index : bool\u001b[39m\n",
      "\u001b[33m            Write the index to Stata dataset.\u001b[39m\n",
      "\u001b[33m        byteorder : str\u001b[39m\n",
      "\u001b[33m            Can be \">\", \"<\", \"little\", or \"big\". default is `sys.byteorder`.\u001b[39m\n",
      "\u001b[33m        time_stamp : datetime\u001b[39m\n",
      "\u001b[33m            A datetime to use as file creation date.  Default is the current\u001b[39m\n",
      "\u001b[33m            time.\u001b[39m\n",
      "\u001b[33m        data_label : str, optional\u001b[39m\n",
      "\u001b[33m            A label for the data set.  Must be 80 characters or smaller.\u001b[39m\n",
      "\u001b[33m        variable_labels : dict\u001b[39m\n",
      "\u001b[33m            Dictionary containing columns as keys and variable labels as\u001b[39m\n",
      "\u001b[33m            values. Each label must be 80 characters or smaller.\u001b[39m\n",
      "\u001b[33m        version : {{114, 117, 118, 119, None}}, default 114\u001b[39m\n",
      "\u001b[33m            Version to use in the output dta file. Set to None to let pandas\u001b[39m\n",
      "\u001b[33m            decide between 118 or 119 formats depending on the number of\u001b[39m\n",
      "\u001b[33m            columns in the frame. Version 114 can be read by Stata 10 and\u001b[39m\n",
      "\u001b[33m            later. Version 117 can be read by Stata 13 or later. Version 118\u001b[39m\n",
      "\u001b[33m            is supported in Stata 14 and later. Version 119 is supported in\u001b[39m\n",
      "\u001b[33m            Stata 15 and later. Version 114 limits string variables to 244\u001b[39m\n",
      "\u001b[33m            characters or fewer while versions 117 and later allow strings\u001b[39m\n",
      "\u001b[33m            with lengths up to 2,000,000 characters. Versions 118 and 119\u001b[39m\n",
      "\u001b[33m            support Unicode characters, and version 119 supports more than\u001b[39m\n",
      "\u001b[33m            32,767 variables.\u001b[39m\n",
      "\n",
      "\u001b[33m            Version 119 should usually only be used when the number of\u001b[39m\n",
      "\u001b[33m            variables exceeds the capacity of dta format 118. Exporting\u001b[39m\n",
      "\u001b[33m            smaller datasets in format 119 may have unintended consequences,\u001b[39m\n",
      "\u001b[33m            and, as of November 2020, Stata SE cannot read version 119 files.\u001b[39m\n",
      "\n",
      "\u001b[33m        convert_strl : list, optional\u001b[39m\n",
      "\u001b[33m            List of column names to convert to string columns to Stata StrL\u001b[39m\n",
      "\u001b[33m            format. Only available if version is 117.  Storing strings in the\u001b[39m\n",
      "\u001b[33m            StrL format can produce smaller dta files if strings have more than\u001b[39m\n",
      "\u001b[33m            8 characters and values are repeated.\u001b[39m\n",
      "\u001b[33m        {compression_options}\u001b[39m\n",
      "\n",
      "\u001b[33m            .. versionchanged:: 1.4.0 Zstandard support.\u001b[39m\n",
      "\n",
      "\u001b[33m        {storage_options}\u001b[39m\n",
      "\n",
      "\u001b[33m        value_labels : dict of dicts\u001b[39m\n",
      "\u001b[33m            Dictionary containing columns as keys and dictionaries of column value\u001b[39m\n",
      "\u001b[33m            to labels as values. Labels for a single variable must be 32,000\u001b[39m\n",
      "\u001b[33m            characters or smaller.\u001b[39m\n",
      "\n",
      "\u001b[33m            .. versionadded:: 1.4.0\u001b[39m\n",
      "\n",
      "\u001b[33m        Raises\u001b[39m\n",
      "\u001b[33m        ------\u001b[39m\n",
      "\u001b[33m        NotImplementedError\u001b[39m\n",
      "\u001b[33m            * If datetimes contain timezone information\u001b[39m\n",
      "\u001b[33m            * Column dtype is not representable in Stata\u001b[39m\n",
      "\u001b[33m        ValueError\u001b[39m\n",
      "\u001b[33m            * Columns listed in convert_dates are neither datetime64[ns]\u001b[39m\n",
      "\u001b[33m              or datetime.datetime\u001b[39m\n",
      "\u001b[33m            * Column listed in convert_dates is not in DataFrame\u001b[39m\n",
      "\u001b[33m            * Categorical label contains more than 32,000 characters\u001b[39m\n",
      "\n",
      "\u001b[33m        See Also\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        read_stata : Import Stata data files.\u001b[39m\n",
      "\u001b[33m        io.stata.StataWriter : Low-level writer for Stata data files.\u001b[39m\n",
      "\u001b[33m        io.stata.StataWriter117 : Low-level writer for version 117 files.\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        >>> df = pd.DataFrame({{'animal': ['falcon', 'parrot', 'falcon',\u001b[39m\n",
      "\u001b[33m        ...                               'parrot'],\u001b[39m\n",
      "\u001b[33m        ...                    'speed': [350, 18, 361, 15]}})\u001b[39m\n",
      "\u001b[33m        >>> df.to_stata('animals.dta')  # doctest: +SKIP\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m version \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01min\u001b[39;00m (\u001b[32m114\u001b[39m, \u001b[32m117\u001b[39m, \u001b[32m118\u001b[39m, \u001b[32m119\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "            \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\u001b[33m\"Only formats 114, 117, 118 and 119 are supported.\"\u001b[39m)\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m version == \u001b[32m114\u001b[39m:\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m convert_strl \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "                \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\u001b[33m\"strl is not supported in format 114\"\u001b[39m)\n",
      "            \u001b[38;5;28;01mfrom\u001b[39;00m pandas.io.stata \u001b[38;5;28;01mimport\u001b[39;00m StataWriter \u001b[38;5;28;01mas\u001b[39;00m statawriter\n",
      "        \u001b[38;5;28;01melif\u001b[39;00m version == \u001b[32m117\u001b[39m:\n",
      "            \u001b[38;5;66;03m# Incompatible import of \"statawriter\" (imported name has type\u001b[39;00m\n",
      "            \u001b[38;5;66;03m# \"Type[StataWriter117]\", local name has type \"Type[StataWriter]\")\u001b[39;00m\n",
      "            \u001b[38;5;28;01mfrom\u001b[39;00m pandas.io.stata \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n",
      "                StataWriter117 \u001b[38;5;28;01mas\u001b[39;00m statawriter,\n",
      "            )\n",
      "        \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# versions 118 and 119\u001b[39;00m\n",
      "            \u001b[38;5;66;03m# Incompatible import of \"statawriter\" (imported name has type\u001b[39;00m\n",
      "            \u001b[38;5;66;03m# \"Type[StataWriter117]\", local name has type \"Type[StataWriter]\")\u001b[39;00m\n",
      "            \u001b[38;5;28;01mfrom\u001b[39;00m pandas.io.stata \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n",
      "                StataWriterUTF8 \u001b[38;5;28;01mas\u001b[39;00m statawriter,\n",
      "            )\n",
      "\n",
      "        kwargs: dict[str, Any] = {}\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m version \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mor\u001b[39;00m version >= \u001b[32m117\u001b[39m:\n",
      "            \u001b[38;5;66;03m# strl conversion is only supported >= 117\u001b[39;00m\n",
      "            kwargs[\u001b[33m\"convert_strl\"\u001b[39m] = convert_strl\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m version \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mor\u001b[39;00m version >= \u001b[32m118\u001b[39m:\n",
      "            \u001b[38;5;66;03m# Specifying the version is only supported for UTF8 (118 or 119)\u001b[39;00m\n",
      "            kwargs[\u001b[33m\"version\"\u001b[39m] = version\n",
      "\n",
      "        writer = statawriter(\n",
      "            path,\n",
      "            self,\n",
      "            convert_dates=convert_dates,\n",
      "            byteorder=byteorder,\n",
      "            time_stamp=time_stamp,\n",
      "            data_label=data_label,\n",
      "            write_index=write_index,\n",
      "            variable_labels=variable_labels,\n",
      "            compression=compression,\n",
      "            storage_options=storage_options,\n",
      "            value_labels=value_labels,\n",
      "            **kwargs,\n",
      "        )\n",
      "        writer.write_file()\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m to_feather(self, path: FilePath | WriteBuffer[bytes], **kwargs) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Write a DataFrame to the binary Feather format.\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        path : str, path object, file-like object\u001b[39m\n",
      "\u001b[33m            String, path object (implementing ``os.PathLike[str]``), or file-like\u001b[39m\n",
      "\u001b[33m            object implementing a binary ``write()`` function. If a string or a path,\u001b[39m\n",
      "\u001b[33m            it will be used as Root Directory path when writing a partitioned dataset.\u001b[39m\n",
      "\u001b[33m        **kwargs :\u001b[39m\n",
      "\u001b[33m            Additional keywords passed to :func:`pyarrow.feather.write_feather`.\u001b[39m\n",
      "\u001b[33m            This includes the `compression`, `compression_level`, `chunksize`\u001b[39m\n",
      "\u001b[33m            and `version` keywords.\u001b[39m\n",
      "\n",
      "\u001b[33m        Notes\u001b[39m\n",
      "\u001b[33m        -----\u001b[39m\n",
      "\u001b[33m        This function writes the dataframe as a `feather file\u001b[39m\n",
      "\u001b[33m        <https://arrow.apache.org/docs/python/feather.html>`_. Requires a default\u001b[39m\n",
      "\u001b[33m        index. For saving the DataFrame with your custom index use a method that\u001b[39m\n",
      "\u001b[33m        supports custom indices e.g. `to_parquet`.\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        >>> df = pd.DataFrame([[1, 2, 3], [4, 5, 6]])\u001b[39m\n",
      "\u001b[33m        >>> df.to_feather(\"file.feather\")  # doctest: +SKIP\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;28;01mfrom\u001b[39;00m pandas.io.feather_format \u001b[38;5;28;01mimport\u001b[39;00m to_feather\n",
      "\n",
      "        to_feather(self, path, **kwargs)\n",
      "\n",
      "    @deprecate_nonkeyword_arguments(\n",
      "        version=\u001b[33m\"3.0\"\u001b[39m, allowed_args=[\u001b[33m\"self\"\u001b[39m, \u001b[33m\"buf\"\u001b[39m], name=\u001b[33m\"to_markdown\"\u001b[39m\n",
      "    )\n",
      "    @doc(\n",
      "        Series.to_markdown,\n",
      "        klass=_shared_doc_kwargs[\u001b[33m\"klass\"\u001b[39m],\n",
      "        storage_options=_shared_docs[\u001b[33m\"storage_options\"\u001b[39m],\n",
      "        examples=\u001b[33m\"\"\"Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        >>> df = pd.DataFrame(\u001b[39m\n",
      "\u001b[33m        ...     data={\"animal_1\": [\"elk\", \"pig\"], \"animal_2\": [\"dog\", \"quetzal\"]}\u001b[39m\n",
      "\u001b[33m        ... )\u001b[39m\n",
      "\u001b[33m        >>> print(df.to_markdown())\u001b[39m\n",
      "\u001b[33m        |    | animal_1   | animal_2   |\u001b[39m\n",
      "\u001b[33m        |---:|:-----------|:-----------|\u001b[39m\n",
      "\u001b[33m        |  0 | elk        | dog        |\u001b[39m\n",
      "\u001b[33m        |  1 | pig        | quetzal    |\u001b[39m\n",
      "\n",
      "\u001b[33m        Output markdown with a tabulate option.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> print(df.to_markdown(tablefmt=\"grid\"))\u001b[39m\n",
      "\u001b[33m        +----+------------+------------+\u001b[39m\n",
      "\u001b[33m        |    | animal_1   | animal_2   |\u001b[39m\n",
      "\u001b[33m        +====+============+============+\u001b[39m\n",
      "\u001b[33m        |  0 | elk        | dog        |\u001b[39m\n",
      "\u001b[33m        +----+------------+------------+\u001b[39m\n",
      "\u001b[33m        |  1 | pig        | quetzal    |\u001b[39m\n",
      "\u001b[33m        +----+------------+------------+\"\"\"\u001b[39m,\n",
      "    )\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m to_markdown(\n",
      "        self,\n",
      "        buf: FilePath | WriteBuffer[str] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        mode: str = \u001b[33m\"wt\"\u001b[39m,\n",
      "        index: bool = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "        storage_options: StorageOptions | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        **kwargs,\n",
      "    ) -> str | \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"showindex\"\u001b[39m \u001b[38;5;28;01min\u001b[39;00m kwargs:\n",
      "            \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\u001b[33m\"Pass 'index' instead of 'showindex\"\u001b[39m)\n",
      "\n",
      "        kwargs.setdefault(\u001b[33m\"headers\"\u001b[39m, \u001b[33m\"keys\"\u001b[39m)\n",
      "        kwargs.setdefault(\u001b[33m\"tablefmt\"\u001b[39m, \u001b[33m\"pipe\"\u001b[39m)\n",
      "        kwargs.setdefault(\u001b[33m\"showindex\"\u001b[39m, index)\n",
      "        tabulate = import_optional_dependency(\u001b[33m\"tabulate\"\u001b[39m)\n",
      "        result = tabulate.tabulate(self, **kwargs)\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m buf \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\n",
      "        \u001b[38;5;28;01mwith\u001b[39;00m get_handle(buf, mode, storage_options=storage_options) \u001b[38;5;28;01mas\u001b[39;00m handles:\n",
      "            handles.handle.write(result)\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\n",
      "    @overload\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m to_parquet(\n",
      "        self,\n",
      "        path: \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        engine: Literal[\u001b[33m\"auto\"\u001b[39m, \u001b[33m\"pyarrow\"\u001b[39m, \u001b[33m\"fastparquet\"\u001b[39m] = ...,\n",
      "        compression: str | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        index: bool | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        partition_cols: list[str] | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        storage_options: StorageOptions = ...,\n",
      "        **kwargs,\n",
      "    ) -> bytes:\n",
      "        ...\n",
      "\n",
      "    @overload\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m to_parquet(\n",
      "        self,\n",
      "        path: FilePath | WriteBuffer[bytes],\n",
      "        engine: Literal[\u001b[33m\"auto\"\u001b[39m, \u001b[33m\"pyarrow\"\u001b[39m, \u001b[33m\"fastparquet\"\u001b[39m] = ...,\n",
      "        compression: str | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        index: bool | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        partition_cols: list[str] | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        storage_options: StorageOptions = ...,\n",
      "        **kwargs,\n",
      "    ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        ...\n",
      "\n",
      "    @deprecate_nonkeyword_arguments(\n",
      "        version=\u001b[33m\"3.0\"\u001b[39m, allowed_args=[\u001b[33m\"self\"\u001b[39m, \u001b[33m\"path\"\u001b[39m], name=\u001b[33m\"to_parquet\"\u001b[39m\n",
      "    )\n",
      "    @doc(storage_options=_shared_docs[\u001b[33m\"storage_options\"\u001b[39m])\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m to_parquet(\n",
      "        self,\n",
      "        path: FilePath | WriteBuffer[bytes] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        engine: Literal[\u001b[33m\"auto\"\u001b[39m, \u001b[33m\"pyarrow\"\u001b[39m, \u001b[33m\"fastparquet\"\u001b[39m] = \u001b[33m\"auto\"\u001b[39m,\n",
      "        compression: str | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[33m\"snappy\"\u001b[39m,\n",
      "        index: bool | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        partition_cols: list[str] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        storage_options: StorageOptions | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        **kwargs,\n",
      "    ) -> bytes | \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Write a DataFrame to the binary parquet format.\u001b[39m\n",
      "\n",
      "\u001b[33m        This function writes the dataframe as a `parquet file\u001b[39m\n",
      "\u001b[33m        <https://parquet.apache.org/>`_. You can choose different parquet\u001b[39m\n",
      "\u001b[33m        backends, and have the option of compression. See\u001b[39m\n",
      "\u001b[33m        :ref:`the user guide <io.parquet>` for more details.\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        path : str, path object, file-like object, or None, default None\u001b[39m\n",
      "\u001b[33m            String, path object (implementing ``os.PathLike[str]``), or file-like\u001b[39m\n",
      "\u001b[33m            object implementing a binary ``write()`` function. If None, the result is\u001b[39m\n",
      "\u001b[33m            returned as bytes. If a string or path, it will be used as Root Directory\u001b[39m\n",
      "\u001b[33m            path when writing a partitioned dataset.\u001b[39m\n",
      "\u001b[33m        engine : {{'auto', 'pyarrow', 'fastparquet'}}, default 'auto'\u001b[39m\n",
      "\u001b[33m            Parquet library to use. If 'auto', then the option\u001b[39m\n",
      "\u001b[33m            ``io.parquet.engine`` is used. The default ``io.parquet.engine``\u001b[39m\n",
      "\u001b[33m            behavior is to try 'pyarrow', falling back to 'fastparquet' if\u001b[39m\n",
      "\u001b[33m            'pyarrow' is unavailable.\u001b[39m\n",
      "\u001b[33m        compression : str or None, default 'snappy'\u001b[39m\n",
      "\u001b[33m            Name of the compression to use. Use ``None`` for no compression.\u001b[39m\n",
      "\u001b[33m            Supported options: 'snappy', 'gzip', 'brotli', 'lz4', 'zstd'.\u001b[39m\n",
      "\u001b[33m        index : bool, default None\u001b[39m\n",
      "\u001b[33m            If ``True``, include the dataframe's index(es) in the file output.\u001b[39m\n",
      "\u001b[33m            If ``False``, they will not be written to the file.\u001b[39m\n",
      "\u001b[33m            If ``None``, similar to ``True`` the dataframe's index(es)\u001b[39m\n",
      "\u001b[33m            will be saved. However, instead of being saved as values,\u001b[39m\n",
      "\u001b[33m            the RangeIndex will be stored as a range in the metadata so it\u001b[39m\n",
      "\u001b[33m            doesn't require much space and is faster. Other indexes will\u001b[39m\n",
      "\u001b[33m            be included as columns in the file output.\u001b[39m\n",
      "\u001b[33m        partition_cols : list, optional, default None\u001b[39m\n",
      "\u001b[33m            Column names by which to partition the dataset.\u001b[39m\n",
      "\u001b[33m            Columns are partitioned in the order they are given.\u001b[39m\n",
      "\u001b[33m            Must be None if path is not a string.\u001b[39m\n",
      "\u001b[33m        {storage_options}\u001b[39m\n",
      "\n",
      "\u001b[33m        **kwargs\u001b[39m\n",
      "\u001b[33m            Additional arguments passed to the parquet library. See\u001b[39m\n",
      "\u001b[33m            :ref:`pandas io <io.parquet>` for more details.\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        bytes if no path argument is provided else None\u001b[39m\n",
      "\n",
      "\u001b[33m        See Also\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        read_parquet : Read a parquet file.\u001b[39m\n",
      "\u001b[33m        DataFrame.to_orc : Write an orc file.\u001b[39m\n",
      "\u001b[33m        DataFrame.to_csv : Write a csv file.\u001b[39m\n",
      "\u001b[33m        DataFrame.to_sql : Write to a sql table.\u001b[39m\n",
      "\u001b[33m        DataFrame.to_hdf : Write to hdf.\u001b[39m\n",
      "\n",
      "\u001b[33m        Notes\u001b[39m\n",
      "\u001b[33m        -----\u001b[39m\n",
      "\u001b[33m        This function requires either the `fastparquet\u001b[39m\n",
      "\u001b[33m        <https://pypi.org/project/fastparquet>`_ or `pyarrow\u001b[39m\n",
      "\u001b[33m        <https://arrow.apache.org/docs/python/>`_ library.\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        >>> df = pd.DataFrame(data={{'col1': [1, 2], 'col2': [3, 4]}})\u001b[39m\n",
      "\u001b[33m        >>> df.to_parquet('df.parquet.gzip',\u001b[39m\n",
      "\u001b[33m        ...               compression='gzip')  # doctest: +SKIP\u001b[39m\n",
      "\u001b[33m        >>> pd.read_parquet('df.parquet.gzip')  # doctest: +SKIP\u001b[39m\n",
      "\u001b[33m           col1  col2\u001b[39m\n",
      "\u001b[33m        0     1     3\u001b[39m\n",
      "\u001b[33m        1     2     4\u001b[39m\n",
      "\n",
      "\u001b[33m        If you want to get a buffer to the parquet content you can use a io.BytesIO\u001b[39m\n",
      "\u001b[33m        object, as long as you don't use partition_cols, which creates multiple files.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> import io\u001b[39m\n",
      "\u001b[33m        >>> f = io.BytesIO()\u001b[39m\n",
      "\u001b[33m        >>> df.to_parquet(f)\u001b[39m\n",
      "\u001b[33m        >>> f.seek(0)\u001b[39m\n",
      "\u001b[33m        0\u001b[39m\n",
      "\u001b[33m        >>> content = f.read()\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;28;01mfrom\u001b[39;00m pandas.io.parquet \u001b[38;5;28;01mimport\u001b[39;00m to_parquet\n",
      "\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m to_parquet(\n",
      "            self,\n",
      "            path,\n",
      "            engine,\n",
      "            compression=compression,\n",
      "            index=index,\n",
      "            partition_cols=partition_cols,\n",
      "            storage_options=storage_options,\n",
      "            **kwargs,\n",
      "        )\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m to_orc(\n",
      "        self,\n",
      "        path: FilePath | WriteBuffer[bytes] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        *,\n",
      "        engine: Literal[\u001b[33m\"pyarrow\"\u001b[39m] = \u001b[33m\"pyarrow\"\u001b[39m,\n",
      "        index: bool | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        engine_kwargs: dict[str, Any] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    ) -> bytes | \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Write a DataFrame to the ORC format.\u001b[39m\n",
      "\n",
      "\u001b[33m        .. versionadded:: 1.5.0\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        path : str, file-like object or None, default None\u001b[39m\n",
      "\u001b[33m            If a string, it will be used as Root Directory path\u001b[39m\n",
      "\u001b[33m            when writing a partitioned dataset. By file-like object,\u001b[39m\n",
      "\u001b[33m            we refer to objects with a write() method, such as a file handle\u001b[39m\n",
      "\u001b[33m            (e.g. via builtin open function). If path is None,\u001b[39m\n",
      "\u001b[33m            a bytes object is returned.\u001b[39m\n",
      "\u001b[33m        engine : {'pyarrow'}, default 'pyarrow'\u001b[39m\n",
      "\u001b[33m            ORC library to use.\u001b[39m\n",
      "\u001b[33m        index : bool, optional\u001b[39m\n",
      "\u001b[33m            If ``True``, include the dataframe's index(es) in the file output.\u001b[39m\n",
      "\u001b[33m            If ``False``, they will not be written to the file.\u001b[39m\n",
      "\u001b[33m            If ``None``, similar to ``infer`` the dataframe's index(es)\u001b[39m\n",
      "\u001b[33m            will be saved. However, instead of being saved as values,\u001b[39m\n",
      "\u001b[33m            the RangeIndex will be stored as a range in the metadata so it\u001b[39m\n",
      "\u001b[33m            doesn't require much space and is faster. Other indexes will\u001b[39m\n",
      "\u001b[33m            be included as columns in the file output.\u001b[39m\n",
      "\u001b[33m        engine_kwargs : dict[str, Any] or None, default None\u001b[39m\n",
      "\u001b[33m            Additional keyword arguments passed to :func:`pyarrow.orc.write_table`.\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        bytes if no path argument is provided else None\u001b[39m\n",
      "\n",
      "\u001b[33m        Raises\u001b[39m\n",
      "\u001b[33m        ------\u001b[39m\n",
      "\u001b[33m        NotImplementedError\u001b[39m\n",
      "\u001b[33m            Dtype of one or more columns is category, unsigned integers, interval,\u001b[39m\n",
      "\u001b[33m            period or sparse.\u001b[39m\n",
      "\u001b[33m        ValueError\u001b[39m\n",
      "\u001b[33m            engine is not pyarrow.\u001b[39m\n",
      "\n",
      "\u001b[33m        See Also\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        read_orc : Read a ORC file.\u001b[39m\n",
      "\u001b[33m        DataFrame.to_parquet : Write a parquet file.\u001b[39m\n",
      "\u001b[33m        DataFrame.to_csv : Write a csv file.\u001b[39m\n",
      "\u001b[33m        DataFrame.to_sql : Write to a sql table.\u001b[39m\n",
      "\u001b[33m        DataFrame.to_hdf : Write to hdf.\u001b[39m\n",
      "\n",
      "\u001b[33m        Notes\u001b[39m\n",
      "\u001b[33m        -----\u001b[39m\n",
      "\u001b[33m        * Before using this function you should read the :ref:`user guide about\u001b[39m\n",
      "\u001b[33m          ORC <io.orc>` and :ref:`install optional dependencies <install.warn_orc>`.\u001b[39m\n",
      "\u001b[33m        * This function requires `pyarrow <https://arrow.apache.org/docs/python/>`_\u001b[39m\n",
      "\u001b[33m          library.\u001b[39m\n",
      "\u001b[33m        * For supported dtypes please refer to `supported ORC features in Arrow\u001b[39m\n",
      "\u001b[33m          <https://arrow.apache.org/docs/cpp/orc.html#data-types>`__.\u001b[39m\n",
      "\u001b[33m        * Currently timezones in datetime columns are not preserved when a\u001b[39m\n",
      "\u001b[33m          dataframe is converted into ORC files.\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        >>> df = pd.DataFrame(data={'col1': [1, 2], 'col2': [4, 3]})\u001b[39m\n",
      "\u001b[33m        >>> df.to_orc('df.orc')  # doctest: +SKIP\u001b[39m\n",
      "\u001b[33m        >>> pd.read_orc('df.orc')  # doctest: +SKIP\u001b[39m\n",
      "\u001b[33m           col1  col2\u001b[39m\n",
      "\u001b[33m        0     1     4\u001b[39m\n",
      "\u001b[33m        1     2     3\u001b[39m\n",
      "\n",
      "\u001b[33m        If you want to get a buffer to the orc content you can write it to io.BytesIO\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> import io\u001b[39m\n",
      "\u001b[33m        >>> b = io.BytesIO(df.to_orc())  # doctest: +SKIP\u001b[39m\n",
      "\u001b[33m        >>> b.seek(0)  # doctest: +SKIP\u001b[39m\n",
      "\u001b[33m        0\u001b[39m\n",
      "\u001b[33m        >>> content = b.read()  # doctest: +SKIP\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;28;01mfrom\u001b[39;00m pandas.io.orc \u001b[38;5;28;01mimport\u001b[39;00m to_orc\n",
      "\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m to_orc(\n",
      "            self, path, engine=engine, index=index, engine_kwargs=engine_kwargs\n",
      "        )\n",
      "\n",
      "    @overload\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m to_html(\n",
      "        self,\n",
      "        buf: FilePath | WriteBuffer[str],\n",
      "        columns: Axes | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        col_space: ColspaceArgType | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        header: bool = ...,\n",
      "        index: bool = ...,\n",
      "        na_rep: str = ...,\n",
      "        formatters: FormattersType | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        float_format: FloatFormatType | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        sparsify: bool | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        index_names: bool = ...,\n",
      "        justify: str | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        max_rows: int | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        max_cols: int | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        show_dimensions: bool | str = ...,\n",
      "        decimal: str = ...,\n",
      "        bold_rows: bool = ...,\n",
      "        classes: str | list | tuple | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        escape: bool = ...,\n",
      "        notebook: bool = ...,\n",
      "        border: int | bool | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        table_id: str | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        render_links: bool = ...,\n",
      "        encoding: str | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "    ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        ...\n",
      "\n",
      "    @overload\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m to_html(\n",
      "        self,\n",
      "        buf: \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        columns: Axes | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        col_space: ColspaceArgType | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        header: bool = ...,\n",
      "        index: bool = ...,\n",
      "        na_rep: str = ...,\n",
      "        formatters: FormattersType | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        float_format: FloatFormatType | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        sparsify: bool | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        index_names: bool = ...,\n",
      "        justify: str | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        max_rows: int | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        max_cols: int | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        show_dimensions: bool | str = ...,\n",
      "        decimal: str = ...,\n",
      "        bold_rows: bool = ...,\n",
      "        classes: str | list | tuple | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        escape: bool = ...,\n",
      "        notebook: bool = ...,\n",
      "        border: int | bool | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        table_id: str | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        render_links: bool = ...,\n",
      "        encoding: str | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "    ) -> str:\n",
      "        ...\n",
      "\n",
      "    @deprecate_nonkeyword_arguments(\n",
      "        version=\u001b[33m\"3.0\"\u001b[39m, allowed_args=[\u001b[33m\"self\"\u001b[39m, \u001b[33m\"buf\"\u001b[39m], name=\u001b[33m\"to_html\"\u001b[39m\n",
      "    )\n",
      "    @Substitution(\n",
      "        header_type=\u001b[33m\"bool\"\u001b[39m,\n",
      "        header=\u001b[33m\"Whether to print column labels, default True\"\u001b[39m,\n",
      "        col_space_type=\u001b[33m\"str or int, list or dict of int or str\"\u001b[39m,\n",
      "        col_space=\u001b[33m\"The minimum width of each column in CSS length \"\u001b[39m\n",
      "        \u001b[33m\"units.  An int is assumed to be px units.\"\u001b[39m,\n",
      "    )\n",
      "    @Substitution(shared_params=fmt.common_docstring, returns=fmt.return_docstring)\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m to_html(\n",
      "        self,\n",
      "        buf: FilePath | WriteBuffer[str] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        columns: Axes | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        col_space: ColspaceArgType | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        header: bool = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "        index: bool = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "        na_rep: str = \u001b[33m\"NaN\"\u001b[39m,\n",
      "        formatters: FormattersType | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        float_format: FloatFormatType | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        sparsify: bool | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        index_names: bool = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "        justify: str | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        max_rows: int | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        max_cols: int | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        show_dimensions: bool | str = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "        decimal: str = \u001b[33m\".\"\u001b[39m,\n",
      "        bold_rows: bool = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "        classes: str | list | tuple | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        escape: bool = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "        notebook: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "        border: int | bool | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        table_id: str | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        render_links: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "        encoding: str | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    ) -> str | \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Render a DataFrame as an HTML table.\u001b[39m\n",
      "\u001b[33m        %(shared_params)s\u001b[39m\n",
      "\u001b[33m        bold_rows : bool, default True\u001b[39m\n",
      "\u001b[33m            Make the row labels bold in the output.\u001b[39m\n",
      "\u001b[33m        classes : str or list or tuple, default None\u001b[39m\n",
      "\u001b[33m            CSS class(es) to apply to the resulting html table.\u001b[39m\n",
      "\u001b[33m        escape : bool, default True\u001b[39m\n",
      "\u001b[33m            Convert the characters <, >, and & to HTML-safe sequences.\u001b[39m\n",
      "\u001b[33m        notebook : {True, False}, default False\u001b[39m\n",
      "\u001b[33m            Whether the generated HTML is for IPython Notebook.\u001b[39m\n",
      "\u001b[33m        border : int\u001b[39m\n",
      "\u001b[33m            A ``border=border`` attribute is included in the opening\u001b[39m\n",
      "\u001b[33m            `<table>` tag. Default ``pd.options.display.html.border``.\u001b[39m\n",
      "\u001b[33m        table_id : str, optional\u001b[39m\n",
      "\u001b[33m            A css id is included in the opening `<table>` tag if specified.\u001b[39m\n",
      "\u001b[33m        render_links : bool, default False\u001b[39m\n",
      "\u001b[33m            Convert URLs to HTML links.\u001b[39m\n",
      "\u001b[33m        encoding : str, default \"utf-8\"\u001b[39m\n",
      "\u001b[33m            Set character encoding.\u001b[39m\n",
      "\u001b[33m        %(returns)s\u001b[39m\n",
      "\u001b[33m        See Also\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        to_string : Convert DataFrame to a string.\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        >>> df = pd.DataFrame(data={'col1': [1, 2], 'col2': [4, 3]})\u001b[39m\n",
      "\u001b[33m        >>> html_string = '''<table border=\"1\" class=\"dataframe\">\u001b[39m\n",
      "\u001b[33m        ...   <thead>\u001b[39m\n",
      "\u001b[33m        ...     <tr style=\"text-align: right;\">\u001b[39m\n",
      "\u001b[33m        ...       <th></th>\u001b[39m\n",
      "\u001b[33m        ...       <th>col1</th>\u001b[39m\n",
      "\u001b[33m        ...       <th>col2</th>\u001b[39m\n",
      "\u001b[33m        ...     </tr>\u001b[39m\n",
      "\u001b[33m        ...   </thead>\u001b[39m\n",
      "\u001b[33m        ...   <tbody>\u001b[39m\n",
      "\u001b[33m        ...     <tr>\u001b[39m\n",
      "\u001b[33m        ...       <th>0</th>\u001b[39m\n",
      "\u001b[33m        ...       <td>1</td>\u001b[39m\n",
      "\u001b[33m        ...       <td>4</td>\u001b[39m\n",
      "\u001b[33m        ...     </tr>\u001b[39m\n",
      "\u001b[33m        ...     <tr>\u001b[39m\n",
      "\u001b[33m        ...       <th>1</th>\u001b[39m\n",
      "\u001b[33m        ...       <td>2</td>\u001b[39m\n",
      "\u001b[33m        ...       <td>3</td>\u001b[39m\n",
      "\u001b[33m        ...     </tr>\u001b[39m\n",
      "\u001b[33m        ...   </tbody>\u001b[39m\n",
      "\u001b[33m        ... </table>'''\u001b[39m\n",
      "\u001b[33m        >>> assert html_string == df.to_html()\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m justify \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mand\u001b[39;00m justify \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01min\u001b[39;00m fmt.VALID_JUSTIFY_PARAMETERS:\n",
      "            \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\u001b[33m\"Invalid value for justify parameter\"\u001b[39m)\n",
      "\n",
      "        formatter = fmt.DataFrameFormatter(\n",
      "            self,\n",
      "            columns=columns,\n",
      "            col_space=col_space,\n",
      "            na_rep=na_rep,\n",
      "            header=header,\n",
      "            index=index,\n",
      "            formatters=formatters,\n",
      "            float_format=float_format,\n",
      "            bold_rows=bold_rows,\n",
      "            sparsify=sparsify,\n",
      "            justify=justify,\n",
      "            index_names=index_names,\n",
      "            escape=escape,\n",
      "            decimal=decimal,\n",
      "            max_rows=max_rows,\n",
      "            max_cols=max_cols,\n",
      "            show_dimensions=show_dimensions,\n",
      "        )\n",
      "        \u001b[38;5;66;03m# TODO: a generic formatter wld b in DataFrameFormatter\u001b[39;00m\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m fmt.DataFrameRenderer(formatter).to_html(\n",
      "            buf=buf,\n",
      "            classes=classes,\n",
      "            notebook=notebook,\n",
      "            border=border,\n",
      "            encoding=encoding,\n",
      "            table_id=table_id,\n",
      "            render_links=render_links,\n",
      "        )\n",
      "\n",
      "    @overload\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m to_xml(\n",
      "        self,\n",
      "        path_or_buffer: \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        *,\n",
      "        index: bool = ...,\n",
      "        root_name: str | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        row_name: str | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        na_rep: str | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        attr_cols: list[str] | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        elem_cols: list[str] | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        namespaces: dict[str | \u001b[38;5;28;01mNone\u001b[39;00m, str] | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        prefix: str | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        encoding: str = ...,\n",
      "        xml_declaration: bool | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        pretty_print: bool | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        parser: XMLParsers | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        stylesheet: FilePath | ReadBuffer[str] | ReadBuffer[bytes] | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        compression: CompressionOptions = ...,\n",
      "        storage_options: StorageOptions | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "    ) -> str:\n",
      "        ...\n",
      "\n",
      "    @overload\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m to_xml(\n",
      "        self,\n",
      "        path_or_buffer: FilePath | WriteBuffer[bytes] | WriteBuffer[str],\n",
      "        *,\n",
      "        index: bool = ...,\n",
      "        root_name: str | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        row_name: str | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        na_rep: str | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        attr_cols: list[str] | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        elem_cols: list[str] | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        namespaces: dict[str | \u001b[38;5;28;01mNone\u001b[39;00m, str] | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        prefix: str | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        encoding: str = ...,\n",
      "        xml_declaration: bool | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        pretty_print: bool | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        parser: XMLParsers | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        stylesheet: FilePath | ReadBuffer[str] | ReadBuffer[bytes] | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        compression: CompressionOptions = ...,\n",
      "        storage_options: StorageOptions | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "    ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        ...\n",
      "\n",
      "    @deprecate_nonkeyword_arguments(\n",
      "        version=\u001b[33m\"3.0\"\u001b[39m, allowed_args=[\u001b[33m\"self\"\u001b[39m, \u001b[33m\"path_or_buffer\"\u001b[39m], name=\u001b[33m\"to_xml\"\u001b[39m\n",
      "    )\n",
      "    @doc(\n",
      "        storage_options=_shared_docs[\u001b[33m\"storage_options\"\u001b[39m],\n",
      "        compression_options=_shared_docs[\u001b[33m\"compression_options\"\u001b[39m] % \u001b[33m\"path_or_buffer\"\u001b[39m,\n",
      "    )\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m to_xml(\n",
      "        self,\n",
      "        path_or_buffer: FilePath | WriteBuffer[bytes] | WriteBuffer[str] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        index: bool = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "        root_name: str | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[33m\"data\"\u001b[39m,\n",
      "        row_name: str | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[33m\"row\"\u001b[39m,\n",
      "        na_rep: str | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        attr_cols: list[str] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        elem_cols: list[str] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        namespaces: dict[str | \u001b[38;5;28;01mNone\u001b[39;00m, str] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        prefix: str | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        encoding: str = \u001b[33m\"utf-8\"\u001b[39m,\n",
      "        xml_declaration: bool | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "        pretty_print: bool | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "        parser: XMLParsers | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[33m\"lxml\"\u001b[39m,\n",
      "        stylesheet: FilePath | ReadBuffer[str] | ReadBuffer[bytes] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        compression: CompressionOptions = \u001b[33m\"infer\"\u001b[39m,\n",
      "        storage_options: StorageOptions | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    ) -> str | \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Render a DataFrame to an XML document.\u001b[39m\n",
      "\n",
      "\u001b[33m        .. versionadded:: 1.3.0\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        path_or_buffer : str, path object, file-like object, or None, default None\u001b[39m\n",
      "\u001b[33m            String, path object (implementing ``os.PathLike[str]``), or file-like\u001b[39m\n",
      "\u001b[33m            object implementing a ``write()`` function. If None, the result is returned\u001b[39m\n",
      "\u001b[33m            as a string.\u001b[39m\n",
      "\u001b[33m        index : bool, default True\u001b[39m\n",
      "\u001b[33m            Whether to include index in XML document.\u001b[39m\n",
      "\u001b[33m        root_name : str, default 'data'\u001b[39m\n",
      "\u001b[33m            The name of root element in XML document.\u001b[39m\n",
      "\u001b[33m        row_name : str, default 'row'\u001b[39m\n",
      "\u001b[33m            The name of row element in XML document.\u001b[39m\n",
      "\u001b[33m        na_rep : str, optional\u001b[39m\n",
      "\u001b[33m            Missing data representation.\u001b[39m\n",
      "\u001b[33m        attr_cols : list-like, optional\u001b[39m\n",
      "\u001b[33m            List of columns to write as attributes in row element.\u001b[39m\n",
      "\u001b[33m            Hierarchical columns will be flattened with underscore\u001b[39m\n",
      "\u001b[33m            delimiting the different levels.\u001b[39m\n",
      "\u001b[33m        elem_cols : list-like, optional\u001b[39m\n",
      "\u001b[33m            List of columns to write as children in row element. By default,\u001b[39m\n",
      "\u001b[33m            all columns output as children of row element. Hierarchical\u001b[39m\n",
      "\u001b[33m            columns will be flattened with underscore delimiting the\u001b[39m\n",
      "\u001b[33m            different levels.\u001b[39m\n",
      "\u001b[33m        namespaces : dict, optional\u001b[39m\n",
      "\u001b[33m            All namespaces to be defined in root element. Keys of dict\u001b[39m\n",
      "\u001b[33m            should be prefix names and values of dict corresponding URIs.\u001b[39m\n",
      "\u001b[33m            Default namespaces should be given empty string key. For\u001b[39m\n",
      "\u001b[33m            example, ::\u001b[39m\n",
      "\n",
      "\u001b[33m                namespaces = {{\"\": \"https://example.com\"}}\u001b[39m\n",
      "\n",
      "\u001b[33m        prefix : str, optional\u001b[39m\n",
      "\u001b[33m            Namespace prefix to be used for every element and/or attribute\u001b[39m\n",
      "\u001b[33m            in document. This should be one of the keys in ``namespaces``\u001b[39m\n",
      "\u001b[33m            dict.\u001b[39m\n",
      "\u001b[33m        encoding : str, default 'utf-8'\u001b[39m\n",
      "\u001b[33m            Encoding of the resulting document.\u001b[39m\n",
      "\u001b[33m        xml_declaration : bool, default True\u001b[39m\n",
      "\u001b[33m            Whether to include the XML declaration at start of document.\u001b[39m\n",
      "\u001b[33m        pretty_print : bool, default True\u001b[39m\n",
      "\u001b[33m            Whether output should be pretty printed with indentation and\u001b[39m\n",
      "\u001b[33m            line breaks.\u001b[39m\n",
      "\u001b[33m        parser : {{'lxml','etree'}}, default 'lxml'\u001b[39m\n",
      "\u001b[33m            Parser module to use for building of tree. Only 'lxml' and\u001b[39m\n",
      "\u001b[33m            'etree' are supported. With 'lxml', the ability to use XSLT\u001b[39m\n",
      "\u001b[33m            stylesheet is supported.\u001b[39m\n",
      "\u001b[33m        stylesheet : str, path object or file-like object, optional\u001b[39m\n",
      "\u001b[33m            A URL, file-like object, or a raw string containing an XSLT\u001b[39m\n",
      "\u001b[33m            script used to transform the raw XML output. Script should use\u001b[39m\n",
      "\u001b[33m            layout of elements and attributes from original output. This\u001b[39m\n",
      "\u001b[33m            argument requires ``lxml`` to be installed. Only XSLT 1.0\u001b[39m\n",
      "\u001b[33m            scripts and not later versions is currently supported.\u001b[39m\n",
      "\u001b[33m        {compression_options}\u001b[39m\n",
      "\n",
      "\u001b[33m            .. versionchanged:: 1.4.0 Zstandard support.\u001b[39m\n",
      "\n",
      "\u001b[33m        {storage_options}\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        None or str\u001b[39m\n",
      "\u001b[33m            If ``io`` is None, returns the resulting XML format as a\u001b[39m\n",
      "\u001b[33m            string. Otherwise returns None.\u001b[39m\n",
      "\n",
      "\u001b[33m        See Also\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        to_json : Convert the pandas object to a JSON string.\u001b[39m\n",
      "\u001b[33m        to_html : Convert DataFrame to a html.\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        >>> df = pd.DataFrame({{'shape': ['square', 'circle', 'triangle'],\u001b[39m\n",
      "\u001b[33m        ...                    'degrees': [360, 360, 180],\u001b[39m\n",
      "\u001b[33m        ...                    'sides': [4, np.nan, 3]}})\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.to_xml()  # doctest: +SKIP\u001b[39m\n",
      "\u001b[33m        <?xml version='1.0' encoding='utf-8'?>\u001b[39m\n",
      "\u001b[33m        <data>\u001b[39m\n",
      "\u001b[33m          <row>\u001b[39m\n",
      "\u001b[33m            <index>0</index>\u001b[39m\n",
      "\u001b[33m            <shape>square</shape>\u001b[39m\n",
      "\u001b[33m            <degrees>360</degrees>\u001b[39m\n",
      "\u001b[33m            <sides>4.0</sides>\u001b[39m\n",
      "\u001b[33m          </row>\u001b[39m\n",
      "\u001b[33m          <row>\u001b[39m\n",
      "\u001b[33m            <index>1</index>\u001b[39m\n",
      "\u001b[33m            <shape>circle</shape>\u001b[39m\n",
      "\u001b[33m            <degrees>360</degrees>\u001b[39m\n",
      "\u001b[33m            <sides/>\u001b[39m\n",
      "\u001b[33m          </row>\u001b[39m\n",
      "\u001b[33m          <row>\u001b[39m\n",
      "\u001b[33m            <index>2</index>\u001b[39m\n",
      "\u001b[33m            <shape>triangle</shape>\u001b[39m\n",
      "\u001b[33m            <degrees>180</degrees>\u001b[39m\n",
      "\u001b[33m            <sides>3.0</sides>\u001b[39m\n",
      "\u001b[33m          </row>\u001b[39m\n",
      "\u001b[33m        </data>\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.to_xml(attr_cols=[\u001b[39m\n",
      "\u001b[33m        ...           'index', 'shape', 'degrees', 'sides'\u001b[39m\n",
      "\u001b[33m        ...           ])  # doctest: +SKIP\u001b[39m\n",
      "\u001b[33m        <?xml version='1.0' encoding='utf-8'?>\u001b[39m\n",
      "\u001b[33m        <data>\u001b[39m\n",
      "\u001b[33m          <row index=\"0\" shape=\"square\" degrees=\"360\" sides=\"4.0\"/>\u001b[39m\n",
      "\u001b[33m          <row index=\"1\" shape=\"circle\" degrees=\"360\"/>\u001b[39m\n",
      "\u001b[33m          <row index=\"2\" shape=\"triangle\" degrees=\"180\" sides=\"3.0\"/>\u001b[39m\n",
      "\u001b[33m        </data>\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.to_xml(namespaces={{\"doc\": \"https://example.com\"}},\u001b[39m\n",
      "\u001b[33m        ...           prefix=\"doc\")  # doctest: +SKIP\u001b[39m\n",
      "\u001b[33m        <?xml version='1.0' encoding='utf-8'?>\u001b[39m\n",
      "\u001b[33m        <doc:data xmlns:doc=\"https://example.com\">\u001b[39m\n",
      "\u001b[33m          <doc:row>\u001b[39m\n",
      "\u001b[33m            <doc:index>0</doc:index>\u001b[39m\n",
      "\u001b[33m            <doc:shape>square</doc:shape>\u001b[39m\n",
      "\u001b[33m            <doc:degrees>360</doc:degrees>\u001b[39m\n",
      "\u001b[33m            <doc:sides>4.0</doc:sides>\u001b[39m\n",
      "\u001b[33m          </doc:row>\u001b[39m\n",
      "\u001b[33m          <doc:row>\u001b[39m\n",
      "\u001b[33m            <doc:index>1</doc:index>\u001b[39m\n",
      "\u001b[33m            <doc:shape>circle</doc:shape>\u001b[39m\n",
      "\u001b[33m            <doc:degrees>360</doc:degrees>\u001b[39m\n",
      "\u001b[33m            <doc:sides/>\u001b[39m\n",
      "\u001b[33m          </doc:row>\u001b[39m\n",
      "\u001b[33m          <doc:row>\u001b[39m\n",
      "\u001b[33m            <doc:index>2</doc:index>\u001b[39m\n",
      "\u001b[33m            <doc:shape>triangle</doc:shape>\u001b[39m\n",
      "\u001b[33m            <doc:degrees>180</doc:degrees>\u001b[39m\n",
      "\u001b[33m            <doc:sides>3.0</doc:sides>\u001b[39m\n",
      "\u001b[33m          </doc:row>\u001b[39m\n",
      "\u001b[33m        </doc:data>\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "\n",
      "        \u001b[38;5;28;01mfrom\u001b[39;00m pandas.io.formats.xml \u001b[38;5;28;01mimport\u001b[39;00m (\n",
      "            EtreeXMLFormatter,\n",
      "            LxmlXMLFormatter,\n",
      "        )\n",
      "\n",
      "        lxml = import_optional_dependency(\u001b[33m\"lxml.etree\"\u001b[39m, errors=\u001b[33m\"ignore\"\u001b[39m)\n",
      "\n",
      "        TreeBuilder: type[EtreeXMLFormatter | LxmlXMLFormatter]\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m parser == \u001b[33m\"lxml\"\u001b[39m:\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m lxml \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "                TreeBuilder = LxmlXMLFormatter\n",
      "            \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "                \u001b[38;5;28;01mraise\u001b[39;00m ImportError(\n",
      "                    \u001b[33m\"lxml not found, please install or use the etree parser.\"\u001b[39m\n",
      "                )\n",
      "\n",
      "        \u001b[38;5;28;01melif\u001b[39;00m parser == \u001b[33m\"etree\"\u001b[39m:\n",
      "            TreeBuilder = EtreeXMLFormatter\n",
      "\n",
      "        \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "            \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\u001b[33m\"Values for parser can only be lxml or etree.\"\u001b[39m)\n",
      "\n",
      "        xml_formatter = TreeBuilder(\n",
      "            self,\n",
      "            path_or_buffer=path_or_buffer,\n",
      "            index=index,\n",
      "            root_name=root_name,\n",
      "            row_name=row_name,\n",
      "            na_rep=na_rep,\n",
      "            attr_cols=attr_cols,\n",
      "            elem_cols=elem_cols,\n",
      "            namespaces=namespaces,\n",
      "            prefix=prefix,\n",
      "            encoding=encoding,\n",
      "            xml_declaration=xml_declaration,\n",
      "            pretty_print=pretty_print,\n",
      "            stylesheet=stylesheet,\n",
      "            compression=compression,\n",
      "            storage_options=storage_options,\n",
      "        )\n",
      "\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m xml_formatter.write_output()\n",
      "\n",
      "    \u001b[38;5;66;03m# ----------------------------------------------------------------------\u001b[39;00m\n",
      "    @doc(INFO_DOCSTRING, **frame_sub_kwargs)\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m info(\n",
      "        self,\n",
      "        verbose: bool | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        buf: WriteBuffer[str] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        max_cols: int | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        memory_usage: bool | str | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        show_counts: bool | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        info = DataFrameInfo(\n",
      "            data=self,\n",
      "            memory_usage=memory_usage,\n",
      "        )\n",
      "        info.render(\n",
      "            buf=buf,\n",
      "            max_cols=max_cols,\n",
      "            verbose=verbose,\n",
      "            show_counts=show_counts,\n",
      "        )\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m memory_usage(self, index: bool = \u001b[38;5;28;01mTrue\u001b[39;00m, deep: bool = \u001b[38;5;28;01mFalse\u001b[39;00m) -> Series:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Return the memory usage of each column in bytes.\u001b[39m\n",
      "\n",
      "\u001b[33m        The memory usage can optionally include the contribution of\u001b[39m\n",
      "\u001b[33m        the index and elements of `object` dtype.\u001b[39m\n",
      "\n",
      "\u001b[33m        This value is displayed in `DataFrame.info` by default. This can be\u001b[39m\n",
      "\u001b[33m        suppressed by setting ``pandas.options.display.memory_usage`` to False.\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        index : bool, default True\u001b[39m\n",
      "\u001b[33m            Specifies whether to include the memory usage of the DataFrame's\u001b[39m\n",
      "\u001b[33m            index in returned Series. If ``index=True``, the memory usage of\u001b[39m\n",
      "\u001b[33m            the index is the first item in the output.\u001b[39m\n",
      "\u001b[33m        deep : bool, default False\u001b[39m\n",
      "\u001b[33m            If True, introspect the data deeply by interrogating\u001b[39m\n",
      "\u001b[33m            `object` dtypes for system-level memory consumption, and include\u001b[39m\n",
      "\u001b[33m            it in the returned values.\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        Series\u001b[39m\n",
      "\u001b[33m            A Series whose index is the original column names and whose values\u001b[39m\n",
      "\u001b[33m            is the memory usage of each column in bytes.\u001b[39m\n",
      "\n",
      "\u001b[33m        See Also\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        numpy.ndarray.nbytes : Total bytes consumed by the elements of an\u001b[39m\n",
      "\u001b[33m            ndarray.\u001b[39m\n",
      "\u001b[33m        Series.memory_usage : Bytes consumed by a Series.\u001b[39m\n",
      "\u001b[33m        Categorical : Memory-efficient array for string values with\u001b[39m\n",
      "\u001b[33m            many repeated values.\u001b[39m\n",
      "\u001b[33m        DataFrame.info : Concise summary of a DataFrame.\u001b[39m\n",
      "\n",
      "\u001b[33m        Notes\u001b[39m\n",
      "\u001b[33m        -----\u001b[39m\n",
      "\u001b[33m        See the :ref:`Frequently Asked Questions <df-memory-usage>` for more\u001b[39m\n",
      "\u001b[33m        details.\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        >>> dtypes = ['int64', 'float64', 'complex128', 'object', 'bool']\u001b[39m\n",
      "\u001b[33m        >>> data = dict([(t, np.ones(shape=5000, dtype=int).astype(t))\u001b[39m\n",
      "\u001b[33m        ...              for t in dtypes])\u001b[39m\n",
      "\u001b[33m        >>> df = pd.DataFrame(data)\u001b[39m\n",
      "\u001b[33m        >>> df.head()\u001b[39m\n",
      "\u001b[33m           int64  float64            complex128  object  bool\u001b[39m\n",
      "\u001b[33m        0      1      1.0              1.0+0.0j       1  True\u001b[39m\n",
      "\u001b[33m        1      1      1.0              1.0+0.0j       1  True\u001b[39m\n",
      "\u001b[33m        2      1      1.0              1.0+0.0j       1  True\u001b[39m\n",
      "\u001b[33m        3      1      1.0              1.0+0.0j       1  True\u001b[39m\n",
      "\u001b[33m        4      1      1.0              1.0+0.0j       1  True\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.memory_usage()\u001b[39m\n",
      "\u001b[33m        Index           128\u001b[39m\n",
      "\u001b[33m        int64         40000\u001b[39m\n",
      "\u001b[33m        float64       40000\u001b[39m\n",
      "\u001b[33m        complex128    80000\u001b[39m\n",
      "\u001b[33m        object        40000\u001b[39m\n",
      "\u001b[33m        bool           5000\u001b[39m\n",
      "\u001b[33m        dtype: int64\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.memory_usage(index=False)\u001b[39m\n",
      "\u001b[33m        int64         40000\u001b[39m\n",
      "\u001b[33m        float64       40000\u001b[39m\n",
      "\u001b[33m        complex128    80000\u001b[39m\n",
      "\u001b[33m        object        40000\u001b[39m\n",
      "\u001b[33m        bool           5000\u001b[39m\n",
      "\u001b[33m        dtype: int64\u001b[39m\n",
      "\n",
      "\u001b[33m        The memory footprint of `object` dtype columns is ignored by default:\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.memory_usage(deep=True)\u001b[39m\n",
      "\u001b[33m        Index            128\u001b[39m\n",
      "\u001b[33m        int64          40000\u001b[39m\n",
      "\u001b[33m        float64        40000\u001b[39m\n",
      "\u001b[33m        complex128     80000\u001b[39m\n",
      "\u001b[33m        object        180000\u001b[39m\n",
      "\u001b[33m        bool            5000\u001b[39m\n",
      "\u001b[33m        dtype: int64\u001b[39m\n",
      "\n",
      "\u001b[33m        Use a Categorical for efficient storage of an object-dtype column with\u001b[39m\n",
      "\u001b[33m        many repeated values.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df['object'].astype('category').memory_usage(deep=True)\u001b[39m\n",
      "\u001b[33m        5244\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        result = self._constructor_sliced(\n",
      "            [c.memory_usage(index=\u001b[38;5;28;01mFalse\u001b[39;00m, deep=deep) \u001b[38;5;28;01mfor\u001b[39;00m col, c \u001b[38;5;28;01min\u001b[39;00m self.items()],\n",
      "            index=self.columns,\n",
      "            dtype=np.intp,\n",
      "        )\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m index:\n",
      "            index_memory_usage = self._constructor_sliced(\n",
      "                self.index.memory_usage(deep=deep), index=[\u001b[33m\"Index\"\u001b[39m]\n",
      "            )\n",
      "            result = index_memory_usage._append(result)\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m transpose(self, *args, copy: bool = \u001b[38;5;28;01mFalse\u001b[39;00m) -> DataFrame:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Transpose index and columns.\u001b[39m\n",
      "\n",
      "\u001b[33m        Reflect the DataFrame over its main diagonal by writing rows as columns\u001b[39m\n",
      "\u001b[33m        and vice-versa. The property :attr:`.T` is an accessor to the method\u001b[39m\n",
      "\u001b[33m        :meth:`transpose`.\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        *args : tuple, optional\u001b[39m\n",
      "\u001b[33m            Accepted for compatibility with NumPy.\u001b[39m\n",
      "\u001b[33m        copy : bool, default False\u001b[39m\n",
      "\u001b[33m            Whether to copy the data after transposing, even for DataFrames\u001b[39m\n",
      "\u001b[33m            with a single dtype.\u001b[39m\n",
      "\n",
      "\u001b[33m            Note that a copy is always required for mixed dtype DataFrames,\u001b[39m\n",
      "\u001b[33m            or for DataFrames with any extension types.\u001b[39m\n",
      "\n",
      "\u001b[33m            .. note::\u001b[39m\n",
      "\u001b[33m                The `copy` keyword will change behavior in pandas 3.0.\u001b[39m\n",
      "\u001b[33m                `Copy-on-Write\u001b[39m\n",
      "\u001b[33m                <https://pandas.pydata.org/docs/dev/user_guide/copy_on_write.html>`__\u001b[39m\n",
      "\u001b[33m                will be enabled by default, which means that all methods with a\u001b[39m\n",
      "\u001b[33m                `copy` keyword will use a lazy copy mechanism to defer the copy and\u001b[39m\n",
      "\u001b[33m                ignore the `copy` keyword. The `copy` keyword will be removed in a\u001b[39m\n",
      "\u001b[33m                future version of pandas.\u001b[39m\n",
      "\n",
      "\u001b[33m                You can already get the future behavior and improvements through\u001b[39m\n",
      "\u001b[33m                enabling copy on write ``pd.options.mode.copy_on_write = True``\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        DataFrame\u001b[39m\n",
      "\u001b[33m            The transposed DataFrame.\u001b[39m\n",
      "\n",
      "\u001b[33m        See Also\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        numpy.transpose : Permute the dimensions of a given array.\u001b[39m\n",
      "\n",
      "\u001b[33m        Notes\u001b[39m\n",
      "\u001b[33m        -----\u001b[39m\n",
      "\u001b[33m        Transposing a DataFrame with mixed dtypes will result in a homogeneous\u001b[39m\n",
      "\u001b[33m        DataFrame with the `object` dtype. In such a case, a copy of the data\u001b[39m\n",
      "\u001b[33m        is always made.\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        **Square DataFrame with homogeneous dtype**\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> d1 = {'col1': [1, 2], 'col2': [3, 4]}\u001b[39m\n",
      "\u001b[33m        >>> df1 = pd.DataFrame(data=d1)\u001b[39m\n",
      "\u001b[33m        >>> df1\u001b[39m\n",
      "\u001b[33m           col1  col2\u001b[39m\n",
      "\u001b[33m        0     1     3\u001b[39m\n",
      "\u001b[33m        1     2     4\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df1_transposed = df1.T  # or df1.transpose()\u001b[39m\n",
      "\u001b[33m        >>> df1_transposed\u001b[39m\n",
      "\u001b[33m              0  1\u001b[39m\n",
      "\u001b[33m        col1  1  2\u001b[39m\n",
      "\u001b[33m        col2  3  4\u001b[39m\n",
      "\n",
      "\u001b[33m        When the dtype is homogeneous in the original DataFrame, we get a\u001b[39m\n",
      "\u001b[33m        transposed DataFrame with the same dtype:\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df1.dtypes\u001b[39m\n",
      "\u001b[33m        col1    int64\u001b[39m\n",
      "\u001b[33m        col2    int64\u001b[39m\n",
      "\u001b[33m        dtype: object\u001b[39m\n",
      "\u001b[33m        >>> df1_transposed.dtypes\u001b[39m\n",
      "\u001b[33m        0    int64\u001b[39m\n",
      "\u001b[33m        1    int64\u001b[39m\n",
      "\u001b[33m        dtype: object\u001b[39m\n",
      "\n",
      "\u001b[33m        **Non-square DataFrame with mixed dtypes**\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> d2 = {'name': ['Alice', 'Bob'],\u001b[39m\n",
      "\u001b[33m        ...       'score': [9.5, 8],\u001b[39m\n",
      "\u001b[33m        ...       'employed': [False, True],\u001b[39m\n",
      "\u001b[33m        ...       'kids': [0, 0]}\u001b[39m\n",
      "\u001b[33m        >>> df2 = pd.DataFrame(data=d2)\u001b[39m\n",
      "\u001b[33m        >>> df2\u001b[39m\n",
      "\u001b[33m            name  score  employed  kids\u001b[39m\n",
      "\u001b[33m        0  Alice    9.5     False     0\u001b[39m\n",
      "\u001b[33m        1    Bob    8.0      True     0\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df2_transposed = df2.T  # or df2.transpose()\u001b[39m\n",
      "\u001b[33m        >>> df2_transposed\u001b[39m\n",
      "\u001b[33m                      0     1\u001b[39m\n",
      "\u001b[33m        name      Alice   Bob\u001b[39m\n",
      "\u001b[33m        score       9.5   8.0\u001b[39m\n",
      "\u001b[33m        employed  False  True\u001b[39m\n",
      "\u001b[33m        kids          0     0\u001b[39m\n",
      "\n",
      "\u001b[33m        When the DataFrame has mixed dtypes, we get a transposed DataFrame with\u001b[39m\n",
      "\u001b[33m        the `object` dtype:\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df2.dtypes\u001b[39m\n",
      "\u001b[33m        name         object\u001b[39m\n",
      "\u001b[33m        score       float64\u001b[39m\n",
      "\u001b[33m        employed       bool\u001b[39m\n",
      "\u001b[33m        kids          int64\u001b[39m\n",
      "\u001b[33m        dtype: object\u001b[39m\n",
      "\u001b[33m        >>> df2_transposed.dtypes\u001b[39m\n",
      "\u001b[33m        0    object\u001b[39m\n",
      "\u001b[33m        1    object\u001b[39m\n",
      "\u001b[33m        dtype: object\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        nv.validate_transpose(args, {})\n",
      "        \u001b[38;5;66;03m# construct the args\u001b[39;00m\n",
      "\n",
      "        dtypes = list(self.dtypes)\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m self._can_fast_transpose:\n",
      "            \u001b[38;5;66;03m# Note: tests pass without this, but this improves perf quite a bit.\u001b[39;00m\n",
      "            new_vals = self._values.T\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01mand\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m using_copy_on_write():\n",
      "                new_vals = new_vals.copy()\n",
      "\n",
      "            result = self._constructor(\n",
      "                new_vals,\n",
      "                index=self.columns,\n",
      "                columns=self.index,\n",
      "                copy=\u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "                dtype=new_vals.dtype,\n",
      "            )\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m using_copy_on_write() \u001b[38;5;28;01mand\u001b[39;00m len(self) > \u001b[32m0\u001b[39m:\n",
      "                result._mgr.add_references(self._mgr)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\n",
      "        \u001b[38;5;28;01melif\u001b[39;00m (\n",
      "            self._is_homogeneous_type\n",
      "            \u001b[38;5;28;01mand\u001b[39;00m dtypes\n",
      "            \u001b[38;5;28;01mand\u001b[39;00m isinstance(dtypes[\u001b[32m0\u001b[39m], ExtensionDtype)\n",
      "        ):\n",
      "            new_values: list\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m isinstance(dtypes[\u001b[32m0\u001b[39m], BaseMaskedDtype):\n",
      "                \u001b[38;5;66;03m# We have masked arrays with the same dtype. We can transpose faster.\u001b[39;00m\n",
      "                \u001b[38;5;28;01mfrom\u001b[39;00m pandas.core.arrays.masked \u001b[38;5;28;01mimport\u001b[39;00m (\n",
      "                    transpose_homogeneous_masked_arrays,\n",
      "                )\n",
      "\n",
      "                new_values = transpose_homogeneous_masked_arrays(\n",
      "                    cast(Sequence[BaseMaskedArray], self._iter_column_arrays())\n",
      "                )\n",
      "            \u001b[38;5;28;01melif\u001b[39;00m isinstance(dtypes[\u001b[32m0\u001b[39m], ArrowDtype):\n",
      "                \u001b[38;5;66;03m# We have arrow EAs with the same dtype. We can transpose faster.\u001b[39;00m\n",
      "                \u001b[38;5;28;01mfrom\u001b[39;00m pandas.core.arrays.arrow.array \u001b[38;5;28;01mimport\u001b[39;00m (\n",
      "                    ArrowExtensionArray,\n",
      "                    transpose_homogeneous_pyarrow,\n",
      "                )\n",
      "\n",
      "                new_values = transpose_homogeneous_pyarrow(\n",
      "                    cast(Sequence[ArrowExtensionArray], self._iter_column_arrays())\n",
      "                )\n",
      "            \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "                \u001b[38;5;66;03m# We have other EAs with the same dtype. We preserve dtype in transpose.\u001b[39;00m\n",
      "                dtyp = dtypes[\u001b[32m0\u001b[39m]\n",
      "                arr_typ = dtyp.construct_array_type()\n",
      "                values = self.values\n",
      "                new_values = [arr_typ._from_sequence(row, dtype=dtyp) \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;28;01min\u001b[39;00m values]\n",
      "\n",
      "            result = type(self)._from_arrays(\n",
      "                new_values,\n",
      "                index=self.columns,\n",
      "                columns=self.index,\n",
      "                verify_integrity=\u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "            )\n",
      "\n",
      "        \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "            new_arr = self.values.T\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01mand\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m using_copy_on_write():\n",
      "                new_arr = new_arr.copy()\n",
      "            result = self._constructor(\n",
      "                new_arr,\n",
      "                index=self.columns,\n",
      "                columns=self.index,\n",
      "                dtype=new_arr.dtype,\n",
      "                \u001b[38;5;66;03m# We already made a copy (more than one block)\u001b[39;00m\n",
      "                copy=\u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "            )\n",
      "\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m result.__finalize__(self, method=\u001b[33m\"transpose\"\u001b[39m)\n",
      "\n",
      "    @property\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m T(self) -> DataFrame:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        The transpose of the DataFrame.\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        DataFrame\u001b[39m\n",
      "\u001b[33m            The transposed DataFrame.\u001b[39m\n",
      "\n",
      "\u001b[33m        See Also\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        DataFrame.transpose : Transpose index and columns.\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})\u001b[39m\n",
      "\u001b[33m        >>> df\u001b[39m\n",
      "\u001b[33m           col1  col2\u001b[39m\n",
      "\u001b[33m        0     1     3\u001b[39m\n",
      "\u001b[33m        1     2     4\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.T\u001b[39m\n",
      "\u001b[33m              0  1\u001b[39m\n",
      "\u001b[33m        col1  1  2\u001b[39m\n",
      "\u001b[33m        col2  3  4\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m self.transpose()\n",
      "\n",
      "    \u001b[38;5;66;03m# ----------------------------------------------------------------------\u001b[39;00m\n",
      "    \u001b[38;5;66;03m# Indexing Methods\u001b[39;00m\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m _ixs(self, i: int, axis: AxisInt = \u001b[32m0\u001b[39m) -> Series:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        i : int\u001b[39m\n",
      "\u001b[33m        axis : int\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        Series\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;66;03m# irow\u001b[39;00m\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m axis == \u001b[32m0\u001b[39m:\n",
      "            new_mgr = self._mgr.fast_xs(i)\n",
      "\n",
      "            \u001b[38;5;66;03m# if we are a copy, mark as such\u001b[39;00m\n",
      "            copy = isinstance(new_mgr.array, np.ndarray) \u001b[38;5;28;01mand\u001b[39;00m new_mgr.array.base \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "            result = self._constructor_sliced_from_mgr(new_mgr, axes=new_mgr.axes)\n",
      "            result._name = self.index[i]\n",
      "            result = result.__finalize__(self)\n",
      "            result._set_is_copy(self, copy=copy)\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\n",
      "        \u001b[38;5;66;03m# icol\u001b[39;00m\n",
      "        \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "            label = self.columns[i]\n",
      "\n",
      "            col_mgr = self._mgr.iget(i)\n",
      "            result = self._box_col_values(col_mgr, i)\n",
      "\n",
      "            \u001b[38;5;66;03m# this is a cached value, mark it so\u001b[39;00m\n",
      "            result._set_as_cached(label, self)\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m _get_column_array(self, i: int) -> ArrayLike:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Get the values of the i'th column (ndarray or ExtensionArray, as stored\u001b[39m\n",
      "\u001b[33m        in the Block)\u001b[39m\n",
      "\n",
      "\u001b[33m        Warning! The returned array is a view but doesn't handle Copy-on-Write,\u001b[39m\n",
      "\u001b[33m        so this should be used with caution (for read-only purposes).\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m self._mgr.iget_values(i)\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m _iter_column_arrays(self) -> Iterator[ArrayLike]:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Iterate over the arrays of all columns in order.\u001b[39m\n",
      "\u001b[33m        This returns the values as stored in the Block (ndarray or ExtensionArray).\u001b[39m\n",
      "\n",
      "\u001b[33m        Warning! The returned array is a view but doesn't handle Copy-on-Write,\u001b[39m\n",
      "\u001b[33m        so this should be used with caution (for read-only purposes).\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m isinstance(self._mgr, ArrayManager):\n",
      "            \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m self._mgr.arrays\n",
      "        \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "            \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;28;01min\u001b[39;00m range(len(self.columns)):\n",
      "                \u001b[38;5;28;01myield\u001b[39;00m self._get_column_array(i)\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m _getitem_nocopy(self, key: list):\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Behaves like __getitem__, but returns a view in cases where __getitem__\u001b[39m\n",
      "\u001b[33m        would make a copy.\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;66;03m# TODO(CoW): can be removed if/when we are always Copy-on-Write\u001b[39;00m\n",
      "        indexer = self.columns._get_indexer_strict(key, \u001b[33m\"columns\"\u001b[39m)[\u001b[32m1\u001b[39m]\n",
      "        new_axis = self.columns[indexer]\n",
      "\n",
      "        new_mgr = self._mgr.reindex_indexer(\n",
      "            new_axis,\n",
      "            indexer,\n",
      "            axis=\u001b[32m0\u001b[39m,\n",
      "            allow_dups=\u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "            copy=\u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "            only_slice=\u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "        )\n",
      "        result = self._constructor_from_mgr(new_mgr, axes=new_mgr.axes)\n",
      "        result = result.__finalize__(self)\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m __getitem__(self, key):\n",
      "        check_dict_or_set_indexers(key)\n",
      "        key = lib.item_from_zerodim(key)\n",
      "        key = com.apply_if_callable(key, self)\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key) \u001b[38;5;28;01mand\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m is_iterator(key):\n",
      "            \u001b[38;5;66;03m# is_iterator to exclude generator e.g. test_getitem_listlike\u001b[39;00m\n",
      "            \u001b[38;5;66;03m# shortcut if the key is in columns\u001b[39;00m\n",
      "            is_mi = isinstance(self.columns, MultiIndex)\n",
      "            \u001b[38;5;66;03m# GH#45316 Return view if key is not duplicated\u001b[39;00m\n",
      "            \u001b[38;5;66;03m# Only use drop_duplicates with duplicates for performance\u001b[39;00m\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m is_mi \u001b[38;5;28;01mand\u001b[39;00m (\n",
      "                self.columns.is_unique\n",
      "                \u001b[38;5;28;01mand\u001b[39;00m key \u001b[38;5;28;01min\u001b[39;00m self.columns\n",
      "                \u001b[38;5;28;01mor\u001b[39;00m key \u001b[38;5;28;01min\u001b[39;00m self.columns.drop_duplicates(keep=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "            ):\n",
      "                \u001b[38;5;28;01mreturn\u001b[39;00m self._get_item_cache(key)\n",
      "\n",
      "            \u001b[38;5;28;01melif\u001b[39;00m is_mi \u001b[38;5;28;01mand\u001b[39;00m self.columns.is_unique \u001b[38;5;28;01mand\u001b[39;00m key \u001b[38;5;28;01min\u001b[39;00m self.columns:\n",
      "                \u001b[38;5;28;01mreturn\u001b[39;00m self._getitem_multilevel(key)\n",
      "\n",
      "        \u001b[38;5;66;03m# Do we have a slicer (on rows)?\u001b[39;00m\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m isinstance(key, slice):\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m self._getitem_slice(key)\n",
      "\n",
      "        \u001b[38;5;66;03m# Do we have a (boolean) DataFrame?\u001b[39;00m\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m isinstance(key, DataFrame):\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m self.where(key)\n",
      "\n",
      "        \u001b[38;5;66;03m# Do we have a (boolean) 1d indexer?\u001b[39;00m\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m com.is_bool_indexer(key):\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m self._getitem_bool_array(key)\n",
      "\n",
      "        \u001b[38;5;66;03m# We are left with two options: a single key, and a collection of keys,\u001b[39;00m\n",
      "        \u001b[38;5;66;03m# We interpret tuples as collections only for non-MultiIndex\u001b[39;00m\n",
      "        is_single_key = isinstance(key, tuple) \u001b[38;5;28;01mor\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m is_list_like(key)\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m is_single_key:\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m self.columns.nlevels > \u001b[32m1\u001b[39m:\n",
      "                \u001b[38;5;28;01mreturn\u001b[39;00m self._getitem_multilevel(key)\n",
      "            indexer = self.columns.get_loc(key)\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n",
      "                indexer = [indexer]\n",
      "        \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "                key = list(key)\n",
      "            indexer = self.columns._get_indexer_strict(key, \u001b[33m\"columns\"\u001b[39m)[\u001b[32m1\u001b[39m]\n",
      "\n",
      "        \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m getattr(indexer, \u001b[33m\"dtype\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == bool:\n",
      "            indexer = np.where(indexer)[\u001b[32m0\u001b[39m]\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m isinstance(indexer, slice):\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m self._slice(indexer, axis=\u001b[32m1\u001b[39m)\n",
      "\n",
      "        data = self._take_with_is_copy(indexer, axis=\u001b[32m1\u001b[39m)\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m is_single_key:\n",
      "            \u001b[38;5;66;03m# What does looking for a single key in a non-unique index return?\u001b[39;00m\n",
      "            \u001b[38;5;66;03m# The behavior is inconsistent. It returns a Series, except when\u001b[39;00m\n",
      "            \u001b[38;5;66;03m# - the key itself is repeated (test on data.shape, #9519), or\u001b[39;00m\n",
      "            \u001b[38;5;66;03m# - we have a MultiIndex on columns (test on self.columns, #21309)\u001b[39;00m\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m data.shape[\u001b[32m1\u001b[39m] == \u001b[32m1\u001b[39m \u001b[38;5;28;01mand\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m isinstance(self.columns, MultiIndex):\n",
      "                \u001b[38;5;66;03m# GH#26490 using data[key] can cause RecursionError\u001b[39;00m\n",
      "                \u001b[38;5;28;01mreturn\u001b[39;00m data._get_item_cache(key)\n",
      "\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m _getitem_bool_array(self, key):\n",
      "        \u001b[38;5;66;03m# also raises Exception if object array with NA values\u001b[39;00m\n",
      "        \u001b[38;5;66;03m# warning here just in case -- previously __setitem__ was\u001b[39;00m\n",
      "        \u001b[38;5;66;03m# reindexing but __getitem__ was not; it seems more reasonable to\u001b[39;00m\n",
      "        \u001b[38;5;66;03m# go with the __setitem__ behavior since that is more consistent\u001b[39;00m\n",
      "        \u001b[38;5;66;03m# with all other indexing behavior\u001b[39;00m\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m isinstance(key, Series) \u001b[38;5;28;01mand\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m key.index.equals(self.index):\n",
      "            warnings.warn(\n",
      "                \u001b[33m\"Boolean Series key will be reindexed to match DataFrame index.\"\u001b[39m,\n",
      "                UserWarning,\n",
      "                stacklevel=find_stack_level(),\n",
      "            )\n",
      "        \u001b[38;5;28;01melif\u001b[39;00m len(key) != len(self.index):\n",
      "            \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\n",
      "                \u001b[33mf\"Item wrong length {len(key)} instead of {len(self.index)}.\"\u001b[39m\n",
      "            )\n",
      "\n",
      "        \u001b[38;5;66;03m# check_bool_indexer will throw exception if Series key cannot\u001b[39;00m\n",
      "        \u001b[38;5;66;03m# be reindexed to match DataFrame rows\u001b[39;00m\n",
      "        key = check_bool_indexer(self.index, key)\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m key.all():\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m self.copy(deep=\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\n",
      "        indexer = key.nonzero()[\u001b[32m0\u001b[39m]\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m self._take_with_is_copy(indexer, axis=\u001b[32m0\u001b[39m)\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m _getitem_multilevel(self, key):\n",
      "        \u001b[38;5;66;03m# self.columns is a MultiIndex\u001b[39;00m\n",
      "        loc = self.columns.get_loc(key)\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m isinstance(loc, (slice, np.ndarray)):\n",
      "            new_columns = self.columns[loc]\n",
      "            result_columns = maybe_droplevels(new_columns, key)\n",
      "            result = self.iloc[:, loc]\n",
      "            result.columns = result_columns\n",
      "\n",
      "            \u001b[38;5;66;03m# If there is only one column being returned, and its name is\u001b[39;00m\n",
      "            \u001b[38;5;66;03m# either an empty string, or a tuple with an empty string as its\u001b[39;00m\n",
      "            \u001b[38;5;66;03m# first element, then treat the empty string as a placeholder\u001b[39;00m\n",
      "            \u001b[38;5;66;03m# and return the column as if the user had provided that empty\u001b[39;00m\n",
      "            \u001b[38;5;66;03m# string in the key. If the result is a Series, exclude the\u001b[39;00m\n",
      "            \u001b[38;5;66;03m# implied empty string from its name.\u001b[39;00m\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m len(result.columns) == \u001b[32m1\u001b[39m:\n",
      "                \u001b[38;5;66;03m# e.g. test_frame_getitem_multicolumn_empty_level,\u001b[39;00m\n",
      "                \u001b[38;5;66;03m#  test_frame_mixed_depth_get, test_loc_setitem_single_column_slice\u001b[39;00m\n",
      "                top = result.columns[\u001b[32m0\u001b[39m]\n",
      "                \u001b[38;5;28;01mif\u001b[39;00m isinstance(top, tuple):\n",
      "                    top = top[\u001b[32m0\u001b[39m]\n",
      "                \u001b[38;5;28;01mif\u001b[39;00m top == \u001b[33m\"\"\u001b[39m:\n",
      "                    result = result[\u001b[33m\"\"\u001b[39m]\n",
      "                    \u001b[38;5;28;01mif\u001b[39;00m isinstance(result, Series):\n",
      "                        result = self._constructor_sliced(\n",
      "                            result, index=self.index, name=key\n",
      "                        )\n",
      "\n",
      "            result._set_is_copy(self)\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "        \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "            \u001b[38;5;66;03m# loc is neither a slice nor ndarray, so must be an int\u001b[39;00m\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m self._ixs(loc, axis=\u001b[32m1\u001b[39m)\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m _get_value(self, index, col, takeable: bool = \u001b[38;5;28;01mFalse\u001b[39;00m) -> Scalar:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Quickly retrieve single value at passed column and index.\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        index : row label\u001b[39m\n",
      "\u001b[33m        col : column label\u001b[39m\n",
      "\u001b[33m        takeable : interpret the index/col as indexers, default False\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        scalar\u001b[39m\n",
      "\n",
      "\u001b[33m        Notes\u001b[39m\n",
      "\u001b[33m        -----\u001b[39m\n",
      "\u001b[33m        Assumes that both `self.index._index_as_unique` and\u001b[39m\n",
      "\u001b[33m        `self.columns._index_as_unique`; Caller is responsible for checking.\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m takeable:\n",
      "            series = self._ixs(col, axis=\u001b[32m1\u001b[39m)\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m series._values[index]\n",
      "\n",
      "        series = self._get_item_cache(col)\n",
      "        engine = self.index._engine\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m isinstance(self.index, MultiIndex):\n",
      "            \u001b[38;5;66;03m# CategoricalIndex: Trying to use the engine fastpath may give incorrect\u001b[39;00m\n",
      "            \u001b[38;5;66;03m#  results if our categories are integers that dont match our codes\u001b[39;00m\n",
      "            \u001b[38;5;66;03m# IntervalIndex: IntervalTree has no get_loc\u001b[39;00m\n",
      "            row = self.index.get_loc(index)\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m series._values[row]\n",
      "\n",
      "        \u001b[38;5;66;03m# For MultiIndex going through engine effectively restricts us to\u001b[39;00m\n",
      "        \u001b[38;5;66;03m#  same-length tuples; see test_get_set_value_no_partial_indexing\u001b[39;00m\n",
      "        loc = engine.get_loc(index)\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m series._values[loc]\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m isetitem(self, loc, value) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Set the given value in the column with position `loc`.\u001b[39m\n",
      "\n",
      "\u001b[33m        This is a positional analogue to ``__setitem__``.\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        loc : int or sequence of ints\u001b[39m\n",
      "\u001b[33m            Index position for the column.\u001b[39m\n",
      "\u001b[33m        value : scalar or arraylike\u001b[39m\n",
      "\u001b[33m            Value(s) for the column.\u001b[39m\n",
      "\n",
      "\u001b[33m        Notes\u001b[39m\n",
      "\u001b[33m        -----\u001b[39m\n",
      "\u001b[33m        ``frame.isetitem(loc, value)`` is an in-place method as it will\u001b[39m\n",
      "\u001b[33m        modify the DataFrame in place (not returning a new object). In contrast to\u001b[39m\n",
      "\u001b[33m        ``frame.iloc[:, i] = value`` which will try to update the existing values in\u001b[39m\n",
      "\u001b[33m        place, ``frame.isetitem(loc, value)`` will not update the values of the column\u001b[39m\n",
      "\u001b[33m        itself in place, it will instead insert a new array.\u001b[39m\n",
      "\n",
      "\u001b[33m        In cases where ``frame.columns`` is unique, this is equivalent to\u001b[39m\n",
      "\u001b[33m        ``frame[frame.columns[i]] = value``.\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m isinstance(value, DataFrame):\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n",
      "                loc = [loc]\n",
      "\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m len(loc) != len(value.columns):\n",
      "                \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\n",
      "                    \u001b[33mf\"Got {len(loc)} positions but value has {len(value.columns)} \"\u001b[39m\n",
      "                    \u001b[33mf\"columns.\"\u001b[39m\n",
      "                )\n",
      "\n",
      "            \u001b[38;5;28;01mfor\u001b[39;00m i, idx \u001b[38;5;28;01min\u001b[39;00m enumerate(loc):\n",
      "                arraylike, refs = self._sanitize_column(value.iloc[:, i])\n",
      "                self._iset_item_mgr(idx, arraylike, inplace=\u001b[38;5;28;01mFalse\u001b[39;00m, refs=refs)\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\n",
      "        arraylike, refs = self._sanitize_column(value)\n",
      "        self._iset_item_mgr(loc, arraylike, inplace=\u001b[38;5;28;01mFalse\u001b[39;00m, refs=refs)\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m __setitem__(self, key, value) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m PYPY \u001b[38;5;28;01mand\u001b[39;00m using_copy_on_write():\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m sys.getrefcount(self) <= \u001b[32m3\u001b[39m:\n",
      "                warnings.warn(\n",
      "                    _chained_assignment_msg, ChainedAssignmentError, stacklevel=\u001b[32m2\u001b[39m\n",
      "                )\n",
      "        \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m PYPY \u001b[38;5;28;01mand\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m using_copy_on_write():\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m sys.getrefcount(self) <= \u001b[32m3\u001b[39m \u001b[38;5;28;01mand\u001b[39;00m (\n",
      "                warn_copy_on_write()\n",
      "                \u001b[38;5;28;01mor\u001b[39;00m (\n",
      "                    \u001b[38;5;28;01mnot\u001b[39;00m warn_copy_on_write()\n",
      "                    \u001b[38;5;28;01mand\u001b[39;00m any(b.refs.has_reference() \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;28;01min\u001b[39;00m self._mgr.blocks)  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n",
      "                )\n",
      "            ):\n",
      "                warnings.warn(\n",
      "                    _chained_assignment_warning_msg, FutureWarning, stacklevel=\u001b[32m2\u001b[39m\n",
      "                )\n",
      "\n",
      "        key = com.apply_if_callable(key, self)\n",
      "\n",
      "        \u001b[38;5;66;03m# see if we can slice the rows\u001b[39;00m\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m isinstance(key, slice):\n",
      "            slc = self.index._convert_slice_indexer(key, kind=\u001b[33m\"getitem\"\u001b[39m)\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m self._setitem_slice(slc, value)\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m isinstance(key, DataFrame) \u001b[38;5;28;01mor\u001b[39;00m getattr(key, \u001b[33m\"ndim\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[32m2\u001b[39m:\n",
      "            self._setitem_frame(key, value)\n",
      "        \u001b[38;5;28;01melif\u001b[39;00m isinstance(key, (Series, np.ndarray, list, Index)):\n",
      "            self._setitem_array(key, value)\n",
      "        \u001b[38;5;28;01melif\u001b[39;00m isinstance(value, DataFrame):\n",
      "            self._set_item_frame_value(key, value)\n",
      "        \u001b[38;5;28;01melif\u001b[39;00m (\n",
      "            is_list_like(value)\n",
      "            \u001b[38;5;28;01mand\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m self.columns.is_unique\n",
      "            \u001b[38;5;28;01mand\u001b[39;00m \u001b[32m1\u001b[39m < len(self.columns.get_indexer_for([key])) == len(value)\n",
      "        ):\n",
      "            \u001b[38;5;66;03m# Column to set is duplicated\u001b[39;00m\n",
      "            self._setitem_array([key], value)\n",
      "        \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "            \u001b[38;5;66;03m# set column\u001b[39;00m\n",
      "            self._set_item(key, value)\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m _setitem_slice(self, key: slice, value) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        \u001b[38;5;66;03m# NB: we can't just use self.loc[key] = value because that\u001b[39;00m\n",
      "        \u001b[38;5;66;03m#  operates on labels and we need to operate positional for\u001b[39;00m\n",
      "        \u001b[38;5;66;03m#  backwards-compat, xref GH#31469\u001b[39;00m\n",
      "        self._check_setitem_copy()\n",
      "        self.iloc[key] = value\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m _setitem_array(self, key, value):\n",
      "        \u001b[38;5;66;03m# also raises Exception if object array with NA values\u001b[39;00m\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m com.is_bool_indexer(key):\n",
      "            \u001b[38;5;66;03m# bool indexer is indexing along rows\u001b[39;00m\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m len(key) != len(self.index):\n",
      "                \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\n",
      "                    \u001b[33mf\"Item wrong length {len(key)} instead of {len(self.index)}!\"\u001b[39m\n",
      "                )\n",
      "            key = check_bool_indexer(self.index, key)\n",
      "            indexer = key.nonzero()[\u001b[32m0\u001b[39m]\n",
      "            self._check_setitem_copy()\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m isinstance(value, DataFrame):\n",
      "                \u001b[38;5;66;03m# GH#39931 reindex since iloc does not align\u001b[39;00m\n",
      "                value = value.reindex(self.index.take(indexer))\n",
      "            self.iloc[indexer] = value\n",
      "\n",
      "        \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "            \u001b[38;5;66;03m# Note: unlike self.iloc[:, indexer] = value, this will\u001b[39;00m\n",
      "            \u001b[38;5;66;03m#  never try to overwrite values inplace\u001b[39;00m\n",
      "\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m isinstance(value, DataFrame):\n",
      "                check_key_length(self.columns, key, value)\n",
      "                \u001b[38;5;28;01mfor\u001b[39;00m k1, k2 \u001b[38;5;28;01min\u001b[39;00m zip(key, value.columns):\n",
      "                    self[k1] = value[k2]\n",
      "\n",
      "            \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m is_list_like(value):\n",
      "                \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;28;01min\u001b[39;00m key:\n",
      "                    self[col] = value\n",
      "\n",
      "            \u001b[38;5;28;01melif\u001b[39;00m isinstance(value, np.ndarray) \u001b[38;5;28;01mand\u001b[39;00m value.ndim == \u001b[32m2\u001b[39m:\n",
      "                self._iset_not_inplace(key, value)\n",
      "\n",
      "            \u001b[38;5;28;01melif\u001b[39;00m np.ndim(value) > \u001b[32m1\u001b[39m:\n",
      "                \u001b[38;5;66;03m# list of lists\u001b[39;00m\n",
      "                value = DataFrame(value).values\n",
      "                \u001b[38;5;28;01mreturn\u001b[39;00m self._setitem_array(key, value)\n",
      "\n",
      "            \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "                self._iset_not_inplace(key, value)\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m _iset_not_inplace(self, key, value):\n",
      "        \u001b[38;5;66;03m# GH#39510 when setting with df[key] = obj with a list-like key and\u001b[39;00m\n",
      "        \u001b[38;5;66;03m#  list-like value, we iterate over those listlikes and set columns\u001b[39;00m\n",
      "        \u001b[38;5;66;03m#  one at a time.  This is different from dispatching to\u001b[39;00m\n",
      "        \u001b[38;5;66;03m#  `self.loc[:, key]= value`  because loc.__setitem__ may overwrite\u001b[39;00m\n",
      "        \u001b[38;5;66;03m#  data inplace, whereas this will insert new arrays.\u001b[39;00m\n",
      "\n",
      "        \u001b[38;5;28;01mdef\u001b[39;00m igetitem(obj, i: int):\n",
      "            \u001b[38;5;66;03m# Note: we catch DataFrame obj before getting here, but\u001b[39;00m\n",
      "            \u001b[38;5;66;03m#  hypothetically would return obj.iloc[:, i]\u001b[39;00m\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m isinstance(obj, np.ndarray):\n",
      "                \u001b[38;5;28;01mreturn\u001b[39;00m obj[..., i]\n",
      "            \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "                \u001b[38;5;28;01mreturn\u001b[39;00m obj[i]\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m self.columns.is_unique:\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m np.shape(value)[-\u001b[32m1\u001b[39m] != len(key):\n",
      "                \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\u001b[33m\"Columns must be same length as key\"\u001b[39m)\n",
      "\n",
      "            \u001b[38;5;28;01mfor\u001b[39;00m i, col \u001b[38;5;28;01min\u001b[39;00m enumerate(key):\n",
      "                self[col] = igetitem(value, i)\n",
      "\n",
      "        \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "            ilocs = self.columns.get_indexer_non_unique(key)[\u001b[32m0\u001b[39m]\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m (ilocs < \u001b[32m0\u001b[39m).any():\n",
      "                \u001b[38;5;66;03m# key entries not in self.columns\u001b[39;00m\n",
      "                \u001b[38;5;28;01mraise\u001b[39;00m NotImplementedError\n",
      "\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m np.shape(value)[-\u001b[32m1\u001b[39m] != len(ilocs):\n",
      "                \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\u001b[33m\"Columns must be same length as key\"\u001b[39m)\n",
      "\n",
      "            \u001b[38;5;28;01massert\u001b[39;00m np.ndim(value) <= \u001b[32m2\u001b[39m\n",
      "\n",
      "            orig_columns = self.columns\n",
      "\n",
      "            \u001b[38;5;66;03m# Using self.iloc[:, i] = ... may set values inplace, which\u001b[39;00m\n",
      "            \u001b[38;5;66;03m#  by convention we do not do in __setitem__\u001b[39;00m\n",
      "            \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "                self.columns = Index(range(len(self.columns)))\n",
      "                \u001b[38;5;28;01mfor\u001b[39;00m i, iloc \u001b[38;5;28;01min\u001b[39;00m enumerate(ilocs):\n",
      "                    self[iloc] = igetitem(value, i)\n",
      "            \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "                self.columns = orig_columns\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m _setitem_frame(self, key, value):\n",
      "        \u001b[38;5;66;03m# support boolean setting with DataFrame input, e.g.\u001b[39;00m\n",
      "        \u001b[38;5;66;03m# df[df > df2] = 0\u001b[39;00m\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m isinstance(key, np.ndarray):\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m key.shape != self.shape:\n",
      "                \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\u001b[33m\"Array conditional must be same shape as self\"\u001b[39m)\n",
      "            key = self._constructor(key, **self._construct_axes_dict(), copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m key.size \u001b[38;5;28;01mand\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m all(is_bool_dtype(dtype) \u001b[38;5;28;01mfor\u001b[39;00m dtype \u001b[38;5;28;01min\u001b[39;00m key.dtypes):\n",
      "            \u001b[38;5;28;01mraise\u001b[39;00m TypeError(\n",
      "                \u001b[33m\"Must pass DataFrame or 2-d ndarray with boolean values only\"\u001b[39m\n",
      "            )\n",
      "\n",
      "        self._check_setitem_copy()\n",
      "        self._where(-key, value, inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m _set_item_frame_value(self, key, value: DataFrame) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        self._ensure_valid_index(value)\n",
      "\n",
      "        \u001b[38;5;66;03m# align columns\u001b[39;00m\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;28;01min\u001b[39;00m self.columns:\n",
      "            loc = self.columns.get_loc(key)\n",
      "            cols = self.columns[loc]\n",
      "            len_cols = \u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_scalar(cols) \u001b[38;5;28;01mor\u001b[39;00m isinstance(cols, tuple) \u001b[38;5;28;01melse\u001b[39;00m len(cols)\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m len_cols != len(value.columns):\n",
      "                \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\u001b[33m\"Columns must be same length as key\"\u001b[39m)\n",
      "\n",
      "            \u001b[38;5;66;03m# align right-hand-side columns if self.columns\u001b[39;00m\n",
      "            \u001b[38;5;66;03m# is multi-index and self[key] is a sub-frame\u001b[39;00m\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m isinstance(self.columns, MultiIndex) \u001b[38;5;28;01mand\u001b[39;00m isinstance(\n",
      "                loc, (slice, Series, np.ndarray, Index)\n",
      "            ):\n",
      "                cols_droplevel = maybe_droplevels(cols, key)\n",
      "                \u001b[38;5;28;01mif\u001b[39;00m len(cols_droplevel) \u001b[38;5;28;01mand\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m cols_droplevel.equals(value.columns):\n",
      "                    value = value.reindex(cols_droplevel, axis=\u001b[32m1\u001b[39m)\n",
      "\n",
      "                \u001b[38;5;28;01mfor\u001b[39;00m col, col_droplevel \u001b[38;5;28;01min\u001b[39;00m zip(cols, cols_droplevel):\n",
      "                    self[col] = value[col_droplevel]\n",
      "                \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m is_scalar(cols):\n",
      "                self[cols] = value[value.columns[\u001b[32m0\u001b[39m]]\n",
      "                \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\n",
      "            locs: np.ndarray | list\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m isinstance(loc, slice):\n",
      "                locs = np.arange(loc.start, loc.stop, loc.step)\n",
      "            \u001b[38;5;28;01melif\u001b[39;00m is_scalar(loc):\n",
      "                locs = [loc]\n",
      "            \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "                locs = loc.nonzero()[\u001b[32m0\u001b[39m]\n",
      "\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m self.isetitem(locs, value)\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m len(value.columns) > \u001b[32m1\u001b[39m:\n",
      "            \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\n",
      "                \u001b[33m\"Cannot set a DataFrame with multiple columns to the single \"\u001b[39m\n",
      "                \u001b[33mf\"column {key}\"\u001b[39m\n",
      "            )\n",
      "        \u001b[38;5;28;01melif\u001b[39;00m len(value.columns) == \u001b[32m0\u001b[39m:\n",
      "            \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\n",
      "                \u001b[33mf\"Cannot set a DataFrame without columns to the column {key}\"\u001b[39m\n",
      "            )\n",
      "\n",
      "        self[key] = value[value.columns[\u001b[32m0\u001b[39m]]\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m _iset_item_mgr(\n",
      "        self,\n",
      "        loc: int | slice | np.ndarray,\n",
      "        value,\n",
      "        inplace: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "        refs: BlockValuesRefs | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        \u001b[38;5;66;03m# when called from _set_item_mgr loc can be anything returned from get_loc\u001b[39;00m\n",
      "        self._mgr.iset(loc, value, inplace=inplace, refs=refs)\n",
      "        self._clear_item_cache()\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m _set_item_mgr(\n",
      "        self, key, value: ArrayLike, refs: BlockValuesRefs | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "    ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "            loc = self._info_axis.get_loc(key)\n",
      "        \u001b[38;5;28;01mexcept\u001b[39;00m KeyError:\n",
      "            \u001b[38;5;66;03m# This item wasn't present, just insert at end\u001b[39;00m\n",
      "            self._mgr.insert(len(self._info_axis), key, value, refs)\n",
      "        \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "            self._iset_item_mgr(loc, value, refs=refs)\n",
      "\n",
      "        \u001b[38;5;66;03m# check if we are modifying a copy\u001b[39;00m\n",
      "        \u001b[38;5;66;03m# try to set first as we want an invalid\u001b[39;00m\n",
      "        \u001b[38;5;66;03m# value exception to occur first\u001b[39;00m\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m len(self):\n",
      "            self._check_setitem_copy()\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m _iset_item(self, loc: int, value: Series, inplace: bool = \u001b[38;5;28;01mTrue\u001b[39;00m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        \u001b[38;5;66;03m# We are only called from _replace_columnwise which guarantees that\u001b[39;00m\n",
      "        \u001b[38;5;66;03m# no reindex is necessary\u001b[39;00m\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m using_copy_on_write():\n",
      "            self._iset_item_mgr(\n",
      "                loc, value._values, inplace=inplace, refs=value._references\n",
      "            )\n",
      "        \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "            self._iset_item_mgr(loc, value._values.copy(), inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\n",
      "        \u001b[38;5;66;03m# check if we are modifying a copy\u001b[39;00m\n",
      "        \u001b[38;5;66;03m# try to set first as we want an invalid\u001b[39;00m\n",
      "        \u001b[38;5;66;03m# value exception to occur first\u001b[39;00m\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m len(self):\n",
      "            self._check_setitem_copy()\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m _set_item(self, key, value) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Add series to DataFrame in specified column.\u001b[39m\n",
      "\n",
      "\u001b[33m        If series is a numpy-array (not a Series/TimeSeries), it must be the\u001b[39m\n",
      "\u001b[33m        same length as the DataFrames index or an error will be thrown.\u001b[39m\n",
      "\n",
      "\u001b[33m        Series/TimeSeries will be conformed to the DataFrames index to\u001b[39m\n",
      "\u001b[33m        ensure homogeneity.\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        value, refs = self._sanitize_column(value)\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m (\n",
      "            key \u001b[38;5;28;01min\u001b[39;00m self.columns\n",
      "            \u001b[38;5;28;01mand\u001b[39;00m value.ndim == \u001b[32m1\u001b[39m\n",
      "            \u001b[38;5;28;01mand\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m isinstance(value.dtype, ExtensionDtype)\n",
      "        ):\n",
      "            \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m self.columns.is_unique \u001b[38;5;28;01mor\u001b[39;00m isinstance(self.columns, MultiIndex):\n",
      "                existing_piece = self[key]\n",
      "                \u001b[38;5;28;01mif\u001b[39;00m isinstance(existing_piece, DataFrame):\n",
      "                    value = np.tile(value, (len(existing_piece.columns), \u001b[32m1\u001b[39m)).T\n",
      "                    refs = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\n",
      "        self._set_item_mgr(key, value, refs)\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m _set_value(\n",
      "        self, index: IndexLabel, col, value: Scalar, takeable: bool = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "    ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Put single value at passed column and index.\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        index : Label\u001b[39m\n",
      "\u001b[33m            row label\u001b[39m\n",
      "\u001b[33m        col : Label\u001b[39m\n",
      "\u001b[33m            column label\u001b[39m\n",
      "\u001b[33m        value : scalar\u001b[39m\n",
      "\u001b[33m        takeable : bool, default False\u001b[39m\n",
      "\u001b[33m            Sets whether or not index/col interpreted as indexers\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m takeable:\n",
      "                icol = col\n",
      "                iindex = cast(int, index)\n",
      "            \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "                icol = self.columns.get_loc(col)\n",
      "                iindex = self.index.get_loc(index)\n",
      "            self._mgr.column_setitem(icol, iindex, value, inplace_only=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "            self._clear_item_cache()\n",
      "\n",
      "        \u001b[38;5;28;01mexcept\u001b[39;00m (KeyError, TypeError, ValueError, LossySetitemError):\n",
      "            \u001b[38;5;66;03m# get_loc might raise a KeyError for missing labels (falling back\u001b[39;00m\n",
      "            \u001b[38;5;66;03m#  to (i)loc will do expansion of the index)\u001b[39;00m\n",
      "            \u001b[38;5;66;03m# column_setitem will do validation that may raise TypeError,\u001b[39;00m\n",
      "            \u001b[38;5;66;03m#  ValueError, or LossySetitemError\u001b[39;00m\n",
      "            \u001b[38;5;66;03m# set using a non-recursive method & reset the cache\u001b[39;00m\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m takeable:\n",
      "                self.iloc[index, col] = value\n",
      "            \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "                self.loc[index, col] = value\n",
      "            self._item_cache.pop(col, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\n",
      "        \u001b[38;5;28;01mexcept\u001b[39;00m InvalidIndexError \u001b[38;5;28;01mas\u001b[39;00m ii_err:\n",
      "            \u001b[38;5;66;03m# GH48729: Seems like you are trying to assign a value to a\u001b[39;00m\n",
      "            \u001b[38;5;66;03m# row when only scalar options are permitted\u001b[39;00m\n",
      "            \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(\n",
      "                \u001b[33mf\"You can only assign a scalar value not a {type(value)}\"\u001b[39m\n",
      "            ) \u001b[38;5;28;01mfrom\u001b[39;00m ii_err\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m _ensure_valid_index(self, value) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Ensure that if we don't have an index, that we can create one from the\u001b[39m\n",
      "\u001b[33m        passed value.\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;66;03m# GH5632, make sure that we are a Series convertible\u001b[39;00m\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m len(self.index) \u001b[38;5;28;01mand\u001b[39;00m is_list_like(value) \u001b[38;5;28;01mand\u001b[39;00m len(value):\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m isinstance(value, DataFrame):\n",
      "                \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "                    value = Series(value)\n",
      "                \u001b[38;5;28;01mexcept\u001b[39;00m (ValueError, NotImplementedError, TypeError) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "                    \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\n",
      "                        \u001b[33m\"Cannot set a frame with no defined index \"\u001b[39m\n",
      "                        \u001b[33m\"and a value that cannot be converted to a Series\"\u001b[39m\n",
      "                    ) \u001b[38;5;28;01mfrom\u001b[39;00m err\n",
      "\n",
      "            \u001b[38;5;66;03m# GH31368 preserve name of index\u001b[39;00m\n",
      "            index_copy = value.index.copy()\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m self.index.name \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "                index_copy.name = self.index.name\n",
      "\n",
      "            self._mgr = self._mgr.reindex_axis(index_copy, axis=\u001b[32m1\u001b[39m, fill_value=np.nan)\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m _box_col_values(self, values: SingleDataManager, loc: int) -> Series:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Provide boxed values for a column.\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;66;03m# Lookup in columns so that if e.g. a str datetime was passed\u001b[39;00m\n",
      "        \u001b[38;5;66;03m#  we attach the Timestamp object as the name.\u001b[39;00m\n",
      "        name = self.columns[loc]\n",
      "        \u001b[38;5;66;03m# We get index=self.index bc values is a SingleDataManager\u001b[39;00m\n",
      "        obj = self._constructor_sliced_from_mgr(values, axes=values.axes)\n",
      "        obj._name = name\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m obj.__finalize__(self)\n",
      "\n",
      "    \u001b[38;5;66;03m# ----------------------------------------------------------------------\u001b[39;00m\n",
      "    \u001b[38;5;66;03m# Lookup Caching\u001b[39;00m\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m _clear_item_cache(self) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        self._item_cache.clear()\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m _get_item_cache(self, item: Hashable) -> Series:\n",
      "        \u001b[33m\"\"\"Return the cached item, item represents a label indexer.\"\"\"\u001b[39m\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m using_copy_on_write() \u001b[38;5;28;01mor\u001b[39;00m warn_copy_on_write():\n",
      "            loc = self.columns.get_loc(item)\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m self._ixs(loc, axis=\u001b[32m1\u001b[39m)\n",
      "\n",
      "        cache = self._item_cache\n",
      "        res = cache.get(item)\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "            \u001b[38;5;66;03m# All places that call _get_item_cache have unique columns,\u001b[39;00m\n",
      "            \u001b[38;5;66;03m#  pending resolution of GH#33047\u001b[39;00m\n",
      "\n",
      "            loc = self.columns.get_loc(item)\n",
      "            res = self._ixs(loc, axis=\u001b[32m1\u001b[39m)\n",
      "\n",
      "            cache[item] = res\n",
      "\n",
      "            \u001b[38;5;66;03m# for a chain\u001b[39;00m\n",
      "            res._is_copy = self._is_copy\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m _reset_cacher(self) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        \u001b[38;5;66;03m# no-op for DataFrame\u001b[39;00m\n",
      "        \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m _maybe_cache_changed(self, item, value: Series, inplace: bool) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        The object has called back to us saying maybe it has changed.\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        loc = self._info_axis.get_loc(item)\n",
      "        arraylike = value._values\n",
      "\n",
      "        old = self._ixs(loc, axis=\u001b[32m1\u001b[39m)\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m old._values \u001b[38;5;28;01mis\u001b[39;00m value._values \u001b[38;5;28;01mand\u001b[39;00m inplace:\n",
      "            \u001b[38;5;66;03m# GH#46149 avoid making unnecessary copies/block-splitting\u001b[39;00m\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\n",
      "        self._mgr.iset(loc, arraylike, inplace=inplace)\n",
      "\n",
      "    \u001b[38;5;66;03m# ----------------------------------------------------------------------\u001b[39;00m\n",
      "    \u001b[38;5;66;03m# Unsorted\u001b[39;00m\n",
      "\n",
      "    @overload\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m query(self, expr: str, *, inplace: Literal[\u001b[38;5;28;01mFalse\u001b[39;00m] = ..., **kwargs) -> DataFrame:\n",
      "        ...\n",
      "\n",
      "    @overload\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m query(self, expr: str, *, inplace: Literal[\u001b[38;5;28;01mTrue\u001b[39;00m], **kwargs) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        ...\n",
      "\n",
      "    @overload\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m query(self, expr: str, *, inplace: bool = ..., **kwargs) -> DataFrame | \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        ...\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m query(self, expr: str, *, inplace: bool = \u001b[38;5;28;01mFalse\u001b[39;00m, **kwargs) -> DataFrame | \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Query the columns of a DataFrame with a boolean expression.\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        expr : str\u001b[39m\n",
      "\u001b[33m            The query string to evaluate.\u001b[39m\n",
      "\n",
      "\u001b[33m            You can refer to variables\u001b[39m\n",
      "\u001b[33m            in the environment by prefixing them with an '@' character like\u001b[39m\n",
      "\u001b[33m            ``@a + b``.\u001b[39m\n",
      "\n",
      "\u001b[33m            You can refer to column names that are not valid Python variable names\u001b[39m\n",
      "\u001b[33m            by surrounding them in backticks. Thus, column names containing spaces\u001b[39m\n",
      "\u001b[33m            or punctuations (besides underscores) or starting with digits must be\u001b[39m\n",
      "\u001b[33m            surrounded by backticks. (For example, a column named \"Area (cm^2)\" would\u001b[39m\n",
      "\u001b[33m            be referenced as ```Area (cm^2)```). Column names which are Python keywords\u001b[39m\n",
      "\u001b[33m            (like \"list\", \"for\", \"import\", etc) cannot be used.\u001b[39m\n",
      "\n",
      "\u001b[33m            For example, if one of your columns is called ``a a`` and you want\u001b[39m\n",
      "\u001b[33m            to sum it with ``b``, your query should be ```a a` + b``.\u001b[39m\n",
      "\n",
      "\u001b[33m        inplace : bool\u001b[39m\n",
      "\u001b[33m            Whether to modify the DataFrame rather than creating a new one.\u001b[39m\n",
      "\u001b[33m        **kwargs\u001b[39m\n",
      "\u001b[33m            See the documentation for :func:`eval` for complete details\u001b[39m\n",
      "\u001b[33m            on the keyword arguments accepted by :meth:`DataFrame.query`.\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        DataFrame or None\u001b[39m\n",
      "\u001b[33m            DataFrame resulting from the provided query expression or\u001b[39m\n",
      "\u001b[33m            None if ``inplace=True``.\u001b[39m\n",
      "\n",
      "\u001b[33m        See Also\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        eval : Evaluate a string describing operations on\u001b[39m\n",
      "\u001b[33m            DataFrame columns.\u001b[39m\n",
      "\u001b[33m        DataFrame.eval : Evaluate a string describing operations on\u001b[39m\n",
      "\u001b[33m            DataFrame columns.\u001b[39m\n",
      "\n",
      "\u001b[33m        Notes\u001b[39m\n",
      "\u001b[33m        -----\u001b[39m\n",
      "\u001b[33m        The result of the evaluation of this expression is first passed to\u001b[39m\n",
      "\u001b[33m        :attr:`DataFrame.loc` and if that fails because of a\u001b[39m\n",
      "\u001b[33m        multidimensional key (e.g., a DataFrame) then the result will be passed\u001b[39m\n",
      "\u001b[33m        to :meth:`DataFrame.__getitem__`.\u001b[39m\n",
      "\n",
      "\u001b[33m        This method uses the top-level :func:`eval` function to\u001b[39m\n",
      "\u001b[33m        evaluate the passed query.\u001b[39m\n",
      "\n",
      "\u001b[33m        The :meth:`~pandas.DataFrame.query` method uses a slightly\u001b[39m\n",
      "\u001b[33m        modified Python syntax by default. For example, the ``&`` and ``|``\u001b[39m\n",
      "\u001b[33m        (bitwise) operators have the precedence of their boolean cousins,\u001b[39m\n",
      "\u001b[33m        :keyword:`and` and :keyword:`or`. This *is* syntactically valid Python,\u001b[39m\n",
      "\u001b[33m        however the semantics are different.\u001b[39m\n",
      "\n",
      "\u001b[33m        You can change the semantics of the expression by passing the keyword\u001b[39m\n",
      "\u001b[33m        argument ``parser='python'``. This enforces the same semantics as\u001b[39m\n",
      "\u001b[33m        evaluation in Python space. Likewise, you can pass ``engine='python'``\u001b[39m\n",
      "\u001b[33m        to evaluate an expression using Python itself as a backend. This is not\u001b[39m\n",
      "\u001b[33m        recommended as it is inefficient compared to using ``numexpr`` as the\u001b[39m\n",
      "\u001b[33m        engine.\u001b[39m\n",
      "\n",
      "\u001b[33m        The :attr:`DataFrame.index` and\u001b[39m\n",
      "\u001b[33m        :attr:`DataFrame.columns` attributes of the\u001b[39m\n",
      "\u001b[33m        :class:`~pandas.DataFrame` instance are placed in the query namespace\u001b[39m\n",
      "\u001b[33m        by default, which allows you to treat both the index and columns of the\u001b[39m\n",
      "\u001b[33m        frame as a column in the frame.\u001b[39m\n",
      "\u001b[33m        The identifier ``index`` is used for the frame index; you can also\u001b[39m\n",
      "\u001b[33m        use the name of the index to identify it in a query. Please note that\u001b[39m\n",
      "\u001b[33m        Python keywords may not be used as identifiers.\u001b[39m\n",
      "\n",
      "\u001b[33m        For further details and examples see the ``query`` documentation in\u001b[39m\n",
      "\u001b[33m        :ref:`indexing <indexing.query>`.\u001b[39m\n",
      "\n",
      "\u001b[33m        *Backtick quoted variables*\u001b[39m\n",
      "\n",
      "\u001b[33m        Backtick quoted variables are parsed as literal Python code and\u001b[39m\n",
      "\u001b[33m        are converted internally to a Python valid identifier.\u001b[39m\n",
      "\u001b[33m        This can lead to the following problems.\u001b[39m\n",
      "\n",
      "\u001b[33m        During parsing a number of disallowed characters inside the backtick\u001b[39m\n",
      "\u001b[33m        quoted string are replaced by strings that are allowed as a Python identifier.\u001b[39m\n",
      "\u001b[33m        These characters include all operators in Python, the space character, the\u001b[39m\n",
      "\u001b[33m        question mark, the exclamation mark, the dollar sign, and the euro sign.\u001b[39m\n",
      "\u001b[33m        For other characters that fall outside the ASCII range (U+0001..U+007F)\u001b[39m\n",
      "\u001b[33m        and those that are not further specified in PEP 3131,\u001b[39m\n",
      "\u001b[33m        the query parser will raise an error.\u001b[39m\n",
      "\u001b[33m        This excludes whitespace different than the space character,\u001b[39m\n",
      "\u001b[33m        but also the hashtag (as it is used for comments) and the backtick\u001b[39m\n",
      "\u001b[33m        itself (backtick can also not be escaped).\u001b[39m\n",
      "\n",
      "\u001b[33m        In a special case, quotes that make a pair around a backtick can\u001b[39m\n",
      "\u001b[33m        confuse the parser.\u001b[39m\n",
      "\u001b[33m        For example, ```it's` > `that's``` will raise an error,\u001b[39m\n",
      "\u001b[33m        as it forms a quoted string (``'s > `that'``) with a backtick inside.\u001b[39m\n",
      "\n",
      "\u001b[33m        See also the Python documentation about lexical analysis\u001b[39m\n",
      "\u001b[33m        (https://docs.python.org/3/reference/lexical_analysis.html)\u001b[39m\n",
      "\u001b[33m        in combination with the source code in :mod:`pandas.core.computation.parsing`.\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        >>> df = pd.DataFrame({'A': range(1, 6),\u001b[39m\n",
      "\u001b[33m        ...                    'B': range(10, 0, -2),\u001b[39m\n",
      "\u001b[33m        ...                    'C C': range(10, 5, -1)})\u001b[39m\n",
      "\u001b[33m        >>> df\u001b[39m\n",
      "\u001b[33m           A   B  C C\u001b[39m\n",
      "\u001b[33m        0  1  10   10\u001b[39m\n",
      "\u001b[33m        1  2   8    9\u001b[39m\n",
      "\u001b[33m        2  3   6    8\u001b[39m\n",
      "\u001b[33m        3  4   4    7\u001b[39m\n",
      "\u001b[33m        4  5   2    6\u001b[39m\n",
      "\u001b[33m        >>> df.query('A > B')\u001b[39m\n",
      "\u001b[33m           A  B  C C\u001b[39m\n",
      "\u001b[33m        4  5  2    6\u001b[39m\n",
      "\n",
      "\u001b[33m        The previous expression is equivalent to\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df[df.A > df.B]\u001b[39m\n",
      "\u001b[33m           A  B  C C\u001b[39m\n",
      "\u001b[33m        4  5  2    6\u001b[39m\n",
      "\n",
      "\u001b[33m        For columns with spaces in their name, you can use backtick quoting.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.query('B == `C C`')\u001b[39m\n",
      "\u001b[33m           A   B  C C\u001b[39m\n",
      "\u001b[33m        0  1  10   10\u001b[39m\n",
      "\n",
      "\u001b[33m        The previous expression is equivalent to\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df[df.B == df['C C']]\u001b[39m\n",
      "\u001b[33m           A   B  C C\u001b[39m\n",
      "\u001b[33m        0  1  10   10\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        inplace = validate_bool_kwarg(inplace, \u001b[33m\"inplace\"\u001b[39m)\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m isinstance(expr, str):\n",
      "            msg = \u001b[33mf\"expr must be a string to be evaluated, {type(expr)} given\"\u001b[39m\n",
      "            \u001b[38;5;28;01mraise\u001b[39;00m ValueError(msg)\n",
      "        kwargs[\u001b[33m\"level\"\u001b[39m] = kwargs.pop(\u001b[33m\"level\"\u001b[39m, \u001b[32m0\u001b[39m) + \u001b[32m1\u001b[39m\n",
      "        kwargs[\u001b[33m\"target\"\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "        res = self.eval(expr, **kwargs)\n",
      "\n",
      "        \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "            result = self.loc[res]\n",
      "        \u001b[38;5;28;01mexcept\u001b[39;00m ValueError:\n",
      "            \u001b[38;5;66;03m# when res is multi-dimensional loc raises, but this is sometimes a\u001b[39;00m\n",
      "            \u001b[38;5;66;03m# valid query\u001b[39;00m\n",
      "            result = self[res]\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m inplace:\n",
      "            self._update_inplace(result)\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "        \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\n",
      "    @overload\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m eval(self, expr: str, *, inplace: Literal[\u001b[38;5;28;01mFalse\u001b[39;00m] = ..., **kwargs) -> Any:\n",
      "        ...\n",
      "\n",
      "    @overload\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m eval(self, expr: str, *, inplace: Literal[\u001b[38;5;28;01mTrue\u001b[39;00m], **kwargs) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        ...\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m eval(self, expr: str, *, inplace: bool = \u001b[38;5;28;01mFalse\u001b[39;00m, **kwargs) -> Any | \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Evaluate a string describing operations on DataFrame columns.\u001b[39m\n",
      "\n",
      "\u001b[33m        Operates on columns only, not specific rows or elements.  This allows\u001b[39m\n",
      "\u001b[33m        `eval` to run arbitrary code, which can make you vulnerable to code\u001b[39m\n",
      "\u001b[33m        injection if you pass user input to this function.\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        expr : str\u001b[39m\n",
      "\u001b[33m            The expression string to evaluate.\u001b[39m\n",
      "\u001b[33m        inplace : bool, default False\u001b[39m\n",
      "\u001b[33m            If the expression contains an assignment, whether to perform the\u001b[39m\n",
      "\u001b[33m            operation inplace and mutate the existing DataFrame. Otherwise,\u001b[39m\n",
      "\u001b[33m            a new DataFrame is returned.\u001b[39m\n",
      "\u001b[33m        **kwargs\u001b[39m\n",
      "\u001b[33m            See the documentation for :func:`eval` for complete details\u001b[39m\n",
      "\u001b[33m            on the keyword arguments accepted by\u001b[39m\n",
      "\u001b[33m            :meth:`~pandas.DataFrame.query`.\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        ndarray, scalar, pandas object, or None\u001b[39m\n",
      "\u001b[33m            The result of the evaluation or None if ``inplace=True``.\u001b[39m\n",
      "\n",
      "\u001b[33m        See Also\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        DataFrame.query : Evaluates a boolean expression to query the columns\u001b[39m\n",
      "\u001b[33m            of a frame.\u001b[39m\n",
      "\u001b[33m        DataFrame.assign : Can evaluate an expression or function to create new\u001b[39m\n",
      "\u001b[33m            values for a column.\u001b[39m\n",
      "\u001b[33m        eval : Evaluate a Python expression as a string using various\u001b[39m\n",
      "\u001b[33m            backends.\u001b[39m\n",
      "\n",
      "\u001b[33m        Notes\u001b[39m\n",
      "\u001b[33m        -----\u001b[39m\n",
      "\u001b[33m        For more details see the API documentation for :func:`~eval`.\u001b[39m\n",
      "\u001b[33m        For detailed examples see :ref:`enhancing performance with eval\u001b[39m\n",
      "\u001b[33m        <enhancingperf.eval>`.\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        >>> df = pd.DataFrame({'A': range(1, 6), 'B': range(10, 0, -2)})\u001b[39m\n",
      "\u001b[33m        >>> df\u001b[39m\n",
      "\u001b[33m           A   B\u001b[39m\n",
      "\u001b[33m        0  1  10\u001b[39m\n",
      "\u001b[33m        1  2   8\u001b[39m\n",
      "\u001b[33m        2  3   6\u001b[39m\n",
      "\u001b[33m        3  4   4\u001b[39m\n",
      "\u001b[33m        4  5   2\u001b[39m\n",
      "\u001b[33m        >>> df.eval('A + B')\u001b[39m\n",
      "\u001b[33m        0    11\u001b[39m\n",
      "\u001b[33m        1    10\u001b[39m\n",
      "\u001b[33m        2     9\u001b[39m\n",
      "\u001b[33m        3     8\u001b[39m\n",
      "\u001b[33m        4     7\u001b[39m\n",
      "\u001b[33m        dtype: int64\u001b[39m\n",
      "\n",
      "\u001b[33m        Assignment is allowed though by default the original DataFrame is not\u001b[39m\n",
      "\u001b[33m        modified.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.eval('C = A + B')\u001b[39m\n",
      "\u001b[33m           A   B   C\u001b[39m\n",
      "\u001b[33m        0  1  10  11\u001b[39m\n",
      "\u001b[33m        1  2   8  10\u001b[39m\n",
      "\u001b[33m        2  3   6   9\u001b[39m\n",
      "\u001b[33m        3  4   4   8\u001b[39m\n",
      "\u001b[33m        4  5   2   7\u001b[39m\n",
      "\u001b[33m        >>> df\u001b[39m\n",
      "\u001b[33m           A   B\u001b[39m\n",
      "\u001b[33m        0  1  10\u001b[39m\n",
      "\u001b[33m        1  2   8\u001b[39m\n",
      "\u001b[33m        2  3   6\u001b[39m\n",
      "\u001b[33m        3  4   4\u001b[39m\n",
      "\u001b[33m        4  5   2\u001b[39m\n",
      "\n",
      "\u001b[33m        Multiple columns can be assigned to using multi-line expressions:\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.eval(\u001b[39m\n",
      "\u001b[33m        ...     '''\u001b[39m\n",
      "\u001b[33m        ... C = A + B\u001b[39m\n",
      "\u001b[33m        ... D = A - B\u001b[39m\n",
      "\u001b[33m        ... '''\u001b[39m\n",
      "\u001b[33m        ... )\u001b[39m\n",
      "\u001b[33m           A   B   C  D\u001b[39m\n",
      "\u001b[33m        0  1  10  11 -9\u001b[39m\n",
      "\u001b[33m        1  2   8  10 -6\u001b[39m\n",
      "\u001b[33m        2  3   6   9 -3\u001b[39m\n",
      "\u001b[33m        3  4   4   8  0\u001b[39m\n",
      "\u001b[33m        4  5   2   7  3\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;28;01mfrom\u001b[39;00m pandas.core.computation.eval \u001b[38;5;28;01mimport\u001b[39;00m eval \u001b[38;5;28;01mas\u001b[39;00m _eval\n",
      "\n",
      "        inplace = validate_bool_kwarg(inplace, \u001b[33m\"inplace\"\u001b[39m)\n",
      "        kwargs[\u001b[33m\"level\"\u001b[39m] = kwargs.pop(\u001b[33m\"level\"\u001b[39m, \u001b[32m0\u001b[39m) + \u001b[32m1\u001b[39m\n",
      "        index_resolvers = self._get_index_resolvers()\n",
      "        column_resolvers = self._get_cleaned_column_resolvers()\n",
      "        resolvers = column_resolvers, index_resolvers\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"target\"\u001b[39m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01min\u001b[39;00m kwargs:\n",
      "            kwargs[\u001b[33m\"target\"\u001b[39m] = self\n",
      "        kwargs[\u001b[33m\"resolvers\"\u001b[39m] = tuple(kwargs.get(\u001b[33m\"resolvers\"\u001b[39m, ())) + resolvers\n",
      "\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m _eval(expr, inplace=inplace, **kwargs)\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m select_dtypes(self, include=\u001b[38;5;28;01mNone\u001b[39;00m, exclude=\u001b[38;5;28;01mNone\u001b[39;00m) -> Self:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Return a subset of the DataFrame's columns based on the column dtypes.\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        include, exclude : scalar or list-like\u001b[39m\n",
      "\u001b[33m            A selection of dtypes or strings to be included/excluded. At least\u001b[39m\n",
      "\u001b[33m            one of these parameters must be supplied.\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        DataFrame\u001b[39m\n",
      "\u001b[33m            The subset of the frame including the dtypes in ``include`` and\u001b[39m\n",
      "\u001b[33m            excluding the dtypes in ``exclude``.\u001b[39m\n",
      "\n",
      "\u001b[33m        Raises\u001b[39m\n",
      "\u001b[33m        ------\u001b[39m\n",
      "\u001b[33m        ValueError\u001b[39m\n",
      "\u001b[33m            * If both of ``include`` and ``exclude`` are empty\u001b[39m\n",
      "\u001b[33m            * If ``include`` and ``exclude`` have overlapping elements\u001b[39m\n",
      "\u001b[33m            * If any kind of string dtype is passed in.\u001b[39m\n",
      "\n",
      "\u001b[33m        See Also\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        DataFrame.dtypes: Return Series with the data type of each column.\u001b[39m\n",
      "\n",
      "\u001b[33m        Notes\u001b[39m\n",
      "\u001b[33m        -----\u001b[39m\n",
      "\u001b[33m        * To select all *numeric* types, use ``np.number`` or ``'number'``\u001b[39m\n",
      "\u001b[33m        * To select strings you must use the ``object`` dtype, but note that\u001b[39m\n",
      "\u001b[33m          this will return *all* object dtype columns\u001b[39m\n",
      "\u001b[33m        * See the `numpy dtype hierarchy\u001b[39m\n",
      "\u001b[33m          <https://numpy.org/doc/stable/reference/arrays.scalars.html>`__\u001b[39m\n",
      "\u001b[33m        * To select datetimes, use ``np.datetime64``, ``'datetime'`` or\u001b[39m\n",
      "\u001b[33m          ``'datetime64'``\u001b[39m\n",
      "\u001b[33m        * To select timedeltas, use ``np.timedelta64``, ``'timedelta'`` or\u001b[39m\n",
      "\u001b[33m          ``'timedelta64'``\u001b[39m\n",
      "\u001b[33m        * To select Pandas categorical dtypes, use ``'category'``\u001b[39m\n",
      "\u001b[33m        * To select Pandas datetimetz dtypes, use ``'datetimetz'``\u001b[39m\n",
      "\u001b[33m          or ``'datetime64[ns, tz]'``\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        >>> df = pd.DataFrame({'a': [1, 2] * 3,\u001b[39m\n",
      "\u001b[33m        ...                    'b': [True, False] * 3,\u001b[39m\n",
      "\u001b[33m        ...                    'c': [1.0, 2.0] * 3})\u001b[39m\n",
      "\u001b[33m        >>> df\u001b[39m\n",
      "\u001b[33m                a      b  c\u001b[39m\n",
      "\u001b[33m        0       1   True  1.0\u001b[39m\n",
      "\u001b[33m        1       2  False  2.0\u001b[39m\n",
      "\u001b[33m        2       1   True  1.0\u001b[39m\n",
      "\u001b[33m        3       2  False  2.0\u001b[39m\n",
      "\u001b[33m        4       1   True  1.0\u001b[39m\n",
      "\u001b[33m        5       2  False  2.0\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.select_dtypes(include='bool')\u001b[39m\n",
      "\u001b[33m           b\u001b[39m\n",
      "\u001b[33m        0  True\u001b[39m\n",
      "\u001b[33m        1  False\u001b[39m\n",
      "\u001b[33m        2  True\u001b[39m\n",
      "\u001b[33m        3  False\u001b[39m\n",
      "\u001b[33m        4  True\u001b[39m\n",
      "\u001b[33m        5  False\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.select_dtypes(include=['float64'])\u001b[39m\n",
      "\u001b[33m           c\u001b[39m\n",
      "\u001b[33m        0  1.0\u001b[39m\n",
      "\u001b[33m        1  2.0\u001b[39m\n",
      "\u001b[33m        2  1.0\u001b[39m\n",
      "\u001b[33m        3  2.0\u001b[39m\n",
      "\u001b[33m        4  1.0\u001b[39m\n",
      "\u001b[33m        5  2.0\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.select_dtypes(exclude=['int64'])\u001b[39m\n",
      "\u001b[33m               b    c\u001b[39m\n",
      "\u001b[33m        0   True  1.0\u001b[39m\n",
      "\u001b[33m        1  False  2.0\u001b[39m\n",
      "\u001b[33m        2   True  1.0\u001b[39m\n",
      "\u001b[33m        3  False  2.0\u001b[39m\n",
      "\u001b[33m        4   True  1.0\u001b[39m\n",
      "\u001b[33m        5  False  2.0\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m is_list_like(include):\n",
      "            include = (include,) \u001b[38;5;28;01mif\u001b[39;00m include \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m ()\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m is_list_like(exclude):\n",
      "            exclude = (exclude,) \u001b[38;5;28;01mif\u001b[39;00m exclude \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m ()\n",
      "\n",
      "        selection = (frozenset(include), frozenset(exclude))\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m any(selection):\n",
      "            \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\u001b[33m\"at least one of include or exclude must be nonempty\"\u001b[39m)\n",
      "\n",
      "        \u001b[38;5;66;03m# convert the myriad valid dtypes object to a single representation\u001b[39;00m\n",
      "        \u001b[38;5;28;01mdef\u001b[39;00m check_int_infer_dtype(dtypes):\n",
      "            converted_dtypes: list[type] = []\n",
      "            \u001b[38;5;28;01mfor\u001b[39;00m dtype \u001b[38;5;28;01min\u001b[39;00m dtypes:\n",
      "                \u001b[38;5;66;03m# Numpy maps int to different types (int32, in64) on Windows and Linux\u001b[39;00m\n",
      "                \u001b[38;5;66;03m# see https://github.com/numpy/numpy/issues/9464\u001b[39;00m\n",
      "                \u001b[38;5;28;01mif\u001b[39;00m (isinstance(dtype, str) \u001b[38;5;28;01mand\u001b[39;00m dtype == \u001b[33m\"int\"\u001b[39m) \u001b[38;5;28;01mor\u001b[39;00m (dtype \u001b[38;5;28;01mis\u001b[39;00m int):\n",
      "                    converted_dtypes.append(np.int32)\n",
      "                    converted_dtypes.append(np.int64)\n",
      "                \u001b[38;5;28;01melif\u001b[39;00m dtype == \u001b[33m\"float\"\u001b[39m \u001b[38;5;28;01mor\u001b[39;00m dtype \u001b[38;5;28;01mis\u001b[39;00m float:\n",
      "                    \u001b[38;5;66;03m# GH#42452 : np.dtype(\"float\") coerces to np.float64 from Numpy 1.20\u001b[39;00m\n",
      "                    converted_dtypes.extend([np.float64, np.float32])\n",
      "                \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "                    converted_dtypes.append(infer_dtype_from_object(dtype))\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m frozenset(converted_dtypes)\n",
      "\n",
      "        include = check_int_infer_dtype(include)\n",
      "        exclude = check_int_infer_dtype(exclude)\n",
      "\n",
      "        \u001b[38;5;28;01mfor\u001b[39;00m dtypes \u001b[38;5;28;01min\u001b[39;00m (include, exclude):\n",
      "            invalidate_string_dtypes(dtypes)\n",
      "\n",
      "        \u001b[38;5;66;03m# can't both include AND exclude!\u001b[39;00m\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m include.isdisjoint(exclude):\n",
      "            \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\u001b[33mf\"include and exclude overlap on {(include & exclude)}\"\u001b[39m)\n",
      "\n",
      "        \u001b[38;5;28;01mdef\u001b[39;00m dtype_predicate(dtype: DtypeObj, dtypes_set) -> bool:\n",
      "            \u001b[38;5;66;03m# GH 46870: BooleanDtype._is_numeric == True but should be excluded\u001b[39;00m\n",
      "            dtype = dtype \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m isinstance(dtype, ArrowDtype) \u001b[38;5;28;01melse\u001b[39;00m dtype.numpy_dtype\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m issubclass(dtype.type, tuple(dtypes_set)) \u001b[38;5;28;01mor\u001b[39;00m (\n",
      "                np.number \u001b[38;5;28;01min\u001b[39;00m dtypes_set\n",
      "                \u001b[38;5;28;01mand\u001b[39;00m getattr(dtype, \u001b[33m\"_is_numeric\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "                \u001b[38;5;28;01mand\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m is_bool_dtype(dtype)\n",
      "            )\n",
      "\n",
      "        \u001b[38;5;28;01mdef\u001b[39;00m predicate(arr: ArrayLike) -> bool:\n",
      "            dtype = arr.dtype\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m include:\n",
      "                \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m dtype_predicate(dtype, include):\n",
      "                    \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m exclude:\n",
      "                \u001b[38;5;28;01mif\u001b[39;00m dtype_predicate(dtype, exclude):\n",
      "                    \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\n",
      "        mgr = self._mgr._get_data_subset(predicate).copy(deep=\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "        \u001b[38;5;66;03m# error: Incompatible return value type (got \"DataFrame\", expected \"Self\")\u001b[39;00m\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m self._constructor_from_mgr(mgr, axes=mgr.axes).__finalize__(self)  \u001b[38;5;66;03m# type: ignore[return-value]\u001b[39;00m\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m insert(\n",
      "        self,\n",
      "        loc: int,\n",
      "        column: Hashable,\n",
      "        value: Scalar | AnyArrayLike,\n",
      "        allow_duplicates: bool | lib.NoDefault = lib.no_default,\n",
      "    ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Insert column into DataFrame at specified location.\u001b[39m\n",
      "\n",
      "\u001b[33m        Raises a ValueError if `column` is already contained in the DataFrame,\u001b[39m\n",
      "\u001b[33m        unless `allow_duplicates` is set to True.\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        loc : int\u001b[39m\n",
      "\u001b[33m            Insertion index. Must verify 0 <= loc <= len(columns).\u001b[39m\n",
      "\u001b[33m        column : str, number, or hashable object\u001b[39m\n",
      "\u001b[33m            Label of the inserted column.\u001b[39m\n",
      "\u001b[33m        value : Scalar, Series, or array-like\u001b[39m\n",
      "\u001b[33m            Content of the inserted column.\u001b[39m\n",
      "\u001b[33m        allow_duplicates : bool, optional, default lib.no_default\u001b[39m\n",
      "\u001b[33m            Allow duplicate column labels to be created.\u001b[39m\n",
      "\n",
      "\u001b[33m        See Also\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        Index.insert : Insert new item by index.\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        >>> df = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})\u001b[39m\n",
      "\u001b[33m        >>> df\u001b[39m\n",
      "\u001b[33m           col1  col2\u001b[39m\n",
      "\u001b[33m        0     1     3\u001b[39m\n",
      "\u001b[33m        1     2     4\u001b[39m\n",
      "\u001b[33m        >>> df.insert(1, \"newcol\", [99, 99])\u001b[39m\n",
      "\u001b[33m        >>> df\u001b[39m\n",
      "\u001b[33m           col1  newcol  col2\u001b[39m\n",
      "\u001b[33m        0     1      99     3\u001b[39m\n",
      "\u001b[33m        1     2      99     4\u001b[39m\n",
      "\u001b[33m        >>> df.insert(0, \"col1\", [100, 100], allow_duplicates=True)\u001b[39m\n",
      "\u001b[33m        >>> df\u001b[39m\n",
      "\u001b[33m           col1  col1  newcol  col2\u001b[39m\n",
      "\u001b[33m        0   100     1      99     3\u001b[39m\n",
      "\u001b[33m        1   100     2      99     4\u001b[39m\n",
      "\n",
      "\u001b[33m        Notice that pandas uses index alignment in case of `value` from type `Series`:\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.insert(0, \"col0\", pd.Series([5, 6], index=[1, 2]))\u001b[39m\n",
      "\u001b[33m        >>> df\u001b[39m\n",
      "\u001b[33m           col0  col1  col1  newcol  col2\u001b[39m\n",
      "\u001b[33m        0   NaN   100     1      99     3\u001b[39m\n",
      "\u001b[33m        1   5.0   100     2      99     4\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m allow_duplicates \u001b[38;5;28;01mis\u001b[39;00m lib.no_default:\n",
      "            allow_duplicates = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m allow_duplicates \u001b[38;5;28;01mand\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m self.flags.allows_duplicate_labels:\n",
      "            \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\n",
      "                \u001b[33m\"Cannot specify 'allow_duplicates=True' when \"\u001b[39m\n",
      "                \u001b[33m\"'self.flags.allows_duplicate_labels' is False.\"\u001b[39m\n",
      "            )\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m allow_duplicates \u001b[38;5;28;01mand\u001b[39;00m column \u001b[38;5;28;01min\u001b[39;00m self.columns:\n",
      "            \u001b[38;5;66;03m# Should this be a different kind of error??\u001b[39;00m\n",
      "            \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\u001b[33mf\"cannot insert {column}, already exists\"\u001b[39m)\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m is_integer(loc):\n",
      "            \u001b[38;5;28;01mraise\u001b[39;00m TypeError(\u001b[33m\"loc must be int\"\u001b[39m)\n",
      "        \u001b[38;5;66;03m# convert non stdlib ints to satisfy typing checks\u001b[39;00m\n",
      "        loc = int(loc)\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m isinstance(value, DataFrame) \u001b[38;5;28;01mand\u001b[39;00m len(value.columns) > \u001b[32m1\u001b[39m:\n",
      "            \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\n",
      "                \u001b[33mf\"Expected a one-dimensional object, got a DataFrame with \"\u001b[39m\n",
      "                \u001b[33mf\"{len(value.columns)} columns instead.\"\u001b[39m\n",
      "            )\n",
      "        \u001b[38;5;28;01melif\u001b[39;00m isinstance(value, DataFrame):\n",
      "            value = value.iloc[:, \u001b[32m0\u001b[39m]\n",
      "\n",
      "        value, refs = self._sanitize_column(value)\n",
      "        self._mgr.insert(loc, column, value, refs=refs)\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m assign(self, **kwargs) -> DataFrame:\n",
      "        \u001b[33mr\"\"\"\u001b[39m\n",
      "\u001b[33m        Assign new columns to a DataFrame.\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns a new object with all original columns in addition to new ones.\u001b[39m\n",
      "\u001b[33m        Existing columns that are re-assigned will be overwritten.\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        **kwargs : dict of {str: callable or Series}\u001b[39m\n",
      "\u001b[33m            The column names are keywords. If the values are\u001b[39m\n",
      "\u001b[33m            callable, they are computed on the DataFrame and\u001b[39m\n",
      "\u001b[33m            assigned to the new columns. The callable must not\u001b[39m\n",
      "\u001b[33m            change input DataFrame (though pandas doesn't check it).\u001b[39m\n",
      "\u001b[33m            If the values are not callable, (e.g. a Series, scalar, or array),\u001b[39m\n",
      "\u001b[33m            they are simply assigned.\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        DataFrame\u001b[39m\n",
      "\u001b[33m            A new DataFrame with the new columns in addition to\u001b[39m\n",
      "\u001b[33m            all the existing columns.\u001b[39m\n",
      "\n",
      "\u001b[33m        Notes\u001b[39m\n",
      "\u001b[33m        -----\u001b[39m\n",
      "\u001b[33m        Assigning multiple columns within the same ``assign`` is possible.\u001b[39m\n",
      "\u001b[33m        Later items in '\\*\\*kwargs' may refer to newly created or modified\u001b[39m\n",
      "\u001b[33m        columns in 'df'; items are computed and assigned into 'df' in order.\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        >>> df = pd.DataFrame({'temp_c': [17.0, 25.0]},\u001b[39m\n",
      "\u001b[33m        ...                   index=['Portland', 'Berkeley'])\u001b[39m\n",
      "\u001b[33m        >>> df\u001b[39m\n",
      "\u001b[33m                  temp_c\u001b[39m\n",
      "\u001b[33m        Portland    17.0\u001b[39m\n",
      "\u001b[33m        Berkeley    25.0\u001b[39m\n",
      "\n",
      "\u001b[33m        Where the value is a callable, evaluated on `df`:\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.assign(temp_f=lambda x: x.temp_c * 9 / 5 + 32)\u001b[39m\n",
      "\u001b[33m                  temp_c  temp_f\u001b[39m\n",
      "\u001b[33m        Portland    17.0    62.6\u001b[39m\n",
      "\u001b[33m        Berkeley    25.0    77.0\u001b[39m\n",
      "\n",
      "\u001b[33m        Alternatively, the same behavior can be achieved by directly\u001b[39m\n",
      "\u001b[33m        referencing an existing Series or sequence:\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.assign(temp_f=df['temp_c'] * 9 / 5 + 32)\u001b[39m\n",
      "\u001b[33m                  temp_c  temp_f\u001b[39m\n",
      "\u001b[33m        Portland    17.0    62.6\u001b[39m\n",
      "\u001b[33m        Berkeley    25.0    77.0\u001b[39m\n",
      "\n",
      "\u001b[33m        You can create multiple columns within the same assign where one\u001b[39m\n",
      "\u001b[33m        of the columns depends on another one defined within the same assign:\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.assign(temp_f=lambda x: x['temp_c'] * 9 / 5 + 32,\u001b[39m\n",
      "\u001b[33m        ...           temp_k=lambda x: (x['temp_f'] + 459.67) * 5 / 9)\u001b[39m\n",
      "\u001b[33m                  temp_c  temp_f  temp_k\u001b[39m\n",
      "\u001b[33m        Portland    17.0    62.6  290.15\u001b[39m\n",
      "\u001b[33m        Berkeley    25.0    77.0  298.15\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        data = self.copy(deep=\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\n",
      "        \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;28;01min\u001b[39;00m kwargs.items():\n",
      "            data[k] = com.apply_if_callable(v, data)\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m _sanitize_column(self, value) -> tuple[ArrayLike, BlockValuesRefs | \u001b[38;5;28;01mNone\u001b[39;00m]:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Ensures new columns (which go into the BlockManager as new blocks) are\u001b[39m\n",
      "\u001b[33m        always copied (or a reference is being tracked to them under CoW)\u001b[39m\n",
      "\u001b[33m        and converted into an array.\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        value : scalar, Series, or array-like\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        tuple of numpy.ndarray or ExtensionArray and optional BlockValuesRefs\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        self._ensure_valid_index(value)\n",
      "\n",
      "        \u001b[38;5;66;03m# Using a DataFrame would mean coercing values to one dtype\u001b[39;00m\n",
      "        \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m isinstance(value, DataFrame)\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m is_dict_like(value):\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m isinstance(value, Series):\n",
      "                value = Series(value)\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(value, self.index)\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n",
      "            com.require_length_match(value, self.index)\n",
      "        arr = sanitize_array(value, self.index, copy=\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m (\n",
      "            isinstance(value, Index)\n",
      "            \u001b[38;5;28;01mand\u001b[39;00m value.dtype == \u001b[33m\"object\"\u001b[39m\n",
      "            \u001b[38;5;28;01mand\u001b[39;00m arr.dtype != value.dtype\n",
      "        ):  \u001b[38;5;66;03m#\u001b[39;00m\n",
      "            \u001b[38;5;66;03m# TODO: Remove kludge in sanitize_array for string mode when enforcing\u001b[39;00m\n",
      "            \u001b[38;5;66;03m# this deprecation\u001b[39;00m\n",
      "            warnings.warn(\n",
      "                \u001b[33m\"Setting an Index with object dtype into a DataFrame will stop \"\u001b[39m\n",
      "                \u001b[33m\"inferring another dtype in a future version. Cast the Index \"\u001b[39m\n",
      "                \u001b[33m\"explicitly before setting it into the DataFrame.\"\u001b[39m,\n",
      "                FutureWarning,\n",
      "                stacklevel=find_stack_level(),\n",
      "            )\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m arr, \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\n",
      "    @property\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m _series(self):\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m {item: self._ixs(idx, axis=\u001b[32m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m idx, item \u001b[38;5;28;01min\u001b[39;00m enumerate(self.columns)}\n",
      "\n",
      "    \u001b[38;5;66;03m# ----------------------------------------------------------------------\u001b[39;00m\n",
      "    \u001b[38;5;66;03m# Reindexing and alignment\u001b[39;00m\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m _reindex_multi(\n",
      "        self, axes: dict[str, Index], copy: bool, fill_value\n",
      "    ) -> DataFrame:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        We are guaranteed non-Nones in the axes.\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "\n",
      "        new_index, row_indexer = self.index.reindex(axes[\u001b[33m\"index\"\u001b[39m])\n",
      "        new_columns, col_indexer = self.columns.reindex(axes[\u001b[33m\"columns\"\u001b[39m])\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m row_indexer \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mand\u001b[39;00m col_indexer \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "            \u001b[38;5;66;03m# Fastpath. By doing two 'take's at once we avoid making an\u001b[39;00m\n",
      "            \u001b[38;5;66;03m#  unnecessary copy.\u001b[39;00m\n",
      "            \u001b[38;5;66;03m# We only get here with `self._can_fast_transpose`, which (almost)\u001b[39;00m\n",
      "            \u001b[38;5;66;03m#  ensures that self.values is cheap. It may be worth making this\u001b[39;00m\n",
      "            \u001b[38;5;66;03m#  condition more specific.\u001b[39;00m\n",
      "            indexer = row_indexer, col_indexer\n",
      "            new_values = take_2d_multi(self.values, indexer, fill_value=fill_value)\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m self._constructor(\n",
      "                new_values, index=new_index, columns=new_columns, copy=\u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "            )\n",
      "        \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m self._reindex_with_indexers(\n",
      "                {\u001b[32m0\u001b[39m: [new_index, row_indexer], \u001b[32m1\u001b[39m: [new_columns, col_indexer]},\n",
      "                copy=copy,\n",
      "                fill_value=fill_value,\n",
      "            )\n",
      "\n",
      "    @Appender(\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        >>> df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})\u001b[39m\n",
      "\n",
      "\u001b[33m        Change the row labels.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.set_axis(['a', 'b', 'c'], axis='index')\u001b[39m\n",
      "\u001b[33m           A  B\u001b[39m\n",
      "\u001b[33m        a  1  4\u001b[39m\n",
      "\u001b[33m        b  2  5\u001b[39m\n",
      "\u001b[33m        c  3  6\u001b[39m\n",
      "\n",
      "\u001b[33m        Change the column labels.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.set_axis(['I', 'II'], axis='columns')\u001b[39m\n",
      "\u001b[33m           I  II\u001b[39m\n",
      "\u001b[33m        0  1   4\u001b[39m\n",
      "\u001b[33m        1  2   5\u001b[39m\n",
      "\u001b[33m        2  3   6\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "    )\n",
      "    @Substitution(\n",
      "        klass=_shared_doc_kwargs[\u001b[33m\"klass\"\u001b[39m],\n",
      "        axes_single_arg=_shared_doc_kwargs[\u001b[33m\"axes_single_arg\"\u001b[39m],\n",
      "        extended_summary_sub=\u001b[33m\" column or\"\u001b[39m,\n",
      "        axis_description_sub=\u001b[33m\", and 1 identifies the columns\"\u001b[39m,\n",
      "        see_also_sub=\u001b[33m\" or columns\"\u001b[39m,\n",
      "    )\n",
      "    @Appender(NDFrame.set_axis.__doc__)\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m set_axis(\n",
      "        self,\n",
      "        labels,\n",
      "        *,\n",
      "        axis: Axis = \u001b[32m0\u001b[39m,\n",
      "        copy: bool | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    ) -> DataFrame:\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m super().set_axis(labels, axis=axis, copy=copy)\n",
      "\n",
      "    @doc(\n",
      "        NDFrame.reindex,\n",
      "        klass=_shared_doc_kwargs[\u001b[33m\"klass\"\u001b[39m],\n",
      "        optional_reindex=_shared_doc_kwargs[\u001b[33m\"optional_reindex\"\u001b[39m],\n",
      "    )\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m reindex(\n",
      "        self,\n",
      "        labels=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        *,\n",
      "        index=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        columns=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        axis: Axis | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        method: ReindexMethod | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        copy: bool | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        level: Level | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        fill_value: Scalar | \u001b[38;5;28;01mNone\u001b[39;00m = np.nan,\n",
      "        limit: int | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        tolerance=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    ) -> DataFrame:\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m super().reindex(\n",
      "            labels=labels,\n",
      "            index=index,\n",
      "            columns=columns,\n",
      "            axis=axis,\n",
      "            method=method,\n",
      "            copy=copy,\n",
      "            level=level,\n",
      "            fill_value=fill_value,\n",
      "            limit=limit,\n",
      "            tolerance=tolerance,\n",
      "        )\n",
      "\n",
      "    @overload\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m drop(\n",
      "        self,\n",
      "        labels: IndexLabel = ...,\n",
      "        *,\n",
      "        axis: Axis = ...,\n",
      "        index: IndexLabel = ...,\n",
      "        columns: IndexLabel = ...,\n",
      "        level: Level = ...,\n",
      "        inplace: Literal[\u001b[38;5;28;01mTrue\u001b[39;00m],\n",
      "        errors: IgnoreRaise = ...,\n",
      "    ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        ...\n",
      "\n",
      "    @overload\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m drop(\n",
      "        self,\n",
      "        labels: IndexLabel = ...,\n",
      "        *,\n",
      "        axis: Axis = ...,\n",
      "        index: IndexLabel = ...,\n",
      "        columns: IndexLabel = ...,\n",
      "        level: Level = ...,\n",
      "        inplace: Literal[\u001b[38;5;28;01mFalse\u001b[39;00m] = ...,\n",
      "        errors: IgnoreRaise = ...,\n",
      "    ) -> DataFrame:\n",
      "        ...\n",
      "\n",
      "    @overload\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m drop(\n",
      "        self,\n",
      "        labels: IndexLabel = ...,\n",
      "        *,\n",
      "        axis: Axis = ...,\n",
      "        index: IndexLabel = ...,\n",
      "        columns: IndexLabel = ...,\n",
      "        level: Level = ...,\n",
      "        inplace: bool = ...,\n",
      "        errors: IgnoreRaise = ...,\n",
      "    ) -> DataFrame | \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        ...\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m drop(\n",
      "        self,\n",
      "        labels: IndexLabel | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        *,\n",
      "        axis: Axis = \u001b[32m0\u001b[39m,\n",
      "        index: IndexLabel | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        columns: IndexLabel | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        level: Level | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        inplace: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "        errors: IgnoreRaise = \u001b[33m\"raise\"\u001b[39m,\n",
      "    ) -> DataFrame | \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Drop specified labels from rows or columns.\u001b[39m\n",
      "\n",
      "\u001b[33m        Remove rows or columns by specifying label names and corresponding\u001b[39m\n",
      "\u001b[33m        axis, or by directly specifying index or column names. When using a\u001b[39m\n",
      "\u001b[33m        multi-index, labels on different levels can be removed by specifying\u001b[39m\n",
      "\u001b[33m        the level. See the :ref:`user guide <advanced.shown_levels>`\u001b[39m\n",
      "\u001b[33m        for more information about the now unused levels.\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        labels : single label or list-like\u001b[39m\n",
      "\u001b[33m            Index or column labels to drop. A tuple will be used as a single\u001b[39m\n",
      "\u001b[33m            label and not treated as a list-like.\u001b[39m\n",
      "\u001b[33m        axis : {0 or 'index', 1 or 'columns'}, default 0\u001b[39m\n",
      "\u001b[33m            Whether to drop labels from the index (0 or 'index') or\u001b[39m\n",
      "\u001b[33m            columns (1 or 'columns').\u001b[39m\n",
      "\u001b[33m        index : single label or list-like\u001b[39m\n",
      "\u001b[33m            Alternative to specifying axis (``labels, axis=0``\u001b[39m\n",
      "\u001b[33m            is equivalent to ``index=labels``).\u001b[39m\n",
      "\u001b[33m        columns : single label or list-like\u001b[39m\n",
      "\u001b[33m            Alternative to specifying axis (``labels, axis=1``\u001b[39m\n",
      "\u001b[33m            is equivalent to ``columns=labels``).\u001b[39m\n",
      "\u001b[33m        level : int or level name, optional\u001b[39m\n",
      "\u001b[33m            For MultiIndex, level from which the labels will be removed.\u001b[39m\n",
      "\u001b[33m        inplace : bool, default False\u001b[39m\n",
      "\u001b[33m            If False, return a copy. Otherwise, do operation\u001b[39m\n",
      "\u001b[33m            in place and return None.\u001b[39m\n",
      "\u001b[33m        errors : {'ignore', 'raise'}, default 'raise'\u001b[39m\n",
      "\u001b[33m            If 'ignore', suppress error and only existing labels are\u001b[39m\n",
      "\u001b[33m            dropped.\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        DataFrame or None\u001b[39m\n",
      "\u001b[33m            Returns DataFrame or None DataFrame with the specified\u001b[39m\n",
      "\u001b[33m            index or column labels removed or None if inplace=True.\u001b[39m\n",
      "\n",
      "\u001b[33m        Raises\u001b[39m\n",
      "\u001b[33m        ------\u001b[39m\n",
      "\u001b[33m        KeyError\u001b[39m\n",
      "\u001b[33m            If any of the labels is not found in the selected axis.\u001b[39m\n",
      "\n",
      "\u001b[33m        See Also\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        DataFrame.loc : Label-location based indexer for selection by label.\u001b[39m\n",
      "\u001b[33m        DataFrame.dropna : Return DataFrame with labels on given axis omitted\u001b[39m\n",
      "\u001b[33m            where (all or any) data are missing.\u001b[39m\n",
      "\u001b[33m        DataFrame.drop_duplicates : Return DataFrame with duplicate rows\u001b[39m\n",
      "\u001b[33m            removed, optionally only considering certain columns.\u001b[39m\n",
      "\u001b[33m        Series.drop : Return Series with specified index labels removed.\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        >>> df = pd.DataFrame(np.arange(12).reshape(3, 4),\u001b[39m\n",
      "\u001b[33m        ...                   columns=['A', 'B', 'C', 'D'])\u001b[39m\n",
      "\u001b[33m        >>> df\u001b[39m\n",
      "\u001b[33m           A  B   C   D\u001b[39m\n",
      "\u001b[33m        0  0  1   2   3\u001b[39m\n",
      "\u001b[33m        1  4  5   6   7\u001b[39m\n",
      "\u001b[33m        2  8  9  10  11\u001b[39m\n",
      "\n",
      "\u001b[33m        Drop columns\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.drop(['B', 'C'], axis=1)\u001b[39m\n",
      "\u001b[33m           A   D\u001b[39m\n",
      "\u001b[33m        0  0   3\u001b[39m\n",
      "\u001b[33m        1  4   7\u001b[39m\n",
      "\u001b[33m        2  8  11\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.drop(columns=['B', 'C'])\u001b[39m\n",
      "\u001b[33m           A   D\u001b[39m\n",
      "\u001b[33m        0  0   3\u001b[39m\n",
      "\u001b[33m        1  4   7\u001b[39m\n",
      "\u001b[33m        2  8  11\u001b[39m\n",
      "\n",
      "\u001b[33m        Drop a row by index\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.drop([0, 1])\u001b[39m\n",
      "\u001b[33m           A  B   C   D\u001b[39m\n",
      "\u001b[33m        2  8  9  10  11\u001b[39m\n",
      "\n",
      "\u001b[33m        Drop columns and/or rows of MultiIndex DataFrame\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> midx = pd.MultiIndex(levels=[['llama', 'cow', 'falcon'],\u001b[39m\n",
      "\u001b[33m        ...                              ['speed', 'weight', 'length']],\u001b[39m\n",
      "\u001b[33m        ...                      codes=[[0, 0, 0, 1, 1, 1, 2, 2, 2],\u001b[39m\n",
      "\u001b[33m        ...                             [0, 1, 2, 0, 1, 2, 0, 1, 2]])\u001b[39m\n",
      "\u001b[33m        >>> df = pd.DataFrame(index=midx, columns=['big', 'small'],\u001b[39m\n",
      "\u001b[33m        ...                   data=[[45, 30], [200, 100], [1.5, 1], [30, 20],\u001b[39m\n",
      "\u001b[33m        ...                         [250, 150], [1.5, 0.8], [320, 250],\u001b[39m\n",
      "\u001b[33m        ...                         [1, 0.8], [0.3, 0.2]])\u001b[39m\n",
      "\u001b[33m        >>> df\u001b[39m\n",
      "\u001b[33m                        big     small\u001b[39m\n",
      "\u001b[33m        llama   speed   45.0    30.0\u001b[39m\n",
      "\u001b[33m                weight  200.0   100.0\u001b[39m\n",
      "\u001b[33m                length  1.5     1.0\u001b[39m\n",
      "\u001b[33m        cow     speed   30.0    20.0\u001b[39m\n",
      "\u001b[33m                weight  250.0   150.0\u001b[39m\n",
      "\u001b[33m                length  1.5     0.8\u001b[39m\n",
      "\u001b[33m        falcon  speed   320.0   250.0\u001b[39m\n",
      "\u001b[33m                weight  1.0     0.8\u001b[39m\n",
      "\u001b[33m                length  0.3     0.2\u001b[39m\n",
      "\n",
      "\u001b[33m        Drop a specific index combination from the MultiIndex\u001b[39m\n",
      "\u001b[33m        DataFrame, i.e., drop the combination ``'falcon'`` and\u001b[39m\n",
      "\u001b[33m        ``'weight'``, which deletes only the corresponding row\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.drop(index=('falcon', 'weight'))\u001b[39m\n",
      "\u001b[33m                        big     small\u001b[39m\n",
      "\u001b[33m        llama   speed   45.0    30.0\u001b[39m\n",
      "\u001b[33m                weight  200.0   100.0\u001b[39m\n",
      "\u001b[33m                length  1.5     1.0\u001b[39m\n",
      "\u001b[33m        cow     speed   30.0    20.0\u001b[39m\n",
      "\u001b[33m                weight  250.0   150.0\u001b[39m\n",
      "\u001b[33m                length  1.5     0.8\u001b[39m\n",
      "\u001b[33m        falcon  speed   320.0   250.0\u001b[39m\n",
      "\u001b[33m                length  0.3     0.2\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.drop(index='cow', columns='small')\u001b[39m\n",
      "\u001b[33m                        big\u001b[39m\n",
      "\u001b[33m        llama   speed   45.0\u001b[39m\n",
      "\u001b[33m                weight  200.0\u001b[39m\n",
      "\u001b[33m                length  1.5\u001b[39m\n",
      "\u001b[33m        falcon  speed   320.0\u001b[39m\n",
      "\u001b[33m                weight  1.0\u001b[39m\n",
      "\u001b[33m                length  0.3\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.drop(index='length', level=1)\u001b[39m\n",
      "\u001b[33m                        big     small\u001b[39m\n",
      "\u001b[33m        llama   speed   45.0    30.0\u001b[39m\n",
      "\u001b[33m                weight  200.0   100.0\u001b[39m\n",
      "\u001b[33m        cow     speed   30.0    20.0\u001b[39m\n",
      "\u001b[33m                weight  250.0   150.0\u001b[39m\n",
      "\u001b[33m        falcon  speed   320.0   250.0\u001b[39m\n",
      "\u001b[33m                weight  1.0     0.8\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m super().drop(\n",
      "            labels=labels,\n",
      "            axis=axis,\n",
      "            index=index,\n",
      "            columns=columns,\n",
      "            level=level,\n",
      "            inplace=inplace,\n",
      "            errors=errors,\n",
      "        )\n",
      "\n",
      "    @overload\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m rename(\n",
      "        self,\n",
      "        mapper: Renamer | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        *,\n",
      "        index: Renamer | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        columns: Renamer | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        axis: Axis | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        copy: bool | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        inplace: Literal[\u001b[38;5;28;01mTrue\u001b[39;00m],\n",
      "        level: Level = ...,\n",
      "        errors: IgnoreRaise = ...,\n",
      "    ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        ...\n",
      "\n",
      "    @overload\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m rename(\n",
      "        self,\n",
      "        mapper: Renamer | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        *,\n",
      "        index: Renamer | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        columns: Renamer | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        axis: Axis | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        copy: bool | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        inplace: Literal[\u001b[38;5;28;01mFalse\u001b[39;00m] = ...,\n",
      "        level: Level = ...,\n",
      "        errors: IgnoreRaise = ...,\n",
      "    ) -> DataFrame:\n",
      "        ...\n",
      "\n",
      "    @overload\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m rename(\n",
      "        self,\n",
      "        mapper: Renamer | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        *,\n",
      "        index: Renamer | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        columns: Renamer | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        axis: Axis | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        copy: bool | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        inplace: bool = ...,\n",
      "        level: Level = ...,\n",
      "        errors: IgnoreRaise = ...,\n",
      "    ) -> DataFrame | \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        ...\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m rename(\n",
      "        self,\n",
      "        mapper: Renamer | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        *,\n",
      "        index: Renamer | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        columns: Renamer | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        axis: Axis | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        copy: bool | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        inplace: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "        level: Level | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        errors: IgnoreRaise = \u001b[33m\"ignore\"\u001b[39m,\n",
      "    ) -> DataFrame | \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Rename columns or index labels.\u001b[39m\n",
      "\n",
      "\u001b[33m        Function / dict values must be unique (1-to-1). Labels not contained in\u001b[39m\n",
      "\u001b[33m        a dict / Series will be left as-is. Extra labels listed don't throw an\u001b[39m\n",
      "\u001b[33m        error.\u001b[39m\n",
      "\n",
      "\u001b[33m        See the :ref:`user guide <basics.rename>` for more.\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        mapper : dict-like or function\u001b[39m\n",
      "\u001b[33m            Dict-like or function transformations to apply to\u001b[39m\n",
      "\u001b[33m            that axis' values. Use either ``mapper`` and ``axis`` to\u001b[39m\n",
      "\u001b[33m            specify the axis to target with ``mapper``, or ``index`` and\u001b[39m\n",
      "\u001b[33m            ``columns``.\u001b[39m\n",
      "\u001b[33m        index : dict-like or function\u001b[39m\n",
      "\u001b[33m            Alternative to specifying axis (``mapper, axis=0``\u001b[39m\n",
      "\u001b[33m            is equivalent to ``index=mapper``).\u001b[39m\n",
      "\u001b[33m        columns : dict-like or function\u001b[39m\n",
      "\u001b[33m            Alternative to specifying axis (``mapper, axis=1``\u001b[39m\n",
      "\u001b[33m            is equivalent to ``columns=mapper``).\u001b[39m\n",
      "\u001b[33m        axis : {0 or 'index', 1 or 'columns'}, default 0\u001b[39m\n",
      "\u001b[33m            Axis to target with ``mapper``. Can be either the axis name\u001b[39m\n",
      "\u001b[33m            ('index', 'columns') or number (0, 1). The default is 'index'.\u001b[39m\n",
      "\u001b[33m        copy : bool, default True\u001b[39m\n",
      "\u001b[33m            Also copy underlying data.\u001b[39m\n",
      "\n",
      "\u001b[33m            .. note::\u001b[39m\n",
      "\u001b[33m                The `copy` keyword will change behavior in pandas 3.0.\u001b[39m\n",
      "\u001b[33m                `Copy-on-Write\u001b[39m\n",
      "\u001b[33m                <https://pandas.pydata.org/docs/dev/user_guide/copy_on_write.html>`__\u001b[39m\n",
      "\u001b[33m                will be enabled by default, which means that all methods with a\u001b[39m\n",
      "\u001b[33m                `copy` keyword will use a lazy copy mechanism to defer the copy and\u001b[39m\n",
      "\u001b[33m                ignore the `copy` keyword. The `copy` keyword will be removed in a\u001b[39m\n",
      "\u001b[33m                future version of pandas.\u001b[39m\n",
      "\n",
      "\u001b[33m                You can already get the future behavior and improvements through\u001b[39m\n",
      "\u001b[33m                enabling copy on write ``pd.options.mode.copy_on_write = True``\u001b[39m\n",
      "\u001b[33m        inplace : bool, default False\u001b[39m\n",
      "\u001b[33m            Whether to modify the DataFrame rather than creating a new one.\u001b[39m\n",
      "\u001b[33m            If True then value of copy is ignored.\u001b[39m\n",
      "\u001b[33m        level : int or level name, default None\u001b[39m\n",
      "\u001b[33m            In case of a MultiIndex, only rename labels in the specified\u001b[39m\n",
      "\u001b[33m            level.\u001b[39m\n",
      "\u001b[33m        errors : {'ignore', 'raise'}, default 'ignore'\u001b[39m\n",
      "\u001b[33m            If 'raise', raise a `KeyError` when a dict-like `mapper`, `index`,\u001b[39m\n",
      "\u001b[33m            or `columns` contains labels that are not present in the Index\u001b[39m\n",
      "\u001b[33m            being transformed.\u001b[39m\n",
      "\u001b[33m            If 'ignore', existing keys will be renamed and extra keys will be\u001b[39m\n",
      "\u001b[33m            ignored.\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        DataFrame or None\u001b[39m\n",
      "\u001b[33m            DataFrame with the renamed axis labels or None if ``inplace=True``.\u001b[39m\n",
      "\n",
      "\u001b[33m        Raises\u001b[39m\n",
      "\u001b[33m        ------\u001b[39m\n",
      "\u001b[33m        KeyError\u001b[39m\n",
      "\u001b[33m            If any of the labels is not found in the selected axis and\u001b[39m\n",
      "\u001b[33m            \"errors='raise'\".\u001b[39m\n",
      "\n",
      "\u001b[33m        See Also\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        DataFrame.rename_axis : Set the name of the axis.\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        ``DataFrame.rename`` supports two calling conventions\u001b[39m\n",
      "\n",
      "\u001b[33m        * ``(index=index_mapper, columns=columns_mapper, ...)``\u001b[39m\n",
      "\u001b[33m        * ``(mapper, axis={'index', 'columns'}, ...)``\u001b[39m\n",
      "\n",
      "\u001b[33m        We *highly* recommend using keyword arguments to clarify your\u001b[39m\n",
      "\u001b[33m        intent.\u001b[39m\n",
      "\n",
      "\u001b[33m        Rename columns using a mapping:\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})\u001b[39m\n",
      "\u001b[33m        >>> df.rename(columns={\"A\": \"a\", \"B\": \"c\"})\u001b[39m\n",
      "\u001b[33m           a  c\u001b[39m\n",
      "\u001b[33m        0  1  4\u001b[39m\n",
      "\u001b[33m        1  2  5\u001b[39m\n",
      "\u001b[33m        2  3  6\u001b[39m\n",
      "\n",
      "\u001b[33m        Rename index using a mapping:\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.rename(index={0: \"x\", 1: \"y\", 2: \"z\"})\u001b[39m\n",
      "\u001b[33m           A  B\u001b[39m\n",
      "\u001b[33m        x  1  4\u001b[39m\n",
      "\u001b[33m        y  2  5\u001b[39m\n",
      "\u001b[33m        z  3  6\u001b[39m\n",
      "\n",
      "\u001b[33m        Cast index labels to a different type:\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.index\u001b[39m\n",
      "\u001b[33m        RangeIndex(start=0, stop=3, step=1)\u001b[39m\n",
      "\u001b[33m        >>> df.rename(index=str).index\u001b[39m\n",
      "\u001b[33m        Index(['0', '1', '2'], dtype='object')\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.rename(columns={\"A\": \"a\", \"B\": \"b\", \"C\": \"c\"}, errors=\"raise\")\u001b[39m\n",
      "\u001b[33m        Traceback (most recent call last):\u001b[39m\n",
      "\u001b[33m        KeyError: ['C'] not found in axis\u001b[39m\n",
      "\n",
      "\u001b[33m        Using axis-style parameters:\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.rename(str.lower, axis='columns')\u001b[39m\n",
      "\u001b[33m           a  b\u001b[39m\n",
      "\u001b[33m        0  1  4\u001b[39m\n",
      "\u001b[33m        1  2  5\u001b[39m\n",
      "\u001b[33m        2  3  6\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.rename({1: 2, 2: 4}, axis='index')\u001b[39m\n",
      "\u001b[33m           A  B\u001b[39m\n",
      "\u001b[33m        0  1  4\u001b[39m\n",
      "\u001b[33m        2  2  5\u001b[39m\n",
      "\u001b[33m        4  3  6\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m super()._rename(\n",
      "            mapper=mapper,\n",
      "            index=index,\n",
      "            columns=columns,\n",
      "            axis=axis,\n",
      "            copy=copy,\n",
      "            inplace=inplace,\n",
      "            level=level,\n",
      "            errors=errors,\n",
      "        )\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m pop(self, item: Hashable) -> Series:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Return item and drop from frame. Raise KeyError if not found.\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        item : label\u001b[39m\n",
      "\u001b[33m            Label of column to be popped.\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        Series\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        >>> df = pd.DataFrame([('falcon', 'bird', 389.0),\u001b[39m\n",
      "\u001b[33m        ...                    ('parrot', 'bird', 24.0),\u001b[39m\n",
      "\u001b[33m        ...                    ('lion', 'mammal', 80.5),\u001b[39m\n",
      "\u001b[33m        ...                    ('monkey', 'mammal', np.nan)],\u001b[39m\n",
      "\u001b[33m        ...                   columns=('name', 'class', 'max_speed'))\u001b[39m\n",
      "\u001b[33m        >>> df\u001b[39m\n",
      "\u001b[33m             name   class  max_speed\u001b[39m\n",
      "\u001b[33m        0  falcon    bird      389.0\u001b[39m\n",
      "\u001b[33m        1  parrot    bird       24.0\u001b[39m\n",
      "\u001b[33m        2    lion  mammal       80.5\u001b[39m\n",
      "\u001b[33m        3  monkey  mammal        NaN\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.pop('class')\u001b[39m\n",
      "\u001b[33m        0      bird\u001b[39m\n",
      "\u001b[33m        1      bird\u001b[39m\n",
      "\u001b[33m        2    mammal\u001b[39m\n",
      "\u001b[33m        3    mammal\u001b[39m\n",
      "\u001b[33m        Name: class, dtype: object\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df\u001b[39m\n",
      "\u001b[33m             name  max_speed\u001b[39m\n",
      "\u001b[33m        0  falcon      389.0\u001b[39m\n",
      "\u001b[33m        1  parrot       24.0\u001b[39m\n",
      "\u001b[33m        2    lion       80.5\u001b[39m\n",
      "\u001b[33m        3  monkey        NaN\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m super().pop(item=item)\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m _replace_columnwise(\n",
      "        self, mapping: dict[Hashable, tuple[Any, Any]], inplace: bool, regex\n",
      "    ):\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Dispatch to Series.replace column-wise.\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        mapping : dict\u001b[39m\n",
      "\u001b[33m            of the form {col: (target, value)}\u001b[39m\n",
      "\u001b[33m        inplace : bool\u001b[39m\n",
      "\u001b[33m        regex : bool or same types as `to_replace` in DataFrame.replace\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        DataFrame or None\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;66;03m# Operate column-wise\u001b[39;00m\n",
      "        res = self \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m self.copy(deep=\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "        ax = self.columns\n",
      "\n",
      "        \u001b[38;5;28;01mfor\u001b[39;00m i, ax_value \u001b[38;5;28;01min\u001b[39;00m enumerate(ax):\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m ax_value \u001b[38;5;28;01min\u001b[39;00m mapping:\n",
      "                ser = self.iloc[:, i]\n",
      "\n",
      "                target, value = mapping[ax_value]\n",
      "                newobj = ser.replace(target, value, regex=regex)\n",
      "\n",
      "                res._iset_item(i, newobj, inplace=inplace)\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m inplace:\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m res.__finalize__(self)\n",
      "\n",
      "    @doc(NDFrame.shift, klass=_shared_doc_kwargs[\u001b[33m\"klass\"\u001b[39m])\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m shift(\n",
      "        self,\n",
      "        periods: int | Sequence[int] = \u001b[32m1\u001b[39m,\n",
      "        freq: Frequency | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        axis: Axis = \u001b[32m0\u001b[39m,\n",
      "        fill_value: Hashable = lib.no_default,\n",
      "        suffix: str | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    ) -> DataFrame:\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m freq \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mand\u001b[39;00m fill_value \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m lib.no_default:\n",
      "            \u001b[38;5;66;03m# GH#53832\u001b[39;00m\n",
      "            warnings.warn(\n",
      "                \u001b[33m\"Passing a 'freq' together with a 'fill_value' silently ignores \"\u001b[39m\n",
      "                \u001b[33m\"the fill_value and is deprecated. This will raise in a future \"\u001b[39m\n",
      "                \u001b[33m\"version.\"\u001b[39m,\n",
      "                FutureWarning,\n",
      "                stacklevel=find_stack_level(),\n",
      "            )\n",
      "            fill_value = lib.no_default\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m self.empty:\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m self.copy()\n",
      "\n",
      "        axis = self._get_axis_number(axis)\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m is_list_like(periods):\n",
      "            periods = cast(Sequence, periods)\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m axis == \u001b[32m1\u001b[39m:\n",
      "                \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\n",
      "                    \u001b[33m\"If `periods` contains multiple shifts, `axis` cannot be 1.\"\u001b[39m\n",
      "                )\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m len(periods) == \u001b[32m0\u001b[39m:\n",
      "                \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\u001b[33m\"If `periods` is an iterable, it cannot be empty.\"\u001b[39m)\n",
      "            \u001b[38;5;28;01mfrom\u001b[39;00m pandas.core.reshape.concat \u001b[38;5;28;01mimport\u001b[39;00m concat\n",
      "\n",
      "            shifted_dataframes = []\n",
      "            \u001b[38;5;28;01mfor\u001b[39;00m period \u001b[38;5;28;01min\u001b[39;00m periods:\n",
      "                \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m is_integer(period):\n",
      "                    \u001b[38;5;28;01mraise\u001b[39;00m TypeError(\n",
      "                        \u001b[33mf\"Periods must be integer, but {period} is {type(period)}.\"\u001b[39m\n",
      "                    )\n",
      "                period = cast(int, period)\n",
      "                shifted_dataframes.append(\n",
      "                    super()\n",
      "                    .shift(periods=period, freq=freq, axis=axis, fill_value=fill_value)\n",
      "                    .add_suffix(\u001b[33mf\"{suffix}_{period}\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m suffix \u001b[38;5;28;01melse\u001b[39;00m \u001b[33mf\"_{period}\"\u001b[39m)\n",
      "                )\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m concat(shifted_dataframes, axis=\u001b[32m1\u001b[39m)\n",
      "        \u001b[38;5;28;01melif\u001b[39;00m suffix:\n",
      "            \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\u001b[33m\"Cannot specify `suffix` if `periods` is an int.\"\u001b[39m)\n",
      "        periods = cast(int, periods)\n",
      "\n",
      "        ncols = len(self.columns)\n",
      "        arrays = self._mgr.arrays\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m axis == \u001b[32m1\u001b[39m \u001b[38;5;28;01mand\u001b[39;00m periods != \u001b[32m0\u001b[39m \u001b[38;5;28;01mand\u001b[39;00m ncols > \u001b[32m0\u001b[39m \u001b[38;5;28;01mand\u001b[39;00m freq \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m fill_value \u001b[38;5;28;01mis\u001b[39;00m lib.no_default:\n",
      "                \u001b[38;5;66;03m# We will infer fill_value to match the closest column\u001b[39;00m\n",
      "\n",
      "                \u001b[38;5;66;03m# Use a column that we know is valid for our column's dtype GH#38434\u001b[39;00m\n",
      "                label = self.columns[\u001b[32m0\u001b[39m]\n",
      "\n",
      "                \u001b[38;5;28;01mif\u001b[39;00m periods > \u001b[32m0\u001b[39m:\n",
      "                    result = self.iloc[:, :-periods]\n",
      "                    \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;28;01min\u001b[39;00m range(min(ncols, abs(periods))):\n",
      "                        \u001b[38;5;66;03m# TODO(EA2D): doing this in a loop unnecessary with 2D EAs\u001b[39;00m\n",
      "                        \u001b[38;5;66;03m# Define filler inside loop so we get a copy\u001b[39;00m\n",
      "                        filler = self.iloc[:, \u001b[32m0\u001b[39m].shift(len(self))\n",
      "                        result.insert(\u001b[32m0\u001b[39m, label, filler, allow_duplicates=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "                \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "                    result = self.iloc[:, -periods:]\n",
      "                    \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;28;01min\u001b[39;00m range(min(ncols, abs(periods))):\n",
      "                        \u001b[38;5;66;03m# Define filler inside loop so we get a copy\u001b[39;00m\n",
      "                        filler = self.iloc[:, -\u001b[32m1\u001b[39m].shift(len(self))\n",
      "                        result.insert(\n",
      "                            len(result.columns), label, filler, allow_duplicates=\u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "                        )\n",
      "\n",
      "                result.columns = self.columns.copy()\n",
      "                \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "            \u001b[38;5;28;01melif\u001b[39;00m len(arrays) > \u001b[32m1\u001b[39m \u001b[38;5;28;01mor\u001b[39;00m (\n",
      "                \u001b[38;5;66;03m# If we only have one block and we know that we can't\u001b[39;00m\n",
      "                \u001b[38;5;66;03m#  keep the same dtype (i.e. the _can_hold_element check)\u001b[39;00m\n",
      "                \u001b[38;5;66;03m#  then we can go through the reindex_indexer path\u001b[39;00m\n",
      "                \u001b[38;5;66;03m#  (and avoid casting logic in the Block method).\u001b[39;00m\n",
      "                \u001b[38;5;28;01mnot\u001b[39;00m can_hold_element(arrays[\u001b[32m0\u001b[39m], fill_value)\n",
      "            ):\n",
      "                \u001b[38;5;66;03m# GH#35488 we need to watch out for multi-block cases\u001b[39;00m\n",
      "                \u001b[38;5;66;03m# We only get here with fill_value not-lib.no_default\u001b[39;00m\n",
      "                nper = abs(periods)\n",
      "                nper = min(nper, ncols)\n",
      "                \u001b[38;5;28;01mif\u001b[39;00m periods > \u001b[32m0\u001b[39m:\n",
      "                    indexer = np.array(\n",
      "                        [-\u001b[32m1\u001b[39m] * nper + list(range(ncols - periods)), dtype=np.intp\n",
      "                    )\n",
      "                \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "                    indexer = np.array(\n",
      "                        list(range(nper, ncols)) + [-\u001b[32m1\u001b[39m] * nper, dtype=np.intp\n",
      "                    )\n",
      "                mgr = self._mgr.reindex_indexer(\n",
      "                    self.columns,\n",
      "                    indexer,\n",
      "                    axis=\u001b[32m0\u001b[39m,\n",
      "                    fill_value=fill_value,\n",
      "                    allow_dups=\u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "                )\n",
      "                res_df = self._constructor_from_mgr(mgr, axes=mgr.axes)\n",
      "                \u001b[38;5;28;01mreturn\u001b[39;00m res_df.__finalize__(self, method=\u001b[33m\"shift\"\u001b[39m)\n",
      "            \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "                \u001b[38;5;28;01mreturn\u001b[39;00m self.T.shift(periods=periods, fill_value=fill_value).T\n",
      "\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m super().shift(\n",
      "            periods=periods, freq=freq, axis=axis, fill_value=fill_value\n",
      "        )\n",
      "\n",
      "    @overload\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m set_index(\n",
      "        self,\n",
      "        keys,\n",
      "        *,\n",
      "        drop: bool = ...,\n",
      "        append: bool = ...,\n",
      "        inplace: Literal[\u001b[38;5;28;01mFalse\u001b[39;00m] = ...,\n",
      "        verify_integrity: bool = ...,\n",
      "    ) -> DataFrame:\n",
      "        ...\n",
      "\n",
      "    @overload\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m set_index(\n",
      "        self,\n",
      "        keys,\n",
      "        *,\n",
      "        drop: bool = ...,\n",
      "        append: bool = ...,\n",
      "        inplace: Literal[\u001b[38;5;28;01mTrue\u001b[39;00m],\n",
      "        verify_integrity: bool = ...,\n",
      "    ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        ...\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m set_index(\n",
      "        self,\n",
      "        keys,\n",
      "        *,\n",
      "        drop: bool = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "        append: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "        inplace: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "        verify_integrity: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "    ) -> DataFrame | \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Set the DataFrame index using existing columns.\u001b[39m\n",
      "\n",
      "\u001b[33m        Set the DataFrame index (row labels) using one or more existing\u001b[39m\n",
      "\u001b[33m        columns or arrays (of the correct length). The index can replace the\u001b[39m\n",
      "\u001b[33m        existing index or expand on it.\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        keys : label or array-like or list of labels/arrays\u001b[39m\n",
      "\u001b[33m            This parameter can be either a single column key, a single array of\u001b[39m\n",
      "\u001b[33m            the same length as the calling DataFrame, or a list containing an\u001b[39m\n",
      "\u001b[33m            arbitrary combination of column keys and arrays. Here, \"array\"\u001b[39m\n",
      "\u001b[33m            encompasses :class:`Series`, :class:`Index`, ``np.ndarray``, and\u001b[39m\n",
      "\u001b[33m            instances of :class:`~collections.abc.Iterator`.\u001b[39m\n",
      "\u001b[33m        drop : bool, default True\u001b[39m\n",
      "\u001b[33m            Delete columns to be used as the new index.\u001b[39m\n",
      "\u001b[33m        append : bool, default False\u001b[39m\n",
      "\u001b[33m            Whether to append columns to existing index.\u001b[39m\n",
      "\u001b[33m        inplace : bool, default False\u001b[39m\n",
      "\u001b[33m            Whether to modify the DataFrame rather than creating a new one.\u001b[39m\n",
      "\u001b[33m        verify_integrity : bool, default False\u001b[39m\n",
      "\u001b[33m            Check the new index for duplicates. Otherwise defer the check until\u001b[39m\n",
      "\u001b[33m            necessary. Setting to False will improve the performance of this\u001b[39m\n",
      "\u001b[33m            method.\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        DataFrame or None\u001b[39m\n",
      "\u001b[33m            Changed row labels or None if ``inplace=True``.\u001b[39m\n",
      "\n",
      "\u001b[33m        See Also\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        DataFrame.reset_index : Opposite of set_index.\u001b[39m\n",
      "\u001b[33m        DataFrame.reindex : Change to new indices or expand indices.\u001b[39m\n",
      "\u001b[33m        DataFrame.reindex_like : Change to same indices as other DataFrame.\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        >>> df = pd.DataFrame({'month': [1, 4, 7, 10],\u001b[39m\n",
      "\u001b[33m        ...                    'year': [2012, 2014, 2013, 2014],\u001b[39m\n",
      "\u001b[33m        ...                    'sale': [55, 40, 84, 31]})\u001b[39m\n",
      "\u001b[33m        >>> df\u001b[39m\n",
      "\u001b[33m           month  year  sale\u001b[39m\n",
      "\u001b[33m        0      1  2012    55\u001b[39m\n",
      "\u001b[33m        1      4  2014    40\u001b[39m\n",
      "\u001b[33m        2      7  2013    84\u001b[39m\n",
      "\u001b[33m        3     10  2014    31\u001b[39m\n",
      "\n",
      "\u001b[33m        Set the index to become the 'month' column:\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.set_index('month')\u001b[39m\n",
      "\u001b[33m               year  sale\u001b[39m\n",
      "\u001b[33m        month\u001b[39m\n",
      "\u001b[33m        1      2012    55\u001b[39m\n",
      "\u001b[33m        4      2014    40\u001b[39m\n",
      "\u001b[33m        7      2013    84\u001b[39m\n",
      "\u001b[33m        10     2014    31\u001b[39m\n",
      "\n",
      "\u001b[33m        Create a MultiIndex using columns 'year' and 'month':\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.set_index(['year', 'month'])\u001b[39m\n",
      "\u001b[33m                    sale\u001b[39m\n",
      "\u001b[33m        year  month\u001b[39m\n",
      "\u001b[33m        2012  1     55\u001b[39m\n",
      "\u001b[33m        2014  4     40\u001b[39m\n",
      "\u001b[33m        2013  7     84\u001b[39m\n",
      "\u001b[33m        2014  10    31\u001b[39m\n",
      "\n",
      "\u001b[33m        Create a MultiIndex using an Index and a column:\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.set_index([pd.Index([1, 2, 3, 4]), 'year'])\u001b[39m\n",
      "\u001b[33m                 month  sale\u001b[39m\n",
      "\u001b[33m           year\u001b[39m\n",
      "\u001b[33m        1  2012  1      55\u001b[39m\n",
      "\u001b[33m        2  2014  4      40\u001b[39m\n",
      "\u001b[33m        3  2013  7      84\u001b[39m\n",
      "\u001b[33m        4  2014  10     31\u001b[39m\n",
      "\n",
      "\u001b[33m        Create a MultiIndex using two Series:\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> s = pd.Series([1, 2, 3, 4])\u001b[39m\n",
      "\u001b[33m        >>> df.set_index([s, s**2])\u001b[39m\n",
      "\u001b[33m              month  year  sale\u001b[39m\n",
      "\u001b[33m        1 1       1  2012    55\u001b[39m\n",
      "\u001b[33m        2 4       4  2014    40\u001b[39m\n",
      "\u001b[33m        3 9       7  2013    84\u001b[39m\n",
      "\u001b[33m        4 16     10  2014    31\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        inplace = validate_bool_kwarg(inplace, \u001b[33m\"inplace\"\u001b[39m)\n",
      "        self._check_inplace_and_allows_duplicate_labels(inplace)\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m isinstance(keys, list):\n",
      "            keys = [keys]\n",
      "\n",
      "        err_msg = (\n",
      "            \u001b[33m'The parameter \"keys\" may be a column key, one-dimensional '\u001b[39m\n",
      "            \u001b[33m\"array, or a list containing only valid column keys and \"\u001b[39m\n",
      "            \u001b[33m\"one-dimensional arrays.\"\u001b[39m\n",
      "        )\n",
      "\n",
      "        missing: list[Hashable] = []\n",
      "        \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;28;01min\u001b[39;00m keys:\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m isinstance(col, (Index, Series, np.ndarray, list, abc.Iterator)):\n",
      "                \u001b[38;5;66;03m# arrays are fine as long as they are one-dimensional\u001b[39;00m\n",
      "                \u001b[38;5;66;03m# iterators get converted to list below\u001b[39;00m\n",
      "                \u001b[38;5;28;01mif\u001b[39;00m getattr(col, \u001b[33m\"ndim\"\u001b[39m, \u001b[32m1\u001b[39m) != \u001b[32m1\u001b[39m:\n",
      "                    \u001b[38;5;28;01mraise\u001b[39;00m ValueError(err_msg)\n",
      "            \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "                \u001b[38;5;66;03m# everything else gets tried as a key; see GH 24969\u001b[39;00m\n",
      "                \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "                    found = col \u001b[38;5;28;01min\u001b[39;00m self.columns\n",
      "                \u001b[38;5;28;01mexcept\u001b[39;00m TypeError \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "                    \u001b[38;5;28;01mraise\u001b[39;00m TypeError(\n",
      "                        \u001b[33mf\"{err_msg}. Received column of type {type(col)}\"\u001b[39m\n",
      "                    ) \u001b[38;5;28;01mfrom\u001b[39;00m err\n",
      "                \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "                    \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m found:\n",
      "                        missing.append(col)\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m missing:\n",
      "            \u001b[38;5;28;01mraise\u001b[39;00m KeyError(\u001b[33mf\"None of {missing} are in the columns\"\u001b[39m)\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m inplace:\n",
      "            frame = self\n",
      "        \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "            \u001b[38;5;66;03m# GH 49473 Use \"lazy copy\" with Copy-on-Write\u001b[39;00m\n",
      "            frame = self.copy(deep=\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\n",
      "        arrays: list[Index] = []\n",
      "        names: list[Hashable] = []\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m append:\n",
      "            names = list(self.index.names)\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m isinstance(self.index, MultiIndex):\n",
      "                arrays.extend(\n",
      "                    self.index._get_level_values(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;28;01min\u001b[39;00m range(self.index.nlevels)\n",
      "                )\n",
      "            \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "                arrays.append(self.index)\n",
      "\n",
      "        to_remove: list[Hashable] = []\n",
      "        \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;28;01min\u001b[39;00m keys:\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m isinstance(col, MultiIndex):\n",
      "                arrays.extend(col._get_level_values(n) \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;28;01min\u001b[39;00m range(col.nlevels))\n",
      "                names.extend(col.names)\n",
      "            \u001b[38;5;28;01melif\u001b[39;00m isinstance(col, (Index, Series)):\n",
      "                \u001b[38;5;66;03m# if Index then not MultiIndex (treated above)\u001b[39;00m\n",
      "\n",
      "                \u001b[38;5;66;03m# error: Argument 1 to \"append\" of \"list\" has incompatible type\u001b[39;00m\n",
      "                \u001b[38;5;66;03m#  \"Union[Index, Series]\"; expected \"Index\"\u001b[39;00m\n",
      "                arrays.append(col)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "                names.append(col.name)\n",
      "            \u001b[38;5;28;01melif\u001b[39;00m isinstance(col, (list, np.ndarray)):\n",
      "                \u001b[38;5;66;03m# error: Argument 1 to \"append\" of \"list\" has incompatible type\u001b[39;00m\n",
      "                \u001b[38;5;66;03m# \"Union[List[Any], ndarray]\"; expected \"Index\"\u001b[39;00m\n",
      "                arrays.append(col)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "                names.append(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "            \u001b[38;5;28;01melif\u001b[39;00m isinstance(col, abc.Iterator):\n",
      "                \u001b[38;5;66;03m# error: Argument 1 to \"append\" of \"list\" has incompatible type\u001b[39;00m\n",
      "                \u001b[38;5;66;03m# \"List[Any]\"; expected \"Index\"\u001b[39;00m\n",
      "                arrays.append(list(col))  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "                names.append(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "            \u001b[38;5;66;03m# from here, col can only be a column label\u001b[39;00m\n",
      "            \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "                arrays.append(frame[col])\n",
      "                names.append(col)\n",
      "                \u001b[38;5;28;01mif\u001b[39;00m drop:\n",
      "                    to_remove.append(col)\n",
      "\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m len(arrays[-\u001b[32m1\u001b[39m]) != len(self):\n",
      "                \u001b[38;5;66;03m# check newest element against length of calling frame, since\u001b[39;00m\n",
      "                \u001b[38;5;66;03m# ensure_index_from_sequences would not raise for append=False.\u001b[39;00m\n",
      "                \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\n",
      "                    \u001b[33mf\"Length mismatch: Expected {len(self)} rows, \"\u001b[39m\n",
      "                    \u001b[33mf\"received array of length {len(arrays[-1])}\"\u001b[39m\n",
      "                )\n",
      "\n",
      "        index = ensure_index_from_sequences(arrays, names)\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m verify_integrity \u001b[38;5;28;01mand\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m index.is_unique:\n",
      "            duplicates = index[index.duplicated()].unique()\n",
      "            \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\u001b[33mf\"Index has duplicate keys: {duplicates}\"\u001b[39m)\n",
      "\n",
      "        \u001b[38;5;66;03m# use set to handle duplicate column names gracefully in case of drop\u001b[39;00m\n",
      "        \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;28;01min\u001b[39;00m set(to_remove):\n",
      "            \u001b[38;5;28;01mdel\u001b[39;00m frame[c]\n",
      "\n",
      "        \u001b[38;5;66;03m# clear up memory usage\u001b[39;00m\n",
      "        index._cleanup()\n",
      "\n",
      "        frame.index = index\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m inplace:\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m frame\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\n",
      "    @overload\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m reset_index(\n",
      "        self,\n",
      "        level: IndexLabel = ...,\n",
      "        *,\n",
      "        drop: bool = ...,\n",
      "        inplace: Literal[\u001b[38;5;28;01mFalse\u001b[39;00m] = ...,\n",
      "        col_level: Hashable = ...,\n",
      "        col_fill: Hashable = ...,\n",
      "        allow_duplicates: bool | lib.NoDefault = ...,\n",
      "        names: Hashable | Sequence[Hashable] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    ) -> DataFrame:\n",
      "        ...\n",
      "\n",
      "    @overload\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m reset_index(\n",
      "        self,\n",
      "        level: IndexLabel = ...,\n",
      "        *,\n",
      "        drop: bool = ...,\n",
      "        inplace: Literal[\u001b[38;5;28;01mTrue\u001b[39;00m],\n",
      "        col_level: Hashable = ...,\n",
      "        col_fill: Hashable = ...,\n",
      "        allow_duplicates: bool | lib.NoDefault = ...,\n",
      "        names: Hashable | Sequence[Hashable] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        ...\n",
      "\n",
      "    @overload\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m reset_index(\n",
      "        self,\n",
      "        level: IndexLabel = ...,\n",
      "        *,\n",
      "        drop: bool = ...,\n",
      "        inplace: bool = ...,\n",
      "        col_level: Hashable = ...,\n",
      "        col_fill: Hashable = ...,\n",
      "        allow_duplicates: bool | lib.NoDefault = ...,\n",
      "        names: Hashable | Sequence[Hashable] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    ) -> DataFrame | \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        ...\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m reset_index(\n",
      "        self,\n",
      "        level: IndexLabel | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        *,\n",
      "        drop: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "        inplace: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "        col_level: Hashable = \u001b[32m0\u001b[39m,\n",
      "        col_fill: Hashable = \u001b[33m\"\"\u001b[39m,\n",
      "        allow_duplicates: bool | lib.NoDefault = lib.no_default,\n",
      "        names: Hashable | Sequence[Hashable] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    ) -> DataFrame | \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Reset the index, or a level of it.\u001b[39m\n",
      "\n",
      "\u001b[33m        Reset the index of the DataFrame, and use the default one instead.\u001b[39m\n",
      "\u001b[33m        If the DataFrame has a MultiIndex, this method can remove one or more\u001b[39m\n",
      "\u001b[33m        levels.\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        level : int, str, tuple, or list, default None\u001b[39m\n",
      "\u001b[33m            Only remove the given levels from the index. Removes all levels by\u001b[39m\n",
      "\u001b[33m            default.\u001b[39m\n",
      "\u001b[33m        drop : bool, default False\u001b[39m\n",
      "\u001b[33m            Do not try to insert index into dataframe columns. This resets\u001b[39m\n",
      "\u001b[33m            the index to the default integer index.\u001b[39m\n",
      "\u001b[33m        inplace : bool, default False\u001b[39m\n",
      "\u001b[33m            Whether to modify the DataFrame rather than creating a new one.\u001b[39m\n",
      "\u001b[33m        col_level : int or str, default 0\u001b[39m\n",
      "\u001b[33m            If the columns have multiple levels, determines which level the\u001b[39m\n",
      "\u001b[33m            labels are inserted into. By default it is inserted into the first\u001b[39m\n",
      "\u001b[33m            level.\u001b[39m\n",
      "\u001b[33m        col_fill : object, default ''\u001b[39m\n",
      "\u001b[33m            If the columns have multiple levels, determines how the other\u001b[39m\n",
      "\u001b[33m            levels are named. If None then the index name is repeated.\u001b[39m\n",
      "\u001b[33m        allow_duplicates : bool, optional, default lib.no_default\u001b[39m\n",
      "\u001b[33m            Allow duplicate column labels to be created.\u001b[39m\n",
      "\n",
      "\u001b[33m            .. versionadded:: 1.5.0\u001b[39m\n",
      "\n",
      "\u001b[33m        names : int, str or 1-dimensional list, default None\u001b[39m\n",
      "\u001b[33m            Using the given string, rename the DataFrame column which contains the\u001b[39m\n",
      "\u001b[33m            index data. If the DataFrame has a MultiIndex, this has to be a list or\u001b[39m\n",
      "\u001b[33m            tuple with length equal to the number of levels.\u001b[39m\n",
      "\n",
      "\u001b[33m            .. versionadded:: 1.5.0\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        DataFrame or None\u001b[39m\n",
      "\u001b[33m            DataFrame with the new index or None if ``inplace=True``.\u001b[39m\n",
      "\n",
      "\u001b[33m        See Also\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        DataFrame.set_index : Opposite of reset_index.\u001b[39m\n",
      "\u001b[33m        DataFrame.reindex : Change to new indices or expand indices.\u001b[39m\n",
      "\u001b[33m        DataFrame.reindex_like : Change to same indices as other DataFrame.\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        >>> df = pd.DataFrame([('bird', 389.0),\u001b[39m\n",
      "\u001b[33m        ...                    ('bird', 24.0),\u001b[39m\n",
      "\u001b[33m        ...                    ('mammal', 80.5),\u001b[39m\n",
      "\u001b[33m        ...                    ('mammal', np.nan)],\u001b[39m\n",
      "\u001b[33m        ...                   index=['falcon', 'parrot', 'lion', 'monkey'],\u001b[39m\n",
      "\u001b[33m        ...                   columns=('class', 'max_speed'))\u001b[39m\n",
      "\u001b[33m        >>> df\u001b[39m\n",
      "\u001b[33m                 class  max_speed\u001b[39m\n",
      "\u001b[33m        falcon    bird      389.0\u001b[39m\n",
      "\u001b[33m        parrot    bird       24.0\u001b[39m\n",
      "\u001b[33m        lion    mammal       80.5\u001b[39m\n",
      "\u001b[33m        monkey  mammal        NaN\u001b[39m\n",
      "\n",
      "\u001b[33m        When we reset the index, the old index is added as a column, and a\u001b[39m\n",
      "\u001b[33m        new sequential index is used:\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.reset_index()\u001b[39m\n",
      "\u001b[33m            index   class  max_speed\u001b[39m\n",
      "\u001b[33m        0  falcon    bird      389.0\u001b[39m\n",
      "\u001b[33m        1  parrot    bird       24.0\u001b[39m\n",
      "\u001b[33m        2    lion  mammal       80.5\u001b[39m\n",
      "\u001b[33m        3  monkey  mammal        NaN\u001b[39m\n",
      "\n",
      "\u001b[33m        We can use the `drop` parameter to avoid the old index being added as\u001b[39m\n",
      "\u001b[33m        a column:\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.reset_index(drop=True)\u001b[39m\n",
      "\u001b[33m            class  max_speed\u001b[39m\n",
      "\u001b[33m        0    bird      389.0\u001b[39m\n",
      "\u001b[33m        1    bird       24.0\u001b[39m\n",
      "\u001b[33m        2  mammal       80.5\u001b[39m\n",
      "\u001b[33m        3  mammal        NaN\u001b[39m\n",
      "\n",
      "\u001b[33m        You can also use `reset_index` with `MultiIndex`.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> index = pd.MultiIndex.from_tuples([('bird', 'falcon'),\u001b[39m\n",
      "\u001b[33m        ...                                    ('bird', 'parrot'),\u001b[39m\n",
      "\u001b[33m        ...                                    ('mammal', 'lion'),\u001b[39m\n",
      "\u001b[33m        ...                                    ('mammal', 'monkey')],\u001b[39m\n",
      "\u001b[33m        ...                                   names=['class', 'name'])\u001b[39m\n",
      "\u001b[33m        >>> columns = pd.MultiIndex.from_tuples([('speed', 'max'),\u001b[39m\n",
      "\u001b[33m        ...                                      ('species', 'type')])\u001b[39m\n",
      "\u001b[33m        >>> df = pd.DataFrame([(389.0, 'fly'),\u001b[39m\n",
      "\u001b[33m        ...                    (24.0, 'fly'),\u001b[39m\n",
      "\u001b[33m        ...                    (80.5, 'run'),\u001b[39m\n",
      "\u001b[33m        ...                    (np.nan, 'jump')],\u001b[39m\n",
      "\u001b[33m        ...                   index=index,\u001b[39m\n",
      "\u001b[33m        ...                   columns=columns)\u001b[39m\n",
      "\u001b[33m        >>> df\u001b[39m\n",
      "\u001b[33m                       speed species\u001b[39m\n",
      "\u001b[33m                         max    type\u001b[39m\n",
      "\u001b[33m        class  name\u001b[39m\n",
      "\u001b[33m        bird   falcon  389.0     fly\u001b[39m\n",
      "\u001b[33m               parrot   24.0     fly\u001b[39m\n",
      "\u001b[33m        mammal lion     80.5     run\u001b[39m\n",
      "\u001b[33m               monkey    NaN    jump\u001b[39m\n",
      "\n",
      "\u001b[33m        Using the `names` parameter, choose a name for the index column:\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.reset_index(names=['classes', 'names'])\u001b[39m\n",
      "\u001b[33m          classes   names  speed species\u001b[39m\n",
      "\u001b[33m                             max    type\u001b[39m\n",
      "\u001b[33m        0    bird  falcon  389.0     fly\u001b[39m\n",
      "\u001b[33m        1    bird  parrot   24.0     fly\u001b[39m\n",
      "\u001b[33m        2  mammal    lion   80.5     run\u001b[39m\n",
      "\u001b[33m        3  mammal  monkey    NaN    jump\u001b[39m\n",
      "\n",
      "\u001b[33m        If the index has multiple levels, we can reset a subset of them:\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.reset_index(level='class')\u001b[39m\n",
      "\u001b[33m                 class  speed species\u001b[39m\n",
      "\u001b[33m                          max    type\u001b[39m\n",
      "\u001b[33m        name\u001b[39m\n",
      "\u001b[33m        falcon    bird  389.0     fly\u001b[39m\n",
      "\u001b[33m        parrot    bird   24.0     fly\u001b[39m\n",
      "\u001b[33m        lion    mammal   80.5     run\u001b[39m\n",
      "\u001b[33m        monkey  mammal    NaN    jump\u001b[39m\n",
      "\n",
      "\u001b[33m        If we are not dropping the index, by default, it is placed in the top\u001b[39m\n",
      "\u001b[33m        level. We can place it in another level:\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.reset_index(level='class', col_level=1)\u001b[39m\n",
      "\u001b[33m                        speed species\u001b[39m\n",
      "\u001b[33m                 class    max    type\u001b[39m\n",
      "\u001b[33m        name\u001b[39m\n",
      "\u001b[33m        falcon    bird  389.0     fly\u001b[39m\n",
      "\u001b[33m        parrot    bird   24.0     fly\u001b[39m\n",
      "\u001b[33m        lion    mammal   80.5     run\u001b[39m\n",
      "\u001b[33m        monkey  mammal    NaN    jump\u001b[39m\n",
      "\n",
      "\u001b[33m        When the index is inserted under another level, we can specify under\u001b[39m\n",
      "\u001b[33m        which one with the parameter `col_fill`:\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.reset_index(level='class', col_level=1, col_fill='species')\u001b[39m\n",
      "\u001b[33m                      species  speed species\u001b[39m\n",
      "\u001b[33m                        class    max    type\u001b[39m\n",
      "\u001b[33m        name\u001b[39m\n",
      "\u001b[33m        falcon           bird  389.0     fly\u001b[39m\n",
      "\u001b[33m        parrot           bird   24.0     fly\u001b[39m\n",
      "\u001b[33m        lion           mammal   80.5     run\u001b[39m\n",
      "\u001b[33m        monkey         mammal    NaN    jump\u001b[39m\n",
      "\n",
      "\u001b[33m        If we specify a nonexistent level for `col_fill`, it is created:\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.reset_index(level='class', col_level=1, col_fill='genus')\u001b[39m\n",
      "\u001b[33m                        genus  speed species\u001b[39m\n",
      "\u001b[33m                        class    max    type\u001b[39m\n",
      "\u001b[33m        name\u001b[39m\n",
      "\u001b[33m        falcon           bird  389.0     fly\u001b[39m\n",
      "\u001b[33m        parrot           bird   24.0     fly\u001b[39m\n",
      "\u001b[33m        lion           mammal   80.5     run\u001b[39m\n",
      "\u001b[33m        monkey         mammal    NaN    jump\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        inplace = validate_bool_kwarg(inplace, \u001b[33m\"inplace\"\u001b[39m)\n",
      "        self._check_inplace_and_allows_duplicate_labels(inplace)\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m inplace:\n",
      "            new_obj = self\n",
      "        \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "            new_obj = self.copy(deep=\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m allow_duplicates \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m lib.no_default:\n",
      "            allow_duplicates = validate_bool_kwarg(allow_duplicates, \u001b[33m\"allow_duplicates\"\u001b[39m)\n",
      "\n",
      "        new_index = default_index(len(new_obj))\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m isinstance(level, (tuple, list)):\n",
      "                level = [level]\n",
      "            level = [self.index._get_level_number(lev) \u001b[38;5;28;01mfor\u001b[39;00m lev \u001b[38;5;28;01min\u001b[39;00m level]\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m len(level) < self.index.nlevels:\n",
      "                new_index = self.index.droplevel(level)\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m drop:\n",
      "            to_insert: Iterable[tuple[Any, Any | \u001b[38;5;28;01mNone\u001b[39;00m]]\n",
      "\n",
      "            default = \u001b[33m\"index\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"index\"\u001b[39m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01min\u001b[39;00m self \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"level_0\"\u001b[39m\n",
      "            names = self.index._get_default_index_names(names, default)\n",
      "\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m isinstance(self.index, MultiIndex):\n",
      "                to_insert = zip(self.index.levels, self.index.codes)\n",
      "            \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "                to_insert = ((self.index, \u001b[38;5;28;01mNone\u001b[39;00m),)\n",
      "\n",
      "            multi_col = isinstance(self.columns, MultiIndex)\n",
      "            \u001b[38;5;28;01mfor\u001b[39;00m i, (lev, lab) \u001b[38;5;28;01min\u001b[39;00m reversed(list(enumerate(to_insert))):\n",
      "                \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mand\u001b[39;00m i \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01min\u001b[39;00m level:\n",
      "                    \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "                name = names[i]\n",
      "                \u001b[38;5;28;01mif\u001b[39;00m multi_col:\n",
      "                    col_name = list(name) \u001b[38;5;28;01mif\u001b[39;00m isinstance(name, tuple) \u001b[38;5;28;01melse\u001b[39;00m [name]\n",
      "                    \u001b[38;5;28;01mif\u001b[39;00m col_fill \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "                        \u001b[38;5;28;01mif\u001b[39;00m len(col_name) \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01min\u001b[39;00m (\u001b[32m1\u001b[39m, self.columns.nlevels):\n",
      "                            \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\n",
      "                                \u001b[33m\"col_fill=None is incompatible \"\u001b[39m\n",
      "                                \u001b[33mf\"with incomplete column name {name}\"\u001b[39m\n",
      "                            )\n",
      "                        col_fill = col_name[\u001b[32m0\u001b[39m]\n",
      "\n",
      "                    lev_num = self.columns._get_level_number(col_level)\n",
      "                    name_lst = [col_fill] * lev_num + col_name\n",
      "                    missing = self.columns.nlevels - len(name_lst)\n",
      "                    name_lst += [col_fill] * missing\n",
      "                    name = tuple(name_lst)\n",
      "\n",
      "                \u001b[38;5;66;03m# to ndarray and maybe infer different dtype\u001b[39;00m\n",
      "                level_values = lev._values\n",
      "                \u001b[38;5;28;01mif\u001b[39;00m level_values.dtype == np.object_:\n",
      "                    level_values = lib.maybe_convert_objects(level_values)\n",
      "\n",
      "                \u001b[38;5;28;01mif\u001b[39;00m lab \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "                    \u001b[38;5;66;03m# if we have the codes, extract the values with a mask\u001b[39;00m\n",
      "                    level_values = algorithms.take(\n",
      "                        level_values, lab, allow_fill=\u001b[38;5;28;01mTrue\u001b[39;00m, fill_value=lev._na_value\n",
      "                    )\n",
      "\n",
      "                new_obj.insert(\n",
      "                    \u001b[32m0\u001b[39m,\n",
      "                    name,\n",
      "                    level_values,\n",
      "                    allow_duplicates=allow_duplicates,\n",
      "                )\n",
      "\n",
      "        new_obj.index = new_index\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m inplace:\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m new_obj\n",
      "\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\n",
      "    \u001b[38;5;66;03m# ----------------------------------------------------------------------\u001b[39;00m\n",
      "    \u001b[38;5;66;03m# Reindex-based selection methods\u001b[39;00m\n",
      "\n",
      "    @doc(NDFrame.isna, klass=_shared_doc_kwargs[\u001b[33m\"klass\"\u001b[39m])\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m isna(self) -> DataFrame:\n",
      "        res_mgr = self._mgr.isna(func=isna)\n",
      "        result = self._constructor_from_mgr(res_mgr, axes=res_mgr.axes)\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m result.__finalize__(self, method=\u001b[33m\"isna\"\u001b[39m)\n",
      "\n",
      "    @doc(NDFrame.isna, klass=_shared_doc_kwargs[\u001b[33m\"klass\"\u001b[39m])\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m isnull(self) -> DataFrame:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        DataFrame.isnull is an alias for DataFrame.isna.\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m self.isna()\n",
      "\n",
      "    @doc(NDFrame.notna, klass=_shared_doc_kwargs[\u001b[33m\"klass\"\u001b[39m])\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m notna(self) -> DataFrame:\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m ~self.isna()\n",
      "\n",
      "    @doc(NDFrame.notna, klass=_shared_doc_kwargs[\u001b[33m\"klass\"\u001b[39m])\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m notnull(self) -> DataFrame:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        DataFrame.notnull is an alias for DataFrame.notna.\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m ~self.isna()\n",
      "\n",
      "    @overload\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m dropna(\n",
      "        self,\n",
      "        *,\n",
      "        axis: Axis = ...,\n",
      "        how: AnyAll | lib.NoDefault = ...,\n",
      "        thresh: int | lib.NoDefault = ...,\n",
      "        subset: IndexLabel = ...,\n",
      "        inplace: Literal[\u001b[38;5;28;01mFalse\u001b[39;00m] = ...,\n",
      "        ignore_index: bool = ...,\n",
      "    ) -> DataFrame:\n",
      "        ...\n",
      "\n",
      "    @overload\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m dropna(\n",
      "        self,\n",
      "        *,\n",
      "        axis: Axis = ...,\n",
      "        how: AnyAll | lib.NoDefault = ...,\n",
      "        thresh: int | lib.NoDefault = ...,\n",
      "        subset: IndexLabel = ...,\n",
      "        inplace: Literal[\u001b[38;5;28;01mTrue\u001b[39;00m],\n",
      "        ignore_index: bool = ...,\n",
      "    ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        ...\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m dropna(\n",
      "        self,\n",
      "        *,\n",
      "        axis: Axis = \u001b[32m0\u001b[39m,\n",
      "        how: AnyAll | lib.NoDefault = lib.no_default,\n",
      "        thresh: int | lib.NoDefault = lib.no_default,\n",
      "        subset: IndexLabel | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        inplace: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "        ignore_index: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "    ) -> DataFrame | \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Remove missing values.\u001b[39m\n",
      "\n",
      "\u001b[33m        See the :ref:`User Guide <missing_data>` for more on which values are\u001b[39m\n",
      "\u001b[33m        considered missing, and how to work with missing data.\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        axis : {0 or 'index', 1 or 'columns'}, default 0\u001b[39m\n",
      "\u001b[33m            Determine if rows or columns which contain missing values are\u001b[39m\n",
      "\u001b[33m            removed.\u001b[39m\n",
      "\n",
      "\u001b[33m            * 0, or 'index' : Drop rows which contain missing values.\u001b[39m\n",
      "\u001b[33m            * 1, or 'columns' : Drop columns which contain missing value.\u001b[39m\n",
      "\n",
      "\u001b[33m            Only a single axis is allowed.\u001b[39m\n",
      "\n",
      "\u001b[33m        how : {'any', 'all'}, default 'any'\u001b[39m\n",
      "\u001b[33m            Determine if row or column is removed from DataFrame, when we have\u001b[39m\n",
      "\u001b[33m            at least one NA or all NA.\u001b[39m\n",
      "\n",
      "\u001b[33m            * 'any' : If any NA values are present, drop that row or column.\u001b[39m\n",
      "\u001b[33m            * 'all' : If all values are NA, drop that row or column.\u001b[39m\n",
      "\n",
      "\u001b[33m        thresh : int, optional\u001b[39m\n",
      "\u001b[33m            Require that many non-NA values. Cannot be combined with how.\u001b[39m\n",
      "\u001b[33m        subset : column label or sequence of labels, optional\u001b[39m\n",
      "\u001b[33m            Labels along other axis to consider, e.g. if you are dropping rows\u001b[39m\n",
      "\u001b[33m            these would be a list of columns to include.\u001b[39m\n",
      "\u001b[33m        inplace : bool, default False\u001b[39m\n",
      "\u001b[33m            Whether to modify the DataFrame rather than creating a new one.\u001b[39m\n",
      "\u001b[33m        ignore_index : bool, default ``False``\u001b[39m\n",
      "\u001b[33m            If ``True``, the resulting axis will be labeled 0, 1, â€¦, n - 1.\u001b[39m\n",
      "\n",
      "\u001b[33m            .. versionadded:: 2.0.0\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        DataFrame or None\u001b[39m\n",
      "\u001b[33m            DataFrame with NA entries dropped from it or None if ``inplace=True``.\u001b[39m\n",
      "\n",
      "\u001b[33m        See Also\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        DataFrame.isna: Indicate missing values.\u001b[39m\n",
      "\u001b[33m        DataFrame.notna : Indicate existing (non-missing) values.\u001b[39m\n",
      "\u001b[33m        DataFrame.fillna : Replace missing values.\u001b[39m\n",
      "\u001b[33m        Series.dropna : Drop missing values.\u001b[39m\n",
      "\u001b[33m        Index.dropna : Drop missing indices.\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        >>> df = pd.DataFrame({\"name\": ['Alfred', 'Batman', 'Catwoman'],\u001b[39m\n",
      "\u001b[33m        ...                    \"toy\": [np.nan, 'Batmobile', 'Bullwhip'],\u001b[39m\n",
      "\u001b[33m        ...                    \"born\": [pd.NaT, pd.Timestamp(\"1940-04-25\"),\u001b[39m\n",
      "\u001b[33m        ...                             pd.NaT]})\u001b[39m\n",
      "\u001b[33m        >>> df\u001b[39m\n",
      "\u001b[33m               name        toy       born\u001b[39m\n",
      "\u001b[33m        0    Alfred        NaN        NaT\u001b[39m\n",
      "\u001b[33m        1    Batman  Batmobile 1940-04-25\u001b[39m\n",
      "\u001b[33m        2  Catwoman   Bullwhip        NaT\u001b[39m\n",
      "\n",
      "\u001b[33m        Drop the rows where at least one element is missing.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.dropna()\u001b[39m\n",
      "\u001b[33m             name        toy       born\u001b[39m\n",
      "\u001b[33m        1  Batman  Batmobile 1940-04-25\u001b[39m\n",
      "\n",
      "\u001b[33m        Drop the columns where at least one element is missing.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.dropna(axis='columns')\u001b[39m\n",
      "\u001b[33m               name\u001b[39m\n",
      "\u001b[33m        0    Alfred\u001b[39m\n",
      "\u001b[33m        1    Batman\u001b[39m\n",
      "\u001b[33m        2  Catwoman\u001b[39m\n",
      "\n",
      "\u001b[33m        Drop the rows where all elements are missing.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.dropna(how='all')\u001b[39m\n",
      "\u001b[33m               name        toy       born\u001b[39m\n",
      "\u001b[33m        0    Alfred        NaN        NaT\u001b[39m\n",
      "\u001b[33m        1    Batman  Batmobile 1940-04-25\u001b[39m\n",
      "\u001b[33m        2  Catwoman   Bullwhip        NaT\u001b[39m\n",
      "\n",
      "\u001b[33m        Keep only the rows with at least 2 non-NA values.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.dropna(thresh=2)\u001b[39m\n",
      "\u001b[33m               name        toy       born\u001b[39m\n",
      "\u001b[33m        1    Batman  Batmobile 1940-04-25\u001b[39m\n",
      "\u001b[33m        2  Catwoman   Bullwhip        NaT\u001b[39m\n",
      "\n",
      "\u001b[33m        Define in which columns to look for missing values.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.dropna(subset=['name', 'toy'])\u001b[39m\n",
      "\u001b[33m               name        toy       born\u001b[39m\n",
      "\u001b[33m        1    Batman  Batmobile 1940-04-25\u001b[39m\n",
      "\u001b[33m        2  Catwoman   Bullwhip        NaT\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m (how \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m lib.no_default) \u001b[38;5;28;01mand\u001b[39;00m (thresh \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m lib.no_default):\n",
      "            \u001b[38;5;28;01mraise\u001b[39;00m TypeError(\n",
      "                \u001b[33m\"You cannot set both the how and thresh arguments at the same time.\"\u001b[39m\n",
      "            )\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m how \u001b[38;5;28;01mis\u001b[39;00m lib.no_default:\n",
      "            how = \u001b[33m\"any\"\u001b[39m\n",
      "\n",
      "        inplace = validate_bool_kwarg(inplace, \u001b[33m\"inplace\"\u001b[39m)\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m isinstance(axis, (tuple, list)):\n",
      "            \u001b[38;5;66;03m# GH20987\u001b[39;00m\n",
      "            \u001b[38;5;28;01mraise\u001b[39;00m TypeError(\u001b[33m\"supplying multiple axes to axis is no longer supported.\"\u001b[39m)\n",
      "\n",
      "        axis = self._get_axis_number(axis)\n",
      "        agg_axis = \u001b[32m1\u001b[39m - axis\n",
      "\n",
      "        agg_obj = self\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m subset \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "            \u001b[38;5;66;03m# subset needs to be list\u001b[39;00m\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m is_list_like(subset):\n",
      "                subset = [subset]\n",
      "            ax = self._get_axis(agg_axis)\n",
      "            indices = ax.get_indexer_for(subset)\n",
      "            check = indices == -\u001b[32m1\u001b[39m\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m check.any():\n",
      "                \u001b[38;5;28;01mraise\u001b[39;00m KeyError(np.array(subset)[check].tolist())\n",
      "            agg_obj = self.take(indices, axis=agg_axis)\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m thresh \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m lib.no_default:\n",
      "            count = agg_obj.count(axis=agg_axis)\n",
      "            mask = count >= thresh\n",
      "        \u001b[38;5;28;01melif\u001b[39;00m how == \u001b[33m\"any\"\u001b[39m:\n",
      "            \u001b[38;5;66;03m# faster equivalent to 'agg_obj.count(agg_axis) == self.shape[agg_axis]'\u001b[39;00m\n",
      "            mask = notna(agg_obj).all(axis=agg_axis, bool_only=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "        \u001b[38;5;28;01melif\u001b[39;00m how == \u001b[33m\"all\"\u001b[39m:\n",
      "            \u001b[38;5;66;03m# faster equivalent to 'agg_obj.count(agg_axis) > 0'\u001b[39;00m\n",
      "            mask = notna(agg_obj).any(axis=agg_axis, bool_only=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "        \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "            \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\u001b[33mf\"invalid how option: {how}\"\u001b[39m)\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m np.all(mask):\n",
      "            result = self.copy(deep=\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "        \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "            result = self.loc(axis=axis)[mask]\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m ignore_index:\n",
      "            result.index = default_index(len(result))\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m inplace:\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "        self._update_inplace(result)\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\n",
      "    @overload\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m drop_duplicates(\n",
      "        self,\n",
      "        subset: Hashable | Sequence[Hashable] | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        *,\n",
      "        keep: DropKeep = ...,\n",
      "        inplace: Literal[\u001b[38;5;28;01mTrue\u001b[39;00m],\n",
      "        ignore_index: bool = ...,\n",
      "    ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        ...\n",
      "\n",
      "    @overload\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m drop_duplicates(\n",
      "        self,\n",
      "        subset: Hashable | Sequence[Hashable] | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        *,\n",
      "        keep: DropKeep = ...,\n",
      "        inplace: Literal[\u001b[38;5;28;01mFalse\u001b[39;00m] = ...,\n",
      "        ignore_index: bool = ...,\n",
      "    ) -> DataFrame:\n",
      "        ...\n",
      "\n",
      "    @overload\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m drop_duplicates(\n",
      "        self,\n",
      "        subset: Hashable | Sequence[Hashable] | \u001b[38;5;28;01mNone\u001b[39;00m = ...,\n",
      "        *,\n",
      "        keep: DropKeep = ...,\n",
      "        inplace: bool = ...,\n",
      "        ignore_index: bool = ...,\n",
      "    ) -> DataFrame | \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        ...\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m drop_duplicates(\n",
      "        self,\n",
      "        subset: Hashable | Sequence[Hashable] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        *,\n",
      "        keep: DropKeep = \u001b[33m\"first\"\u001b[39m,\n",
      "        inplace: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "        ignore_index: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "    ) -> DataFrame | \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Return DataFrame with duplicate rows removed.\u001b[39m\n",
      "\n",
      "\u001b[33m        Considering certain columns is optional. Indexes, including time indexes\u001b[39m\n",
      "\u001b[33m        are ignored.\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        subset : column label or sequence of labels, optional\u001b[39m\n",
      "\u001b[33m            Only consider certain columns for identifying duplicates, by\u001b[39m\n",
      "\u001b[33m            default use all of the columns.\u001b[39m\n",
      "\u001b[33m        keep : {'first', 'last', ``False``}, default 'first'\u001b[39m\n",
      "\u001b[33m            Determines which duplicates (if any) to keep.\u001b[39m\n",
      "\n",
      "\u001b[33m            - 'first' : Drop duplicates except for the first occurrence.\u001b[39m\n",
      "\u001b[33m            - 'last' : Drop duplicates except for the last occurrence.\u001b[39m\n",
      "\u001b[33m            - ``False`` : Drop all duplicates.\u001b[39m\n",
      "\n",
      "\u001b[33m        inplace : bool, default ``False``\u001b[39m\n",
      "\u001b[33m            Whether to modify the DataFrame rather than creating a new one.\u001b[39m\n",
      "\u001b[33m        ignore_index : bool, default ``False``\u001b[39m\n",
      "\u001b[33m            If ``True``, the resulting axis will be labeled 0, 1, â€¦, n - 1.\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        DataFrame or None\u001b[39m\n",
      "\u001b[33m            DataFrame with duplicates removed or None if ``inplace=True``.\u001b[39m\n",
      "\n",
      "\u001b[33m        See Also\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        DataFrame.value_counts: Count unique combinations of columns.\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        Consider dataset containing ramen rating.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df = pd.DataFrame({\u001b[39m\n",
      "\u001b[33m        ...     'brand': ['Yum Yum', 'Yum Yum', 'Indomie', 'Indomie', 'Indomie'],\u001b[39m\n",
      "\u001b[33m        ...     'style': ['cup', 'cup', 'cup', 'pack', 'pack'],\u001b[39m\n",
      "\u001b[33m        ...     'rating': [4, 4, 3.5, 15, 5]\u001b[39m\n",
      "\u001b[33m        ... })\u001b[39m\n",
      "\u001b[33m        >>> df\u001b[39m\n",
      "\u001b[33m            brand style  rating\u001b[39m\n",
      "\u001b[33m        0  Yum Yum   cup     4.0\u001b[39m\n",
      "\u001b[33m        1  Yum Yum   cup     4.0\u001b[39m\n",
      "\u001b[33m        2  Indomie   cup     3.5\u001b[39m\n",
      "\u001b[33m        3  Indomie  pack    15.0\u001b[39m\n",
      "\u001b[33m        4  Indomie  pack     5.0\u001b[39m\n",
      "\n",
      "\u001b[33m        By default, it removes duplicate rows based on all columns.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.drop_duplicates()\u001b[39m\n",
      "\u001b[33m            brand style  rating\u001b[39m\n",
      "\u001b[33m        0  Yum Yum   cup     4.0\u001b[39m\n",
      "\u001b[33m        2  Indomie   cup     3.5\u001b[39m\n",
      "\u001b[33m        3  Indomie  pack    15.0\u001b[39m\n",
      "\u001b[33m        4  Indomie  pack     5.0\u001b[39m\n",
      "\n",
      "\u001b[33m        To remove duplicates on specific column(s), use ``subset``.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.drop_duplicates(subset=['brand'])\u001b[39m\n",
      "\u001b[33m            brand style  rating\u001b[39m\n",
      "\u001b[33m        0  Yum Yum   cup     4.0\u001b[39m\n",
      "\u001b[33m        2  Indomie   cup     3.5\u001b[39m\n",
      "\n",
      "\u001b[33m        To remove duplicates and keep last occurrences, use ``keep``.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.drop_duplicates(subset=['brand', 'style'], keep='last')\u001b[39m\n",
      "\u001b[33m            brand style  rating\u001b[39m\n",
      "\u001b[33m        1  Yum Yum   cup     4.0\u001b[39m\n",
      "\u001b[33m        2  Indomie   cup     3.5\u001b[39m\n",
      "\u001b[33m        4  Indomie  pack     5.0\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m self.empty:\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m self.copy(deep=\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\n",
      "        inplace = validate_bool_kwarg(inplace, \u001b[33m\"inplace\"\u001b[39m)\n",
      "        ignore_index = validate_bool_kwarg(ignore_index, \u001b[33m\"ignore_index\"\u001b[39m)\n",
      "\n",
      "        result = self[-self.duplicated(subset, keep=keep)]\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m ignore_index:\n",
      "            result.index = default_index(len(result))\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m inplace:\n",
      "            self._update_inplace(result)\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "        \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m duplicated(\n",
      "        self,\n",
      "        subset: Hashable | Sequence[Hashable] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        keep: DropKeep = \u001b[33m\"first\"\u001b[39m,\n",
      "    ) -> Series:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Return boolean Series denoting duplicate rows.\u001b[39m\n",
      "\n",
      "\u001b[33m        Considering certain columns is optional.\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        subset : column label or sequence of labels, optional\u001b[39m\n",
      "\u001b[33m            Only consider certain columns for identifying duplicates, by\u001b[39m\n",
      "\u001b[33m            default use all of the columns.\u001b[39m\n",
      "\u001b[33m        keep : {'first', 'last', False}, default 'first'\u001b[39m\n",
      "\u001b[33m            Determines which duplicates (if any) to mark.\u001b[39m\n",
      "\n",
      "\u001b[33m            - ``first`` : Mark duplicates as ``True`` except for the first occurrence.\u001b[39m\n",
      "\u001b[33m            - ``last`` : Mark duplicates as ``True`` except for the last occurrence.\u001b[39m\n",
      "\u001b[33m            - False : Mark all duplicates as ``True``.\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        Series\u001b[39m\n",
      "\u001b[33m            Boolean series for each duplicated rows.\u001b[39m\n",
      "\n",
      "\u001b[33m        See Also\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        Index.duplicated : Equivalent method on index.\u001b[39m\n",
      "\u001b[33m        Series.duplicated : Equivalent method on Series.\u001b[39m\n",
      "\u001b[33m        Series.drop_duplicates : Remove duplicate values from Series.\u001b[39m\n",
      "\u001b[33m        DataFrame.drop_duplicates : Remove duplicate values from DataFrame.\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        Consider dataset containing ramen rating.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df = pd.DataFrame({\u001b[39m\n",
      "\u001b[33m        ...     'brand': ['Yum Yum', 'Yum Yum', 'Indomie', 'Indomie', 'Indomie'],\u001b[39m\n",
      "\u001b[33m        ...     'style': ['cup', 'cup', 'cup', 'pack', 'pack'],\u001b[39m\n",
      "\u001b[33m        ...     'rating': [4, 4, 3.5, 15, 5]\u001b[39m\n",
      "\u001b[33m        ... })\u001b[39m\n",
      "\u001b[33m        >>> df\u001b[39m\n",
      "\u001b[33m            brand style  rating\u001b[39m\n",
      "\u001b[33m        0  Yum Yum   cup     4.0\u001b[39m\n",
      "\u001b[33m        1  Yum Yum   cup     4.0\u001b[39m\n",
      "\u001b[33m        2  Indomie   cup     3.5\u001b[39m\n",
      "\u001b[33m        3  Indomie  pack    15.0\u001b[39m\n",
      "\u001b[33m        4  Indomie  pack     5.0\u001b[39m\n",
      "\n",
      "\u001b[33m        By default, for each set of duplicated values, the first occurrence\u001b[39m\n",
      "\u001b[33m        is set on False and all others on True.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.duplicated()\u001b[39m\n",
      "\u001b[33m        0    False\u001b[39m\n",
      "\u001b[33m        1     True\u001b[39m\n",
      "\u001b[33m        2    False\u001b[39m\n",
      "\u001b[33m        3    False\u001b[39m\n",
      "\u001b[33m        4    False\u001b[39m\n",
      "\u001b[33m        dtype: bool\u001b[39m\n",
      "\n",
      "\u001b[33m        By using 'last', the last occurrence of each set of duplicated values\u001b[39m\n",
      "\u001b[33m        is set on False and all others on True.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.duplicated(keep='last')\u001b[39m\n",
      "\u001b[33m        0     True\u001b[39m\n",
      "\u001b[33m        1    False\u001b[39m\n",
      "\u001b[33m        2    False\u001b[39m\n",
      "\u001b[33m        3    False\u001b[39m\n",
      "\u001b[33m        4    False\u001b[39m\n",
      "\u001b[33m        dtype: bool\u001b[39m\n",
      "\n",
      "\u001b[33m        By setting ``keep`` on False, all duplicates are True.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.duplicated(keep=False)\u001b[39m\n",
      "\u001b[33m        0     True\u001b[39m\n",
      "\u001b[33m        1     True\u001b[39m\n",
      "\u001b[33m        2    False\u001b[39m\n",
      "\u001b[33m        3    False\u001b[39m\n",
      "\u001b[33m        4    False\u001b[39m\n",
      "\u001b[33m        dtype: bool\u001b[39m\n",
      "\n",
      "\u001b[33m        To find duplicates on specific column(s), use ``subset``.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.duplicated(subset=['brand'])\u001b[39m\n",
      "\u001b[33m        0    False\u001b[39m\n",
      "\u001b[33m        1     True\u001b[39m\n",
      "\u001b[33m        2    False\u001b[39m\n",
      "\u001b[33m        3     True\u001b[39m\n",
      "\u001b[33m        4     True\u001b[39m\n",
      "\u001b[33m        dtype: bool\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m self.empty:\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m self._constructor_sliced(dtype=bool)\n",
      "\n",
      "        \u001b[38;5;28;01mdef\u001b[39;00m f(vals) -> tuple[np.ndarray, int]:\n",
      "            labels, shape = algorithms.factorize(vals, size_hint=len(self))\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m labels.astype(\u001b[33m\"i8\"\u001b[39m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m), len(shape)\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m subset \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "            \u001b[38;5;66;03m# https://github.com/pandas-dev/pandas/issues/28770\u001b[39;00m\n",
      "            \u001b[38;5;66;03m# Incompatible types in assignment (expression has type \"Index\", variable\u001b[39;00m\n",
      "            \u001b[38;5;66;03m# has type \"Sequence[Any]\")\u001b[39;00m\n",
      "            subset = self.columns  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n",
      "        \u001b[38;5;28;01melif\u001b[39;00m (\n",
      "            \u001b[38;5;28;01mnot\u001b[39;00m np.iterable(subset)\n",
      "            \u001b[38;5;28;01mor\u001b[39;00m isinstance(subset, str)\n",
      "            \u001b[38;5;28;01mor\u001b[39;00m isinstance(subset, tuple)\n",
      "            \u001b[38;5;28;01mand\u001b[39;00m subset \u001b[38;5;28;01min\u001b[39;00m self.columns\n",
      "        ):\n",
      "            subset = (subset,)\n",
      "\n",
      "        \u001b[38;5;66;03m#  needed for mypy since can't narrow types using np.iterable\u001b[39;00m\n",
      "        subset = cast(Sequence, subset)\n",
      "\n",
      "        \u001b[38;5;66;03m# Verify all columns in subset exist in the queried dataframe\u001b[39;00m\n",
      "        \u001b[38;5;66;03m# Otherwise, raise a KeyError, same as if you try to __getitem__ with a\u001b[39;00m\n",
      "        \u001b[38;5;66;03m# key that doesn't exist.\u001b[39;00m\n",
      "        diff = set(subset) - set(self.columns)\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m diff:\n",
      "            \u001b[38;5;28;01mraise\u001b[39;00m KeyError(Index(diff))\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m len(subset) == \u001b[32m1\u001b[39m \u001b[38;5;28;01mand\u001b[39;00m self.columns.is_unique:\n",
      "            \u001b[38;5;66;03m# GH#45236 This is faster than get_group_index below\u001b[39;00m\n",
      "            result = self[subset[\u001b[32m0\u001b[39m]].duplicated(keep)\n",
      "            result.name = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "        \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "            vals = (col.values \u001b[38;5;28;01mfor\u001b[39;00m name, col \u001b[38;5;28;01min\u001b[39;00m self.items() \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;28;01min\u001b[39;00m subset)\n",
      "            labels, shape = map(list, zip(*map(f, vals)))\n",
      "\n",
      "            ids = get_group_index(labels, tuple(shape), sort=\u001b[38;5;28;01mFalse\u001b[39;00m, xnull=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "            result = self._constructor_sliced(duplicated(ids, keep), index=self.index)\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m result.__finalize__(self, method=\u001b[33m\"duplicated\"\u001b[39m)\n",
      "\n",
      "    \u001b[38;5;66;03m# ----------------------------------------------------------------------\u001b[39;00m\n",
      "    \u001b[38;5;66;03m# Sorting\u001b[39;00m\n",
      "    \u001b[38;5;66;03m# error: Signature of \"sort_values\" incompatible with supertype \"NDFrame\"\u001b[39;00m\n",
      "    @overload  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m sort_values(\n",
      "        self,\n",
      "        by: IndexLabel,\n",
      "        *,\n",
      "        axis: Axis = ...,\n",
      "        ascending=...,\n",
      "        inplace: Literal[\u001b[38;5;28;01mFalse\u001b[39;00m] = ...,\n",
      "        kind: SortKind = ...,\n",
      "        na_position: NaPosition = ...,\n",
      "        ignore_index: bool = ...,\n",
      "        key: ValueKeyFunc = ...,\n",
      "    ) -> DataFrame:\n",
      "        ...\n",
      "\n",
      "    @overload\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m sort_values(\n",
      "        self,\n",
      "        by: IndexLabel,\n",
      "        *,\n",
      "        axis: Axis = ...,\n",
      "        ascending=...,\n",
      "        inplace: Literal[\u001b[38;5;28;01mTrue\u001b[39;00m],\n",
      "        kind: SortKind = ...,\n",
      "        na_position: str = ...,\n",
      "        ignore_index: bool = ...,\n",
      "        key: ValueKeyFunc = ...,\n",
      "    ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        ...\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m sort_values(\n",
      "        self,\n",
      "        by: IndexLabel,\n",
      "        *,\n",
      "        axis: Axis = \u001b[32m0\u001b[39m,\n",
      "        ascending: bool | list[bool] | tuple[bool, ...] = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "        inplace: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "        kind: SortKind = \u001b[33m\"quicksort\"\u001b[39m,\n",
      "        na_position: str = \u001b[33m\"last\"\u001b[39m,\n",
      "        ignore_index: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "        key: ValueKeyFunc | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    ) -> DataFrame | \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Sort by the values along either axis.\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        by : str or list of str\u001b[39m\n",
      "\u001b[33m            Name or list of names to sort by.\u001b[39m\n",
      "\n",
      "\u001b[33m            - if `axis` is 0 or `'index'` then `by` may contain index\u001b[39m\n",
      "\u001b[33m              levels and/or column labels.\u001b[39m\n",
      "\u001b[33m            - if `axis` is 1 or `'columns'` then `by` may contain column\u001b[39m\n",
      "\u001b[33m              levels and/or index labels.\u001b[39m\n",
      "\u001b[33m        axis : \"{0 or 'index', 1 or 'columns'}\", default 0\u001b[39m\n",
      "\u001b[33m             Axis to be sorted.\u001b[39m\n",
      "\u001b[33m        ascending : bool or list of bool, default True\u001b[39m\n",
      "\u001b[33m             Sort ascending vs. descending. Specify list for multiple sort\u001b[39m\n",
      "\u001b[33m             orders.  If this is a list of bools, must match the length of\u001b[39m\n",
      "\u001b[33m             the by.\u001b[39m\n",
      "\u001b[33m        inplace : bool, default False\u001b[39m\n",
      "\u001b[33m             If True, perform operation in-place.\u001b[39m\n",
      "\u001b[33m        kind : {'quicksort', 'mergesort', 'heapsort', 'stable'}, default 'quicksort'\u001b[39m\n",
      "\u001b[33m             Choice of sorting algorithm. See also :func:`numpy.sort` for more\u001b[39m\n",
      "\u001b[33m             information. `mergesort` and `stable` are the only stable algorithms. For\u001b[39m\n",
      "\u001b[33m             DataFrames, this option is only applied when sorting on a single\u001b[39m\n",
      "\u001b[33m             column or label.\u001b[39m\n",
      "\u001b[33m        na_position : {'first', 'last'}, default 'last'\u001b[39m\n",
      "\u001b[33m             Puts NaNs at the beginning if `first`; `last` puts NaNs at the\u001b[39m\n",
      "\u001b[33m             end.\u001b[39m\n",
      "\u001b[33m        ignore_index : bool, default False\u001b[39m\n",
      "\u001b[33m             If True, the resulting axis will be labeled 0, 1, â€¦, n - 1.\u001b[39m\n",
      "\u001b[33m        key : callable, optional\u001b[39m\n",
      "\u001b[33m            Apply the key function to the values\u001b[39m\n",
      "\u001b[33m            before sorting. This is similar to the `key` argument in the\u001b[39m\n",
      "\u001b[33m            builtin :meth:`sorted` function, with the notable difference that\u001b[39m\n",
      "\u001b[33m            this `key` function should be *vectorized*. It should expect a\u001b[39m\n",
      "\u001b[33m            ``Series`` and return a Series with the same shape as the input.\u001b[39m\n",
      "\u001b[33m            It will be applied to each column in `by` independently.\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        DataFrame or None\u001b[39m\n",
      "\u001b[33m            DataFrame with sorted values or None if ``inplace=True``.\u001b[39m\n",
      "\n",
      "\u001b[33m        See Also\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        DataFrame.sort_index : Sort a DataFrame by the index.\u001b[39m\n",
      "\u001b[33m        Series.sort_values : Similar method for a Series.\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        >>> df = pd.DataFrame({\u001b[39m\n",
      "\u001b[33m        ...     'col1': ['A', 'A', 'B', np.nan, 'D', 'C'],\u001b[39m\n",
      "\u001b[33m        ...     'col2': [2, 1, 9, 8, 7, 4],\u001b[39m\n",
      "\u001b[33m        ...     'col3': [0, 1, 9, 4, 2, 3],\u001b[39m\n",
      "\u001b[33m        ...     'col4': ['a', 'B', 'c', 'D', 'e', 'F']\u001b[39m\n",
      "\u001b[33m        ... })\u001b[39m\n",
      "\u001b[33m        >>> df\u001b[39m\n",
      "\u001b[33m          col1  col2  col3 col4\u001b[39m\n",
      "\u001b[33m        0    A     2     0    a\u001b[39m\n",
      "\u001b[33m        1    A     1     1    B\u001b[39m\n",
      "\u001b[33m        2    B     9     9    c\u001b[39m\n",
      "\u001b[33m        3  NaN     8     4    D\u001b[39m\n",
      "\u001b[33m        4    D     7     2    e\u001b[39m\n",
      "\u001b[33m        5    C     4     3    F\u001b[39m\n",
      "\n",
      "\u001b[33m        Sort by col1\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.sort_values(by=['col1'])\u001b[39m\n",
      "\u001b[33m          col1  col2  col3 col4\u001b[39m\n",
      "\u001b[33m        0    A     2     0    a\u001b[39m\n",
      "\u001b[33m        1    A     1     1    B\u001b[39m\n",
      "\u001b[33m        2    B     9     9    c\u001b[39m\n",
      "\u001b[33m        5    C     4     3    F\u001b[39m\n",
      "\u001b[33m        4    D     7     2    e\u001b[39m\n",
      "\u001b[33m        3  NaN     8     4    D\u001b[39m\n",
      "\n",
      "\u001b[33m        Sort by multiple columns\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.sort_values(by=['col1', 'col2'])\u001b[39m\n",
      "\u001b[33m          col1  col2  col3 col4\u001b[39m\n",
      "\u001b[33m        1    A     1     1    B\u001b[39m\n",
      "\u001b[33m        0    A     2     0    a\u001b[39m\n",
      "\u001b[33m        2    B     9     9    c\u001b[39m\n",
      "\u001b[33m        5    C     4     3    F\u001b[39m\n",
      "\u001b[33m        4    D     7     2    e\u001b[39m\n",
      "\u001b[33m        3  NaN     8     4    D\u001b[39m\n",
      "\n",
      "\u001b[33m        Sort Descending\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.sort_values(by='col1', ascending=False)\u001b[39m\n",
      "\u001b[33m          col1  col2  col3 col4\u001b[39m\n",
      "\u001b[33m        4    D     7     2    e\u001b[39m\n",
      "\u001b[33m        5    C     4     3    F\u001b[39m\n",
      "\u001b[33m        2    B     9     9    c\u001b[39m\n",
      "\u001b[33m        0    A     2     0    a\u001b[39m\n",
      "\u001b[33m        1    A     1     1    B\u001b[39m\n",
      "\u001b[33m        3  NaN     8     4    D\u001b[39m\n",
      "\n",
      "\u001b[33m        Putting NAs first\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.sort_values(by='col1', ascending=False, na_position='first')\u001b[39m\n",
      "\u001b[33m          col1  col2  col3 col4\u001b[39m\n",
      "\u001b[33m        3  NaN     8     4    D\u001b[39m\n",
      "\u001b[33m        4    D     7     2    e\u001b[39m\n",
      "\u001b[33m        5    C     4     3    F\u001b[39m\n",
      "\u001b[33m        2    B     9     9    c\u001b[39m\n",
      "\u001b[33m        0    A     2     0    a\u001b[39m\n",
      "\u001b[33m        1    A     1     1    B\u001b[39m\n",
      "\n",
      "\u001b[33m        Sorting with a key function\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.sort_values(by='col4', key=lambda col: col.str.lower())\u001b[39m\n",
      "\u001b[33m           col1  col2  col3 col4\u001b[39m\n",
      "\u001b[33m        0    A     2     0    a\u001b[39m\n",
      "\u001b[33m        1    A     1     1    B\u001b[39m\n",
      "\u001b[33m        2    B     9     9    c\u001b[39m\n",
      "\u001b[33m        3  NaN     8     4    D\u001b[39m\n",
      "\u001b[33m        4    D     7     2    e\u001b[39m\n",
      "\u001b[33m        5    C     4     3    F\u001b[39m\n",
      "\n",
      "\u001b[33m        Natural sort with the key argument,\u001b[39m\n",
      "\u001b[33m        using the `natsort <https://github.com/SethMMorton/natsort>` package.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df = pd.DataFrame({\u001b[39m\n",
      "\u001b[33m        ...    \"time\": ['0hr', '128hr', '72hr', '48hr', '96hr'],\u001b[39m\n",
      "\u001b[33m        ...    \"value\": [10, 20, 30, 40, 50]\u001b[39m\n",
      "\u001b[33m        ... })\u001b[39m\n",
      "\u001b[33m        >>> df\u001b[39m\n",
      "\u001b[33m            time  value\u001b[39m\n",
      "\u001b[33m        0    0hr     10\u001b[39m\n",
      "\u001b[33m        1  128hr     20\u001b[39m\n",
      "\u001b[33m        2   72hr     30\u001b[39m\n",
      "\u001b[33m        3   48hr     40\u001b[39m\n",
      "\u001b[33m        4   96hr     50\u001b[39m\n",
      "\u001b[33m        >>> from natsort import index_natsorted\u001b[39m\n",
      "\u001b[33m        >>> df.sort_values(\u001b[39m\n",
      "\u001b[33m        ...     by=\"time\",\u001b[39m\n",
      "\u001b[33m        ...     key=lambda x: np.argsort(index_natsorted(df[\"time\"]))\u001b[39m\n",
      "\u001b[33m        ... )\u001b[39m\n",
      "\u001b[33m            time  value\u001b[39m\n",
      "\u001b[33m        0    0hr     10\u001b[39m\n",
      "\u001b[33m        3   48hr     40\u001b[39m\n",
      "\u001b[33m        2   72hr     30\u001b[39m\n",
      "\u001b[33m        4   96hr     50\u001b[39m\n",
      "\u001b[33m        1  128hr     20\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        inplace = validate_bool_kwarg(inplace, \u001b[33m\"inplace\"\u001b[39m)\n",
      "        axis = self._get_axis_number(axis)\n",
      "        ascending = validate_ascending(ascending)\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m isinstance(by, list):\n",
      "            by = [by]\n",
      "        \u001b[38;5;66;03m# error: Argument 1 to \"len\" has incompatible type \"Union[bool, List[bool]]\";\u001b[39;00m\n",
      "        \u001b[38;5;66;03m# expected \"Sized\"\u001b[39;00m\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m is_sequence(ascending) \u001b[38;5;28;01mand\u001b[39;00m (\n",
      "            len(by) != len(ascending)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "        ):\n",
      "            \u001b[38;5;66;03m# error: Argument 1 to \"len\" has incompatible type \"Union[bool,\u001b[39;00m\n",
      "            \u001b[38;5;66;03m# List[bool]]\"; expected \"Sized\"\u001b[39;00m\n",
      "            \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\n",
      "                \u001b[33mf\"Length of ascending ({len(ascending)})\"\u001b[39m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "                \u001b[33mf\" != length of by ({len(by)})\"\u001b[39m\n",
      "            )\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m len(by) > \u001b[32m1\u001b[39m:\n",
      "            keys = [self._get_label_or_level_values(x, axis=axis) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;28;01min\u001b[39;00m by]\n",
      "\n",
      "            \u001b[38;5;66;03m# need to rewrap columns in Series to apply key function\u001b[39;00m\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "                \u001b[38;5;66;03m# error: List comprehension has incompatible type List[Series];\u001b[39;00m\n",
      "                \u001b[38;5;66;03m# expected List[ndarray]\u001b[39;00m\n",
      "                keys = [\n",
      "                    Series(k, name=name)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "                    \u001b[38;5;28;01mfor\u001b[39;00m (k, name) \u001b[38;5;28;01min\u001b[39;00m zip(keys, by)\n",
      "                ]\n",
      "\n",
      "            indexer = lexsort_indexer(\n",
      "                keys, orders=ascending, na_position=na_position, key=key\n",
      "            )\n",
      "        \u001b[38;5;28;01melif\u001b[39;00m len(by):\n",
      "            \u001b[38;5;66;03m# len(by) == 1\u001b[39;00m\n",
      "\n",
      "            k = self._get_label_or_level_values(by[\u001b[32m0\u001b[39m], axis=axis)\n",
      "\n",
      "            \u001b[38;5;66;03m# need to rewrap column in Series to apply key function\u001b[39;00m\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "                \u001b[38;5;66;03m# error: Incompatible types in assignment (expression has type\u001b[39;00m\n",
      "                \u001b[38;5;66;03m# \"Series\", variable has type \"ndarray\")\u001b[39;00m\n",
      "                k = Series(k, name=by[\u001b[32m0\u001b[39m])  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n",
      "\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m isinstance(ascending, (tuple, list)):\n",
      "                ascending = ascending[\u001b[32m0\u001b[39m]\n",
      "\n",
      "            indexer = nargsort(\n",
      "                k, kind=kind, ascending=ascending, na_position=na_position, key=key\n",
      "            )\n",
      "        \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m inplace:\n",
      "                \u001b[38;5;28;01mreturn\u001b[39;00m self._update_inplace(self)\n",
      "            \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "                \u001b[38;5;28;01mreturn\u001b[39;00m self.copy(deep=\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m is_range_indexer(indexer, len(indexer)):\n",
      "            result = self.copy(deep=(\u001b[38;5;28;01mnot\u001b[39;00m inplace \u001b[38;5;28;01mand\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m using_copy_on_write()))\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m ignore_index:\n",
      "                result.index = default_index(len(result))\n",
      "\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m inplace:\n",
      "                \u001b[38;5;28;01mreturn\u001b[39;00m self._update_inplace(result)\n",
      "            \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "                \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\n",
      "        new_data = self._mgr.take(\n",
      "            indexer, axis=self._get_block_manager_axis(axis), verify=\u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "        )\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m ignore_index:\n",
      "            new_data.set_axis(\n",
      "                self._get_block_manager_axis(axis), default_index(len(indexer))\n",
      "            )\n",
      "\n",
      "        result = self._constructor_from_mgr(new_data, axes=new_data.axes)\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m inplace:\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m self._update_inplace(result)\n",
      "        \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m result.__finalize__(self, method=\u001b[33m\"sort_values\"\u001b[39m)\n",
      "\n",
      "    @overload\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m sort_index(\n",
      "        self,\n",
      "        *,\n",
      "        axis: Axis = ...,\n",
      "        level: IndexLabel = ...,\n",
      "        ascending: bool | Sequence[bool] = ...,\n",
      "        inplace: Literal[\u001b[38;5;28;01mTrue\u001b[39;00m],\n",
      "        kind: SortKind = ...,\n",
      "        na_position: NaPosition = ...,\n",
      "        sort_remaining: bool = ...,\n",
      "        ignore_index: bool = ...,\n",
      "        key: IndexKeyFunc = ...,\n",
      "    ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        ...\n",
      "\n",
      "    @overload\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m sort_index(\n",
      "        self,\n",
      "        *,\n",
      "        axis: Axis = ...,\n",
      "        level: IndexLabel = ...,\n",
      "        ascending: bool | Sequence[bool] = ...,\n",
      "        inplace: Literal[\u001b[38;5;28;01mFalse\u001b[39;00m] = ...,\n",
      "        kind: SortKind = ...,\n",
      "        na_position: NaPosition = ...,\n",
      "        sort_remaining: bool = ...,\n",
      "        ignore_index: bool = ...,\n",
      "        key: IndexKeyFunc = ...,\n",
      "    ) -> DataFrame:\n",
      "        ...\n",
      "\n",
      "    @overload\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m sort_index(\n",
      "        self,\n",
      "        *,\n",
      "        axis: Axis = ...,\n",
      "        level: IndexLabel = ...,\n",
      "        ascending: bool | Sequence[bool] = ...,\n",
      "        inplace: bool = ...,\n",
      "        kind: SortKind = ...,\n",
      "        na_position: NaPosition = ...,\n",
      "        sort_remaining: bool = ...,\n",
      "        ignore_index: bool = ...,\n",
      "        key: IndexKeyFunc = ...,\n",
      "    ) -> DataFrame | \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        ...\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m sort_index(\n",
      "        self,\n",
      "        *,\n",
      "        axis: Axis = \u001b[32m0\u001b[39m,\n",
      "        level: IndexLabel | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        ascending: bool | Sequence[bool] = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "        inplace: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "        kind: SortKind = \u001b[33m\"quicksort\"\u001b[39m,\n",
      "        na_position: NaPosition = \u001b[33m\"last\"\u001b[39m,\n",
      "        sort_remaining: bool = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "        ignore_index: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "        key: IndexKeyFunc | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    ) -> DataFrame | \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Sort object by labels (along an axis).\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns a new DataFrame sorted by label if `inplace` argument is\u001b[39m\n",
      "\u001b[33m        ``False``, otherwise updates the original DataFrame and returns None.\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        axis : {0 or 'index', 1 or 'columns'}, default 0\u001b[39m\n",
      "\u001b[33m            The axis along which to sort.  The value 0 identifies the rows,\u001b[39m\n",
      "\u001b[33m            and 1 identifies the columns.\u001b[39m\n",
      "\u001b[33m        level : int or level name or list of ints or list of level names\u001b[39m\n",
      "\u001b[33m            If not None, sort on values in specified index level(s).\u001b[39m\n",
      "\u001b[33m        ascending : bool or list-like of bools, default True\u001b[39m\n",
      "\u001b[33m            Sort ascending vs. descending. When the index is a MultiIndex the\u001b[39m\n",
      "\u001b[33m            sort direction can be controlled for each level individually.\u001b[39m\n",
      "\u001b[33m        inplace : bool, default False\u001b[39m\n",
      "\u001b[33m            Whether to modify the DataFrame rather than creating a new one.\u001b[39m\n",
      "\u001b[33m        kind : {'quicksort', 'mergesort', 'heapsort', 'stable'}, default 'quicksort'\u001b[39m\n",
      "\u001b[33m            Choice of sorting algorithm. See also :func:`numpy.sort` for more\u001b[39m\n",
      "\u001b[33m            information. `mergesort` and `stable` are the only stable algorithms. For\u001b[39m\n",
      "\u001b[33m            DataFrames, this option is only applied when sorting on a single\u001b[39m\n",
      "\u001b[33m            column or label.\u001b[39m\n",
      "\u001b[33m        na_position : {'first', 'last'}, default 'last'\u001b[39m\n",
      "\u001b[33m            Puts NaNs at the beginning if `first`; `last` puts NaNs at the end.\u001b[39m\n",
      "\u001b[33m            Not implemented for MultiIndex.\u001b[39m\n",
      "\u001b[33m        sort_remaining : bool, default True\u001b[39m\n",
      "\u001b[33m            If True and sorting by level and index is multilevel, sort by other\u001b[39m\n",
      "\u001b[33m            levels too (in order) after sorting by specified level.\u001b[39m\n",
      "\u001b[33m        ignore_index : bool, default False\u001b[39m\n",
      "\u001b[33m            If True, the resulting axis will be labeled 0, 1, â€¦, n - 1.\u001b[39m\n",
      "\u001b[33m        key : callable, optional\u001b[39m\n",
      "\u001b[33m            If not None, apply the key function to the index values\u001b[39m\n",
      "\u001b[33m            before sorting. This is similar to the `key` argument in the\u001b[39m\n",
      "\u001b[33m            builtin :meth:`sorted` function, with the notable difference that\u001b[39m\n",
      "\u001b[33m            this `key` function should be *vectorized*. It should expect an\u001b[39m\n",
      "\u001b[33m            ``Index`` and return an ``Index`` of the same shape. For MultiIndex\u001b[39m\n",
      "\u001b[33m            inputs, the key is applied *per level*.\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        DataFrame or None\u001b[39m\n",
      "\u001b[33m            The original DataFrame sorted by the labels or None if ``inplace=True``.\u001b[39m\n",
      "\n",
      "\u001b[33m        See Also\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        Series.sort_index : Sort Series by the index.\u001b[39m\n",
      "\u001b[33m        DataFrame.sort_values : Sort DataFrame by the value.\u001b[39m\n",
      "\u001b[33m        Series.sort_values : Sort Series by the value.\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        >>> df = pd.DataFrame([1, 2, 3, 4, 5], index=[100, 29, 234, 1, 150],\u001b[39m\n",
      "\u001b[33m        ...                   columns=['A'])\u001b[39m\n",
      "\u001b[33m        >>> df.sort_index()\u001b[39m\n",
      "\u001b[33m             A\u001b[39m\n",
      "\u001b[33m        1    4\u001b[39m\n",
      "\u001b[33m        29   2\u001b[39m\n",
      "\u001b[33m        100  1\u001b[39m\n",
      "\u001b[33m        150  5\u001b[39m\n",
      "\u001b[33m        234  3\u001b[39m\n",
      "\n",
      "\u001b[33m        By default, it sorts in ascending order, to sort in descending order,\u001b[39m\n",
      "\u001b[33m        use ``ascending=False``\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.sort_index(ascending=False)\u001b[39m\n",
      "\u001b[33m             A\u001b[39m\n",
      "\u001b[33m        234  3\u001b[39m\n",
      "\u001b[33m        150  5\u001b[39m\n",
      "\u001b[33m        100  1\u001b[39m\n",
      "\u001b[33m        29   2\u001b[39m\n",
      "\u001b[33m        1    4\u001b[39m\n",
      "\n",
      "\u001b[33m        A key function can be specified which is applied to the index before\u001b[39m\n",
      "\u001b[33m        sorting. For a ``MultiIndex`` this is applied to each level separately.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df = pd.DataFrame({\"a\": [1, 2, 3, 4]}, index=['A', 'b', 'C', 'd'])\u001b[39m\n",
      "\u001b[33m        >>> df.sort_index(key=lambda x: x.str.lower())\u001b[39m\n",
      "\u001b[33m           a\u001b[39m\n",
      "\u001b[33m        A  1\u001b[39m\n",
      "\u001b[33m        b  2\u001b[39m\n",
      "\u001b[33m        C  3\u001b[39m\n",
      "\u001b[33m        d  4\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m super().sort_index(\n",
      "            axis=axis,\n",
      "            level=level,\n",
      "            ascending=ascending,\n",
      "            inplace=inplace,\n",
      "            kind=kind,\n",
      "            na_position=na_position,\n",
      "            sort_remaining=sort_remaining,\n",
      "            ignore_index=ignore_index,\n",
      "            key=key,\n",
      "        )\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m value_counts(\n",
      "        self,\n",
      "        subset: IndexLabel | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        normalize: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "        sort: bool = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "        ascending: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "        dropna: bool = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "    ) -> Series:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Return a Series containing the frequency of each distinct row in the Dataframe.\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        subset : label or list of labels, optional\u001b[39m\n",
      "\u001b[33m            Columns to use when counting unique combinations.\u001b[39m\n",
      "\u001b[33m        normalize : bool, default False\u001b[39m\n",
      "\u001b[33m            Return proportions rather than frequencies.\u001b[39m\n",
      "\u001b[33m        sort : bool, default True\u001b[39m\n",
      "\u001b[33m            Sort by frequencies when True. Sort by DataFrame column values when False.\u001b[39m\n",
      "\u001b[33m        ascending : bool, default False\u001b[39m\n",
      "\u001b[33m            Sort in ascending order.\u001b[39m\n",
      "\u001b[33m        dropna : bool, default True\u001b[39m\n",
      "\u001b[33m            Don't include counts of rows that contain NA values.\u001b[39m\n",
      "\n",
      "\u001b[33m            .. versionadded:: 1.3.0\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        Series\u001b[39m\n",
      "\n",
      "\u001b[33m        See Also\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        Series.value_counts: Equivalent method on Series.\u001b[39m\n",
      "\n",
      "\u001b[33m        Notes\u001b[39m\n",
      "\u001b[33m        -----\u001b[39m\n",
      "\u001b[33m        The returned Series will have a MultiIndex with one level per input\u001b[39m\n",
      "\u001b[33m        column but an Index (non-multi) for a single label. By default, rows\u001b[39m\n",
      "\u001b[33m        that contain any NA values are omitted from the result. By default,\u001b[39m\n",
      "\u001b[33m        the resulting Series will be in descending order so that the first\u001b[39m\n",
      "\u001b[33m        element is the most frequently-occurring row.\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        >>> df = pd.DataFrame({'num_legs': [2, 4, 4, 6],\u001b[39m\n",
      "\u001b[33m        ...                    'num_wings': [2, 0, 0, 0]},\u001b[39m\n",
      "\u001b[33m        ...                   index=['falcon', 'dog', 'cat', 'ant'])\u001b[39m\n",
      "\u001b[33m        >>> df\u001b[39m\n",
      "\u001b[33m                num_legs  num_wings\u001b[39m\n",
      "\u001b[33m        falcon         2          2\u001b[39m\n",
      "\u001b[33m        dog            4          0\u001b[39m\n",
      "\u001b[33m        cat            4          0\u001b[39m\n",
      "\u001b[33m        ant            6          0\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.value_counts()\u001b[39m\n",
      "\u001b[33m        num_legs  num_wings\u001b[39m\n",
      "\u001b[33m        4         0            2\u001b[39m\n",
      "\u001b[33m        2         2            1\u001b[39m\n",
      "\u001b[33m        6         0            1\u001b[39m\n",
      "\u001b[33m        Name: count, dtype: int64\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.value_counts(sort=False)\u001b[39m\n",
      "\u001b[33m        num_legs  num_wings\u001b[39m\n",
      "\u001b[33m        2         2            1\u001b[39m\n",
      "\u001b[33m        4         0            2\u001b[39m\n",
      "\u001b[33m        6         0            1\u001b[39m\n",
      "\u001b[33m        Name: count, dtype: int64\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.value_counts(ascending=True)\u001b[39m\n",
      "\u001b[33m        num_legs  num_wings\u001b[39m\n",
      "\u001b[33m        2         2            1\u001b[39m\n",
      "\u001b[33m        6         0            1\u001b[39m\n",
      "\u001b[33m        4         0            2\u001b[39m\n",
      "\u001b[33m        Name: count, dtype: int64\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.value_counts(normalize=True)\u001b[39m\n",
      "\u001b[33m        num_legs  num_wings\u001b[39m\n",
      "\u001b[33m        4         0            0.50\u001b[39m\n",
      "\u001b[33m        2         2            0.25\u001b[39m\n",
      "\u001b[33m        6         0            0.25\u001b[39m\n",
      "\u001b[33m        Name: proportion, dtype: float64\u001b[39m\n",
      "\n",
      "\u001b[33m        With `dropna` set to `False` we can also count rows with NA values.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df = pd.DataFrame({'first_name': ['John', 'Anne', 'John', 'Beth'],\u001b[39m\n",
      "\u001b[33m        ...                    'middle_name': ['Smith', pd.NA, pd.NA, 'Louise']})\u001b[39m\n",
      "\u001b[33m        >>> df\u001b[39m\n",
      "\u001b[33m          first_name middle_name\u001b[39m\n",
      "\u001b[33m        0       John       Smith\u001b[39m\n",
      "\u001b[33m        1       Anne        <NA>\u001b[39m\n",
      "\u001b[33m        2       John        <NA>\u001b[39m\n",
      "\u001b[33m        3       Beth      Louise\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.value_counts()\u001b[39m\n",
      "\u001b[33m        first_name  middle_name\u001b[39m\n",
      "\u001b[33m        Beth        Louise         1\u001b[39m\n",
      "\u001b[33m        John        Smith          1\u001b[39m\n",
      "\u001b[33m        Name: count, dtype: int64\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.value_counts(dropna=False)\u001b[39m\n",
      "\u001b[33m        first_name  middle_name\u001b[39m\n",
      "\u001b[33m        Anne        NaN            1\u001b[39m\n",
      "\u001b[33m        Beth        Louise         1\u001b[39m\n",
      "\u001b[33m        John        Smith          1\u001b[39m\n",
      "\u001b[33m                    NaN            1\u001b[39m\n",
      "\u001b[33m        Name: count, dtype: int64\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.value_counts(\"first_name\")\u001b[39m\n",
      "\u001b[33m        first_name\u001b[39m\n",
      "\u001b[33m        John    2\u001b[39m\n",
      "\u001b[33m        Anne    1\u001b[39m\n",
      "\u001b[33m        Beth    1\u001b[39m\n",
      "\u001b[33m        Name: count, dtype: int64\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m subset \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "            subset = self.columns.tolist()\n",
      "\n",
      "        name = \u001b[33m\"proportion\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m normalize \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"count\"\u001b[39m\n",
      "        counts = self.groupby(subset, dropna=dropna, observed=\u001b[38;5;28;01mFalse\u001b[39;00m)._grouper.size()\n",
      "        counts.name = name\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m sort:\n",
      "            counts = counts.sort_values(ascending=ascending)\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m normalize:\n",
      "            counts /= counts.sum()\n",
      "\n",
      "        \u001b[38;5;66;03m# Force MultiIndex for a list_like subset with a single column\u001b[39;00m\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m is_list_like(subset) \u001b[38;5;28;01mand\u001b[39;00m len(subset) == \u001b[32m1\u001b[39m:  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "            counts.index = MultiIndex.from_arrays(\n",
      "                [counts.index], names=[counts.index.name]\n",
      "            )\n",
      "\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m counts\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m nlargest(\n",
      "        self, n: int, columns: IndexLabel, keep: NsmallestNlargestKeep = \u001b[33m\"first\"\u001b[39m\n",
      "    ) -> DataFrame:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Return the first `n` rows ordered by `columns` in descending order.\u001b[39m\n",
      "\n",
      "\u001b[33m        Return the first `n` rows with the largest values in `columns`, in\u001b[39m\n",
      "\u001b[33m        descending order. The columns that are not specified are returned as\u001b[39m\n",
      "\u001b[33m        well, but not used for ordering.\u001b[39m\n",
      "\n",
      "\u001b[33m        This method is equivalent to\u001b[39m\n",
      "\u001b[33m        ``df.sort_values(columns, ascending=False).head(n)``, but more\u001b[39m\n",
      "\u001b[33m        performant.\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        n : int\u001b[39m\n",
      "\u001b[33m            Number of rows to return.\u001b[39m\n",
      "\u001b[33m        columns : label or list of labels\u001b[39m\n",
      "\u001b[33m            Column label(s) to order by.\u001b[39m\n",
      "\u001b[33m        keep : {'first', 'last', 'all'}, default 'first'\u001b[39m\n",
      "\u001b[33m            Where there are duplicate values:\u001b[39m\n",
      "\n",
      "\u001b[33m            - ``first`` : prioritize the first occurrence(s)\u001b[39m\n",
      "\u001b[33m            - ``last`` : prioritize the last occurrence(s)\u001b[39m\n",
      "\u001b[33m            - ``all`` : keep all the ties of the smallest item even if it means\u001b[39m\n",
      "\u001b[33m              selecting more than ``n`` items.\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        DataFrame\u001b[39m\n",
      "\u001b[33m            The first `n` rows ordered by the given columns in descending\u001b[39m\n",
      "\u001b[33m            order.\u001b[39m\n",
      "\n",
      "\u001b[33m        See Also\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        DataFrame.nsmallest : Return the first `n` rows ordered by `columns` in\u001b[39m\n",
      "\u001b[33m            ascending order.\u001b[39m\n",
      "\u001b[33m        DataFrame.sort_values : Sort DataFrame by the values.\u001b[39m\n",
      "\u001b[33m        DataFrame.head : Return the first `n` rows without re-ordering.\u001b[39m\n",
      "\n",
      "\u001b[33m        Notes\u001b[39m\n",
      "\u001b[33m        -----\u001b[39m\n",
      "\u001b[33m        This function cannot be used with all column types. For example, when\u001b[39m\n",
      "\u001b[33m        specifying columns with `object` or `category` dtypes, ``TypeError`` is\u001b[39m\n",
      "\u001b[33m        raised.\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        >>> df = pd.DataFrame({'population': [59000000, 65000000, 434000,\u001b[39m\n",
      "\u001b[33m        ...                                   434000, 434000, 337000, 11300,\u001b[39m\n",
      "\u001b[33m        ...                                   11300, 11300],\u001b[39m\n",
      "\u001b[33m        ...                    'GDP': [1937894, 2583560 , 12011, 4520, 12128,\u001b[39m\n",
      "\u001b[33m        ...                            17036, 182, 38, 311],\u001b[39m\n",
      "\u001b[33m        ...                    'alpha-2': [\"IT\", \"FR\", \"MT\", \"MV\", \"BN\",\u001b[39m\n",
      "\u001b[33m        ...                                \"IS\", \"NR\", \"TV\", \"AI\"]},\u001b[39m\n",
      "\u001b[33m        ...                   index=[\"Italy\", \"France\", \"Malta\",\u001b[39m\n",
      "\u001b[33m        ...                          \"Maldives\", \"Brunei\", \"Iceland\",\u001b[39m\n",
      "\u001b[33m        ...                          \"Nauru\", \"Tuvalu\", \"Anguilla\"])\u001b[39m\n",
      "\u001b[33m        >>> df\u001b[39m\n",
      "\u001b[33m                  population      GDP alpha-2\u001b[39m\n",
      "\u001b[33m        Italy       59000000  1937894      IT\u001b[39m\n",
      "\u001b[33m        France      65000000  2583560      FR\u001b[39m\n",
      "\u001b[33m        Malta         434000    12011      MT\u001b[39m\n",
      "\u001b[33m        Maldives      434000     4520      MV\u001b[39m\n",
      "\u001b[33m        Brunei        434000    12128      BN\u001b[39m\n",
      "\u001b[33m        Iceland       337000    17036      IS\u001b[39m\n",
      "\u001b[33m        Nauru          11300      182      NR\u001b[39m\n",
      "\u001b[33m        Tuvalu         11300       38      TV\u001b[39m\n",
      "\u001b[33m        Anguilla       11300      311      AI\u001b[39m\n",
      "\n",
      "\u001b[33m        In the following example, we will use ``nlargest`` to select the three\u001b[39m\n",
      "\u001b[33m        rows having the largest values in column \"population\".\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.nlargest(3, 'population')\u001b[39m\n",
      "\u001b[33m                population      GDP alpha-2\u001b[39m\n",
      "\u001b[33m        France    65000000  2583560      FR\u001b[39m\n",
      "\u001b[33m        Italy     59000000  1937894      IT\u001b[39m\n",
      "\u001b[33m        Malta       434000    12011      MT\u001b[39m\n",
      "\n",
      "\u001b[33m        When using ``keep='last'``, ties are resolved in reverse order:\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.nlargest(3, 'population', keep='last')\u001b[39m\n",
      "\u001b[33m                population      GDP alpha-2\u001b[39m\n",
      "\u001b[33m        France    65000000  2583560      FR\u001b[39m\n",
      "\u001b[33m        Italy     59000000  1937894      IT\u001b[39m\n",
      "\u001b[33m        Brunei      434000    12128      BN\u001b[39m\n",
      "\n",
      "\u001b[33m        When using ``keep='all'``, the number of element kept can go beyond ``n``\u001b[39m\n",
      "\u001b[33m        if there are duplicate values for the smallest element, all the\u001b[39m\n",
      "\u001b[33m        ties are kept:\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.nlargest(3, 'population', keep='all')\u001b[39m\n",
      "\u001b[33m                  population      GDP alpha-2\u001b[39m\n",
      "\u001b[33m        France      65000000  2583560      FR\u001b[39m\n",
      "\u001b[33m        Italy       59000000  1937894      IT\u001b[39m\n",
      "\u001b[33m        Malta         434000    12011      MT\u001b[39m\n",
      "\u001b[33m        Maldives      434000     4520      MV\u001b[39m\n",
      "\u001b[33m        Brunei        434000    12128      BN\u001b[39m\n",
      "\n",
      "\u001b[33m        However, ``nlargest`` does not keep ``n`` distinct largest elements:\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.nlargest(5, 'population', keep='all')\u001b[39m\n",
      "\u001b[33m                  population      GDP alpha-2\u001b[39m\n",
      "\u001b[33m        France      65000000  2583560      FR\u001b[39m\n",
      "\u001b[33m        Italy       59000000  1937894      IT\u001b[39m\n",
      "\u001b[33m        Malta         434000    12011      MT\u001b[39m\n",
      "\u001b[33m        Maldives      434000     4520      MV\u001b[39m\n",
      "\u001b[33m        Brunei        434000    12128      BN\u001b[39m\n",
      "\n",
      "\u001b[33m        To order by the largest values in column \"population\" and then \"GDP\",\u001b[39m\n",
      "\u001b[33m        we can specify multiple columns like in the next example.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.nlargest(3, ['population', 'GDP'])\u001b[39m\n",
      "\u001b[33m                population      GDP alpha-2\u001b[39m\n",
      "\u001b[33m        France    65000000  2583560      FR\u001b[39m\n",
      "\u001b[33m        Italy     59000000  1937894      IT\u001b[39m\n",
      "\u001b[33m        Brunei      434000    12128      BN\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m selectn.SelectNFrame(self, n=n, keep=keep, columns=columns).nlargest()\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m nsmallest(\n",
      "        self, n: int, columns: IndexLabel, keep: NsmallestNlargestKeep = \u001b[33m\"first\"\u001b[39m\n",
      "    ) -> DataFrame:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Return the first `n` rows ordered by `columns` in ascending order.\u001b[39m\n",
      "\n",
      "\u001b[33m        Return the first `n` rows with the smallest values in `columns`, in\u001b[39m\n",
      "\u001b[33m        ascending order. The columns that are not specified are returned as\u001b[39m\n",
      "\u001b[33m        well, but not used for ordering.\u001b[39m\n",
      "\n",
      "\u001b[33m        This method is equivalent to\u001b[39m\n",
      "\u001b[33m        ``df.sort_values(columns, ascending=True).head(n)``, but more\u001b[39m\n",
      "\u001b[33m        performant.\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        n : int\u001b[39m\n",
      "\u001b[33m            Number of items to retrieve.\u001b[39m\n",
      "\u001b[33m        columns : list or str\u001b[39m\n",
      "\u001b[33m            Column name or names to order by.\u001b[39m\n",
      "\u001b[33m        keep : {'first', 'last', 'all'}, default 'first'\u001b[39m\n",
      "\u001b[33m            Where there are duplicate values:\u001b[39m\n",
      "\n",
      "\u001b[33m            - ``first`` : take the first occurrence.\u001b[39m\n",
      "\u001b[33m            - ``last`` : take the last occurrence.\u001b[39m\n",
      "\u001b[33m            - ``all`` : keep all the ties of the largest item even if it means\u001b[39m\n",
      "\u001b[33m              selecting more than ``n`` items.\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        DataFrame\u001b[39m\n",
      "\n",
      "\u001b[33m        See Also\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        DataFrame.nlargest : Return the first `n` rows ordered by `columns` in\u001b[39m\n",
      "\u001b[33m            descending order.\u001b[39m\n",
      "\u001b[33m        DataFrame.sort_values : Sort DataFrame by the values.\u001b[39m\n",
      "\u001b[33m        DataFrame.head : Return the first `n` rows without re-ordering.\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        >>> df = pd.DataFrame({'population': [59000000, 65000000, 434000,\u001b[39m\n",
      "\u001b[33m        ...                                   434000, 434000, 337000, 337000,\u001b[39m\n",
      "\u001b[33m        ...                                   11300, 11300],\u001b[39m\n",
      "\u001b[33m        ...                    'GDP': [1937894, 2583560 , 12011, 4520, 12128,\u001b[39m\n",
      "\u001b[33m        ...                            17036, 182, 38, 311],\u001b[39m\n",
      "\u001b[33m        ...                    'alpha-2': [\"IT\", \"FR\", \"MT\", \"MV\", \"BN\",\u001b[39m\n",
      "\u001b[33m        ...                                \"IS\", \"NR\", \"TV\", \"AI\"]},\u001b[39m\n",
      "\u001b[33m        ...                   index=[\"Italy\", \"France\", \"Malta\",\u001b[39m\n",
      "\u001b[33m        ...                          \"Maldives\", \"Brunei\", \"Iceland\",\u001b[39m\n",
      "\u001b[33m        ...                          \"Nauru\", \"Tuvalu\", \"Anguilla\"])\u001b[39m\n",
      "\u001b[33m        >>> df\u001b[39m\n",
      "\u001b[33m                  population      GDP alpha-2\u001b[39m\n",
      "\u001b[33m        Italy       59000000  1937894      IT\u001b[39m\n",
      "\u001b[33m        France      65000000  2583560      FR\u001b[39m\n",
      "\u001b[33m        Malta         434000    12011      MT\u001b[39m\n",
      "\u001b[33m        Maldives      434000     4520      MV\u001b[39m\n",
      "\u001b[33m        Brunei        434000    12128      BN\u001b[39m\n",
      "\u001b[33m        Iceland       337000    17036      IS\u001b[39m\n",
      "\u001b[33m        Nauru         337000      182      NR\u001b[39m\n",
      "\u001b[33m        Tuvalu         11300       38      TV\u001b[39m\n",
      "\u001b[33m        Anguilla       11300      311      AI\u001b[39m\n",
      "\n",
      "\u001b[33m        In the following example, we will use ``nsmallest`` to select the\u001b[39m\n",
      "\u001b[33m        three rows having the smallest values in column \"population\".\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.nsmallest(3, 'population')\u001b[39m\n",
      "\u001b[33m                  population    GDP alpha-2\u001b[39m\n",
      "\u001b[33m        Tuvalu         11300     38      TV\u001b[39m\n",
      "\u001b[33m        Anguilla       11300    311      AI\u001b[39m\n",
      "\u001b[33m        Iceland       337000  17036      IS\u001b[39m\n",
      "\n",
      "\u001b[33m        When using ``keep='last'``, ties are resolved in reverse order:\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.nsmallest(3, 'population', keep='last')\u001b[39m\n",
      "\u001b[33m                  population  GDP alpha-2\u001b[39m\n",
      "\u001b[33m        Anguilla       11300  311      AI\u001b[39m\n",
      "\u001b[33m        Tuvalu         11300   38      TV\u001b[39m\n",
      "\u001b[33m        Nauru         337000  182      NR\u001b[39m\n",
      "\n",
      "\u001b[33m        When using ``keep='all'``, the number of element kept can go beyond ``n``\u001b[39m\n",
      "\u001b[33m        if there are duplicate values for the largest element, all the\u001b[39m\n",
      "\u001b[33m        ties are kept.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.nsmallest(3, 'population', keep='all')\u001b[39m\n",
      "\u001b[33m                  population    GDP alpha-2\u001b[39m\n",
      "\u001b[33m        Tuvalu         11300     38      TV\u001b[39m\n",
      "\u001b[33m        Anguilla       11300    311      AI\u001b[39m\n",
      "\u001b[33m        Iceland       337000  17036      IS\u001b[39m\n",
      "\u001b[33m        Nauru         337000    182      NR\u001b[39m\n",
      "\n",
      "\u001b[33m        However, ``nsmallest`` does not keep ``n`` distinct\u001b[39m\n",
      "\u001b[33m        smallest elements:\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.nsmallest(4, 'population', keep='all')\u001b[39m\n",
      "\u001b[33m                  population    GDP alpha-2\u001b[39m\n",
      "\u001b[33m        Tuvalu         11300     38      TV\u001b[39m\n",
      "\u001b[33m        Anguilla       11300    311      AI\u001b[39m\n",
      "\u001b[33m        Iceland       337000  17036      IS\u001b[39m\n",
      "\u001b[33m        Nauru         337000    182      NR\u001b[39m\n",
      "\n",
      "\u001b[33m        To order by the smallest values in column \"population\" and then \"GDP\", we can\u001b[39m\n",
      "\u001b[33m        specify multiple columns like in the next example.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.nsmallest(3, ['population', 'GDP'])\u001b[39m\n",
      "\u001b[33m                  population  GDP alpha-2\u001b[39m\n",
      "\u001b[33m        Tuvalu         11300   38      TV\u001b[39m\n",
      "\u001b[33m        Anguilla       11300  311      AI\u001b[39m\n",
      "\u001b[33m        Nauru         337000  182      NR\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m selectn.SelectNFrame(self, n=n, keep=keep, columns=columns).nsmallest()\n",
      "\n",
      "    @doc(\n",
      "        Series.swaplevel,\n",
      "        klass=_shared_doc_kwargs[\u001b[33m\"klass\"\u001b[39m],\n",
      "        extra_params=dedent(\n",
      "            \u001b[33m\"\"\"axis : {0 or 'index', 1 or 'columns'}, default 0\u001b[39m\n",
      "\u001b[33m            The axis to swap levels on. 0 or 'index' for row-wise, 1 or\u001b[39m\n",
      "\u001b[33m            'columns' for column-wise.\"\"\"\u001b[39m\n",
      "        ),\n",
      "        examples=dedent(\n",
      "            \u001b[33m\"\"\"\\\u001b[39m\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        >>> df = pd.DataFrame(\u001b[39m\n",
      "\u001b[33m        ...     {\"Grade\": [\"A\", \"B\", \"A\", \"C\"]},\u001b[39m\n",
      "\u001b[33m        ...     index=[\u001b[39m\n",
      "\u001b[33m        ...         [\"Final exam\", \"Final exam\", \"Coursework\", \"Coursework\"],\u001b[39m\n",
      "\u001b[33m        ...         [\"History\", \"Geography\", \"History\", \"Geography\"],\u001b[39m\n",
      "\u001b[33m        ...         [\"January\", \"February\", \"March\", \"April\"],\u001b[39m\n",
      "\u001b[33m        ...     ],\u001b[39m\n",
      "\u001b[33m        ... )\u001b[39m\n",
      "\u001b[33m        >>> df\u001b[39m\n",
      "\u001b[33m                                            Grade\u001b[39m\n",
      "\u001b[33m        Final exam  History     January      A\u001b[39m\n",
      "\u001b[33m                    Geography   February     B\u001b[39m\n",
      "\u001b[33m        Coursework  History     March        A\u001b[39m\n",
      "\u001b[33m                    Geography   April        C\u001b[39m\n",
      "\n",
      "\u001b[33m        In the following example, we will swap the levels of the indices.\u001b[39m\n",
      "\u001b[33m        Here, we will swap the levels column-wise, but levels can be swapped row-wise\u001b[39m\n",
      "\u001b[33m        in a similar manner. Note that column-wise is the default behaviour.\u001b[39m\n",
      "\u001b[33m        By not supplying any arguments for i and j, we swap the last and second to\u001b[39m\n",
      "\u001b[33m        last indices.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.swaplevel()\u001b[39m\n",
      "\u001b[33m                                            Grade\u001b[39m\n",
      "\u001b[33m        Final exam  January     History         A\u001b[39m\n",
      "\u001b[33m                    February    Geography       B\u001b[39m\n",
      "\u001b[33m        Coursework  March       History         A\u001b[39m\n",
      "\u001b[33m                    April       Geography       C\u001b[39m\n",
      "\n",
      "\u001b[33m        By supplying one argument, we can choose which index to swap the last\u001b[39m\n",
      "\u001b[33m        index with. We can for example swap the first index with the last one as\u001b[39m\n",
      "\u001b[33m        follows.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.swaplevel(0)\u001b[39m\n",
      "\u001b[33m                                            Grade\u001b[39m\n",
      "\u001b[33m        January     History     Final exam      A\u001b[39m\n",
      "\u001b[33m        February    Geography   Final exam      B\u001b[39m\n",
      "\u001b[33m        March       History     Coursework      A\u001b[39m\n",
      "\u001b[33m        April       Geography   Coursework      C\u001b[39m\n",
      "\n",
      "\u001b[33m        We can also define explicitly which indices we want to swap by supplying values\u001b[39m\n",
      "\u001b[33m        for both i and j. Here, we for example swap the first and second indices.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.swaplevel(0, 1)\u001b[39m\n",
      "\u001b[33m                                            Grade\u001b[39m\n",
      "\u001b[33m        History     Final exam  January         A\u001b[39m\n",
      "\u001b[33m        Geography   Final exam  February        B\u001b[39m\n",
      "\u001b[33m        History     Coursework  March           A\u001b[39m\n",
      "\u001b[33m        Geography   Coursework  April           C\"\"\"\u001b[39m\n",
      "        ),\n",
      "    )\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m swaplevel(self, i: Axis = -\u001b[32m2\u001b[39m, j: Axis = -\u001b[32m1\u001b[39m, axis: Axis = \u001b[32m0\u001b[39m) -> DataFrame:\n",
      "        result = self.copy(deep=\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\n",
      "        axis = self._get_axis_number(axis)\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m isinstance(result._get_axis(axis), MultiIndex):  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n",
      "            \u001b[38;5;28;01mraise\u001b[39;00m TypeError(\u001b[33m\"Can only swap levels on a hierarchical axis.\"\u001b[39m)\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m axis == \u001b[32m0\u001b[39m:\n",
      "            \u001b[38;5;28;01massert\u001b[39;00m isinstance(result.index, MultiIndex)\n",
      "            result.index = result.index.swaplevel(i, j)\n",
      "        \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "            \u001b[38;5;28;01massert\u001b[39;00m isinstance(result.columns, MultiIndex)\n",
      "            result.columns = result.columns.swaplevel(i, j)\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m reorder_levels(self, order: Sequence[int | str], axis: Axis = \u001b[32m0\u001b[39m) -> DataFrame:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Rearrange index levels using input order. May not drop or duplicate levels.\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        order : list of int or list of str\u001b[39m\n",
      "\u001b[33m            List representing new level order. Reference level by number\u001b[39m\n",
      "\u001b[33m            (position) or by key (label).\u001b[39m\n",
      "\u001b[33m        axis : {0 or 'index', 1 or 'columns'}, default 0\u001b[39m\n",
      "\u001b[33m            Where to reorder levels.\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        DataFrame\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        >>> data = {\u001b[39m\n",
      "\u001b[33m        ...     \"class\": [\"Mammals\", \"Mammals\", \"Reptiles\"],\u001b[39m\n",
      "\u001b[33m        ...     \"diet\": [\"Omnivore\", \"Carnivore\", \"Carnivore\"],\u001b[39m\n",
      "\u001b[33m        ...     \"species\": [\"Humans\", \"Dogs\", \"Snakes\"],\u001b[39m\n",
      "\u001b[33m        ... }\u001b[39m\n",
      "\u001b[33m        >>> df = pd.DataFrame(data, columns=[\"class\", \"diet\", \"species\"])\u001b[39m\n",
      "\u001b[33m        >>> df = df.set_index([\"class\", \"diet\"])\u001b[39m\n",
      "\u001b[33m        >>> df\u001b[39m\n",
      "\u001b[33m                                          species\u001b[39m\n",
      "\u001b[33m        class      diet\u001b[39m\n",
      "\u001b[33m        Mammals    Omnivore                Humans\u001b[39m\n",
      "\u001b[33m                   Carnivore                 Dogs\u001b[39m\n",
      "\u001b[33m        Reptiles   Carnivore               Snakes\u001b[39m\n",
      "\n",
      "\u001b[33m        Let's reorder the levels of the index:\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.reorder_levels([\"diet\", \"class\"])\u001b[39m\n",
      "\u001b[33m                                          species\u001b[39m\n",
      "\u001b[33m        diet      class\u001b[39m\n",
      "\u001b[33m        Omnivore  Mammals                  Humans\u001b[39m\n",
      "\u001b[33m        Carnivore Mammals                    Dogs\u001b[39m\n",
      "\u001b[33m                  Reptiles                 Snakes\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        axis = self._get_axis_number(axis)\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m isinstance(self._get_axis(axis), MultiIndex):  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n",
      "            \u001b[38;5;28;01mraise\u001b[39;00m TypeError(\u001b[33m\"Can only reorder levels on a hierarchical axis.\"\u001b[39m)\n",
      "\n",
      "        result = self.copy(deep=\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m axis == \u001b[32m0\u001b[39m:\n",
      "            \u001b[38;5;28;01massert\u001b[39;00m isinstance(result.index, MultiIndex)\n",
      "            result.index = result.index.reorder_levels(order)\n",
      "        \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "            \u001b[38;5;28;01massert\u001b[39;00m isinstance(result.columns, MultiIndex)\n",
      "            result.columns = result.columns.reorder_levels(order)\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\n",
      "    \u001b[38;5;66;03m# ----------------------------------------------------------------------\u001b[39;00m\n",
      "    \u001b[38;5;66;03m# Arithmetic Methods\u001b[39;00m\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m _cmp_method(self, other, op):\n",
      "        axis: Literal[\u001b[32m1\u001b[39m] = \u001b[32m1\u001b[39m  \u001b[38;5;66;03m# only relevant for Series other case\u001b[39;00m\n",
      "\n",
      "        self, other = self._align_for_op(other, axis, flex=\u001b[38;5;28;01mFalse\u001b[39;00m, level=\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\n",
      "        \u001b[38;5;66;03m# See GH#4537 for discussion of scalar op behavior\u001b[39;00m\n",
      "        new_data = self._dispatch_frame_op(other, op, axis=axis)\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m self._construct_result(new_data)\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m _arith_method(self, other, op):\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m self._should_reindex_frame_op(other, op, \u001b[32m1\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m self._arith_method_with_reindex(other, op)\n",
      "\n",
      "        axis: Literal[\u001b[32m1\u001b[39m] = \u001b[32m1\u001b[39m  \u001b[38;5;66;03m# only relevant for Series other case\u001b[39;00m\n",
      "        other = ops.maybe_prepare_scalar_for_op(other, (self.shape[axis],))\n",
      "\n",
      "        self, other = self._align_for_op(other, axis, flex=\u001b[38;5;28;01mTrue\u001b[39;00m, level=\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\n",
      "        \u001b[38;5;28;01mwith\u001b[39;00m np.errstate(all=\u001b[33m\"ignore\"\u001b[39m):\n",
      "            new_data = self._dispatch_frame_op(other, op, axis=axis)\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m self._construct_result(new_data)\n",
      "\n",
      "    _logical_method = _arith_method\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m _dispatch_frame_op(\n",
      "        self, right, func: Callable, axis: AxisInt | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "    ) -> DataFrame:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Evaluate the frame operation func(left, right) by evaluating\u001b[39m\n",
      "\u001b[33m        column-by-column, dispatching to the Series implementation.\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        right : scalar, Series, or DataFrame\u001b[39m\n",
      "\u001b[33m        func : arithmetic or comparison operator\u001b[39m\n",
      "\u001b[33m        axis : {None, 0, 1}\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        DataFrame\u001b[39m\n",
      "\n",
      "\u001b[33m        Notes\u001b[39m\n",
      "\u001b[33m        -----\u001b[39m\n",
      "\u001b[33m        Caller is responsible for setting np.errstate where relevant.\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;66;03m# Get the appropriate array-op to apply to each column/block's values.\u001b[39;00m\n",
      "        array_op = ops.get_array_op(func)\n",
      "\n",
      "        right = lib.item_from_zerodim(right)\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m is_list_like(right):\n",
      "            \u001b[38;5;66;03m# i.e. scalar, faster than checking np.ndim(right) == 0\u001b[39;00m\n",
      "            bm = self._mgr.apply(array_op, right=right)\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m self._constructor_from_mgr(bm, axes=bm.axes)\n",
      "\n",
      "        \u001b[38;5;28;01melif\u001b[39;00m isinstance(right, DataFrame):\n",
      "            \u001b[38;5;28;01massert\u001b[39;00m self.index.equals(right.index)\n",
      "            \u001b[38;5;28;01massert\u001b[39;00m self.columns.equals(right.columns)\n",
      "            \u001b[38;5;66;03m# TODO: The previous assertion `assert right._indexed_same(self)`\u001b[39;00m\n",
      "            \u001b[38;5;66;03m#  fails in cases with empty columns reached via\u001b[39;00m\n",
      "            \u001b[38;5;66;03m#  _frame_arith_method_with_reindex\u001b[39;00m\n",
      "\n",
      "            \u001b[38;5;66;03m# TODO operate_blockwise expects a manager of the same type\u001b[39;00m\n",
      "            bm = self._mgr.operate_blockwise(\n",
      "                \u001b[38;5;66;03m# error: Argument 1 to \"operate_blockwise\" of \"ArrayManager\" has\u001b[39;00m\n",
      "                \u001b[38;5;66;03m# incompatible type \"Union[ArrayManager, BlockManager]\"; expected\u001b[39;00m\n",
      "                \u001b[38;5;66;03m# \"ArrayManager\"\u001b[39;00m\n",
      "                \u001b[38;5;66;03m# error: Argument 1 to \"operate_blockwise\" of \"BlockManager\" has\u001b[39;00m\n",
      "                \u001b[38;5;66;03m# incompatible type \"Union[ArrayManager, BlockManager]\"; expected\u001b[39;00m\n",
      "                \u001b[38;5;66;03m# \"BlockManager\"\u001b[39;00m\n",
      "                right._mgr,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "                array_op,\n",
      "            )\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m self._constructor_from_mgr(bm, axes=bm.axes)\n",
      "\n",
      "        \u001b[38;5;28;01melif\u001b[39;00m isinstance(right, Series) \u001b[38;5;28;01mand\u001b[39;00m axis == \u001b[32m1\u001b[39m:\n",
      "            \u001b[38;5;66;03m# axis=1 means we want to operate row-by-row\u001b[39;00m\n",
      "            \u001b[38;5;28;01massert\u001b[39;00m right.index.equals(self.columns)\n",
      "\n",
      "            right = right._values\n",
      "            \u001b[38;5;66;03m# maybe_align_as_frame ensures we do not have an ndarray here\u001b[39;00m\n",
      "            \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m isinstance(right, np.ndarray)\n",
      "\n",
      "            arrays = [\n",
      "                array_op(_left, _right)\n",
      "                \u001b[38;5;28;01mfor\u001b[39;00m _left, _right \u001b[38;5;28;01min\u001b[39;00m zip(self._iter_column_arrays(), right)\n",
      "            ]\n",
      "\n",
      "        \u001b[38;5;28;01melif\u001b[39;00m isinstance(right, Series):\n",
      "            \u001b[38;5;28;01massert\u001b[39;00m right.index.equals(self.index)\n",
      "            right = right._values\n",
      "\n",
      "            arrays = [array_op(left, right) \u001b[38;5;28;01mfor\u001b[39;00m left \u001b[38;5;28;01min\u001b[39;00m self._iter_column_arrays()]\n",
      "\n",
      "        \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "            \u001b[38;5;28;01mraise\u001b[39;00m NotImplementedError(right)\n",
      "\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m type(self)._from_arrays(\n",
      "            arrays, self.columns, self.index, verify_integrity=\u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "        )\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m _combine_frame(self, other: DataFrame, func, fill_value=\u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "        \u001b[38;5;66;03m# at this point we have `self._indexed_same(other)`\u001b[39;00m\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m fill_value \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "            \u001b[38;5;66;03m# since _arith_op may be called in a loop, avoid function call\u001b[39;00m\n",
      "            \u001b[38;5;66;03m#  overhead if possible by doing this check once\u001b[39;00m\n",
      "            _arith_op = func\n",
      "\n",
      "        \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\n",
      "            \u001b[38;5;28;01mdef\u001b[39;00m _arith_op(left, right):\n",
      "                \u001b[38;5;66;03m# for the mixed_type case where we iterate over columns,\u001b[39;00m\n",
      "                \u001b[38;5;66;03m# _arith_op(left, right) is equivalent to\u001b[39;00m\n",
      "                \u001b[38;5;66;03m# left._binop(right, func, fill_value=fill_value)\u001b[39;00m\n",
      "                left, right = ops.fill_binop(left, right, fill_value)\n",
      "                \u001b[38;5;28;01mreturn\u001b[39;00m func(left, right)\n",
      "\n",
      "        new_data = self._dispatch_frame_op(other, _arith_op)\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m new_data\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m _arith_method_with_reindex(self, right: DataFrame, op) -> DataFrame:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        For DataFrame-with-DataFrame operations that require reindexing,\u001b[39m\n",
      "\u001b[33m        operate only on shared columns, then reindex.\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        right : DataFrame\u001b[39m\n",
      "\u001b[33m        op : binary operator\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        DataFrame\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        left = self\n",
      "\n",
      "        \u001b[38;5;66;03m# GH#31623, only operate on shared columns\u001b[39;00m\n",
      "        cols, lcols, rcols = left.columns.join(\n",
      "            right.columns, how=\u001b[33m\"inner\"\u001b[39m, level=\u001b[38;5;28;01mNone\u001b[39;00m, return_indexers=\u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "        )\n",
      "\n",
      "        new_left = left.iloc[:, lcols]\n",
      "        new_right = right.iloc[:, rcols]\n",
      "        result = op(new_left, new_right)\n",
      "\n",
      "        \u001b[38;5;66;03m# Do the join on the columns instead of using left._align_for_op\u001b[39;00m\n",
      "        \u001b[38;5;66;03m#  to avoid constructing two potentially large/sparse DataFrames\u001b[39;00m\n",
      "        join_columns, _, _ = left.columns.join(\n",
      "            right.columns, how=\u001b[33m\"outer\"\u001b[39m, level=\u001b[38;5;28;01mNone\u001b[39;00m, return_indexers=\u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "        )\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m result.columns.has_duplicates:\n",
      "            \u001b[38;5;66;03m# Avoid reindexing with a duplicate axis.\u001b[39;00m\n",
      "            \u001b[38;5;66;03m# https://github.com/pandas-dev/pandas/issues/35194\u001b[39;00m\n",
      "            indexer, _ = result.columns.get_indexer_non_unique(join_columns)\n",
      "            indexer = algorithms.unique1d(indexer)\n",
      "            result = result._reindex_with_indexers(\n",
      "                {\u001b[32m1\u001b[39m: [join_columns, indexer]}, allow_dups=\u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "            )\n",
      "        \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "            result = result.reindex(join_columns, axis=\u001b[32m1\u001b[39m)\n",
      "\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m _should_reindex_frame_op(self, right, op, axis: int, fill_value, level) -> bool:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Check if this is an operation between DataFrames that will need to reindex.\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m op \u001b[38;5;28;01mis\u001b[39;00m operator.pow \u001b[38;5;28;01mor\u001b[39;00m op \u001b[38;5;28;01mis\u001b[39;00m roperator.rpow:\n",
      "            \u001b[38;5;66;03m# GH#32685 pow has special semantics for operating with null values\u001b[39;00m\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m isinstance(right, DataFrame):\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m fill_value \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mand\u001b[39;00m level \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mand\u001b[39;00m axis == \u001b[32m1\u001b[39m:\n",
      "            \u001b[38;5;66;03m# TODO: any other cases we should handle here?\u001b[39;00m\n",
      "\n",
      "            \u001b[38;5;66;03m# Intersection is always unique so we have to check the unique columns\u001b[39;00m\n",
      "            left_uniques = self.columns.unique()\n",
      "            right_uniques = right.columns.unique()\n",
      "            cols = left_uniques.intersection(right_uniques)\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m len(cols) \u001b[38;5;28;01mand\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m (\n",
      "                len(cols) == len(left_uniques) \u001b[38;5;28;01mand\u001b[39;00m len(cols) == len(right_uniques)\n",
      "            ):\n",
      "                \u001b[38;5;66;03m# TODO: is there a shortcut available when len(cols) == 0?\u001b[39;00m\n",
      "                \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m _align_for_op(\n",
      "        self,\n",
      "        other,\n",
      "        axis: AxisInt,\n",
      "        flex: bool | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "        level: Level | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    ):\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Convert rhs to meet lhs dims if input is list, tuple or np.ndarray.\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        left : DataFrame\u001b[39m\n",
      "\u001b[33m        right : Any\u001b[39m\n",
      "\u001b[33m        axis : int\u001b[39m\n",
      "\u001b[33m        flex : bool or None, default False\u001b[39m\n",
      "\u001b[33m            Whether this is a flex op, in which case we reindex.\u001b[39m\n",
      "\u001b[33m            None indicates not to check for alignment.\u001b[39m\n",
      "\u001b[33m        level : int or level name, default None\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        left : DataFrame\u001b[39m\n",
      "\u001b[33m        right : Any\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        left, right = self, other\n",
      "\n",
      "        \u001b[38;5;28;01mdef\u001b[39;00m to_series(right):\n",
      "            msg = (\n",
      "                \u001b[33m\"Unable to coerce to Series, \"\u001b[39m\n",
      "                \u001b[33m\"length must be {req_len}: given {given_len}\"\u001b[39m\n",
      "            )\n",
      "\n",
      "            \u001b[38;5;66;03m# pass dtype to avoid doing inference, which would break consistency\u001b[39;00m\n",
      "            \u001b[38;5;66;03m#  with Index/Series ops\u001b[39;00m\n",
      "            dtype = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m getattr(right, \u001b[33m\"dtype\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == object:\n",
      "                \u001b[38;5;66;03m# can't pass right.dtype unconditionally as that would break on e.g.\u001b[39;00m\n",
      "                \u001b[38;5;66;03m#  datetime64[h] ndarray\u001b[39;00m\n",
      "                dtype = object\n",
      "\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m axis == \u001b[32m0\u001b[39m:\n",
      "                \u001b[38;5;28;01mif\u001b[39;00m len(left.index) != len(right):\n",
      "                    \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\n",
      "                        msg.format(req_len=len(left.index), given_len=len(right))\n",
      "                    )\n",
      "                right = left._constructor_sliced(right, index=left.index, dtype=dtype)\n",
      "            \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "                \u001b[38;5;28;01mif\u001b[39;00m len(left.columns) != len(right):\n",
      "                    \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\n",
      "                        msg.format(req_len=len(left.columns), given_len=len(right))\n",
      "                    )\n",
      "                right = left._constructor_sliced(right, index=left.columns, dtype=dtype)\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m right\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m isinstance(right, np.ndarray):\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m right.ndim == \u001b[32m1\u001b[39m:\n",
      "                right = to_series(right)\n",
      "\n",
      "            \u001b[38;5;28;01melif\u001b[39;00m right.ndim == \u001b[32m2\u001b[39m:\n",
      "                \u001b[38;5;66;03m# We need to pass dtype=right.dtype to retain object dtype\u001b[39;00m\n",
      "                \u001b[38;5;66;03m#  otherwise we lose consistency with Index and array ops\u001b[39;00m\n",
      "                dtype = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "                \u001b[38;5;28;01mif\u001b[39;00m right.dtype == object:\n",
      "                    \u001b[38;5;66;03m# can't pass right.dtype unconditionally as that would break on e.g.\u001b[39;00m\n",
      "                    \u001b[38;5;66;03m#  datetime64[h] ndarray\u001b[39;00m\n",
      "                    dtype = object\n",
      "\n",
      "                \u001b[38;5;28;01mif\u001b[39;00m right.shape == left.shape:\n",
      "                    right = left._constructor(\n",
      "                        right, index=left.index, columns=left.columns, dtype=dtype\n",
      "                    )\n",
      "\n",
      "                \u001b[38;5;28;01melif\u001b[39;00m right.shape[\u001b[32m0\u001b[39m] == left.shape[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mand\u001b[39;00m right.shape[\u001b[32m1\u001b[39m] == \u001b[32m1\u001b[39m:\n",
      "                    \u001b[38;5;66;03m# Broadcast across columns\u001b[39;00m\n",
      "                    right = np.broadcast_to(right, left.shape)\n",
      "                    right = left._constructor(\n",
      "                        right, index=left.index, columns=left.columns, dtype=dtype\n",
      "                    )\n",
      "\n",
      "                \u001b[38;5;28;01melif\u001b[39;00m right.shape[\u001b[32m1\u001b[39m] == left.shape[\u001b[32m1\u001b[39m] \u001b[38;5;28;01mand\u001b[39;00m right.shape[\u001b[32m0\u001b[39m] == \u001b[32m1\u001b[39m:\n",
      "                    \u001b[38;5;66;03m# Broadcast along rows\u001b[39;00m\n",
      "                    right = to_series(right[\u001b[32m0\u001b[39m, :])\n",
      "\n",
      "                \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "                    \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\n",
      "                        \u001b[33m\"Unable to coerce to DataFrame, shape \"\u001b[39m\n",
      "                        \u001b[33mf\"must be {left.shape}: given {right.shape}\"\u001b[39m\n",
      "                    )\n",
      "\n",
      "            \u001b[38;5;28;01melif\u001b[39;00m right.ndim > \u001b[32m2\u001b[39m:\n",
      "                \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\n",
      "                    \u001b[33m\"Unable to coerce to Series/DataFrame, \"\u001b[39m\n",
      "                    \u001b[33mf\"dimension must be <= 2: {right.shape}\"\u001b[39m\n",
      "                )\n",
      "\n",
      "        \u001b[38;5;28;01melif\u001b[39;00m is_list_like(right) \u001b[38;5;28;01mand\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m isinstance(right, (Series, DataFrame)):\n",
      "            \u001b[38;5;66;03m# GH#36702. Raise when attempting arithmetic with list of array-like.\u001b[39;00m\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m any(is_array_like(el) \u001b[38;5;28;01mfor\u001b[39;00m el \u001b[38;5;28;01min\u001b[39;00m right):\n",
      "                \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\n",
      "                    \u001b[33mf\"Unable to coerce list of {type(right[0])} to Series/DataFrame\"\u001b[39m\n",
      "                )\n",
      "            \u001b[38;5;66;03m# GH#17901\u001b[39;00m\n",
      "            right = to_series(right)\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m flex \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mand\u001b[39;00m isinstance(right, DataFrame):\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m left._indexed_same(right):\n",
      "                \u001b[38;5;28;01mif\u001b[39;00m flex:\n",
      "                    left, right = left.align(\n",
      "                        right, join=\u001b[33m\"outer\"\u001b[39m, level=level, copy=\u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "                    )\n",
      "                \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "                    \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\n",
      "                        \u001b[33m\"Can only compare identically-labeled (both index and columns) \"\u001b[39m\n",
      "                        \u001b[33m\"DataFrame objects\"\u001b[39m\n",
      "                    )\n",
      "        \u001b[38;5;28;01melif\u001b[39;00m isinstance(right, Series):\n",
      "            \u001b[38;5;66;03m# axis=1 is default for DataFrame-with-Series op\u001b[39;00m\n",
      "            axis = axis \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m1\u001b[39m\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m flex:\n",
      "                \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m left.axes[axis].equals(right.index):\n",
      "                    \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\n",
      "                        \u001b[33m\"Operands are not aligned. Do \"\u001b[39m\n",
      "                        \u001b[33m\"`left, right = left.align(right, axis=1, copy=False)` \"\u001b[39m\n",
      "                        \u001b[33m\"before operating.\"\u001b[39m\n",
      "                    )\n",
      "\n",
      "            left, right = left.align(\n",
      "                right,\n",
      "                join=\u001b[33m\"outer\"\u001b[39m,\n",
      "                axis=axis,\n",
      "                level=level,\n",
      "                copy=\u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "            )\n",
      "            right = left._maybe_align_series_as_frame(right, axis)\n",
      "\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m left, right\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m _maybe_align_series_as_frame(self, series: Series, axis: AxisInt):\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        If the Series operand is not EA-dtype, we can broadcast to 2D and operate\u001b[39m\n",
      "\u001b[33m        blockwise.\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        rvalues = series._values\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m isinstance(rvalues, np.ndarray):\n",
      "            \u001b[38;5;66;03m# TODO(EA2D): no need to special-case with 2D EAs\u001b[39;00m\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m rvalues.dtype \u001b[38;5;28;01min\u001b[39;00m (\u001b[33m\"datetime64[ns]\"\u001b[39m, \u001b[33m\"timedelta64[ns]\"\u001b[39m):\n",
      "                \u001b[38;5;66;03m# We can losslessly+cheaply cast to ndarray\u001b[39;00m\n",
      "                rvalues = np.asarray(rvalues)\n",
      "            \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "                \u001b[38;5;28;01mreturn\u001b[39;00m series\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m axis == \u001b[32m0\u001b[39m:\n",
      "            rvalues = rvalues.reshape(-\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m)\n",
      "        \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "            rvalues = rvalues.reshape(\u001b[32m1\u001b[39m, -\u001b[32m1\u001b[39m)\n",
      "\n",
      "        rvalues = np.broadcast_to(rvalues, self.shape)\n",
      "        \u001b[38;5;66;03m# pass dtype to avoid doing inference\u001b[39;00m\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m self._constructor(\n",
      "            rvalues,\n",
      "            index=self.index,\n",
      "            columns=self.columns,\n",
      "            dtype=rvalues.dtype,\n",
      "        )\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m _flex_arith_method(\n",
      "        self, other, op, *, axis: Axis = \u001b[33m\"columns\"\u001b[39m, level=\u001b[38;5;28;01mNone\u001b[39;00m, fill_value=\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "    ):\n",
      "        axis = self._get_axis_number(axis) \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m1\u001b[39m\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m self._should_reindex_frame_op(other, op, axis, fill_value, level):\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m self._arith_method_with_reindex(other, op)\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m isinstance(other, Series) \u001b[38;5;28;01mand\u001b[39;00m fill_value \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "            \u001b[38;5;66;03m# TODO: We could allow this in cases where we end up going\u001b[39;00m\n",
      "            \u001b[38;5;66;03m#  through the DataFrame path\u001b[39;00m\n",
      "            \u001b[38;5;28;01mraise\u001b[39;00m NotImplementedError(\u001b[33mf\"fill_value {fill_value} not supported.\"\u001b[39m)\n",
      "\n",
      "        other = ops.maybe_prepare_scalar_for_op(other, self.shape)\n",
      "        self, other = self._align_for_op(other, axis, flex=\u001b[38;5;28;01mTrue\u001b[39;00m, level=level)\n",
      "\n",
      "        \u001b[38;5;28;01mwith\u001b[39;00m np.errstate(all=\u001b[33m\"ignore\"\u001b[39m):\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m isinstance(other, DataFrame):\n",
      "                \u001b[38;5;66;03m# Another DataFrame\u001b[39;00m\n",
      "                new_data = self._combine_frame(other, op, fill_value)\n",
      "\n",
      "            \u001b[38;5;28;01melif\u001b[39;00m isinstance(other, Series):\n",
      "                new_data = self._dispatch_frame_op(other, op, axis=axis)\n",
      "            \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "                \u001b[38;5;66;03m# in this case we always have `np.ndim(other) == 0`\u001b[39;00m\n",
      "                \u001b[38;5;28;01mif\u001b[39;00m fill_value \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "                    self = self.fillna(fill_value)\n",
      "\n",
      "                new_data = self._dispatch_frame_op(other, op)\n",
      "\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m self._construct_result(new_data)\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m _construct_result(self, result) -> DataFrame:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Wrap the result of an arithmetic, comparison, or logical operation.\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        result : DataFrame\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        DataFrame\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        out = self._constructor(result, copy=\u001b[38;5;28;01mFalse\u001b[39;00m).__finalize__(self)\n",
      "        \u001b[38;5;66;03m# Pin columns instead of passing to constructor for compat with\u001b[39;00m\n",
      "        \u001b[38;5;66;03m#  non-unique columns case\u001b[39;00m\n",
      "        out.columns = self.columns\n",
      "        out.index = self.index\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m __divmod__(self, other) -> tuple[DataFrame, DataFrame]:\n",
      "        \u001b[38;5;66;03m# Naive implementation, room for optimization\u001b[39;00m\n",
      "        div = self // other\n",
      "        mod = self - div * other\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m div, mod\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m __rdivmod__(self, other) -> tuple[DataFrame, DataFrame]:\n",
      "        \u001b[38;5;66;03m# Naive implementation, room for optimization\u001b[39;00m\n",
      "        div = other // self\n",
      "        mod = other - div * self\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m div, mod\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m _flex_cmp_method(self, other, op, *, axis: Axis = \u001b[33m\"columns\"\u001b[39m, level=\u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "        axis = self._get_axis_number(axis) \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m1\u001b[39m\n",
      "\n",
      "        self, other = self._align_for_op(other, axis, flex=\u001b[38;5;28;01mTrue\u001b[39;00m, level=level)\n",
      "\n",
      "        new_data = self._dispatch_frame_op(other, op, axis=axis)\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m self._construct_result(new_data)\n",
      "\n",
      "    @Appender(ops.make_flex_doc(\u001b[33m\"eq\"\u001b[39m, \u001b[33m\"dataframe\"\u001b[39m))\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m eq(self, other, axis: Axis = \u001b[33m\"columns\"\u001b[39m, level=\u001b[38;5;28;01mNone\u001b[39;00m) -> DataFrame:\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m self._flex_cmp_method(other, operator.eq, axis=axis, level=level)\n",
      "\n",
      "    @Appender(ops.make_flex_doc(\u001b[33m\"ne\"\u001b[39m, \u001b[33m\"dataframe\"\u001b[39m))\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m ne(self, other, axis: Axis = \u001b[33m\"columns\"\u001b[39m, level=\u001b[38;5;28;01mNone\u001b[39;00m) -> DataFrame:\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m self._flex_cmp_method(other, operator.ne, axis=axis, level=level)\n",
      "\n",
      "    @Appender(ops.make_flex_doc(\u001b[33m\"le\"\u001b[39m, \u001b[33m\"dataframe\"\u001b[39m))\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m le(self, other, axis: Axis = \u001b[33m\"columns\"\u001b[39m, level=\u001b[38;5;28;01mNone\u001b[39;00m) -> DataFrame:\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m self._flex_cmp_method(other, operator.le, axis=axis, level=level)\n",
      "\n",
      "    @Appender(ops.make_flex_doc(\u001b[33m\"lt\"\u001b[39m, \u001b[33m\"dataframe\"\u001b[39m))\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m lt(self, other, axis: Axis = \u001b[33m\"columns\"\u001b[39m, level=\u001b[38;5;28;01mNone\u001b[39;00m) -> DataFrame:\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m self._flex_cmp_method(other, operator.lt, axis=axis, level=level)\n",
      "\n",
      "    @Appender(ops.make_flex_doc(\u001b[33m\"ge\"\u001b[39m, \u001b[33m\"dataframe\"\u001b[39m))\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m ge(self, other, axis: Axis = \u001b[33m\"columns\"\u001b[39m, level=\u001b[38;5;28;01mNone\u001b[39;00m) -> DataFrame:\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m self._flex_cmp_method(other, operator.ge, axis=axis, level=level)\n",
      "\n",
      "    @Appender(ops.make_flex_doc(\u001b[33m\"gt\"\u001b[39m, \u001b[33m\"dataframe\"\u001b[39m))\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m gt(self, other, axis: Axis = \u001b[33m\"columns\"\u001b[39m, level=\u001b[38;5;28;01mNone\u001b[39;00m) -> DataFrame:\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m self._flex_cmp_method(other, operator.gt, axis=axis, level=level)\n",
      "\n",
      "    @Appender(ops.make_flex_doc(\u001b[33m\"add\"\u001b[39m, \u001b[33m\"dataframe\"\u001b[39m))\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m add(\n",
      "        self, other, axis: Axis = \u001b[33m\"columns\"\u001b[39m, level=\u001b[38;5;28;01mNone\u001b[39;00m, fill_value=\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "    ) -> DataFrame:\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m self._flex_arith_method(\n",
      "            other, operator.add, level=level, fill_value=fill_value, axis=axis\n",
      "        )\n",
      "\n",
      "    @Appender(ops.make_flex_doc(\u001b[33m\"radd\"\u001b[39m, \u001b[33m\"dataframe\"\u001b[39m))\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m radd(\n",
      "        self, other, axis: Axis = \u001b[33m\"columns\"\u001b[39m, level=\u001b[38;5;28;01mNone\u001b[39;00m, fill_value=\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "    ) -> DataFrame:\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m self._flex_arith_method(\n",
      "            other, roperator.radd, level=level, fill_value=fill_value, axis=axis\n",
      "        )\n",
      "\n",
      "    @Appender(ops.make_flex_doc(\u001b[33m\"sub\"\u001b[39m, \u001b[33m\"dataframe\"\u001b[39m))\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m sub(\n",
      "        self, other, axis: Axis = \u001b[33m\"columns\"\u001b[39m, level=\u001b[38;5;28;01mNone\u001b[39;00m, fill_value=\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "    ) -> DataFrame:\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m self._flex_arith_method(\n",
      "            other, operator.sub, level=level, fill_value=fill_value, axis=axis\n",
      "        )\n",
      "\n",
      "    subtract = sub\n",
      "\n",
      "    @Appender(ops.make_flex_doc(\u001b[33m\"rsub\"\u001b[39m, \u001b[33m\"dataframe\"\u001b[39m))\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m rsub(\n",
      "        self, other, axis: Axis = \u001b[33m\"columns\"\u001b[39m, level=\u001b[38;5;28;01mNone\u001b[39;00m, fill_value=\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "    ) -> DataFrame:\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m self._flex_arith_method(\n",
      "            other, roperator.rsub, level=level, fill_value=fill_value, axis=axis\n",
      "        )\n",
      "\n",
      "    @Appender(ops.make_flex_doc(\u001b[33m\"mul\"\u001b[39m, \u001b[33m\"dataframe\"\u001b[39m))\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m mul(\n",
      "        self, other, axis: Axis = \u001b[33m\"columns\"\u001b[39m, level=\u001b[38;5;28;01mNone\u001b[39;00m, fill_value=\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "    ) -> DataFrame:\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m self._flex_arith_method(\n",
      "            other, operator.mul, level=level, fill_value=fill_value, axis=axis\n",
      "        )\n",
      "\n",
      "    multiply = mul\n",
      "\n",
      "    @Appender(ops.make_flex_doc(\u001b[33m\"rmul\"\u001b[39m, \u001b[33m\"dataframe\"\u001b[39m))\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m rmul(\n",
      "        self, other, axis: Axis = \u001b[33m\"columns\"\u001b[39m, level=\u001b[38;5;28;01mNone\u001b[39;00m, fill_value=\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "    ) -> DataFrame:\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m self._flex_arith_method(\n",
      "            other, roperator.rmul, level=level, fill_value=fill_value, axis=axis\n",
      "        )\n",
      "\n",
      "    @Appender(ops.make_flex_doc(\u001b[33m\"truediv\"\u001b[39m, \u001b[33m\"dataframe\"\u001b[39m))\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m truediv(\n",
      "        self, other, axis: Axis = \u001b[33m\"columns\"\u001b[39m, level=\u001b[38;5;28;01mNone\u001b[39;00m, fill_value=\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "    ) -> DataFrame:\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m self._flex_arith_method(\n",
      "            other, operator.truediv, level=level, fill_value=fill_value, axis=axis\n",
      "        )\n",
      "\n",
      "    div = truediv\n",
      "    divide = truediv\n",
      "\n",
      "    @Appender(ops.make_flex_doc(\u001b[33m\"rtruediv\"\u001b[39m, \u001b[33m\"dataframe\"\u001b[39m))\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m rtruediv(\n",
      "        self, other, axis: Axis = \u001b[33m\"columns\"\u001b[39m, level=\u001b[38;5;28;01mNone\u001b[39;00m, fill_value=\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "    ) -> DataFrame:\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m self._flex_arith_method(\n",
      "            other, roperator.rtruediv, level=level, fill_value=fill_value, axis=axis\n",
      "        )\n",
      "\n",
      "    rdiv = rtruediv\n",
      "\n",
      "    @Appender(ops.make_flex_doc(\u001b[33m\"floordiv\"\u001b[39m, \u001b[33m\"dataframe\"\u001b[39m))\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m floordiv(\n",
      "        self, other, axis: Axis = \u001b[33m\"columns\"\u001b[39m, level=\u001b[38;5;28;01mNone\u001b[39;00m, fill_value=\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "    ) -> DataFrame:\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m self._flex_arith_method(\n",
      "            other, operator.floordiv, level=level, fill_value=fill_value, axis=axis\n",
      "        )\n",
      "\n",
      "    @Appender(ops.make_flex_doc(\u001b[33m\"rfloordiv\"\u001b[39m, \u001b[33m\"dataframe\"\u001b[39m))\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m rfloordiv(\n",
      "        self, other, axis: Axis = \u001b[33m\"columns\"\u001b[39m, level=\u001b[38;5;28;01mNone\u001b[39;00m, fill_value=\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "    ) -> DataFrame:\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m self._flex_arith_method(\n",
      "            other, roperator.rfloordiv, level=level, fill_value=fill_value, axis=axis\n",
      "        )\n",
      "\n",
      "    @Appender(ops.make_flex_doc(\u001b[33m\"mod\"\u001b[39m, \u001b[33m\"dataframe\"\u001b[39m))\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m mod(\n",
      "        self, other, axis: Axis = \u001b[33m\"columns\"\u001b[39m, level=\u001b[38;5;28;01mNone\u001b[39;00m, fill_value=\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "    ) -> DataFrame:\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m self._flex_arith_method(\n",
      "            other, operator.mod, level=level, fill_value=fill_value, axis=axis\n",
      "        )\n",
      "\n",
      "    @Appender(ops.make_flex_doc(\u001b[33m\"rmod\"\u001b[39m, \u001b[33m\"dataframe\"\u001b[39m))\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m rmod(\n",
      "        self, other, axis: Axis = \u001b[33m\"columns\"\u001b[39m, level=\u001b[38;5;28;01mNone\u001b[39;00m, fill_value=\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "    ) -> DataFrame:\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m self._flex_arith_method(\n",
      "            other, roperator.rmod, level=level, fill_value=fill_value, axis=axis\n",
      "        )\n",
      "\n",
      "    @Appender(ops.make_flex_doc(\u001b[33m\"pow\"\u001b[39m, \u001b[33m\"dataframe\"\u001b[39m))\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m pow(\n",
      "        self, other, axis: Axis = \u001b[33m\"columns\"\u001b[39m, level=\u001b[38;5;28;01mNone\u001b[39;00m, fill_value=\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "    ) -> DataFrame:\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m self._flex_arith_method(\n",
      "            other, operator.pow, level=level, fill_value=fill_value, axis=axis\n",
      "        )\n",
      "\n",
      "    @Appender(ops.make_flex_doc(\u001b[33m\"rpow\"\u001b[39m, \u001b[33m\"dataframe\"\u001b[39m))\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m rpow(\n",
      "        self, other, axis: Axis = \u001b[33m\"columns\"\u001b[39m, level=\u001b[38;5;28;01mNone\u001b[39;00m, fill_value=\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "    ) -> DataFrame:\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m self._flex_arith_method(\n",
      "            other, roperator.rpow, level=level, fill_value=fill_value, axis=axis\n",
      "        )\n",
      "\n",
      "    \u001b[38;5;66;03m# ----------------------------------------------------------------------\u001b[39;00m\n",
      "    \u001b[38;5;66;03m# Combination-Related\u001b[39;00m\n",
      "\n",
      "    @doc(\n",
      "        _shared_docs[\u001b[33m\"compare\"\u001b[39m],\n",
      "        dedent(\n",
      "            \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        DataFrame\u001b[39m\n",
      "\u001b[33m            DataFrame that shows the differences stacked side by side.\u001b[39m\n",
      "\n",
      "\u001b[33m            The resulting index will be a MultiIndex with 'self' and 'other'\u001b[39m\n",
      "\u001b[33m            stacked alternately at the inner level.\u001b[39m\n",
      "\n",
      "\u001b[33m        Raises\u001b[39m\n",
      "\u001b[33m        ------\u001b[39m\n",
      "\u001b[33m        ValueError\u001b[39m\n",
      "\u001b[33m            When the two DataFrames don't have identical labels or shape.\u001b[39m\n",
      "\n",
      "\u001b[33m        See Also\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        Series.compare : Compare with another Series and show differences.\u001b[39m\n",
      "\u001b[33m        DataFrame.equals : Test whether two objects contain the same elements.\u001b[39m\n",
      "\n",
      "\u001b[33m        Notes\u001b[39m\n",
      "\u001b[33m        -----\u001b[39m\n",
      "\u001b[33m        Matching NaNs will not appear as a difference.\u001b[39m\n",
      "\n",
      "\u001b[33m        Can only compare identically-labeled\u001b[39m\n",
      "\u001b[33m        (i.e. same shape, identical row and column labels) DataFrames\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        >>> df = pd.DataFrame(\u001b[39m\n",
      "\u001b[33m        ...     {{\u001b[39m\n",
      "\u001b[33m        ...         \"col1\": [\"a\", \"a\", \"b\", \"b\", \"a\"],\u001b[39m\n",
      "\u001b[33m        ...         \"col2\": [1.0, 2.0, 3.0, np.nan, 5.0],\u001b[39m\n",
      "\u001b[33m        ...         \"col3\": [1.0, 2.0, 3.0, 4.0, 5.0]\u001b[39m\n",
      "\u001b[33m        ...     }},\u001b[39m\n",
      "\u001b[33m        ...     columns=[\"col1\", \"col2\", \"col3\"],\u001b[39m\n",
      "\u001b[33m        ... )\u001b[39m\n",
      "\u001b[33m        >>> df\u001b[39m\n",
      "\u001b[33m          col1  col2  col3\u001b[39m\n",
      "\u001b[33m        0    a   1.0   1.0\u001b[39m\n",
      "\u001b[33m        1    a   2.0   2.0\u001b[39m\n",
      "\u001b[33m        2    b   3.0   3.0\u001b[39m\n",
      "\u001b[33m        3    b   NaN   4.0\u001b[39m\n",
      "\u001b[33m        4    a   5.0   5.0\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df2 = df.copy()\u001b[39m\n",
      "\u001b[33m        >>> df2.loc[0, 'col1'] = 'c'\u001b[39m\n",
      "\u001b[33m        >>> df2.loc[2, 'col3'] = 4.0\u001b[39m\n",
      "\u001b[33m        >>> df2\u001b[39m\n",
      "\u001b[33m          col1  col2  col3\u001b[39m\n",
      "\u001b[33m        0    c   1.0   1.0\u001b[39m\n",
      "\u001b[33m        1    a   2.0   2.0\u001b[39m\n",
      "\u001b[33m        2    b   3.0   4.0\u001b[39m\n",
      "\u001b[33m        3    b   NaN   4.0\u001b[39m\n",
      "\u001b[33m        4    a   5.0   5.0\u001b[39m\n",
      "\n",
      "\u001b[33m        Align the differences on columns\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.compare(df2)\u001b[39m\n",
      "\u001b[33m          col1       col3\u001b[39m\n",
      "\u001b[33m          self other self other\u001b[39m\n",
      "\u001b[33m        0    a     c  NaN   NaN\u001b[39m\n",
      "\u001b[33m        2  NaN   NaN  3.0   4.0\u001b[39m\n",
      "\n",
      "\u001b[33m        Assign result_names\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.compare(df2, result_names=(\"left\", \"right\"))\u001b[39m\n",
      "\u001b[33m          col1       col3\u001b[39m\n",
      "\u001b[33m          left right left right\u001b[39m\n",
      "\u001b[33m        0    a     c  NaN   NaN\u001b[39m\n",
      "\u001b[33m        2  NaN   NaN  3.0   4.0\u001b[39m\n",
      "\n",
      "\u001b[33m        Stack the differences on rows\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.compare(df2, align_axis=0)\u001b[39m\n",
      "\u001b[33m                col1  col3\u001b[39m\n",
      "\u001b[33m        0 self     a   NaN\u001b[39m\n",
      "\u001b[33m          other    c   NaN\u001b[39m\n",
      "\u001b[33m        2 self   NaN   3.0\u001b[39m\n",
      "\u001b[33m          other  NaN   4.0\u001b[39m\n",
      "\n",
      "\u001b[33m        Keep the equal values\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.compare(df2, keep_equal=True)\u001b[39m\n",
      "\u001b[33m          col1       col3\u001b[39m\n",
      "\u001b[33m          self other self other\u001b[39m\n",
      "\u001b[33m        0    a     c  1.0   1.0\u001b[39m\n",
      "\u001b[33m        2    b     b  3.0   4.0\u001b[39m\n",
      "\n",
      "\u001b[33m        Keep all original rows and columns\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.compare(df2, keep_shape=True)\u001b[39m\n",
      "\u001b[33m          col1       col2       col3\u001b[39m\n",
      "\u001b[33m          self other self other self other\u001b[39m\n",
      "\u001b[33m        0    a     c  NaN   NaN  NaN   NaN\u001b[39m\n",
      "\u001b[33m        1  NaN   NaN  NaN   NaN  NaN   NaN\u001b[39m\n",
      "\u001b[33m        2  NaN   NaN  NaN   NaN  3.0   4.0\u001b[39m\n",
      "\u001b[33m        3  NaN   NaN  NaN   NaN  NaN   NaN\u001b[39m\n",
      "\u001b[33m        4  NaN   NaN  NaN   NaN  NaN   NaN\u001b[39m\n",
      "\n",
      "\u001b[33m        Keep all original rows and columns and also all original values\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.compare(df2, keep_shape=True, keep_equal=True)\u001b[39m\n",
      "\u001b[33m          col1       col2       col3\u001b[39m\n",
      "\u001b[33m          self other self other self other\u001b[39m\n",
      "\u001b[33m        0    a     c  1.0   1.0  1.0   1.0\u001b[39m\n",
      "\u001b[33m        1    a     a  2.0   2.0  2.0   2.0\u001b[39m\n",
      "\u001b[33m        2    b     b  3.0   3.0  3.0   4.0\u001b[39m\n",
      "\u001b[33m        3    b     b  NaN   NaN  4.0   4.0\u001b[39m\n",
      "\u001b[33m        4    a     a  5.0   5.0  5.0   5.0\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        ),\n",
      "        klass=_shared_doc_kwargs[\u001b[33m\"klass\"\u001b[39m],\n",
      "    )\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m compare(\n",
      "        self,\n",
      "        other: DataFrame,\n",
      "        align_axis: Axis = \u001b[32m1\u001b[39m,\n",
      "        keep_shape: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "        keep_equal: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "        result_names: Suffixes = (\u001b[33m\"self\"\u001b[39m, \u001b[33m\"other\"\u001b[39m),\n",
      "    ) -> DataFrame:\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m super().compare(\n",
      "            other=other,\n",
      "            align_axis=align_axis,\n",
      "            keep_shape=keep_shape,\n",
      "            keep_equal=keep_equal,\n",
      "            result_names=result_names,\n",
      "        )\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m combine(\n",
      "        self,\n",
      "        other: DataFrame,\n",
      "        func: Callable[[Series, Series], Series | Hashable],\n",
      "        fill_value=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        overwrite: bool = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "    ) -> DataFrame:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Perform column-wise combine with another DataFrame.\u001b[39m\n",
      "\n",
      "\u001b[33m        Combines a DataFrame with `other` DataFrame using `func`\u001b[39m\n",
      "\u001b[33m        to element-wise combine columns. The row and column indexes of the\u001b[39m\n",
      "\u001b[33m        resulting DataFrame will be the union of the two.\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        other : DataFrame\u001b[39m\n",
      "\u001b[33m            The DataFrame to merge column-wise.\u001b[39m\n",
      "\u001b[33m        func : function\u001b[39m\n",
      "\u001b[33m            Function that takes two series as inputs and return a Series or a\u001b[39m\n",
      "\u001b[33m            scalar. Used to merge the two dataframes column by columns.\u001b[39m\n",
      "\u001b[33m        fill_value : scalar value, default None\u001b[39m\n",
      "\u001b[33m            The value to fill NaNs with prior to passing any column to the\u001b[39m\n",
      "\u001b[33m            merge func.\u001b[39m\n",
      "\u001b[33m        overwrite : bool, default True\u001b[39m\n",
      "\u001b[33m            If True, columns in `self` that do not exist in `other` will be\u001b[39m\n",
      "\u001b[33m            overwritten with NaNs.\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        DataFrame\u001b[39m\n",
      "\u001b[33m            Combination of the provided DataFrames.\u001b[39m\n",
      "\n",
      "\u001b[33m        See Also\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        DataFrame.combine_first : Combine two DataFrame objects and default to\u001b[39m\n",
      "\u001b[33m            non-null values in frame calling the method.\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        Combine using a simple function that chooses the smaller column.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df1 = pd.DataFrame({'A': [0, 0], 'B': [4, 4]})\u001b[39m\n",
      "\u001b[33m        >>> df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]})\u001b[39m\n",
      "\u001b[33m        >>> take_smaller = lambda s1, s2: s1 if s1.sum() < s2.sum() else s2\u001b[39m\n",
      "\u001b[33m        >>> df1.combine(df2, take_smaller)\u001b[39m\n",
      "\u001b[33m           A  B\u001b[39m\n",
      "\u001b[33m        0  0  3\u001b[39m\n",
      "\u001b[33m        1  0  3\u001b[39m\n",
      "\n",
      "\u001b[33m        Example using a true element-wise combine function.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df1 = pd.DataFrame({'A': [5, 0], 'B': [2, 4]})\u001b[39m\n",
      "\u001b[33m        >>> df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]})\u001b[39m\n",
      "\u001b[33m        >>> df1.combine(df2, np.minimum)\u001b[39m\n",
      "\u001b[33m           A  B\u001b[39m\n",
      "\u001b[33m        0  1  2\u001b[39m\n",
      "\u001b[33m        1  0  3\u001b[39m\n",
      "\n",
      "\u001b[33m        Using `fill_value` fills Nones prior to passing the column to the\u001b[39m\n",
      "\u001b[33m        merge function.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df1 = pd.DataFrame({'A': [0, 0], 'B': [None, 4]})\u001b[39m\n",
      "\u001b[33m        >>> df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]})\u001b[39m\n",
      "\u001b[33m        >>> df1.combine(df2, take_smaller, fill_value=-5)\u001b[39m\n",
      "\u001b[33m           A    B\u001b[39m\n",
      "\u001b[33m        0  0 -5.0\u001b[39m\n",
      "\u001b[33m        1  0  4.0\u001b[39m\n",
      "\n",
      "\u001b[33m        However, if the same element in both dataframes is None, that None\u001b[39m\n",
      "\u001b[33m        is preserved\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df1 = pd.DataFrame({'A': [0, 0], 'B': [None, 4]})\u001b[39m\n",
      "\u001b[33m        >>> df2 = pd.DataFrame({'A': [1, 1], 'B': [None, 3]})\u001b[39m\n",
      "\u001b[33m        >>> df1.combine(df2, take_smaller, fill_value=-5)\u001b[39m\n",
      "\u001b[33m            A    B\u001b[39m\n",
      "\u001b[33m        0  0 -5.0\u001b[39m\n",
      "\u001b[33m        1  0  3.0\u001b[39m\n",
      "\n",
      "\u001b[33m        Example that demonstrates the use of `overwrite` and behavior when\u001b[39m\n",
      "\u001b[33m        the axis differ between the dataframes.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df1 = pd.DataFrame({'A': [0, 0], 'B': [4, 4]})\u001b[39m\n",
      "\u001b[33m        >>> df2 = pd.DataFrame({'B': [3, 3], 'C': [-10, 1], }, index=[1, 2])\u001b[39m\n",
      "\u001b[33m        >>> df1.combine(df2, take_smaller)\u001b[39m\n",
      "\u001b[33m             A    B     C\u001b[39m\n",
      "\u001b[33m        0  NaN  NaN   NaN\u001b[39m\n",
      "\u001b[33m        1  NaN  3.0 -10.0\u001b[39m\n",
      "\u001b[33m        2  NaN  3.0   1.0\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df1.combine(df2, take_smaller, overwrite=False)\u001b[39m\n",
      "\u001b[33m             A    B     C\u001b[39m\n",
      "\u001b[33m        0  0.0  NaN   NaN\u001b[39m\n",
      "\u001b[33m        1  0.0  3.0 -10.0\u001b[39m\n",
      "\u001b[33m        2  NaN  3.0   1.0\u001b[39m\n",
      "\n",
      "\u001b[33m        Demonstrating the preference of the passed in dataframe.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df2 = pd.DataFrame({'B': [3, 3], 'C': [1, 1], }, index=[1, 2])\u001b[39m\n",
      "\u001b[33m        >>> df2.combine(df1, take_smaller)\u001b[39m\n",
      "\u001b[33m           A    B   C\u001b[39m\n",
      "\u001b[33m        0  0.0  NaN NaN\u001b[39m\n",
      "\u001b[33m        1  0.0  3.0 NaN\u001b[39m\n",
      "\u001b[33m        2  NaN  3.0 NaN\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df2.combine(df1, take_smaller, overwrite=False)\u001b[39m\n",
      "\u001b[33m             A    B   C\u001b[39m\n",
      "\u001b[33m        0  0.0  NaN NaN\u001b[39m\n",
      "\u001b[33m        1  0.0  3.0 1.0\u001b[39m\n",
      "\u001b[33m        2  NaN  3.0 1.0\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        other_idxlen = len(other.index)  \u001b[38;5;66;03m# save for compare\u001b[39;00m\n",
      "\n",
      "        this, other = self.align(other, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "        new_index = this.index\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m other.empty \u001b[38;5;28;01mand\u001b[39;00m len(new_index) == len(self.index):\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m self.copy()\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m self.empty \u001b[38;5;28;01mand\u001b[39;00m len(other) == other_idxlen:\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m other.copy()\n",
      "\n",
      "        \u001b[38;5;66;03m# sorts if possible; otherwise align above ensures that these are set-equal\u001b[39;00m\n",
      "        new_columns = this.columns.union(other.columns)\n",
      "        do_fill = fill_value \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "        result = {}\n",
      "        \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;28;01min\u001b[39;00m new_columns:\n",
      "            series = this[col]\n",
      "            other_series = other[col]\n",
      "\n",
      "            this_dtype = series.dtype\n",
      "            other_dtype = other_series.dtype\n",
      "\n",
      "            this_mask = isna(series)\n",
      "            other_mask = isna(other_series)\n",
      "\n",
      "            \u001b[38;5;66;03m# don't overwrite columns unnecessarily\u001b[39;00m\n",
      "            \u001b[38;5;66;03m# DO propagate if this column is not in the intersection\u001b[39;00m\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m overwrite \u001b[38;5;28;01mand\u001b[39;00m other_mask.all():\n",
      "                result[col] = this[col].copy()\n",
      "                \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m do_fill:\n",
      "                series = series.copy()\n",
      "                other_series = other_series.copy()\n",
      "                series[this_mask] = fill_value\n",
      "                other_series[other_mask] = fill_value\n",
      "\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01min\u001b[39;00m self.columns:\n",
      "                \u001b[38;5;66;03m# If self DataFrame does not have col in other DataFrame,\u001b[39;00m\n",
      "                \u001b[38;5;66;03m# try to promote series, which is all NaN, as other_dtype.\u001b[39;00m\n",
      "                new_dtype = other_dtype\n",
      "                \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "                    series = series.astype(new_dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "                \u001b[38;5;28;01mexcept\u001b[39;00m ValueError:\n",
      "                    \u001b[38;5;66;03m# e.g. new_dtype is integer types\u001b[39;00m\n",
      "                    \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "            \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "                \u001b[38;5;66;03m# if we have different dtypes, possibly promote\u001b[39;00m\n",
      "                new_dtype = find_common_type([this_dtype, other_dtype])\n",
      "                series = series.astype(new_dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "                other_series = other_series.astype(new_dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\n",
      "            arr = func(series, other_series)\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m isinstance(new_dtype, np.dtype):\n",
      "                \u001b[38;5;66;03m# if new_dtype is an EA Dtype, then `func` is expected to return\u001b[39;00m\n",
      "                \u001b[38;5;66;03m# the correct dtype without any additional casting\u001b[39;00m\n",
      "                \u001b[38;5;66;03m# error: No overload variant of \"maybe_downcast_to_dtype\" matches\u001b[39;00m\n",
      "                \u001b[38;5;66;03m# argument types \"Union[Series, Hashable]\", \"dtype[Any]\"\u001b[39;00m\n",
      "                arr = maybe_downcast_to_dtype(  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n",
      "                    arr, new_dtype\n",
      "                )\n",
      "\n",
      "            result[col] = arr\n",
      "\n",
      "        \u001b[38;5;66;03m# convert_objects just in case\u001b[39;00m\n",
      "        frame_result = self._constructor(result, index=new_index, columns=new_columns)\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m frame_result.__finalize__(self, method=\u001b[33m\"combine\"\u001b[39m)\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m combine_first(self, other: DataFrame) -> DataFrame:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Update null elements with value in the same location in `other`.\u001b[39m\n",
      "\n",
      "\u001b[33m        Combine two DataFrame objects by filling null values in one DataFrame\u001b[39m\n",
      "\u001b[33m        with non-null values from other DataFrame. The row and column indexes\u001b[39m\n",
      "\u001b[33m        of the resulting DataFrame will be the union of the two. The resulting\u001b[39m\n",
      "\u001b[33m        dataframe contains the 'first' dataframe values and overrides the\u001b[39m\n",
      "\u001b[33m        second one values where both first.loc[index, col] and\u001b[39m\n",
      "\u001b[33m        second.loc[index, col] are not missing values, upon calling\u001b[39m\n",
      "\u001b[33m        first.combine_first(second).\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        other : DataFrame\u001b[39m\n",
      "\u001b[33m            Provided DataFrame to use to fill null values.\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        DataFrame\u001b[39m\n",
      "\u001b[33m            The result of combining the provided DataFrame with the other object.\u001b[39m\n",
      "\n",
      "\u001b[33m        See Also\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        DataFrame.combine : Perform series-wise operation on two DataFrames\u001b[39m\n",
      "\u001b[33m            using a given function.\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        >>> df1 = pd.DataFrame({'A': [None, 0], 'B': [None, 4]})\u001b[39m\n",
      "\u001b[33m        >>> df2 = pd.DataFrame({'A': [1, 1], 'B': [3, 3]})\u001b[39m\n",
      "\u001b[33m        >>> df1.combine_first(df2)\u001b[39m\n",
      "\u001b[33m             A    B\u001b[39m\n",
      "\u001b[33m        0  1.0  3.0\u001b[39m\n",
      "\u001b[33m        1  0.0  4.0\u001b[39m\n",
      "\n",
      "\u001b[33m        Null values still persist if the location of that null value\u001b[39m\n",
      "\u001b[33m        does not exist in `other`\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df1 = pd.DataFrame({'A': [None, 0], 'B': [4, None]})\u001b[39m\n",
      "\u001b[33m        >>> df2 = pd.DataFrame({'B': [3, 3], 'C': [1, 1]}, index=[1, 2])\u001b[39m\n",
      "\u001b[33m        >>> df1.combine_first(df2)\u001b[39m\n",
      "\u001b[33m             A    B    C\u001b[39m\n",
      "\u001b[33m        0  NaN  4.0  NaN\u001b[39m\n",
      "\u001b[33m        1  0.0  3.0  1.0\u001b[39m\n",
      "\u001b[33m        2  NaN  3.0  1.0\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;28;01mfrom\u001b[39;00m pandas.core.computation \u001b[38;5;28;01mimport\u001b[39;00m expressions\n",
      "\n",
      "        \u001b[38;5;28;01mdef\u001b[39;00m combiner(x: Series, y: Series):\n",
      "            mask = x.isna()._values\n",
      "\n",
      "            x_values = x._values\n",
      "            y_values = y._values\n",
      "\n",
      "            \u001b[38;5;66;03m# If the column y in other DataFrame is not in first DataFrame,\u001b[39;00m\n",
      "            \u001b[38;5;66;03m# just return y_values.\u001b[39;00m\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m y.name \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01min\u001b[39;00m self.columns:\n",
      "                \u001b[38;5;28;01mreturn\u001b[39;00m y_values\n",
      "\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m expressions.where(mask, y_values, x_values)\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m len(other) == \u001b[32m0\u001b[39m:\n",
      "            combined = self.reindex(\n",
      "                self.columns.append(other.columns.difference(self.columns)), axis=\u001b[32m1\u001b[39m\n",
      "            )\n",
      "            combined = combined.astype(other.dtypes)\n",
      "        \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "            combined = self.combine(other, combiner, overwrite=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\n",
      "        dtypes = {\n",
      "            col: find_common_type([self.dtypes[col], other.dtypes[col]])\n",
      "            \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;28;01min\u001b[39;00m self.columns.intersection(other.columns)\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m combined.dtypes[col] != self.dtypes[col]\n",
      "        }\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m dtypes:\n",
      "            combined = combined.astype(dtypes)\n",
      "\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m combined.__finalize__(self, method=\u001b[33m\"combine_first\"\u001b[39m)\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m update(\n",
      "        self,\n",
      "        other,\n",
      "        join: UpdateJoin = \u001b[33m\"left\"\u001b[39m,\n",
      "        overwrite: bool = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "        filter_func=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        errors: IgnoreRaise = \u001b[33m\"ignore\"\u001b[39m,\n",
      "    ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Modify in place using non-NA values from another DataFrame.\u001b[39m\n",
      "\n",
      "\u001b[33m        Aligns on indices. There is no return value.\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        other : DataFrame, or object coercible into a DataFrame\u001b[39m\n",
      "\u001b[33m            Should have at least one matching index/column label\u001b[39m\n",
      "\u001b[33m            with the original DataFrame. If a Series is passed,\u001b[39m\n",
      "\u001b[33m            its name attribute must be set, and that will be\u001b[39m\n",
      "\u001b[33m            used as the column name to align with the original DataFrame.\u001b[39m\n",
      "\u001b[33m        join : {'left'}, default 'left'\u001b[39m\n",
      "\u001b[33m            Only left join is implemented, keeping the index and columns of the\u001b[39m\n",
      "\u001b[33m            original object.\u001b[39m\n",
      "\u001b[33m        overwrite : bool, default True\u001b[39m\n",
      "\u001b[33m            How to handle non-NA values for overlapping keys:\u001b[39m\n",
      "\n",
      "\u001b[33m            * True: overwrite original DataFrame's values\u001b[39m\n",
      "\u001b[33m              with values from `other`.\u001b[39m\n",
      "\u001b[33m            * False: only update values that are NA in\u001b[39m\n",
      "\u001b[33m              the original DataFrame.\u001b[39m\n",
      "\n",
      "\u001b[33m        filter_func : callable(1d-array) -> bool 1d-array, optional\u001b[39m\n",
      "\u001b[33m            Can choose to replace values other than NA. Return True for values\u001b[39m\n",
      "\u001b[33m            that should be updated.\u001b[39m\n",
      "\u001b[33m        errors : {'raise', 'ignore'}, default 'ignore'\u001b[39m\n",
      "\u001b[33m            If 'raise', will raise a ValueError if the DataFrame and `other`\u001b[39m\n",
      "\u001b[33m            both contain non-NA data in the same place.\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        None\u001b[39m\n",
      "\u001b[33m            This method directly changes calling object.\u001b[39m\n",
      "\n",
      "\u001b[33m        Raises\u001b[39m\n",
      "\u001b[33m        ------\u001b[39m\n",
      "\u001b[33m        ValueError\u001b[39m\n",
      "\u001b[33m            * When `errors='raise'` and there's overlapping non-NA data.\u001b[39m\n",
      "\u001b[33m            * When `errors` is not either `'ignore'` or `'raise'`\u001b[39m\n",
      "\u001b[33m        NotImplementedError\u001b[39m\n",
      "\u001b[33m            * If `join != 'left'`\u001b[39m\n",
      "\n",
      "\u001b[33m        See Also\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        dict.update : Similar method for dictionaries.\u001b[39m\n",
      "\u001b[33m        DataFrame.merge : For column(s)-on-column(s) operations.\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        >>> df = pd.DataFrame({'A': [1, 2, 3],\u001b[39m\n",
      "\u001b[33m        ...                    'B': [400, 500, 600]})\u001b[39m\n",
      "\u001b[33m        >>> new_df = pd.DataFrame({'B': [4, 5, 6],\u001b[39m\n",
      "\u001b[33m        ...                        'C': [7, 8, 9]})\u001b[39m\n",
      "\u001b[33m        >>> df.update(new_df)\u001b[39m\n",
      "\u001b[33m        >>> df\u001b[39m\n",
      "\u001b[33m           A  B\u001b[39m\n",
      "\u001b[33m        0  1  4\u001b[39m\n",
      "\u001b[33m        1  2  5\u001b[39m\n",
      "\u001b[33m        2  3  6\u001b[39m\n",
      "\n",
      "\u001b[33m        The DataFrame's length does not increase as a result of the update,\u001b[39m\n",
      "\u001b[33m        only values at matching index/column labels are updated.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df = pd.DataFrame({'A': ['a', 'b', 'c'],\u001b[39m\n",
      "\u001b[33m        ...                    'B': ['x', 'y', 'z']})\u001b[39m\n",
      "\u001b[33m        >>> new_df = pd.DataFrame({'B': ['d', 'e', 'f', 'g', 'h', 'i']})\u001b[39m\n",
      "\u001b[33m        >>> df.update(new_df)\u001b[39m\n",
      "\u001b[33m        >>> df\u001b[39m\n",
      "\u001b[33m           A  B\u001b[39m\n",
      "\u001b[33m        0  a  d\u001b[39m\n",
      "\u001b[33m        1  b  e\u001b[39m\n",
      "\u001b[33m        2  c  f\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df = pd.DataFrame({'A': ['a', 'b', 'c'],\u001b[39m\n",
      "\u001b[33m        ...                    'B': ['x', 'y', 'z']})\u001b[39m\n",
      "\u001b[33m        >>> new_df = pd.DataFrame({'B': ['d', 'f']}, index=[0, 2])\u001b[39m\n",
      "\u001b[33m        >>> df.update(new_df)\u001b[39m\n",
      "\u001b[33m        >>> df\u001b[39m\n",
      "\u001b[33m           A  B\u001b[39m\n",
      "\u001b[33m        0  a  d\u001b[39m\n",
      "\u001b[33m        1  b  y\u001b[39m\n",
      "\u001b[33m        2  c  f\u001b[39m\n",
      "\n",
      "\u001b[33m        For Series, its name attribute must be set.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df = pd.DataFrame({'A': ['a', 'b', 'c'],\u001b[39m\n",
      "\u001b[33m        ...                    'B': ['x', 'y', 'z']})\u001b[39m\n",
      "\u001b[33m        >>> new_column = pd.Series(['d', 'e', 'f'], name='B')\u001b[39m\n",
      "\u001b[33m        >>> df.update(new_column)\u001b[39m\n",
      "\u001b[33m        >>> df\u001b[39m\n",
      "\u001b[33m           A  B\u001b[39m\n",
      "\u001b[33m        0  a  d\u001b[39m\n",
      "\u001b[33m        1  b  e\u001b[39m\n",
      "\u001b[33m        2  c  f\u001b[39m\n",
      "\n",
      "\u001b[33m        If `other` contains NaNs the corresponding values are not updated\u001b[39m\n",
      "\u001b[33m        in the original dataframe.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df = pd.DataFrame({'A': [1, 2, 3],\u001b[39m\n",
      "\u001b[33m        ...                    'B': [400., 500., 600.]})\u001b[39m\n",
      "\u001b[33m        >>> new_df = pd.DataFrame({'B': [4, np.nan, 6]})\u001b[39m\n",
      "\u001b[33m        >>> df.update(new_df)\u001b[39m\n",
      "\u001b[33m        >>> df\u001b[39m\n",
      "\u001b[33m           A      B\u001b[39m\n",
      "\u001b[33m        0  1    4.0\u001b[39m\n",
      "\u001b[33m        1  2  500.0\u001b[39m\n",
      "\u001b[33m        2  3    6.0\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m PYPY \u001b[38;5;28;01mand\u001b[39;00m using_copy_on_write():\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m sys.getrefcount(self) <= REF_COUNT:\n",
      "                warnings.warn(\n",
      "                    _chained_assignment_method_msg,\n",
      "                    ChainedAssignmentError,\n",
      "                    stacklevel=\u001b[32m2\u001b[39m,\n",
      "                )\n",
      "        \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m PYPY \u001b[38;5;28;01mand\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m using_copy_on_write() \u001b[38;5;28;01mand\u001b[39;00m self._is_view_after_cow_rules():\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m sys.getrefcount(self) <= REF_COUNT:\n",
      "                warnings.warn(\n",
      "                    _chained_assignment_warning_method_msg,\n",
      "                    FutureWarning,\n",
      "                    stacklevel=\u001b[32m2\u001b[39m,\n",
      "                )\n",
      "\n",
      "        \u001b[38;5;66;03m# TODO: Support other joins\u001b[39;00m\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m join != \u001b[33m\"left\"\u001b[39m:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n",
      "            \u001b[38;5;28;01mraise\u001b[39;00m NotImplementedError(\u001b[33m\"Only left join is supported\"\u001b[39m)\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01min\u001b[39;00m [\u001b[33m\"ignore\"\u001b[39m, \u001b[33m\"raise\"\u001b[39m]:\n",
      "            \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\u001b[33m\"The parameter errors must be either 'ignore' or 'raise'\"\u001b[39m)\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m isinstance(other, DataFrame):\n",
      "            other = DataFrame(other)\n",
      "\n",
      "        other = other.reindex(self.index)\n",
      "\n",
      "        \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;28;01min\u001b[39;00m self.columns.intersection(other.columns):\n",
      "            this = self[col]._values\n",
      "            that = other[col]._values\n",
      "\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m filter_func \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "                mask = ~filter_func(this) | isna(that)\n",
      "            \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "                \u001b[38;5;28;01mif\u001b[39;00m errors == \u001b[33m\"raise\"\u001b[39m:\n",
      "                    mask_this = notna(that)\n",
      "                    mask_that = notna(this)\n",
      "                    \u001b[38;5;28;01mif\u001b[39;00m any(mask_this & mask_that):\n",
      "                        \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\u001b[33m\"Data overlaps.\"\u001b[39m)\n",
      "\n",
      "                \u001b[38;5;28;01mif\u001b[39;00m overwrite:\n",
      "                    mask = isna(that)\n",
      "                \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "                    mask = notna(this)\n",
      "\n",
      "            \u001b[38;5;66;03m# don't overwrite columns unnecessarily\u001b[39;00m\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m mask.all():\n",
      "                \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\n",
      "            \u001b[38;5;28;01mwith\u001b[39;00m warnings.catch_warnings():\n",
      "                warnings.filterwarnings(\n",
      "                    \u001b[33m\"ignore\"\u001b[39m,\n",
      "                    message=\u001b[33m\"Downcasting behavior\"\u001b[39m,\n",
      "                    category=FutureWarning,\n",
      "                )\n",
      "                \u001b[38;5;66;03m# GH#57124 - `that` might get upcasted because of NA values, and then\u001b[39;00m\n",
      "                \u001b[38;5;66;03m# downcasted in where because of the mask. Ignoring the warning\u001b[39;00m\n",
      "                \u001b[38;5;66;03m# is a stopgap, will replace with a new implementation of update\u001b[39;00m\n",
      "                \u001b[38;5;66;03m# in 3.0.\u001b[39;00m\n",
      "                self.loc[:, col] = self[col].where(mask, that)\n",
      "\n",
      "    \u001b[38;5;66;03m# ----------------------------------------------------------------------\u001b[39;00m\n",
      "    \u001b[38;5;66;03m# Data reshaping\u001b[39;00m\n",
      "    @Appender(\n",
      "        dedent(\n",
      "            \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        >>> df = pd.DataFrame({'Animal': ['Falcon', 'Falcon',\u001b[39m\n",
      "\u001b[33m        ...                               'Parrot', 'Parrot'],\u001b[39m\n",
      "\u001b[33m        ...                    'Max Speed': [380., 370., 24., 26.]})\u001b[39m\n",
      "\u001b[33m        >>> df\u001b[39m\n",
      "\u001b[33m           Animal  Max Speed\u001b[39m\n",
      "\u001b[33m        0  Falcon      380.0\u001b[39m\n",
      "\u001b[33m        1  Falcon      370.0\u001b[39m\n",
      "\u001b[33m        2  Parrot       24.0\u001b[39m\n",
      "\u001b[33m        3  Parrot       26.0\u001b[39m\n",
      "\u001b[33m        >>> df.groupby(['Animal']).mean()\u001b[39m\n",
      "\u001b[33m                Max Speed\u001b[39m\n",
      "\u001b[33m        Animal\u001b[39m\n",
      "\u001b[33m        Falcon      375.0\u001b[39m\n",
      "\u001b[33m        Parrot       25.0\u001b[39m\n",
      "\n",
      "\u001b[33m        **Hierarchical Indexes**\u001b[39m\n",
      "\n",
      "\u001b[33m        We can groupby different levels of a hierarchical index\u001b[39m\n",
      "\u001b[33m        using the `level` parameter:\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> arrays = [['Falcon', 'Falcon', 'Parrot', 'Parrot'],\u001b[39m\n",
      "\u001b[33m        ...           ['Captive', 'Wild', 'Captive', 'Wild']]\u001b[39m\n",
      "\u001b[33m        >>> index = pd.MultiIndex.from_arrays(arrays, names=('Animal', 'Type'))\u001b[39m\n",
      "\u001b[33m        >>> df = pd.DataFrame({'Max Speed': [390., 350., 30., 20.]},\u001b[39m\n",
      "\u001b[33m        ...                   index=index)\u001b[39m\n",
      "\u001b[33m        >>> df\u001b[39m\n",
      "\u001b[33m                        Max Speed\u001b[39m\n",
      "\u001b[33m        Animal Type\u001b[39m\n",
      "\u001b[33m        Falcon Captive      390.0\u001b[39m\n",
      "\u001b[33m               Wild         350.0\u001b[39m\n",
      "\u001b[33m        Parrot Captive       30.0\u001b[39m\n",
      "\u001b[33m               Wild          20.0\u001b[39m\n",
      "\u001b[33m        >>> df.groupby(level=0).mean()\u001b[39m\n",
      "\u001b[33m                Max Speed\u001b[39m\n",
      "\u001b[33m        Animal\u001b[39m\n",
      "\u001b[33m        Falcon      370.0\u001b[39m\n",
      "\u001b[33m        Parrot       25.0\u001b[39m\n",
      "\u001b[33m        >>> df.groupby(level=\"Type\").mean()\u001b[39m\n",
      "\u001b[33m                 Max Speed\u001b[39m\n",
      "\u001b[33m        Type\u001b[39m\n",
      "\u001b[33m        Captive      210.0\u001b[39m\n",
      "\u001b[33m        Wild         185.0\u001b[39m\n",
      "\n",
      "\u001b[33m        We can also choose to include NA in group keys or not by setting\u001b[39m\n",
      "\u001b[33m        `dropna` parameter, the default setting is `True`.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> l = [[1, 2, 3], [1, None, 4], [2, 1, 3], [1, 2, 2]]\u001b[39m\n",
      "\u001b[33m        >>> df = pd.DataFrame(l, columns=[\"a\", \"b\", \"c\"])\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.groupby(by=[\"b\"]).sum()\u001b[39m\n",
      "\u001b[33m            a   c\u001b[39m\n",
      "\u001b[33m        b\u001b[39m\n",
      "\u001b[33m        1.0 2   3\u001b[39m\n",
      "\u001b[33m        2.0 2   5\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.groupby(by=[\"b\"], dropna=False).sum()\u001b[39m\n",
      "\u001b[33m            a   c\u001b[39m\n",
      "\u001b[33m        b\u001b[39m\n",
      "\u001b[33m        1.0 2   3\u001b[39m\n",
      "\u001b[33m        2.0 2   5\u001b[39m\n",
      "\u001b[33m        NaN 1   4\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> l = [[\"a\", 12, 12], [None, 12.3, 33.], [\"b\", 12.3, 123], [\"a\", 1, 1]]\u001b[39m\n",
      "\u001b[33m        >>> df = pd.DataFrame(l, columns=[\"a\", \"b\", \"c\"])\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.groupby(by=\"a\").sum()\u001b[39m\n",
      "\u001b[33m            b     c\u001b[39m\n",
      "\u001b[33m        a\u001b[39m\n",
      "\u001b[33m        a   13.0   13.0\u001b[39m\n",
      "\u001b[33m        b   12.3  123.0\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.groupby(by=\"a\", dropna=False).sum()\u001b[39m\n",
      "\u001b[33m            b     c\u001b[39m\n",
      "\u001b[33m        a\u001b[39m\n",
      "\u001b[33m        a   13.0   13.0\u001b[39m\n",
      "\u001b[33m        b   12.3  123.0\u001b[39m\n",
      "\u001b[33m        NaN 12.3   33.0\u001b[39m\n",
      "\n",
      "\u001b[33m        When using ``.apply()``, use ``group_keys`` to include or exclude the\u001b[39m\n",
      "\u001b[33m        group keys. The ``group_keys`` argument defaults to ``True`` (include).\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df = pd.DataFrame({'Animal': ['Falcon', 'Falcon',\u001b[39m\n",
      "\u001b[33m        ...                               'Parrot', 'Parrot'],\u001b[39m\n",
      "\u001b[33m        ...                    'Max Speed': [380., 370., 24., 26.]})\u001b[39m\n",
      "\u001b[33m        >>> df.groupby(\"Animal\", group_keys=True)[['Max Speed']].apply(lambda x: x)\u001b[39m\n",
      "\u001b[33m                  Max Speed\u001b[39m\n",
      "\u001b[33m        Animal\u001b[39m\n",
      "\u001b[33m        Falcon 0      380.0\u001b[39m\n",
      "\u001b[33m               1      370.0\u001b[39m\n",
      "\u001b[33m        Parrot 2       24.0\u001b[39m\n",
      "\u001b[33m               3       26.0\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.groupby(\"Animal\", group_keys=False)[['Max Speed']].apply(lambda x: x)\u001b[39m\n",
      "\u001b[33m           Max Speed\u001b[39m\n",
      "\u001b[33m        0      380.0\u001b[39m\n",
      "\u001b[33m        1      370.0\u001b[39m\n",
      "\u001b[33m        2       24.0\u001b[39m\n",
      "\u001b[33m        3       26.0\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        )\n",
      "    )\n",
      "    @Appender(_shared_docs[\u001b[33m\"groupby\"\u001b[39m] % _shared_doc_kwargs)\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m groupby(\n",
      "        self,\n",
      "        by=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        axis: Axis | lib.NoDefault = lib.no_default,\n",
      "        level: IndexLabel | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        as_index: bool = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "        sort: bool = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "        group_keys: bool = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "        observed: bool | lib.NoDefault = lib.no_default,\n",
      "        dropna: bool = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "    ) -> DataFrameGroupBy:\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m lib.no_default:\n",
      "            axis = self._get_axis_number(axis)\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m axis == \u001b[32m1\u001b[39m:\n",
      "                warnings.warn(\n",
      "                    \u001b[33m\"DataFrame.groupby with axis=1 is deprecated. Do \"\u001b[39m\n",
      "                    \u001b[33m\"`frame.T.groupby(...)` without axis instead.\"\u001b[39m,\n",
      "                    FutureWarning,\n",
      "                    stacklevel=find_stack_level(),\n",
      "                )\n",
      "            \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "                warnings.warn(\n",
      "                    \u001b[33m\"The 'axis' keyword in DataFrame.groupby is deprecated and \"\u001b[39m\n",
      "                    \u001b[33m\"will be removed in a future version.\"\u001b[39m,\n",
      "                    FutureWarning,\n",
      "                    stacklevel=find_stack_level(),\n",
      "                )\n",
      "        \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "            axis = \u001b[32m0\u001b[39m\n",
      "\n",
      "        \u001b[38;5;28;01mfrom\u001b[39;00m pandas.core.groupby.generic \u001b[38;5;28;01mimport\u001b[39;00m DataFrameGroupBy\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mand\u001b[39;00m by \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "            \u001b[38;5;28;01mraise\u001b[39;00m TypeError(\u001b[33m\"You have to supply one of 'by' and 'level'\"\u001b[39m)\n",
      "\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m DataFrameGroupBy(\n",
      "            obj=self,\n",
      "            keys=by,\n",
      "            axis=axis,\n",
      "            level=level,\n",
      "            as_index=as_index,\n",
      "            sort=sort,\n",
      "            group_keys=group_keys,\n",
      "            observed=observed,\n",
      "            dropna=dropna,\n",
      "        )\n",
      "\n",
      "    _shared_docs[\n",
      "        \u001b[33m\"pivot\"\u001b[39m\n",
      "    ] = \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Return reshaped DataFrame organized by given index / column values.\u001b[39m\n",
      "\n",
      "\u001b[33m        Reshape data (produce a \"pivot\" table) based on column values. Uses\u001b[39m\n",
      "\u001b[33m        unique values from specified `index` / `columns` to form axes of the\u001b[39m\n",
      "\u001b[33m        resulting DataFrame. This function does not support data\u001b[39m\n",
      "\u001b[33m        aggregation, multiple values will result in a MultiIndex in the\u001b[39m\n",
      "\u001b[33m        columns. See the :ref:`User Guide <reshaping>` for more on reshaping.\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------%s\u001b[39m\n",
      "\u001b[33m        columns : str or object or a list of str\u001b[39m\n",
      "\u001b[33m            Column to use to make new frame's columns.\u001b[39m\n",
      "\u001b[33m        index : str or object or a list of str, optional\u001b[39m\n",
      "\u001b[33m            Column to use to make new frame's index. If not given, uses existing index.\u001b[39m\n",
      "\u001b[33m        values : str, object or a list of the previous, optional\u001b[39m\n",
      "\u001b[33m            Column(s) to use for populating new frame's values. If not\u001b[39m\n",
      "\u001b[33m            specified, all remaining columns will be used and the result will\u001b[39m\n",
      "\u001b[33m            have hierarchically indexed columns.\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        DataFrame\u001b[39m\n",
      "\u001b[33m            Returns reshaped DataFrame.\u001b[39m\n",
      "\n",
      "\u001b[33m        Raises\u001b[39m\n",
      "\u001b[33m        ------\u001b[39m\n",
      "\u001b[33m        ValueError:\u001b[39m\n",
      "\u001b[33m            When there are any `index`, `columns` combinations with multiple\u001b[39m\n",
      "\u001b[33m            values. `DataFrame.pivot_table` when you need to aggregate.\u001b[39m\n",
      "\n",
      "\u001b[33m        See Also\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        DataFrame.pivot_table : Generalization of pivot that can handle\u001b[39m\n",
      "\u001b[33m            duplicate values for one index/column pair.\u001b[39m\n",
      "\u001b[33m        DataFrame.unstack : Pivot based on the index values instead of a\u001b[39m\n",
      "\u001b[33m            column.\u001b[39m\n",
      "\u001b[33m        wide_to_long : Wide panel to long format. Less flexible but more\u001b[39m\n",
      "\u001b[33m            user-friendly than melt.\u001b[39m\n",
      "\n",
      "\u001b[33m        Notes\u001b[39m\n",
      "\u001b[33m        -----\u001b[39m\n",
      "\u001b[33m        For finer-tuned control, see hierarchical indexing documentation along\u001b[39m\n",
      "\u001b[33m        with the related stack/unstack methods.\u001b[39m\n",
      "\n",
      "\u001b[33m        Reference :ref:`the user guide <reshaping.pivot>` for more examples.\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        >>> df = pd.DataFrame({'foo': ['one', 'one', 'one', 'two', 'two',\u001b[39m\n",
      "\u001b[33m        ...                            'two'],\u001b[39m\n",
      "\u001b[33m        ...                    'bar': ['A', 'B', 'C', 'A', 'B', 'C'],\u001b[39m\n",
      "\u001b[33m        ...                    'baz': [1, 2, 3, 4, 5, 6],\u001b[39m\n",
      "\u001b[33m        ...                    'zoo': ['x', 'y', 'z', 'q', 'w', 't']})\u001b[39m\n",
      "\u001b[33m        >>> df\u001b[39m\n",
      "\u001b[33m            foo   bar  baz  zoo\u001b[39m\n",
      "\u001b[33m        0   one   A    1    x\u001b[39m\n",
      "\u001b[33m        1   one   B    2    y\u001b[39m\n",
      "\u001b[33m        2   one   C    3    z\u001b[39m\n",
      "\u001b[33m        3   two   A    4    q\u001b[39m\n",
      "\u001b[33m        4   two   B    5    w\u001b[39m\n",
      "\u001b[33m        5   two   C    6    t\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.pivot(index='foo', columns='bar', values='baz')\u001b[39m\n",
      "\u001b[33m        bar  A   B   C\u001b[39m\n",
      "\u001b[33m        foo\u001b[39m\n",
      "\u001b[33m        one  1   2   3\u001b[39m\n",
      "\u001b[33m        two  4   5   6\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.pivot(index='foo', columns='bar')['baz']\u001b[39m\n",
      "\u001b[33m        bar  A   B   C\u001b[39m\n",
      "\u001b[33m        foo\u001b[39m\n",
      "\u001b[33m        one  1   2   3\u001b[39m\n",
      "\u001b[33m        two  4   5   6\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.pivot(index='foo', columns='bar', values=['baz', 'zoo'])\u001b[39m\n",
      "\u001b[33m              baz       zoo\u001b[39m\n",
      "\u001b[33m        bar   A  B  C   A  B  C\u001b[39m\n",
      "\u001b[33m        foo\u001b[39m\n",
      "\u001b[33m        one   1  2  3   x  y  z\u001b[39m\n",
      "\u001b[33m        two   4  5  6   q  w  t\u001b[39m\n",
      "\n",
      "\u001b[33m        You could also assign a list of column names or a list of index names.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df = pd.DataFrame({\u001b[39m\n",
      "\u001b[33m        ...        \"lev1\": [1, 1, 1, 2, 2, 2],\u001b[39m\n",
      "\u001b[33m        ...        \"lev2\": [1, 1, 2, 1, 1, 2],\u001b[39m\n",
      "\u001b[33m        ...        \"lev3\": [1, 2, 1, 2, 1, 2],\u001b[39m\n",
      "\u001b[33m        ...        \"lev4\": [1, 2, 3, 4, 5, 6],\u001b[39m\n",
      "\u001b[33m        ...        \"values\": [0, 1, 2, 3, 4, 5]})\u001b[39m\n",
      "\u001b[33m        >>> df\u001b[39m\n",
      "\u001b[33m            lev1 lev2 lev3 lev4 values\u001b[39m\n",
      "\u001b[33m        0   1    1    1    1    0\u001b[39m\n",
      "\u001b[33m        1   1    1    2    2    1\u001b[39m\n",
      "\u001b[33m        2   1    2    1    3    2\u001b[39m\n",
      "\u001b[33m        3   2    1    2    4    3\u001b[39m\n",
      "\u001b[33m        4   2    1    1    5    4\u001b[39m\n",
      "\u001b[33m        5   2    2    2    6    5\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.pivot(index=\"lev1\", columns=[\"lev2\", \"lev3\"], values=\"values\")\u001b[39m\n",
      "\u001b[33m        lev2    1         2\u001b[39m\n",
      "\u001b[33m        lev3    1    2    1    2\u001b[39m\n",
      "\u001b[33m        lev1\u001b[39m\n",
      "\u001b[33m        1     0.0  1.0  2.0  NaN\u001b[39m\n",
      "\u001b[33m        2     4.0  3.0  NaN  5.0\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.pivot(index=[\"lev1\", \"lev2\"], columns=[\"lev3\"], values=\"values\")\u001b[39m\n",
      "\u001b[33m              lev3    1    2\u001b[39m\n",
      "\u001b[33m        lev1  lev2\u001b[39m\n",
      "\u001b[33m           1     1  0.0  1.0\u001b[39m\n",
      "\u001b[33m                 2  2.0  NaN\u001b[39m\n",
      "\u001b[33m           2     1  4.0  3.0\u001b[39m\n",
      "\u001b[33m                 2  NaN  5.0\u001b[39m\n",
      "\n",
      "\u001b[33m        A ValueError is raised if there are any duplicates.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df = pd.DataFrame({\"foo\": ['one', 'one', 'two', 'two'],\u001b[39m\n",
      "\u001b[33m        ...                    \"bar\": ['A', 'A', 'B', 'C'],\u001b[39m\n",
      "\u001b[33m        ...                    \"baz\": [1, 2, 3, 4]})\u001b[39m\n",
      "\u001b[33m        >>> df\u001b[39m\n",
      "\u001b[33m           foo bar  baz\u001b[39m\n",
      "\u001b[33m        0  one   A    1\u001b[39m\n",
      "\u001b[33m        1  one   A    2\u001b[39m\n",
      "\u001b[33m        2  two   B    3\u001b[39m\n",
      "\u001b[33m        3  two   C    4\u001b[39m\n",
      "\n",
      "\u001b[33m        Notice that the first two rows are the same for our `index`\u001b[39m\n",
      "\u001b[33m        and `columns` arguments.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.pivot(index='foo', columns='bar', values='baz')\u001b[39m\n",
      "\u001b[33m        Traceback (most recent call last):\u001b[39m\n",
      "\u001b[33m           ...\u001b[39m\n",
      "\u001b[33m        ValueError: Index contains duplicate entries, cannot reshape\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "\n",
      "    @Substitution(\u001b[33m\"\"\u001b[39m)\n",
      "    @Appender(_shared_docs[\u001b[33m\"pivot\"\u001b[39m])\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m pivot(\n",
      "        self, *, columns, index=lib.no_default, values=lib.no_default\n",
      "    ) -> DataFrame:\n",
      "        \u001b[38;5;28;01mfrom\u001b[39;00m pandas.core.reshape.pivot \u001b[38;5;28;01mimport\u001b[39;00m pivot\n",
      "\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m pivot(self, index=index, columns=columns, values=values)\n",
      "\n",
      "    _shared_docs[\n",
      "        \u001b[33m\"pivot_table\"\u001b[39m\n",
      "    ] = \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Create a spreadsheet-style pivot table as a DataFrame.\u001b[39m\n",
      "\n",
      "\u001b[33m        The levels in the pivot table will be stored in MultiIndex objects\u001b[39m\n",
      "\u001b[33m        (hierarchical indexes) on the index and columns of the result DataFrame.\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------%s\u001b[39m\n",
      "\u001b[33m        values : list-like or scalar, optional\u001b[39m\n",
      "\u001b[33m            Column or columns to aggregate.\u001b[39m\n",
      "\u001b[33m        index : column, Grouper, array, or list of the previous\u001b[39m\n",
      "\u001b[33m            Keys to group by on the pivot table index. If a list is passed,\u001b[39m\n",
      "\u001b[33m            it can contain any of the other types (except list). If an array is\u001b[39m\n",
      "\u001b[33m            passed, it must be the same length as the data and will be used in\u001b[39m\n",
      "\u001b[33m            the same manner as column values.\u001b[39m\n",
      "\u001b[33m        columns : column, Grouper, array, or list of the previous\u001b[39m\n",
      "\u001b[33m            Keys to group by on the pivot table column. If a list is passed,\u001b[39m\n",
      "\u001b[33m            it can contain any of the other types (except list). If an array is\u001b[39m\n",
      "\u001b[33m            passed, it must be the same length as the data and will be used in\u001b[39m\n",
      "\u001b[33m            the same manner as column values.\u001b[39m\n",
      "\u001b[33m        aggfunc : function, list of functions, dict, default \"mean\"\u001b[39m\n",
      "\u001b[33m            If a list of functions is passed, the resulting pivot table will have\u001b[39m\n",
      "\u001b[33m            hierarchical columns whose top level are the function names\u001b[39m\n",
      "\u001b[33m            (inferred from the function objects themselves).\u001b[39m\n",
      "\u001b[33m            If a dict is passed, the key is column to aggregate and the value is\u001b[39m\n",
      "\u001b[33m            function or list of functions. If ``margin=True``, aggfunc will be\u001b[39m\n",
      "\u001b[33m            used to calculate the partial aggregates.\u001b[39m\n",
      "\u001b[33m        fill_value : scalar, default None\u001b[39m\n",
      "\u001b[33m            Value to replace missing values with (in the resulting pivot table,\u001b[39m\n",
      "\u001b[33m            after aggregation).\u001b[39m\n",
      "\u001b[33m        margins : bool, default False\u001b[39m\n",
      "\u001b[33m            If ``margins=True``, special ``All`` columns and rows\u001b[39m\n",
      "\u001b[33m            will be added with partial group aggregates across the categories\u001b[39m\n",
      "\u001b[33m            on the rows and columns.\u001b[39m\n",
      "\u001b[33m        dropna : bool, default True\u001b[39m\n",
      "\u001b[33m            Do not include columns whose entries are all NaN. If True,\u001b[39m\n",
      "\u001b[33m            rows with a NaN value in any column will be omitted before\u001b[39m\n",
      "\u001b[33m            computing margins.\u001b[39m\n",
      "\u001b[33m        margins_name : str, default 'All'\u001b[39m\n",
      "\u001b[33m            Name of the row / column that will contain the totals\u001b[39m\n",
      "\u001b[33m            when margins is True.\u001b[39m\n",
      "\u001b[33m        observed : bool, default False\u001b[39m\n",
      "\u001b[33m            This only applies if any of the groupers are Categoricals.\u001b[39m\n",
      "\u001b[33m            If True: only show observed values for categorical groupers.\u001b[39m\n",
      "\u001b[33m            If False: show all values for categorical groupers.\u001b[39m\n",
      "\n",
      "\u001b[33m            .. deprecated:: 2.2.0\u001b[39m\n",
      "\n",
      "\u001b[33m                The default value of ``False`` is deprecated and will change to\u001b[39m\n",
      "\u001b[33m                ``True`` in a future version of pandas.\u001b[39m\n",
      "\n",
      "\u001b[33m        sort : bool, default True\u001b[39m\n",
      "\u001b[33m            Specifies if the result should be sorted.\u001b[39m\n",
      "\n",
      "\u001b[33m            .. versionadded:: 1.3.0\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        DataFrame\u001b[39m\n",
      "\u001b[33m            An Excel style pivot table.\u001b[39m\n",
      "\n",
      "\u001b[33m        See Also\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        DataFrame.pivot : Pivot without aggregation that can handle\u001b[39m\n",
      "\u001b[33m            non-numeric data.\u001b[39m\n",
      "\u001b[33m        DataFrame.melt: Unpivot a DataFrame from wide to long format,\u001b[39m\n",
      "\u001b[33m            optionally leaving identifiers set.\u001b[39m\n",
      "\u001b[33m        wide_to_long : Wide panel to long format. Less flexible but more\u001b[39m\n",
      "\u001b[33m            user-friendly than melt.\u001b[39m\n",
      "\n",
      "\u001b[33m        Notes\u001b[39m\n",
      "\u001b[33m        -----\u001b[39m\n",
      "\u001b[33m        Reference :ref:`the user guide <reshaping.pivot>` for more examples.\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        >>> df = pd.DataFrame({\"A\": [\"foo\", \"foo\", \"foo\", \"foo\", \"foo\",\u001b[39m\n",
      "\u001b[33m        ...                          \"bar\", \"bar\", \"bar\", \"bar\"],\u001b[39m\n",
      "\u001b[33m        ...                    \"B\": [\"one\", \"one\", \"one\", \"two\", \"two\",\u001b[39m\n",
      "\u001b[33m        ...                          \"one\", \"one\", \"two\", \"two\"],\u001b[39m\n",
      "\u001b[33m        ...                    \"C\": [\"small\", \"large\", \"large\", \"small\",\u001b[39m\n",
      "\u001b[33m        ...                          \"small\", \"large\", \"small\", \"small\",\u001b[39m\n",
      "\u001b[33m        ...                          \"large\"],\u001b[39m\n",
      "\u001b[33m        ...                    \"D\": [1, 2, 2, 3, 3, 4, 5, 6, 7],\u001b[39m\n",
      "\u001b[33m        ...                    \"E\": [2, 4, 5, 5, 6, 6, 8, 9, 9]})\u001b[39m\n",
      "\u001b[33m        >>> df\u001b[39m\n",
      "\u001b[33m             A    B      C  D  E\u001b[39m\n",
      "\u001b[33m        0  foo  one  small  1  2\u001b[39m\n",
      "\u001b[33m        1  foo  one  large  2  4\u001b[39m\n",
      "\u001b[33m        2  foo  one  large  2  5\u001b[39m\n",
      "\u001b[33m        3  foo  two  small  3  5\u001b[39m\n",
      "\u001b[33m        4  foo  two  small  3  6\u001b[39m\n",
      "\u001b[33m        5  bar  one  large  4  6\u001b[39m\n",
      "\u001b[33m        6  bar  one  small  5  8\u001b[39m\n",
      "\u001b[33m        7  bar  two  small  6  9\u001b[39m\n",
      "\u001b[33m        8  bar  two  large  7  9\u001b[39m\n",
      "\n",
      "\u001b[33m        This first example aggregates values by taking the sum.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> table = pd.pivot_table(df, values='D', index=['A', 'B'],\u001b[39m\n",
      "\u001b[33m        ...                        columns=['C'], aggfunc=\"sum\")\u001b[39m\n",
      "\u001b[33m        >>> table\u001b[39m\n",
      "\u001b[33m        C        large  small\u001b[39m\n",
      "\u001b[33m        A   B\u001b[39m\n",
      "\u001b[33m        bar one    4.0    5.0\u001b[39m\n",
      "\u001b[33m            two    7.0    6.0\u001b[39m\n",
      "\u001b[33m        foo one    4.0    1.0\u001b[39m\n",
      "\u001b[33m            two    NaN    6.0\u001b[39m\n",
      "\n",
      "\u001b[33m        We can also fill missing values using the `fill_value` parameter.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> table = pd.pivot_table(df, values='D', index=['A', 'B'],\u001b[39m\n",
      "\u001b[33m        ...                        columns=['C'], aggfunc=\"sum\", fill_value=0)\u001b[39m\n",
      "\u001b[33m        >>> table\u001b[39m\n",
      "\u001b[33m        C        large  small\u001b[39m\n",
      "\u001b[33m        A   B\u001b[39m\n",
      "\u001b[33m        bar one      4      5\u001b[39m\n",
      "\u001b[33m            two      7      6\u001b[39m\n",
      "\u001b[33m        foo one      4      1\u001b[39m\n",
      "\u001b[33m            two      0      6\u001b[39m\n",
      "\n",
      "\u001b[33m        The next example aggregates by taking the mean across multiple columns.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> table = pd.pivot_table(df, values=['D', 'E'], index=['A', 'C'],\u001b[39m\n",
      "\u001b[33m        ...                        aggfunc={'D': \"mean\", 'E': \"mean\"})\u001b[39m\n",
      "\u001b[33m        >>> table\u001b[39m\n",
      "\u001b[33m                        D         E\u001b[39m\n",
      "\u001b[33m        A   C\u001b[39m\n",
      "\u001b[33m        bar large  5.500000  7.500000\u001b[39m\n",
      "\u001b[33m            small  5.500000  8.500000\u001b[39m\n",
      "\u001b[33m        foo large  2.000000  4.500000\u001b[39m\n",
      "\u001b[33m            small  2.333333  4.333333\u001b[39m\n",
      "\n",
      "\u001b[33m        We can also calculate multiple types of aggregations for any given\u001b[39m\n",
      "\u001b[33m        value column.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> table = pd.pivot_table(df, values=['D', 'E'], index=['A', 'C'],\u001b[39m\n",
      "\u001b[33m        ...                        aggfunc={'D': \"mean\",\u001b[39m\n",
      "\u001b[33m        ...                                 'E': [\"min\", \"max\", \"mean\"]})\u001b[39m\n",
      "\u001b[33m        >>> table\u001b[39m\n",
      "\u001b[33m                          D   E\u001b[39m\n",
      "\u001b[33m                       mean max      mean  min\u001b[39m\n",
      "\u001b[33m        A   C\u001b[39m\n",
      "\u001b[33m        bar large  5.500000   9  7.500000    6\u001b[39m\n",
      "\u001b[33m            small  5.500000   9  8.500000    8\u001b[39m\n",
      "\u001b[33m        foo large  2.000000   5  4.500000    4\u001b[39m\n",
      "\u001b[33m            small  2.333333   6  4.333333    2\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "\n",
      "    @Substitution(\u001b[33m\"\"\u001b[39m)\n",
      "    @Appender(_shared_docs[\u001b[33m\"pivot_table\"\u001b[39m])\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m pivot_table(\n",
      "        self,\n",
      "        values=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        index=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        columns=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        aggfunc: AggFuncType = \u001b[33m\"mean\"\u001b[39m,\n",
      "        fill_value=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        margins: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "        dropna: bool = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "        margins_name: Level = \u001b[33m\"All\"\u001b[39m,\n",
      "        observed: bool | lib.NoDefault = lib.no_default,\n",
      "        sort: bool = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "    ) -> DataFrame:\n",
      "        \u001b[38;5;28;01mfrom\u001b[39;00m pandas.core.reshape.pivot \u001b[38;5;28;01mimport\u001b[39;00m pivot_table\n",
      "\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m pivot_table(\n",
      "            self,\n",
      "            values=values,\n",
      "            index=index,\n",
      "            columns=columns,\n",
      "            aggfunc=aggfunc,\n",
      "            fill_value=fill_value,\n",
      "            margins=margins,\n",
      "            dropna=dropna,\n",
      "            margins_name=margins_name,\n",
      "            observed=observed,\n",
      "            sort=sort,\n",
      "        )\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m stack(\n",
      "        self,\n",
      "        level: IndexLabel = -\u001b[32m1\u001b[39m,\n",
      "        dropna: bool | lib.NoDefault = lib.no_default,\n",
      "        sort: bool | lib.NoDefault = lib.no_default,\n",
      "        future_stack: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "    ):\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Stack the prescribed level(s) from columns to index.\u001b[39m\n",
      "\n",
      "\u001b[33m        Return a reshaped DataFrame or Series having a multi-level\u001b[39m\n",
      "\u001b[33m        index with one or more new inner-most levels compared to the current\u001b[39m\n",
      "\u001b[33m        DataFrame. The new inner-most levels are created by pivoting the\u001b[39m\n",
      "\u001b[33m        columns of the current dataframe:\u001b[39m\n",
      "\n",
      "\u001b[33m          - if the columns have a single level, the output is a Series;\u001b[39m\n",
      "\u001b[33m          - if the columns have multiple levels, the new index\u001b[39m\n",
      "\u001b[33m            level(s) is (are) taken from the prescribed level(s) and\u001b[39m\n",
      "\u001b[33m            the output is a DataFrame.\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        level : int, str, list, default -1\u001b[39m\n",
      "\u001b[33m            Level(s) to stack from the column axis onto the index\u001b[39m\n",
      "\u001b[33m            axis, defined as one index or label, or a list of indices\u001b[39m\n",
      "\u001b[33m            or labels.\u001b[39m\n",
      "\u001b[33m        dropna : bool, default True\u001b[39m\n",
      "\u001b[33m            Whether to drop rows in the resulting Frame/Series with\u001b[39m\n",
      "\u001b[33m            missing values. Stacking a column level onto the index\u001b[39m\n",
      "\u001b[33m            axis can create combinations of index and column values\u001b[39m\n",
      "\u001b[33m            that are missing from the original dataframe. See Examples\u001b[39m\n",
      "\u001b[33m            section.\u001b[39m\n",
      "\u001b[33m        sort : bool, default True\u001b[39m\n",
      "\u001b[33m            Whether to sort the levels of the resulting MultiIndex.\u001b[39m\n",
      "\u001b[33m        future_stack : bool, default False\u001b[39m\n",
      "\u001b[33m            Whether to use the new implementation that will replace the current\u001b[39m\n",
      "\u001b[33m            implementation in pandas 3.0. When True, dropna and sort have no impact\u001b[39m\n",
      "\u001b[33m            on the result and must remain unspecified. See :ref:`pandas 2.1.0 Release\u001b[39m\n",
      "\u001b[33m            notes <whatsnew_210.enhancements.new_stack>` for more details.\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        DataFrame or Series\u001b[39m\n",
      "\u001b[33m            Stacked dataframe or series.\u001b[39m\n",
      "\n",
      "\u001b[33m        See Also\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        DataFrame.unstack : Unstack prescribed level(s) from index axis\u001b[39m\n",
      "\u001b[33m             onto column axis.\u001b[39m\n",
      "\u001b[33m        DataFrame.pivot : Reshape dataframe from long format to wide\u001b[39m\n",
      "\u001b[33m             format.\u001b[39m\n",
      "\u001b[33m        DataFrame.pivot_table : Create a spreadsheet-style pivot table\u001b[39m\n",
      "\u001b[33m             as a DataFrame.\u001b[39m\n",
      "\n",
      "\u001b[33m        Notes\u001b[39m\n",
      "\u001b[33m        -----\u001b[39m\n",
      "\u001b[33m        The function is named by analogy with a collection of books\u001b[39m\n",
      "\u001b[33m        being reorganized from being side by side on a horizontal\u001b[39m\n",
      "\u001b[33m        position (the columns of the dataframe) to being stacked\u001b[39m\n",
      "\u001b[33m        vertically on top of each other (in the index of the\u001b[39m\n",
      "\u001b[33m        dataframe).\u001b[39m\n",
      "\n",
      "\u001b[33m        Reference :ref:`the user guide <reshaping.stacking>` for more examples.\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        **Single level columns**\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df_single_level_cols = pd.DataFrame([[0, 1], [2, 3]],\u001b[39m\n",
      "\u001b[33m        ...                                     index=['cat', 'dog'],\u001b[39m\n",
      "\u001b[33m        ...                                     columns=['weight', 'height'])\u001b[39m\n",
      "\n",
      "\u001b[33m        Stacking a dataframe with a single level column axis returns a Series:\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df_single_level_cols\u001b[39m\n",
      "\u001b[33m             weight height\u001b[39m\n",
      "\u001b[33m        cat       0      1\u001b[39m\n",
      "\u001b[33m        dog       2      3\u001b[39m\n",
      "\u001b[33m        >>> df_single_level_cols.stack(future_stack=True)\u001b[39m\n",
      "\u001b[33m        cat  weight    0\u001b[39m\n",
      "\u001b[33m             height    1\u001b[39m\n",
      "\u001b[33m        dog  weight    2\u001b[39m\n",
      "\u001b[33m             height    3\u001b[39m\n",
      "\u001b[33m        dtype: int64\u001b[39m\n",
      "\n",
      "\u001b[33m        **Multi level columns: simple case**\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> multicol1 = pd.MultiIndex.from_tuples([('weight', 'kg'),\u001b[39m\n",
      "\u001b[33m        ...                                        ('weight', 'pounds')])\u001b[39m\n",
      "\u001b[33m        >>> df_multi_level_cols1 = pd.DataFrame([[1, 2], [2, 4]],\u001b[39m\n",
      "\u001b[33m        ...                                     index=['cat', 'dog'],\u001b[39m\n",
      "\u001b[33m        ...                                     columns=multicol1)\u001b[39m\n",
      "\n",
      "\u001b[33m        Stacking a dataframe with a multi-level column axis:\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df_multi_level_cols1\u001b[39m\n",
      "\u001b[33m             weight\u001b[39m\n",
      "\u001b[33m                 kg    pounds\u001b[39m\n",
      "\u001b[33m        cat       1        2\u001b[39m\n",
      "\u001b[33m        dog       2        4\u001b[39m\n",
      "\u001b[33m        >>> df_multi_level_cols1.stack(future_stack=True)\u001b[39m\n",
      "\u001b[33m                    weight\u001b[39m\n",
      "\u001b[33m        cat kg           1\u001b[39m\n",
      "\u001b[33m            pounds       2\u001b[39m\n",
      "\u001b[33m        dog kg           2\u001b[39m\n",
      "\u001b[33m            pounds       4\u001b[39m\n",
      "\n",
      "\u001b[33m        **Missing values**\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> multicol2 = pd.MultiIndex.from_tuples([('weight', 'kg'),\u001b[39m\n",
      "\u001b[33m        ...                                        ('height', 'm')])\u001b[39m\n",
      "\u001b[33m        >>> df_multi_level_cols2 = pd.DataFrame([[1.0, 2.0], [3.0, 4.0]],\u001b[39m\n",
      "\u001b[33m        ...                                     index=['cat', 'dog'],\u001b[39m\n",
      "\u001b[33m        ...                                     columns=multicol2)\u001b[39m\n",
      "\n",
      "\u001b[33m        It is common to have missing values when stacking a dataframe\u001b[39m\n",
      "\u001b[33m        with multi-level columns, as the stacked dataframe typically\u001b[39m\n",
      "\u001b[33m        has more values than the original dataframe. Missing values\u001b[39m\n",
      "\u001b[33m        are filled with NaNs:\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df_multi_level_cols2\u001b[39m\n",
      "\u001b[33m            weight height\u001b[39m\n",
      "\u001b[33m                kg      m\u001b[39m\n",
      "\u001b[33m        cat    1.0    2.0\u001b[39m\n",
      "\u001b[33m        dog    3.0    4.0\u001b[39m\n",
      "\u001b[33m        >>> df_multi_level_cols2.stack(future_stack=True)\u001b[39m\n",
      "\u001b[33m                weight  height\u001b[39m\n",
      "\u001b[33m        cat kg     1.0     NaN\u001b[39m\n",
      "\u001b[33m            m      NaN     2.0\u001b[39m\n",
      "\u001b[33m        dog kg     3.0     NaN\u001b[39m\n",
      "\u001b[33m            m      NaN     4.0\u001b[39m\n",
      "\n",
      "\u001b[33m        **Prescribing the level(s) to be stacked**\u001b[39m\n",
      "\n",
      "\u001b[33m        The first parameter controls which level or levels are stacked:\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df_multi_level_cols2.stack(0, future_stack=True)\u001b[39m\n",
      "\u001b[33m                     kg    m\u001b[39m\n",
      "\u001b[33m        cat weight  1.0  NaN\u001b[39m\n",
      "\u001b[33m            height  NaN  2.0\u001b[39m\n",
      "\u001b[33m        dog weight  3.0  NaN\u001b[39m\n",
      "\u001b[33m            height  NaN  4.0\u001b[39m\n",
      "\u001b[33m        >>> df_multi_level_cols2.stack([0, 1], future_stack=True)\u001b[39m\n",
      "\u001b[33m        cat  weight  kg    1.0\u001b[39m\n",
      "\u001b[33m             height  m     2.0\u001b[39m\n",
      "\u001b[33m        dog  weight  kg    3.0\u001b[39m\n",
      "\u001b[33m             height  m     4.0\u001b[39m\n",
      "\u001b[33m        dtype: float64\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m future_stack:\n",
      "            \u001b[38;5;28;01mfrom\u001b[39;00m pandas.core.reshape.reshape \u001b[38;5;28;01mimport\u001b[39;00m (\n",
      "                stack,\n",
      "                stack_multiple,\n",
      "            )\n",
      "\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m (\n",
      "                dropna \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m lib.no_default\n",
      "                \u001b[38;5;28;01mor\u001b[39;00m sort \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m lib.no_default\n",
      "                \u001b[38;5;28;01mor\u001b[39;00m self.columns.nlevels > \u001b[32m1\u001b[39m\n",
      "            ):\n",
      "                warnings.warn(\n",
      "                    \u001b[33m\"The previous implementation of stack is deprecated and will be \"\u001b[39m\n",
      "                    \u001b[33m\"removed in a future version of pandas. See the What's New notes \"\u001b[39m\n",
      "                    \u001b[33m\"for pandas 2.1.0 for details. Specify future_stack=True to adopt \"\u001b[39m\n",
      "                    \u001b[33m\"the new implementation and silence this warning.\"\u001b[39m,\n",
      "                    FutureWarning,\n",
      "                    stacklevel=find_stack_level(),\n",
      "                )\n",
      "\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m dropna \u001b[38;5;28;01mis\u001b[39;00m lib.no_default:\n",
      "                dropna = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m sort \u001b[38;5;28;01mis\u001b[39;00m lib.no_default:\n",
      "                sort = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m isinstance(level, (tuple, list)):\n",
      "                result = stack_multiple(self, level, dropna=dropna, sort=sort)\n",
      "            \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "                result = stack(self, level, dropna=dropna, sort=sort)\n",
      "        \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "            \u001b[38;5;28;01mfrom\u001b[39;00m pandas.core.reshape.reshape \u001b[38;5;28;01mimport\u001b[39;00m stack_v3\n",
      "\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m dropna \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m lib.no_default:\n",
      "                \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\n",
      "                    \u001b[33m\"dropna must be unspecified with future_stack=True as the new \"\u001b[39m\n",
      "                    \u001b[33m\"implementation does not introduce rows of NA values. This \"\u001b[39m\n",
      "                    \u001b[33m\"argument will be removed in a future version of pandas.\"\u001b[39m\n",
      "                )\n",
      "\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m sort \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m lib.no_default:\n",
      "                \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\n",
      "                    \u001b[33m\"Cannot specify sort with future_stack=True, this argument will be \"\u001b[39m\n",
      "                    \u001b[33m\"removed in a future version of pandas. Sort the result using \"\u001b[39m\n",
      "                    \u001b[33m\".sort_index instead.\"\u001b[39m\n",
      "                )\n",
      "\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m (\n",
      "                isinstance(level, (tuple, list))\n",
      "                \u001b[38;5;28;01mand\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m all(lev \u001b[38;5;28;01min\u001b[39;00m self.columns.names \u001b[38;5;28;01mfor\u001b[39;00m lev \u001b[38;5;28;01min\u001b[39;00m level)\n",
      "                \u001b[38;5;28;01mand\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m all(isinstance(lev, int) \u001b[38;5;28;01mfor\u001b[39;00m lev \u001b[38;5;28;01min\u001b[39;00m level)\n",
      "            ):\n",
      "                \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\n",
      "                    \u001b[33m\"level should contain all level names or all level \"\u001b[39m\n",
      "                    \u001b[33m\"numbers, not a mixture of the two.\"\u001b[39m\n",
      "                )\n",
      "\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m isinstance(level, (tuple, list)):\n",
      "                level = [level]\n",
      "            level = [self.columns._get_level_number(lev) \u001b[38;5;28;01mfor\u001b[39;00m lev \u001b[38;5;28;01min\u001b[39;00m level]\n",
      "            result = stack_v3(self, level)\n",
      "\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m result.__finalize__(self, method=\u001b[33m\"stack\"\u001b[39m)\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m explode(\n",
      "        self,\n",
      "        column: IndexLabel,\n",
      "        ignore_index: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "    ) -> DataFrame:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Transform each element of a list-like to a row, replicating index values.\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        column : IndexLabel\u001b[39m\n",
      "\u001b[33m            Column(s) to explode.\u001b[39m\n",
      "\u001b[33m            For multiple columns, specify a non-empty list with each element\u001b[39m\n",
      "\u001b[33m            be str or tuple, and all specified columns their list-like data\u001b[39m\n",
      "\u001b[33m            on same row of the frame must have matching length.\u001b[39m\n",
      "\n",
      "\u001b[33m            .. versionadded:: 1.3.0\u001b[39m\n",
      "\u001b[33m                Multi-column explode\u001b[39m\n",
      "\n",
      "\u001b[33m        ignore_index : bool, default False\u001b[39m\n",
      "\u001b[33m            If True, the resulting index will be labeled 0, 1, â€¦, n - 1.\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        DataFrame\u001b[39m\n",
      "\u001b[33m            Exploded lists to rows of the subset columns;\u001b[39m\n",
      "\u001b[33m            index will be duplicated for these rows.\u001b[39m\n",
      "\n",
      "\u001b[33m        Raises\u001b[39m\n",
      "\u001b[33m        ------\u001b[39m\n",
      "\u001b[33m        ValueError :\u001b[39m\n",
      "\u001b[33m            * If columns of the frame are not unique.\u001b[39m\n",
      "\u001b[33m            * If specified columns to explode is empty list.\u001b[39m\n",
      "\u001b[33m            * If specified columns to explode have not matching count of\u001b[39m\n",
      "\u001b[33m              elements rowwise in the frame.\u001b[39m\n",
      "\n",
      "\u001b[33m        See Also\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        DataFrame.unstack : Pivot a level of the (necessarily hierarchical)\u001b[39m\n",
      "\u001b[33m            index labels.\u001b[39m\n",
      "\u001b[33m        DataFrame.melt : Unpivot a DataFrame from wide format to long format.\u001b[39m\n",
      "\u001b[33m        Series.explode : Explode a DataFrame from list-like columns to long format.\u001b[39m\n",
      "\n",
      "\u001b[33m        Notes\u001b[39m\n",
      "\u001b[33m        -----\u001b[39m\n",
      "\u001b[33m        This routine will explode list-likes including lists, tuples, sets,\u001b[39m\n",
      "\u001b[33m        Series, and np.ndarray. The result dtype of the subset rows will\u001b[39m\n",
      "\u001b[33m        be object. Scalars will be returned unchanged, and empty list-likes will\u001b[39m\n",
      "\u001b[33m        result in a np.nan for that row. In addition, the ordering of rows in the\u001b[39m\n",
      "\u001b[33m        output will be non-deterministic when exploding sets.\u001b[39m\n",
      "\n",
      "\u001b[33m        Reference :ref:`the user guide <reshaping.explode>` for more examples.\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        >>> df = pd.DataFrame({'A': [[0, 1, 2], 'foo', [], [3, 4]],\u001b[39m\n",
      "\u001b[33m        ...                    'B': 1,\u001b[39m\n",
      "\u001b[33m        ...                    'C': [['a', 'b', 'c'], np.nan, [], ['d', 'e']]})\u001b[39m\n",
      "\u001b[33m        >>> df\u001b[39m\n",
      "\u001b[33m                   A  B          C\u001b[39m\n",
      "\u001b[33m        0  [0, 1, 2]  1  [a, b, c]\u001b[39m\n",
      "\u001b[33m        1        foo  1        NaN\u001b[39m\n",
      "\u001b[33m        2         []  1         []\u001b[39m\n",
      "\u001b[33m        3     [3, 4]  1     [d, e]\u001b[39m\n",
      "\n",
      "\u001b[33m        Single-column explode.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.explode('A')\u001b[39m\n",
      "\u001b[33m             A  B          C\u001b[39m\n",
      "\u001b[33m        0    0  1  [a, b, c]\u001b[39m\n",
      "\u001b[33m        0    1  1  [a, b, c]\u001b[39m\n",
      "\u001b[33m        0    2  1  [a, b, c]\u001b[39m\n",
      "\u001b[33m        1  foo  1        NaN\u001b[39m\n",
      "\u001b[33m        2  NaN  1         []\u001b[39m\n",
      "\u001b[33m        3    3  1     [d, e]\u001b[39m\n",
      "\u001b[33m        3    4  1     [d, e]\u001b[39m\n",
      "\n",
      "\u001b[33m        Multi-column explode.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.explode(list('AC'))\u001b[39m\n",
      "\u001b[33m             A  B    C\u001b[39m\n",
      "\u001b[33m        0    0  1    a\u001b[39m\n",
      "\u001b[33m        0    1  1    b\u001b[39m\n",
      "\u001b[33m        0    2  1    c\u001b[39m\n",
      "\u001b[33m        1  foo  1  NaN\u001b[39m\n",
      "\u001b[33m        2  NaN  1  NaN\u001b[39m\n",
      "\u001b[33m        3    3  1    d\u001b[39m\n",
      "\u001b[33m        3    4  1    e\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m self.columns.is_unique:\n",
      "            duplicate_cols = self.columns[self.columns.duplicated()].tolist()\n",
      "            \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\n",
      "                \u001b[33mf\"DataFrame columns must be unique. Duplicate columns: {duplicate_cols}\"\u001b[39m\n",
      "            )\n",
      "\n",
      "        columns: list[Hashable]\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m is_scalar(column) \u001b[38;5;28;01mor\u001b[39;00m isinstance(column, tuple):\n",
      "            columns = [column]\n",
      "        \u001b[38;5;28;01melif\u001b[39;00m isinstance(column, list) \u001b[38;5;28;01mand\u001b[39;00m all(\n",
      "            is_scalar(c) \u001b[38;5;28;01mor\u001b[39;00m isinstance(c, tuple) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;28;01min\u001b[39;00m column\n",
      "        ):\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m column:\n",
      "                \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\u001b[33m\"column must be nonempty\"\u001b[39m)\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m len(column) > len(set(column)):\n",
      "                \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\u001b[33m\"column must be unique\"\u001b[39m)\n",
      "            columns = column\n",
      "        \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "            \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\u001b[33m\"column must be a scalar, tuple, or list thereof\"\u001b[39m)\n",
      "\n",
      "        df = self.reset_index(drop=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m len(columns) == \u001b[32m1\u001b[39m:\n",
      "            result = df[columns[\u001b[32m0\u001b[39m]].explode()\n",
      "        \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "            mylen = \u001b[38;5;28;01mlambda\u001b[39;00m x: len(x) \u001b[38;5;28;01mif\u001b[39;00m (is_list_like(x) \u001b[38;5;28;01mand\u001b[39;00m len(x) > \u001b[32m0\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m1\u001b[39m\n",
      "            counts0 = self[columns[\u001b[32m0\u001b[39m]].apply(mylen)\n",
      "            \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;28;01min\u001b[39;00m columns[\u001b[32m1\u001b[39m:]:\n",
      "                \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m all(counts0 == self[c].apply(mylen)):\n",
      "                    \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\u001b[33m\"columns must have matching element counts\"\u001b[39m)\n",
      "            result = DataFrame({c: df[c].explode() \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;28;01min\u001b[39;00m columns})\n",
      "        result = df.drop(columns, axis=\u001b[32m1\u001b[39m).join(result)\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m ignore_index:\n",
      "            result.index = default_index(len(result))\n",
      "        \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "            result.index = self.index.take(result.index)\n",
      "        result = result.reindex(columns=self.columns, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m result.__finalize__(self, method=\u001b[33m\"explode\"\u001b[39m)\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m unstack(self, level: IndexLabel = -\u001b[32m1\u001b[39m, fill_value=\u001b[38;5;28;01mNone\u001b[39;00m, sort: bool = \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Pivot a level of the (necessarily hierarchical) index labels.\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns a DataFrame having a new level of column labels whose inner-most level\u001b[39m\n",
      "\u001b[33m        consists of the pivoted index labels.\u001b[39m\n",
      "\n",
      "\u001b[33m        If the index is not a MultiIndex, the output will be a Series\u001b[39m\n",
      "\u001b[33m        (the analogue of stack when the columns are not a MultiIndex).\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        level : int, str, or list of these, default -1 (last level)\u001b[39m\n",
      "\u001b[33m            Level(s) of index to unstack, can pass level name.\u001b[39m\n",
      "\u001b[33m        fill_value : int, str or dict\u001b[39m\n",
      "\u001b[33m            Replace NaN with this value if the unstack produces missing values.\u001b[39m\n",
      "\u001b[33m        sort : bool, default True\u001b[39m\n",
      "\u001b[33m            Sort the level(s) in the resulting MultiIndex columns.\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        Series or DataFrame\u001b[39m\n",
      "\n",
      "\u001b[33m        See Also\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        DataFrame.pivot : Pivot a table based on column values.\u001b[39m\n",
      "\u001b[33m        DataFrame.stack : Pivot a level of the column labels (inverse operation\u001b[39m\n",
      "\u001b[33m            from `unstack`).\u001b[39m\n",
      "\n",
      "\u001b[33m        Notes\u001b[39m\n",
      "\u001b[33m        -----\u001b[39m\n",
      "\u001b[33m        Reference :ref:`the user guide <reshaping.stacking>` for more examples.\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        >>> index = pd.MultiIndex.from_tuples([('one', 'a'), ('one', 'b'),\u001b[39m\n",
      "\u001b[33m        ...                                    ('two', 'a'), ('two', 'b')])\u001b[39m\n",
      "\u001b[33m        >>> s = pd.Series(np.arange(1.0, 5.0), index=index)\u001b[39m\n",
      "\u001b[33m        >>> s\u001b[39m\n",
      "\u001b[33m        one  a   1.0\u001b[39m\n",
      "\u001b[33m             b   2.0\u001b[39m\n",
      "\u001b[33m        two  a   3.0\u001b[39m\n",
      "\u001b[33m             b   4.0\u001b[39m\n",
      "\u001b[33m        dtype: float64\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> s.unstack(level=-1)\u001b[39m\n",
      "\u001b[33m             a   b\u001b[39m\n",
      "\u001b[33m        one  1.0  2.0\u001b[39m\n",
      "\u001b[33m        two  3.0  4.0\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> s.unstack(level=0)\u001b[39m\n",
      "\u001b[33m           one  two\u001b[39m\n",
      "\u001b[33m        a  1.0   3.0\u001b[39m\n",
      "\u001b[33m        b  2.0   4.0\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df = s.unstack(level=0)\u001b[39m\n",
      "\u001b[33m        >>> df.unstack()\u001b[39m\n",
      "\u001b[33m        one  a  1.0\u001b[39m\n",
      "\u001b[33m             b  2.0\u001b[39m\n",
      "\u001b[33m        two  a  3.0\u001b[39m\n",
      "\u001b[33m             b  4.0\u001b[39m\n",
      "\u001b[33m        dtype: float64\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;28;01mfrom\u001b[39;00m pandas.core.reshape.reshape \u001b[38;5;28;01mimport\u001b[39;00m unstack\n",
      "\n",
      "        result = unstack(self, level, fill_value, sort)\n",
      "\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m result.__finalize__(self, method=\u001b[33m\"unstack\"\u001b[39m)\n",
      "\n",
      "    @Appender(_shared_docs[\u001b[33m\"melt\"\u001b[39m] % {\u001b[33m\"caller\"\u001b[39m: \u001b[33m\"df.melt(\"\u001b[39m, \u001b[33m\"other\"\u001b[39m: \u001b[33m\"melt\"\u001b[39m})\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m melt(\n",
      "        self,\n",
      "        id_vars=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        value_vars=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        var_name=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        value_name: Hashable = \u001b[33m\"value\"\u001b[39m,\n",
      "        col_level: Level | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        ignore_index: bool = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "    ) -> DataFrame:\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m melt(\n",
      "            self,\n",
      "            id_vars=id_vars,\n",
      "            value_vars=value_vars,\n",
      "            var_name=var_name,\n",
      "            value_name=value_name,\n",
      "            col_level=col_level,\n",
      "            ignore_index=ignore_index,\n",
      "        ).__finalize__(self, method=\u001b[33m\"melt\"\u001b[39m)\n",
      "\n",
      "    \u001b[38;5;66;03m# ----------------------------------------------------------------------\u001b[39;00m\n",
      "    \u001b[38;5;66;03m# Time series-related\u001b[39;00m\n",
      "\n",
      "    @doc(\n",
      "        Series.diff,\n",
      "        klass=\u001b[33m\"DataFrame\"\u001b[39m,\n",
      "        extra_params=\u001b[33m\"axis : {0 or 'index', 1 or 'columns'}, default 0\\n    \"\u001b[39m\n",
      "        \u001b[33m\"Take difference over rows (0) or columns (1).\\n\"\u001b[39m,\n",
      "        other_klass=\u001b[33m\"Series\"\u001b[39m,\n",
      "        examples=dedent(\n",
      "            \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Difference with previous row\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df = pd.DataFrame({'a': [1, 2, 3, 4, 5, 6],\u001b[39m\n",
      "\u001b[33m        ...                    'b': [1, 1, 2, 3, 5, 8],\u001b[39m\n",
      "\u001b[33m        ...                    'c': [1, 4, 9, 16, 25, 36]})\u001b[39m\n",
      "\u001b[33m        >>> df\u001b[39m\n",
      "\u001b[33m           a  b   c\u001b[39m\n",
      "\u001b[33m        0  1  1   1\u001b[39m\n",
      "\u001b[33m        1  2  1   4\u001b[39m\n",
      "\u001b[33m        2  3  2   9\u001b[39m\n",
      "\u001b[33m        3  4  3  16\u001b[39m\n",
      "\u001b[33m        4  5  5  25\u001b[39m\n",
      "\u001b[33m        5  6  8  36\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.diff()\u001b[39m\n",
      "\u001b[33m             a    b     c\u001b[39m\n",
      "\u001b[33m        0  NaN  NaN   NaN\u001b[39m\n",
      "\u001b[33m        1  1.0  0.0   3.0\u001b[39m\n",
      "\u001b[33m        2  1.0  1.0   5.0\u001b[39m\n",
      "\u001b[33m        3  1.0  1.0   7.0\u001b[39m\n",
      "\u001b[33m        4  1.0  2.0   9.0\u001b[39m\n",
      "\u001b[33m        5  1.0  3.0  11.0\u001b[39m\n",
      "\n",
      "\u001b[33m        Difference with previous column\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.diff(axis=1)\u001b[39m\n",
      "\u001b[33m            a  b   c\u001b[39m\n",
      "\u001b[33m        0 NaN  0   0\u001b[39m\n",
      "\u001b[33m        1 NaN -1   3\u001b[39m\n",
      "\u001b[33m        2 NaN -1   7\u001b[39m\n",
      "\u001b[33m        3 NaN -1  13\u001b[39m\n",
      "\u001b[33m        4 NaN  0  20\u001b[39m\n",
      "\u001b[33m        5 NaN  2  28\u001b[39m\n",
      "\n",
      "\u001b[33m        Difference with 3rd previous row\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.diff(periods=3)\u001b[39m\n",
      "\u001b[33m             a    b     c\u001b[39m\n",
      "\u001b[33m        0  NaN  NaN   NaN\u001b[39m\n",
      "\u001b[33m        1  NaN  NaN   NaN\u001b[39m\n",
      "\u001b[33m        2  NaN  NaN   NaN\u001b[39m\n",
      "\u001b[33m        3  3.0  2.0  15.0\u001b[39m\n",
      "\u001b[33m        4  3.0  4.0  21.0\u001b[39m\n",
      "\u001b[33m        5  3.0  6.0  27.0\u001b[39m\n",
      "\n",
      "\u001b[33m        Difference with following row\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.diff(periods=-1)\u001b[39m\n",
      "\u001b[33m             a    b     c\u001b[39m\n",
      "\u001b[33m        0 -1.0  0.0  -3.0\u001b[39m\n",
      "\u001b[33m        1 -1.0 -1.0  -5.0\u001b[39m\n",
      "\u001b[33m        2 -1.0 -1.0  -7.0\u001b[39m\n",
      "\u001b[33m        3 -1.0 -2.0  -9.0\u001b[39m\n",
      "\u001b[33m        4 -1.0 -3.0 -11.0\u001b[39m\n",
      "\u001b[33m        5  NaN  NaN   NaN\u001b[39m\n",
      "\n",
      "\u001b[33m        Overflow in input dtype\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df = pd.DataFrame({'a': [1, 0]}, dtype=np.uint8)\u001b[39m\n",
      "\u001b[33m        >>> df.diff()\u001b[39m\n",
      "\u001b[33m               a\u001b[39m\n",
      "\u001b[33m        0    NaN\u001b[39m\n",
      "\u001b[33m        1  255.0\"\"\"\u001b[39m\n",
      "        ),\n",
      "    )\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m diff(self, periods: int = \u001b[32m1\u001b[39m, axis: Axis = \u001b[32m0\u001b[39m) -> DataFrame:\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m lib.is_integer(periods):\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m (is_float(periods) \u001b[38;5;28;01mand\u001b[39;00m periods.is_integer()):\n",
      "                \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\u001b[33m\"periods must be an integer\"\u001b[39m)\n",
      "            periods = int(periods)\n",
      "\n",
      "        axis = self._get_axis_number(axis)\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m axis == \u001b[32m1\u001b[39m:\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m periods != \u001b[32m0\u001b[39m:\n",
      "                \u001b[38;5;66;03m# in the periods == 0 case, this is equivalent diff of 0 periods\u001b[39;00m\n",
      "                \u001b[38;5;66;03m#  along axis=0, and the Manager method may be somewhat more\u001b[39;00m\n",
      "                \u001b[38;5;66;03m#  performant, so we dispatch in that case.\u001b[39;00m\n",
      "                \u001b[38;5;28;01mreturn\u001b[39;00m self - self.shift(periods, axis=axis)\n",
      "            \u001b[38;5;66;03m# With periods=0 this is equivalent to a diff with axis=0\u001b[39;00m\n",
      "            axis = \u001b[32m0\u001b[39m\n",
      "\n",
      "        new_data = self._mgr.diff(n=periods)\n",
      "        res_df = self._constructor_from_mgr(new_data, axes=new_data.axes)\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m res_df.__finalize__(self, \u001b[33m\"diff\"\u001b[39m)\n",
      "\n",
      "    \u001b[38;5;66;03m# ----------------------------------------------------------------------\u001b[39;00m\n",
      "    \u001b[38;5;66;03m# Function application\u001b[39;00m\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m _gotitem(\n",
      "        self,\n",
      "        key: IndexLabel,\n",
      "        ndim: int,\n",
      "        subset: DataFrame | Series | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    ) -> DataFrame | Series:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Sub-classes to define. Return a sliced object.\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        key : string / list of selections\u001b[39m\n",
      "\u001b[33m        ndim : {1, 2}\u001b[39m\n",
      "\u001b[33m            requested ndim of result\u001b[39m\n",
      "\u001b[33m        subset : object, default None\u001b[39m\n",
      "\u001b[33m            subset to act on\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m subset \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "            subset = self\n",
      "        \u001b[38;5;28;01melif\u001b[39;00m subset.ndim == \u001b[32m1\u001b[39m:  \u001b[38;5;66;03m# is Series\u001b[39;00m\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m subset\n",
      "\n",
      "        \u001b[38;5;66;03m# TODO: _shallow_copy(subset)?\u001b[39;00m\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m subset[key]\n",
      "\n",
      "    _agg_see_also_doc = dedent(\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m    See Also\u001b[39m\n",
      "\u001b[33m    --------\u001b[39m\n",
      "\u001b[33m    DataFrame.apply : Perform any type of operations.\u001b[39m\n",
      "\u001b[33m    DataFrame.transform : Perform transformation type operations.\u001b[39m\n",
      "\u001b[33m    pandas.DataFrame.groupby : Perform operations over groups.\u001b[39m\n",
      "\u001b[33m    pandas.DataFrame.resample : Perform operations over resampled bins.\u001b[39m\n",
      "\u001b[33m    pandas.DataFrame.rolling : Perform operations over rolling window.\u001b[39m\n",
      "\u001b[33m    pandas.DataFrame.expanding : Perform operations over expanding window.\u001b[39m\n",
      "\u001b[33m    pandas.core.window.ewm.ExponentialMovingWindow : Perform operation over exponential\u001b[39m\n",
      "\u001b[33m        weighted window.\u001b[39m\n",
      "\u001b[33m    \"\"\"\u001b[39m\n",
      "    )\n",
      "\n",
      "    _agg_examples_doc = dedent(\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m    Examples\u001b[39m\n",
      "\u001b[33m    --------\u001b[39m\n",
      "\u001b[33m    >>> df = pd.DataFrame([[1, 2, 3],\u001b[39m\n",
      "\u001b[33m    ...                    [4, 5, 6],\u001b[39m\n",
      "\u001b[33m    ...                    [7, 8, 9],\u001b[39m\n",
      "\u001b[33m    ...                    [np.nan, np.nan, np.nan]],\u001b[39m\n",
      "\u001b[33m    ...                   columns=['A', 'B', 'C'])\u001b[39m\n",
      "\n",
      "\u001b[33m    Aggregate these functions over the rows.\u001b[39m\n",
      "\n",
      "\u001b[33m    >>> df.agg(['sum', 'min'])\u001b[39m\n",
      "\u001b[33m            A     B     C\u001b[39m\n",
      "\u001b[33m    sum  12.0  15.0  18.0\u001b[39m\n",
      "\u001b[33m    min   1.0   2.0   3.0\u001b[39m\n",
      "\n",
      "\u001b[33m    Different aggregations per column.\u001b[39m\n",
      "\n",
      "\u001b[33m    >>> df.agg({'A' : ['sum', 'min'], 'B' : ['min', 'max']})\u001b[39m\n",
      "\u001b[33m            A    B\u001b[39m\n",
      "\u001b[33m    sum  12.0  NaN\u001b[39m\n",
      "\u001b[33m    min   1.0  2.0\u001b[39m\n",
      "\u001b[33m    max   NaN  8.0\u001b[39m\n",
      "\n",
      "\u001b[33m    Aggregate different functions over the columns and rename the index of the resulting\u001b[39m\n",
      "\u001b[33m    DataFrame.\u001b[39m\n",
      "\n",
      "\u001b[33m    >>> df.agg(x=('A', 'max'), y=('B', 'min'), z=('C', 'mean'))\u001b[39m\n",
      "\u001b[33m         A    B    C\u001b[39m\n",
      "\u001b[33m    x  7.0  NaN  NaN\u001b[39m\n",
      "\u001b[33m    y  NaN  2.0  NaN\u001b[39m\n",
      "\u001b[33m    z  NaN  NaN  6.0\u001b[39m\n",
      "\n",
      "\u001b[33m    Aggregate over the columns.\u001b[39m\n",
      "\n",
      "\u001b[33m    >>> df.agg(\"mean\", axis=\"columns\")\u001b[39m\n",
      "\u001b[33m    0    2.0\u001b[39m\n",
      "\u001b[33m    1    5.0\u001b[39m\n",
      "\u001b[33m    2    8.0\u001b[39m\n",
      "\u001b[33m    3    NaN\u001b[39m\n",
      "\u001b[33m    dtype: float64\u001b[39m\n",
      "\u001b[33m    \"\"\"\u001b[39m\n",
      "    )\n",
      "\n",
      "    @doc(\n",
      "        _shared_docs[\u001b[33m\"aggregate\"\u001b[39m],\n",
      "        klass=_shared_doc_kwargs[\u001b[33m\"klass\"\u001b[39m],\n",
      "        axis=_shared_doc_kwargs[\u001b[33m\"axis\"\u001b[39m],\n",
      "        see_also=_agg_see_also_doc,\n",
      "        examples=_agg_examples_doc,\n",
      "    )\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m aggregate(self, func=\u001b[38;5;28;01mNone\u001b[39;00m, axis: Axis = \u001b[32m0\u001b[39m, *args, **kwargs):\n",
      "        \u001b[38;5;28;01mfrom\u001b[39;00m pandas.core.apply \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n",
      "\n",
      "        axis = self._get_axis_number(axis)\n",
      "\n",
      "        op = frame_apply(self, func=func, axis=axis, args=args, kwargs=kwargs)\n",
      "        result = op.agg()\n",
      "        result = reconstruct_and_relabel_result(result, func, **kwargs)\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\n",
      "    agg = aggregate\n",
      "\n",
      "    @doc(\n",
      "        _shared_docs[\u001b[33m\"transform\"\u001b[39m],\n",
      "        klass=_shared_doc_kwargs[\u001b[33m\"klass\"\u001b[39m],\n",
      "        axis=_shared_doc_kwargs[\u001b[33m\"axis\"\u001b[39m],\n",
      "    )\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m transform(\n",
      "        self, func: AggFuncType, axis: Axis = \u001b[32m0\u001b[39m, *args, **kwargs\n",
      "    ) -> DataFrame:\n",
      "        \u001b[38;5;28;01mfrom\u001b[39;00m pandas.core.apply \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n",
      "\n",
      "        op = frame_apply(self, func=func, axis=axis, args=args, kwargs=kwargs)\n",
      "        result = op.transform()\n",
      "        \u001b[38;5;28;01massert\u001b[39;00m isinstance(result, DataFrame)\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m apply(\n",
      "        self,\n",
      "        func: AggFuncType,\n",
      "        axis: Axis = \u001b[32m0\u001b[39m,\n",
      "        raw: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "        result_type: Literal[\u001b[33m\"expand\"\u001b[39m, \u001b[33m\"reduce\"\u001b[39m, \u001b[33m\"broadcast\"\u001b[39m] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        args=(),\n",
      "        by_row: Literal[\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"compat\"\u001b[39m] = \u001b[33m\"compat\"\u001b[39m,\n",
      "        engine: Literal[\u001b[33m\"python\"\u001b[39m, \u001b[33m\"numba\"\u001b[39m] = \u001b[33m\"python\"\u001b[39m,\n",
      "        engine_kwargs: dict[str, bool] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        **kwargs,\n",
      "    ):\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Apply a function along an axis of the DataFrame.\u001b[39m\n",
      "\n",
      "\u001b[33m        Objects passed to the function are Series objects whose index is\u001b[39m\n",
      "\u001b[33m        either the DataFrame's index (``axis=0``) or the DataFrame's columns\u001b[39m\n",
      "\u001b[33m        (``axis=1``). By default (``result_type=None``), the final return type\u001b[39m\n",
      "\u001b[33m        is inferred from the return type of the applied function. Otherwise,\u001b[39m\n",
      "\u001b[33m        it depends on the `result_type` argument.\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        func : function\u001b[39m\n",
      "\u001b[33m            Function to apply to each column or row.\u001b[39m\n",
      "\u001b[33m        axis : {0 or 'index', 1 or 'columns'}, default 0\u001b[39m\n",
      "\u001b[33m            Axis along which the function is applied:\u001b[39m\n",
      "\n",
      "\u001b[33m            * 0 or 'index': apply function to each column.\u001b[39m\n",
      "\u001b[33m            * 1 or 'columns': apply function to each row.\u001b[39m\n",
      "\n",
      "\u001b[33m        raw : bool, default False\u001b[39m\n",
      "\u001b[33m            Determines if row or column is passed as a Series or ndarray object:\u001b[39m\n",
      "\n",
      "\u001b[33m            * ``False`` : passes each row or column as a Series to the\u001b[39m\n",
      "\u001b[33m              function.\u001b[39m\n",
      "\u001b[33m            * ``True`` : the passed function will receive ndarray objects\u001b[39m\n",
      "\u001b[33m              instead.\u001b[39m\n",
      "\u001b[33m              If you are just applying a NumPy reduction function this will\u001b[39m\n",
      "\u001b[33m              achieve much better performance.\u001b[39m\n",
      "\n",
      "\u001b[33m        result_type : {'expand', 'reduce', 'broadcast', None}, default None\u001b[39m\n",
      "\u001b[33m            These only act when ``axis=1`` (columns):\u001b[39m\n",
      "\n",
      "\u001b[33m            * 'expand' : list-like results will be turned into columns.\u001b[39m\n",
      "\u001b[33m            * 'reduce' : returns a Series if possible rather than expanding\u001b[39m\n",
      "\u001b[33m              list-like results. This is the opposite of 'expand'.\u001b[39m\n",
      "\u001b[33m            * 'broadcast' : results will be broadcast to the original shape\u001b[39m\n",
      "\u001b[33m              of the DataFrame, the original index and columns will be\u001b[39m\n",
      "\u001b[33m              retained.\u001b[39m\n",
      "\n",
      "\u001b[33m            The default behaviour (None) depends on the return value of the\u001b[39m\n",
      "\u001b[33m            applied function: list-like results will be returned as a Series\u001b[39m\n",
      "\u001b[33m            of those. However if the apply function returns a Series these\u001b[39m\n",
      "\u001b[33m            are expanded to columns.\u001b[39m\n",
      "\u001b[33m        args : tuple\u001b[39m\n",
      "\u001b[33m            Positional arguments to pass to `func` in addition to the\u001b[39m\n",
      "\u001b[33m            array/series.\u001b[39m\n",
      "\u001b[33m        by_row : False or \"compat\", default \"compat\"\u001b[39m\n",
      "\u001b[33m            Only has an effect when ``func`` is a listlike or dictlike of funcs\u001b[39m\n",
      "\u001b[33m            and the func isn't a string.\u001b[39m\n",
      "\u001b[33m            If \"compat\", will if possible first translate the func into pandas\u001b[39m\n",
      "\u001b[33m            methods (e.g. ``Series().apply(np.sum)`` will be translated to\u001b[39m\n",
      "\u001b[33m            ``Series().sum()``). If that doesn't work, will try call to apply again with\u001b[39m\n",
      "\u001b[33m            ``by_row=True`` and if that fails, will call apply again with\u001b[39m\n",
      "\u001b[33m            ``by_row=False`` (backward compatible).\u001b[39m\n",
      "\u001b[33m            If False, the funcs will be passed the whole Series at once.\u001b[39m\n",
      "\n",
      "\u001b[33m            .. versionadded:: 2.1.0\u001b[39m\n",
      "\n",
      "\u001b[33m        engine : {'python', 'numba'}, default 'python'\u001b[39m\n",
      "\u001b[33m            Choose between the python (default) engine or the numba engine in apply.\u001b[39m\n",
      "\n",
      "\u001b[33m            The numba engine will attempt to JIT compile the passed function,\u001b[39m\n",
      "\u001b[33m            which may result in speedups for large DataFrames.\u001b[39m\n",
      "\u001b[33m            It also supports the following engine_kwargs :\u001b[39m\n",
      "\n",
      "\u001b[33m            - nopython (compile the function in nopython mode)\u001b[39m\n",
      "\u001b[33m            - nogil (release the GIL inside the JIT compiled function)\u001b[39m\n",
      "\u001b[33m            - parallel (try to apply the function in parallel over the DataFrame)\u001b[39m\n",
      "\n",
      "\u001b[33m              Note: Due to limitations within numba/how pandas interfaces with numba,\u001b[39m\n",
      "\u001b[33m              you should only use this if raw=True\u001b[39m\n",
      "\n",
      "\u001b[33m            Note: The numba compiler only supports a subset of\u001b[39m\n",
      "\u001b[33m            valid Python/numpy operations.\u001b[39m\n",
      "\n",
      "\u001b[33m            Please read more about the `supported python features\u001b[39m\n",
      "\u001b[33m            <https://numba.pydata.org/numba-doc/dev/reference/pysupported.html>`_\u001b[39m\n",
      "\u001b[33m            and `supported numpy features\u001b[39m\n",
      "\u001b[33m            <https://numba.pydata.org/numba-doc/dev/reference/numpysupported.html>`_\u001b[39m\n",
      "\u001b[33m            in numba to learn what you can or cannot use in the passed function.\u001b[39m\n",
      "\n",
      "\u001b[33m            .. versionadded:: 2.2.0\u001b[39m\n",
      "\n",
      "\u001b[33m        engine_kwargs : dict\u001b[39m\n",
      "\u001b[33m            Pass keyword arguments to the engine.\u001b[39m\n",
      "\u001b[33m            This is currently only used by the numba engine,\u001b[39m\n",
      "\u001b[33m            see the documentation for the engine argument for more information.\u001b[39m\n",
      "\u001b[33m        **kwargs\u001b[39m\n",
      "\u001b[33m            Additional keyword arguments to pass as keywords arguments to\u001b[39m\n",
      "\u001b[33m            `func`.\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        Series or DataFrame\u001b[39m\n",
      "\u001b[33m            Result of applying ``func`` along the given axis of the\u001b[39m\n",
      "\u001b[33m            DataFrame.\u001b[39m\n",
      "\n",
      "\u001b[33m        See Also\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        DataFrame.map: For elementwise operations.\u001b[39m\n",
      "\u001b[33m        DataFrame.aggregate: Only perform aggregating type operations.\u001b[39m\n",
      "\u001b[33m        DataFrame.transform: Only perform transforming type operations.\u001b[39m\n",
      "\n",
      "\u001b[33m        Notes\u001b[39m\n",
      "\u001b[33m        -----\u001b[39m\n",
      "\u001b[33m        Functions that mutate the passed object can produce unexpected\u001b[39m\n",
      "\u001b[33m        behavior or errors and are not supported. See :ref:`gotchas.udf-mutation`\u001b[39m\n",
      "\u001b[33m        for more details.\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        >>> df = pd.DataFrame([[4, 9]] * 3, columns=['A', 'B'])\u001b[39m\n",
      "\u001b[33m        >>> df\u001b[39m\n",
      "\u001b[33m           A  B\u001b[39m\n",
      "\u001b[33m        0  4  9\u001b[39m\n",
      "\u001b[33m        1  4  9\u001b[39m\n",
      "\u001b[33m        2  4  9\u001b[39m\n",
      "\n",
      "\u001b[33m        Using a numpy universal function (in this case the same as\u001b[39m\n",
      "\u001b[33m        ``np.sqrt(df)``):\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.apply(np.sqrt)\u001b[39m\n",
      "\u001b[33m             A    B\u001b[39m\n",
      "\u001b[33m        0  2.0  3.0\u001b[39m\n",
      "\u001b[33m        1  2.0  3.0\u001b[39m\n",
      "\u001b[33m        2  2.0  3.0\u001b[39m\n",
      "\n",
      "\u001b[33m        Using a reducing function on either axis\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.apply(np.sum, axis=0)\u001b[39m\n",
      "\u001b[33m        A    12\u001b[39m\n",
      "\u001b[33m        B    27\u001b[39m\n",
      "\u001b[33m        dtype: int64\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.apply(np.sum, axis=1)\u001b[39m\n",
      "\u001b[33m        0    13\u001b[39m\n",
      "\u001b[33m        1    13\u001b[39m\n",
      "\u001b[33m        2    13\u001b[39m\n",
      "\u001b[33m        dtype: int64\u001b[39m\n",
      "\n",
      "\u001b[33m        Returning a list-like will result in a Series\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.apply(lambda x: [1, 2], axis=1)\u001b[39m\n",
      "\u001b[33m        0    [1, 2]\u001b[39m\n",
      "\u001b[33m        1    [1, 2]\u001b[39m\n",
      "\u001b[33m        2    [1, 2]\u001b[39m\n",
      "\u001b[33m        dtype: object\u001b[39m\n",
      "\n",
      "\u001b[33m        Passing ``result_type='expand'`` will expand list-like results\u001b[39m\n",
      "\u001b[33m        to columns of a Dataframe\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.apply(lambda x: [1, 2], axis=1, result_type='expand')\u001b[39m\n",
      "\u001b[33m           0  1\u001b[39m\n",
      "\u001b[33m        0  1  2\u001b[39m\n",
      "\u001b[33m        1  1  2\u001b[39m\n",
      "\u001b[33m        2  1  2\u001b[39m\n",
      "\n",
      "\u001b[33m        Returning a Series inside the function is similar to passing\u001b[39m\n",
      "\u001b[33m        ``result_type='expand'``. The resulting column names\u001b[39m\n",
      "\u001b[33m        will be the Series index.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.apply(lambda x: pd.Series([1, 2], index=['foo', 'bar']), axis=1)\u001b[39m\n",
      "\u001b[33m           foo  bar\u001b[39m\n",
      "\u001b[33m        0    1    2\u001b[39m\n",
      "\u001b[33m        1    1    2\u001b[39m\n",
      "\u001b[33m        2    1    2\u001b[39m\n",
      "\n",
      "\u001b[33m        Passing ``result_type='broadcast'`` will ensure the same shape\u001b[39m\n",
      "\u001b[33m        result, whether list-like or scalar is returned by the function,\u001b[39m\n",
      "\u001b[33m        and broadcast it along the axis. The resulting column names will\u001b[39m\n",
      "\u001b[33m        be the originals.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.apply(lambda x: [1, 2], axis=1, result_type='broadcast')\u001b[39m\n",
      "\u001b[33m           A  B\u001b[39m\n",
      "\u001b[33m        0  1  2\u001b[39m\n",
      "\u001b[33m        1  1  2\u001b[39m\n",
      "\u001b[33m        2  1  2\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;28;01mfrom\u001b[39;00m pandas.core.apply \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n",
      "\n",
      "        op = frame_apply(\n",
      "            self,\n",
      "            func=func,\n",
      "            axis=axis,\n",
      "            raw=raw,\n",
      "            result_type=result_type,\n",
      "            by_row=by_row,\n",
      "            engine=engine,\n",
      "            engine_kwargs=engine_kwargs,\n",
      "            args=args,\n",
      "            kwargs=kwargs,\n",
      "        )\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m op.apply().__finalize__(self, method=\u001b[33m\"apply\"\u001b[39m)\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m map(\n",
      "        self, func: PythonFuncType, na_action: str | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m, **kwargs\n",
      "    ) -> DataFrame:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Apply a function to a Dataframe elementwise.\u001b[39m\n",
      "\n",
      "\u001b[33m        .. versionadded:: 2.1.0\u001b[39m\n",
      "\n",
      "\u001b[33m           DataFrame.applymap was deprecated and renamed to DataFrame.map.\u001b[39m\n",
      "\n",
      "\u001b[33m        This method applies a function that accepts and returns a scalar\u001b[39m\n",
      "\u001b[33m        to every element of a DataFrame.\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        func : callable\u001b[39m\n",
      "\u001b[33m            Python function, returns a single value from a single value.\u001b[39m\n",
      "\u001b[33m        na_action : {None, 'ignore'}, default None\u001b[39m\n",
      "\u001b[33m            If 'ignore', propagate NaN values, without passing them to func.\u001b[39m\n",
      "\u001b[33m        **kwargs\u001b[39m\n",
      "\u001b[33m            Additional keyword arguments to pass as keywords arguments to\u001b[39m\n",
      "\u001b[33m            `func`.\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        DataFrame\u001b[39m\n",
      "\u001b[33m            Transformed DataFrame.\u001b[39m\n",
      "\n",
      "\u001b[33m        See Also\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        DataFrame.apply : Apply a function along input axis of DataFrame.\u001b[39m\n",
      "\u001b[33m        DataFrame.replace: Replace values given in `to_replace` with `value`.\u001b[39m\n",
      "\u001b[33m        Series.map : Apply a function elementwise on a Series.\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        >>> df = pd.DataFrame([[1, 2.12], [3.356, 4.567]])\u001b[39m\n",
      "\u001b[33m        >>> df\u001b[39m\n",
      "\u001b[33m               0      1\u001b[39m\n",
      "\u001b[33m        0  1.000  2.120\u001b[39m\n",
      "\u001b[33m        1  3.356  4.567\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.map(lambda x: len(str(x)))\u001b[39m\n",
      "\u001b[33m           0  1\u001b[39m\n",
      "\u001b[33m        0  3  4\u001b[39m\n",
      "\u001b[33m        1  5  5\u001b[39m\n",
      "\n",
      "\u001b[33m        Like Series.map, NA values can be ignored:\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df_copy = df.copy()\u001b[39m\n",
      "\u001b[33m        >>> df_copy.iloc[0, 0] = pd.NA\u001b[39m\n",
      "\u001b[33m        >>> df_copy.map(lambda x: len(str(x)), na_action='ignore')\u001b[39m\n",
      "\u001b[33m             0  1\u001b[39m\n",
      "\u001b[33m        0  NaN  4\u001b[39m\n",
      "\u001b[33m        1  5.0  5\u001b[39m\n",
      "\n",
      "\u001b[33m        It is also possible to use `map` with functions that are not\u001b[39m\n",
      "\u001b[33m        `lambda` functions:\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.map(round, ndigits=1)\u001b[39m\n",
      "\u001b[33m             0    1\u001b[39m\n",
      "\u001b[33m        0  1.0  2.1\u001b[39m\n",
      "\u001b[33m        1  3.4  4.6\u001b[39m\n",
      "\n",
      "\u001b[33m        Note that a vectorized version of `func` often exists, which will\u001b[39m\n",
      "\u001b[33m        be much faster. You could square each number elementwise.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.map(lambda x: x**2)\u001b[39m\n",
      "\u001b[33m                   0          1\u001b[39m\n",
      "\u001b[33m        0   1.000000   4.494400\u001b[39m\n",
      "\u001b[33m        1  11.262736  20.857489\u001b[39m\n",
      "\n",
      "\u001b[33m        But it's better to avoid map in that case.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df ** 2\u001b[39m\n",
      "\u001b[33m                   0          1\u001b[39m\n",
      "\u001b[33m        0   1.000000   4.494400\u001b[39m\n",
      "\u001b[33m        1  11.262736  20.857489\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01min\u001b[39;00m {\u001b[33m\"ignore\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m}:\n",
      "            \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\n",
      "                \u001b[33mf\"na_action must be 'ignore' or None. Got {repr(na_action)}\"\u001b[39m\n",
      "            )\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m self.empty:\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m self.copy()\n",
      "\n",
      "        func = functools.partial(func, **kwargs)\n",
      "\n",
      "        \u001b[38;5;28;01mdef\u001b[39;00m infer(x):\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m x._map_values(func, na_action=na_action)\n",
      "\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m self.apply(infer).__finalize__(self, \u001b[33m\"map\"\u001b[39m)\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m applymap(\n",
      "        self, func: PythonFuncType, na_action: NaAction | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m, **kwargs\n",
      "    ) -> DataFrame:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Apply a function to a Dataframe elementwise.\u001b[39m\n",
      "\n",
      "\u001b[33m        .. deprecated:: 2.1.0\u001b[39m\n",
      "\n",
      "\u001b[33m           DataFrame.applymap has been deprecated. Use DataFrame.map instead.\u001b[39m\n",
      "\n",
      "\u001b[33m        This method applies a function that accepts and returns a scalar\u001b[39m\n",
      "\u001b[33m        to every element of a DataFrame.\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        func : callable\u001b[39m\n",
      "\u001b[33m            Python function, returns a single value from a single value.\u001b[39m\n",
      "\u001b[33m        na_action : {None, 'ignore'}, default None\u001b[39m\n",
      "\u001b[33m            If 'ignore', propagate NaN values, without passing them to func.\u001b[39m\n",
      "\u001b[33m        **kwargs\u001b[39m\n",
      "\u001b[33m            Additional keyword arguments to pass as keywords arguments to\u001b[39m\n",
      "\u001b[33m            `func`.\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        DataFrame\u001b[39m\n",
      "\u001b[33m            Transformed DataFrame.\u001b[39m\n",
      "\n",
      "\u001b[33m        See Also\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        DataFrame.apply : Apply a function along input axis of DataFrame.\u001b[39m\n",
      "\u001b[33m        DataFrame.map : Apply a function along input axis of DataFrame.\u001b[39m\n",
      "\u001b[33m        DataFrame.replace: Replace values given in `to_replace` with `value`.\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        >>> df = pd.DataFrame([[1, 2.12], [3.356, 4.567]])\u001b[39m\n",
      "\u001b[33m        >>> df\u001b[39m\n",
      "\u001b[33m               0      1\u001b[39m\n",
      "\u001b[33m        0  1.000  2.120\u001b[39m\n",
      "\u001b[33m        1  3.356  4.567\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.map(lambda x: len(str(x)))\u001b[39m\n",
      "\u001b[33m           0  1\u001b[39m\n",
      "\u001b[33m        0  3  4\u001b[39m\n",
      "\u001b[33m        1  5  5\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        warnings.warn(\n",
      "            \u001b[33m\"DataFrame.applymap has been deprecated. Use DataFrame.map instead.\"\u001b[39m,\n",
      "            FutureWarning,\n",
      "            stacklevel=find_stack_level(),\n",
      "        )\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m self.map(func, na_action=na_action, **kwargs)\n",
      "\n",
      "    \u001b[38;5;66;03m# ----------------------------------------------------------------------\u001b[39;00m\n",
      "    \u001b[38;5;66;03m# Merging / joining methods\u001b[39;00m\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m _append(\n",
      "        self,\n",
      "        other,\n",
      "        ignore_index: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "        verify_integrity: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "        sort: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "    ) -> DataFrame:\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m isinstance(other, (Series, dict)):\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m isinstance(other, dict):\n",
      "                \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m ignore_index:\n",
      "                    \u001b[38;5;28;01mraise\u001b[39;00m TypeError(\u001b[33m\"Can only append a dict if ignore_index=True\"\u001b[39m)\n",
      "                other = Series(other)\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m other.name \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mand\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m ignore_index:\n",
      "                \u001b[38;5;28;01mraise\u001b[39;00m TypeError(\n",
      "                    \u001b[33m\"Can only append a Series if ignore_index=True \"\u001b[39m\n",
      "                    \u001b[33m\"or if the Series has a name\"\u001b[39m\n",
      "                )\n",
      "\n",
      "            index = Index(\n",
      "                [other.name],\n",
      "                name=self.index.names\n",
      "                \u001b[38;5;28;01mif\u001b[39;00m isinstance(self.index, MultiIndex)\n",
      "                \u001b[38;5;28;01melse\u001b[39;00m self.index.name,\n",
      "            )\n",
      "            row_df = other.to_frame().T\n",
      "            \u001b[38;5;66;03m# infer_objects is needed for\u001b[39;00m\n",
      "            \u001b[38;5;66;03m#  test_append_empty_frame_to_series_with_dateutil_tz\u001b[39;00m\n",
      "            other = row_df.infer_objects(copy=\u001b[38;5;28;01mFalse\u001b[39;00m).rename_axis(\n",
      "                index.names, copy=\u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "            )\n",
      "        \u001b[38;5;28;01melif\u001b[39;00m isinstance(other, list):\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m other:\n",
      "                \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "            \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m isinstance(other[\u001b[32m0\u001b[39m], DataFrame):\n",
      "                other = DataFrame(other)\n",
      "                \u001b[38;5;28;01mif\u001b[39;00m self.index.name \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mand\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m ignore_index:\n",
      "                    other.index.name = self.index.name\n",
      "\n",
      "        \u001b[38;5;28;01mfrom\u001b[39;00m pandas.core.reshape.concat \u001b[38;5;28;01mimport\u001b[39;00m concat\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m isinstance(other, (list, tuple)):\n",
      "            to_concat = [self, *other]\n",
      "        \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "            to_concat = [self, other]\n",
      "\n",
      "        result = concat(\n",
      "            to_concat,\n",
      "            ignore_index=ignore_index,\n",
      "            verify_integrity=verify_integrity,\n",
      "            sort=sort,\n",
      "        )\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m result.__finalize__(self, method=\u001b[33m\"append\"\u001b[39m)\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m join(\n",
      "        self,\n",
      "        other: DataFrame | Series | Iterable[DataFrame | Series],\n",
      "        on: IndexLabel | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        how: MergeHow = \u001b[33m\"left\"\u001b[39m,\n",
      "        lsuffix: str = \u001b[33m\"\"\u001b[39m,\n",
      "        rsuffix: str = \u001b[33m\"\"\u001b[39m,\n",
      "        sort: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "        validate: JoinValidate | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    ) -> DataFrame:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Join columns of another DataFrame.\u001b[39m\n",
      "\n",
      "\u001b[33m        Join columns with `other` DataFrame either on index or on a key\u001b[39m\n",
      "\u001b[33m        column. Efficiently join multiple DataFrame objects by index at once by\u001b[39m\n",
      "\u001b[33m        passing a list.\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        other : DataFrame, Series, or a list containing any combination of them\u001b[39m\n",
      "\u001b[33m            Index should be similar to one of the columns in this one. If a\u001b[39m\n",
      "\u001b[33m            Series is passed, its name attribute must be set, and that will be\u001b[39m\n",
      "\u001b[33m            used as the column name in the resulting joined DataFrame.\u001b[39m\n",
      "\u001b[33m        on : str, list of str, or array-like, optional\u001b[39m\n",
      "\u001b[33m            Column or index level name(s) in the caller to join on the index\u001b[39m\n",
      "\u001b[33m            in `other`, otherwise joins index-on-index. If multiple\u001b[39m\n",
      "\u001b[33m            values given, the `other` DataFrame must have a MultiIndex. Can\u001b[39m\n",
      "\u001b[33m            pass an array as the join key if it is not already contained in\u001b[39m\n",
      "\u001b[33m            the calling DataFrame. Like an Excel VLOOKUP operation.\u001b[39m\n",
      "\u001b[33m        how : {'left', 'right', 'outer', 'inner', 'cross'}, default 'left'\u001b[39m\n",
      "\u001b[33m            How to handle the operation of the two objects.\u001b[39m\n",
      "\n",
      "\u001b[33m            * left: use calling frame's index (or column if on is specified)\u001b[39m\n",
      "\u001b[33m            * right: use `other`'s index.\u001b[39m\n",
      "\u001b[33m            * outer: form union of calling frame's index (or column if on is\u001b[39m\n",
      "\u001b[33m              specified) with `other`'s index, and sort it lexicographically.\u001b[39m\n",
      "\u001b[33m            * inner: form intersection of calling frame's index (or column if\u001b[39m\n",
      "\u001b[33m              on is specified) with `other`'s index, preserving the order\u001b[39m\n",
      "\u001b[33m              of the calling's one.\u001b[39m\n",
      "\u001b[33m            * cross: creates the cartesian product from both frames, preserves the order\u001b[39m\n",
      "\u001b[33m              of the left keys.\u001b[39m\n",
      "\u001b[33m        lsuffix : str, default ''\u001b[39m\n",
      "\u001b[33m            Suffix to use from left frame's overlapping columns.\u001b[39m\n",
      "\u001b[33m        rsuffix : str, default ''\u001b[39m\n",
      "\u001b[33m            Suffix to use from right frame's overlapping columns.\u001b[39m\n",
      "\u001b[33m        sort : bool, default False\u001b[39m\n",
      "\u001b[33m            Order result DataFrame lexicographically by the join key. If False,\u001b[39m\n",
      "\u001b[33m            the order of the join key depends on the join type (how keyword).\u001b[39m\n",
      "\u001b[33m        validate : str, optional\u001b[39m\n",
      "\u001b[33m            If specified, checks if join is of specified type.\u001b[39m\n",
      "\n",
      "\u001b[33m            * \"one_to_one\" or \"1:1\": check if join keys are unique in both left\u001b[39m\n",
      "\u001b[33m              and right datasets.\u001b[39m\n",
      "\u001b[33m            * \"one_to_many\" or \"1:m\": check if join keys are unique in left dataset.\u001b[39m\n",
      "\u001b[33m            * \"many_to_one\" or \"m:1\": check if join keys are unique in right dataset.\u001b[39m\n",
      "\u001b[33m            * \"many_to_many\" or \"m:m\": allowed, but does not result in checks.\u001b[39m\n",
      "\n",
      "\u001b[33m            .. versionadded:: 1.5.0\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        DataFrame\u001b[39m\n",
      "\u001b[33m            A dataframe containing columns from both the caller and `other`.\u001b[39m\n",
      "\n",
      "\u001b[33m        See Also\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        DataFrame.merge : For column(s)-on-column(s) operations.\u001b[39m\n",
      "\n",
      "\u001b[33m        Notes\u001b[39m\n",
      "\u001b[33m        -----\u001b[39m\n",
      "\u001b[33m        Parameters `on`, `lsuffix`, and `rsuffix` are not supported when\u001b[39m\n",
      "\u001b[33m        passing a list of `DataFrame` objects.\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        >>> df = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3', 'K4', 'K5'],\u001b[39m\n",
      "\u001b[33m        ...                    'A': ['A0', 'A1', 'A2', 'A3', 'A4', 'A5']})\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df\u001b[39m\n",
      "\u001b[33m          key   A\u001b[39m\n",
      "\u001b[33m        0  K0  A0\u001b[39m\n",
      "\u001b[33m        1  K1  A1\u001b[39m\n",
      "\u001b[33m        2  K2  A2\u001b[39m\n",
      "\u001b[33m        3  K3  A3\u001b[39m\n",
      "\u001b[33m        4  K4  A4\u001b[39m\n",
      "\u001b[33m        5  K5  A5\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> other = pd.DataFrame({'key': ['K0', 'K1', 'K2'],\u001b[39m\n",
      "\u001b[33m        ...                       'B': ['B0', 'B1', 'B2']})\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> other\u001b[39m\n",
      "\u001b[33m          key   B\u001b[39m\n",
      "\u001b[33m        0  K0  B0\u001b[39m\n",
      "\u001b[33m        1  K1  B1\u001b[39m\n",
      "\u001b[33m        2  K2  B2\u001b[39m\n",
      "\n",
      "\u001b[33m        Join DataFrames using their indexes.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.join(other, lsuffix='_caller', rsuffix='_other')\u001b[39m\n",
      "\u001b[33m          key_caller   A key_other    B\u001b[39m\n",
      "\u001b[33m        0         K0  A0        K0   B0\u001b[39m\n",
      "\u001b[33m        1         K1  A1        K1   B1\u001b[39m\n",
      "\u001b[33m        2         K2  A2        K2   B2\u001b[39m\n",
      "\u001b[33m        3         K3  A3       NaN  NaN\u001b[39m\n",
      "\u001b[33m        4         K4  A4       NaN  NaN\u001b[39m\n",
      "\u001b[33m        5         K5  A5       NaN  NaN\u001b[39m\n",
      "\n",
      "\u001b[33m        If we want to join using the key columns, we need to set key to be\u001b[39m\n",
      "\u001b[33m        the index in both `df` and `other`. The joined DataFrame will have\u001b[39m\n",
      "\u001b[33m        key as its index.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.set_index('key').join(other.set_index('key'))\u001b[39m\n",
      "\u001b[33m              A    B\u001b[39m\n",
      "\u001b[33m        key\u001b[39m\n",
      "\u001b[33m        K0   A0   B0\u001b[39m\n",
      "\u001b[33m        K1   A1   B1\u001b[39m\n",
      "\u001b[33m        K2   A2   B2\u001b[39m\n",
      "\u001b[33m        K3   A3  NaN\u001b[39m\n",
      "\u001b[33m        K4   A4  NaN\u001b[39m\n",
      "\u001b[33m        K5   A5  NaN\u001b[39m\n",
      "\n",
      "\u001b[33m        Another option to join using the key columns is to use the `on`\u001b[39m\n",
      "\u001b[33m        parameter. DataFrame.join always uses `other`'s index but we can use\u001b[39m\n",
      "\u001b[33m        any column in `df`. This method preserves the original DataFrame's\u001b[39m\n",
      "\u001b[33m        index in the result.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.join(other.set_index('key'), on='key')\u001b[39m\n",
      "\u001b[33m          key   A    B\u001b[39m\n",
      "\u001b[33m        0  K0  A0   B0\u001b[39m\n",
      "\u001b[33m        1  K1  A1   B1\u001b[39m\n",
      "\u001b[33m        2  K2  A2   B2\u001b[39m\n",
      "\u001b[33m        3  K3  A3  NaN\u001b[39m\n",
      "\u001b[33m        4  K4  A4  NaN\u001b[39m\n",
      "\u001b[33m        5  K5  A5  NaN\u001b[39m\n",
      "\n",
      "\u001b[33m        Using non-unique key values shows how they are matched.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df = pd.DataFrame({'key': ['K0', 'K1', 'K1', 'K3', 'K0', 'K1'],\u001b[39m\n",
      "\u001b[33m        ...                    'A': ['A0', 'A1', 'A2', 'A3', 'A4', 'A5']})\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df\u001b[39m\n",
      "\u001b[33m          key   A\u001b[39m\n",
      "\u001b[33m        0  K0  A0\u001b[39m\n",
      "\u001b[33m        1  K1  A1\u001b[39m\n",
      "\u001b[33m        2  K1  A2\u001b[39m\n",
      "\u001b[33m        3  K3  A3\u001b[39m\n",
      "\u001b[33m        4  K0  A4\u001b[39m\n",
      "\u001b[33m        5  K1  A5\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.join(other.set_index('key'), on='key', validate='m:1')\u001b[39m\n",
      "\u001b[33m          key   A    B\u001b[39m\n",
      "\u001b[33m        0  K0  A0   B0\u001b[39m\n",
      "\u001b[33m        1  K1  A1   B1\u001b[39m\n",
      "\u001b[33m        2  K1  A2   B1\u001b[39m\n",
      "\u001b[33m        3  K3  A3  NaN\u001b[39m\n",
      "\u001b[33m        4  K0  A4   B0\u001b[39m\n",
      "\u001b[33m        5  K1  A5   B1\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;28;01mfrom\u001b[39;00m pandas.core.reshape.concat \u001b[38;5;28;01mimport\u001b[39;00m concat\n",
      "        \u001b[38;5;28;01mfrom\u001b[39;00m pandas.core.reshape.merge \u001b[38;5;28;01mimport\u001b[39;00m merge\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m isinstance(other, Series):\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m other.name \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "                \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\u001b[33m\"Other Series must have a name\"\u001b[39m)\n",
      "            other = DataFrame({other.name: other})\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m isinstance(other, DataFrame):\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m how == \u001b[33m\"cross\"\u001b[39m:\n",
      "                \u001b[38;5;28;01mreturn\u001b[39;00m merge(\n",
      "                    self,\n",
      "                    other,\n",
      "                    how=how,\n",
      "                    on=on,\n",
      "                    suffixes=(lsuffix, rsuffix),\n",
      "                    sort=sort,\n",
      "                    validate=validate,\n",
      "                )\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m merge(\n",
      "                self,\n",
      "                other,\n",
      "                left_on=on,\n",
      "                how=how,\n",
      "                left_index=on \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "                right_index=\u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "                suffixes=(lsuffix, rsuffix),\n",
      "                sort=sort,\n",
      "                validate=validate,\n",
      "            )\n",
      "        \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m on \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "                \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\n",
      "                    \u001b[33m\"Joining multiple DataFrames only supported for joining on index\"\u001b[39m\n",
      "                )\n",
      "\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m rsuffix \u001b[38;5;28;01mor\u001b[39;00m lsuffix:\n",
      "                \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\n",
      "                    \u001b[33m\"Suffixes not supported when joining multiple DataFrames\"\u001b[39m\n",
      "                )\n",
      "\n",
      "            \u001b[38;5;66;03m# Mypy thinks the RHS is a\u001b[39;00m\n",
      "            \u001b[38;5;66;03m# \"Union[DataFrame, Series, Iterable[Union[DataFrame, Series]]]\" whereas\u001b[39;00m\n",
      "            \u001b[38;5;66;03m# the LHS is an \"Iterable[DataFrame]\", but in reality both types are\u001b[39;00m\n",
      "            \u001b[38;5;66;03m# \"Iterable[Union[DataFrame, Series]]\" due to the if statements\u001b[39;00m\n",
      "            frames = [cast(\u001b[33m\"DataFrame | Series\"\u001b[39m, self)] + list(other)\n",
      "\n",
      "            can_concat = all(df.index.is_unique \u001b[38;5;28;01mfor\u001b[39;00m df \u001b[38;5;28;01min\u001b[39;00m frames)\n",
      "\n",
      "            \u001b[38;5;66;03m# join indexes only using concat\u001b[39;00m\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m can_concat:\n",
      "                \u001b[38;5;28;01mif\u001b[39;00m how == \u001b[33m\"left\"\u001b[39m:\n",
      "                    res = concat(\n",
      "                        frames, axis=\u001b[32m1\u001b[39m, join=\u001b[33m\"outer\"\u001b[39m, verify_integrity=\u001b[38;5;28;01mTrue\u001b[39;00m, sort=sort\n",
      "                    )\n",
      "                    \u001b[38;5;28;01mreturn\u001b[39;00m res.reindex(self.index, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "                \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "                    \u001b[38;5;28;01mreturn\u001b[39;00m concat(\n",
      "                        frames, axis=\u001b[32m1\u001b[39m, join=how, verify_integrity=\u001b[38;5;28;01mTrue\u001b[39;00m, sort=sort\n",
      "                    )\n",
      "\n",
      "            joined = frames[\u001b[32m0\u001b[39m]\n",
      "\n",
      "            \u001b[38;5;28;01mfor\u001b[39;00m frame \u001b[38;5;28;01min\u001b[39;00m frames[\u001b[32m1\u001b[39m:]:\n",
      "                joined = merge(\n",
      "                    joined,\n",
      "                    frame,\n",
      "                    how=how,\n",
      "                    left_index=\u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "                    right_index=\u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "                    validate=validate,\n",
      "                )\n",
      "\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m joined\n",
      "\n",
      "    @Substitution(\u001b[33m\"\"\u001b[39m)\n",
      "    @Appender(_merge_doc, indents=\u001b[32m2\u001b[39m)\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m merge(\n",
      "        self,\n",
      "        right: DataFrame | Series,\n",
      "        how: MergeHow = \u001b[33m\"inner\"\u001b[39m,\n",
      "        on: IndexLabel | AnyArrayLike | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        left_on: IndexLabel | AnyArrayLike | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        right_on: IndexLabel | AnyArrayLike | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        left_index: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "        right_index: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "        sort: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "        suffixes: Suffixes = (\u001b[33m\"_x\"\u001b[39m, \u001b[33m\"_y\"\u001b[39m),\n",
      "        copy: bool | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        indicator: str | bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "        validate: MergeValidate | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    ) -> DataFrame:\n",
      "        \u001b[38;5;28;01mfrom\u001b[39;00m pandas.core.reshape.merge \u001b[38;5;28;01mimport\u001b[39;00m merge\n",
      "\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m merge(\n",
      "            self,\n",
      "            right,\n",
      "            how=how,\n",
      "            on=on,\n",
      "            left_on=left_on,\n",
      "            right_on=right_on,\n",
      "            left_index=left_index,\n",
      "            right_index=right_index,\n",
      "            sort=sort,\n",
      "            suffixes=suffixes,\n",
      "            copy=copy,\n",
      "            indicator=indicator,\n",
      "            validate=validate,\n",
      "        )\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m round(\n",
      "        self, decimals: int | dict[IndexLabel, int] | Series = \u001b[32m0\u001b[39m, *args, **kwargs\n",
      "    ) -> DataFrame:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Round a DataFrame to a variable number of decimal places.\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        decimals : int, dict, Series\u001b[39m\n",
      "\u001b[33m            Number of decimal places to round each column to. If an int is\u001b[39m\n",
      "\u001b[33m            given, round each column to the same number of places.\u001b[39m\n",
      "\u001b[33m            Otherwise dict and Series round to variable numbers of places.\u001b[39m\n",
      "\u001b[33m            Column names should be in the keys if `decimals` is a\u001b[39m\n",
      "\u001b[33m            dict-like, or in the index if `decimals` is a Series. Any\u001b[39m\n",
      "\u001b[33m            columns not included in `decimals` will be left as is. Elements\u001b[39m\n",
      "\u001b[33m            of `decimals` which are not columns of the input will be\u001b[39m\n",
      "\u001b[33m            ignored.\u001b[39m\n",
      "\u001b[33m        *args\u001b[39m\n",
      "\u001b[33m            Additional keywords have no effect but might be accepted for\u001b[39m\n",
      "\u001b[33m            compatibility with numpy.\u001b[39m\n",
      "\u001b[33m        **kwargs\u001b[39m\n",
      "\u001b[33m            Additional keywords have no effect but might be accepted for\u001b[39m\n",
      "\u001b[33m            compatibility with numpy.\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        DataFrame\u001b[39m\n",
      "\u001b[33m            A DataFrame with the affected columns rounded to the specified\u001b[39m\n",
      "\u001b[33m            number of decimal places.\u001b[39m\n",
      "\n",
      "\u001b[33m        See Also\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        numpy.around : Round a numpy array to the given number of decimals.\u001b[39m\n",
      "\u001b[33m        Series.round : Round a Series to the given number of decimals.\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        >>> df = pd.DataFrame([(.21, .32), (.01, .67), (.66, .03), (.21, .18)],\u001b[39m\n",
      "\u001b[33m        ...                   columns=['dogs', 'cats'])\u001b[39m\n",
      "\u001b[33m        >>> df\u001b[39m\n",
      "\u001b[33m            dogs  cats\u001b[39m\n",
      "\u001b[33m        0  0.21  0.32\u001b[39m\n",
      "\u001b[33m        1  0.01  0.67\u001b[39m\n",
      "\u001b[33m        2  0.66  0.03\u001b[39m\n",
      "\u001b[33m        3  0.21  0.18\u001b[39m\n",
      "\n",
      "\u001b[33m        By providing an integer each column is rounded to the same number\u001b[39m\n",
      "\u001b[33m        of decimal places\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.round(1)\u001b[39m\n",
      "\u001b[33m            dogs  cats\u001b[39m\n",
      "\u001b[33m        0   0.2   0.3\u001b[39m\n",
      "\u001b[33m        1   0.0   0.7\u001b[39m\n",
      "\u001b[33m        2   0.7   0.0\u001b[39m\n",
      "\u001b[33m        3   0.2   0.2\u001b[39m\n",
      "\n",
      "\u001b[33m        With a dict, the number of places for specific columns can be\u001b[39m\n",
      "\u001b[33m        specified with the column names as key and the number of decimal\u001b[39m\n",
      "\u001b[33m        places as value\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.round({'dogs': 1, 'cats': 0})\u001b[39m\n",
      "\u001b[33m            dogs  cats\u001b[39m\n",
      "\u001b[33m        0   0.2   0.0\u001b[39m\n",
      "\u001b[33m        1   0.0   1.0\u001b[39m\n",
      "\u001b[33m        2   0.7   0.0\u001b[39m\n",
      "\u001b[33m        3   0.2   0.0\u001b[39m\n",
      "\n",
      "\u001b[33m        Using a Series, the number of places for specific columns can be\u001b[39m\n",
      "\u001b[33m        specified with the column names as index and the number of\u001b[39m\n",
      "\u001b[33m        decimal places as value\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> decimals = pd.Series([0, 1], index=['cats', 'dogs'])\u001b[39m\n",
      "\u001b[33m        >>> df.round(decimals)\u001b[39m\n",
      "\u001b[33m            dogs  cats\u001b[39m\n",
      "\u001b[33m        0   0.2   0.0\u001b[39m\n",
      "\u001b[33m        1   0.0   1.0\u001b[39m\n",
      "\u001b[33m        2   0.7   0.0\u001b[39m\n",
      "\u001b[33m        3   0.2   0.0\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;28;01mfrom\u001b[39;00m pandas.core.reshape.concat \u001b[38;5;28;01mimport\u001b[39;00m concat\n",
      "\n",
      "        \u001b[38;5;28;01mdef\u001b[39;00m _dict_round(df: DataFrame, decimals):\n",
      "            \u001b[38;5;28;01mfor\u001b[39;00m col, vals \u001b[38;5;28;01min\u001b[39;00m df.items():\n",
      "                \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "                    \u001b[38;5;28;01myield\u001b[39;00m _series_round(vals, decimals[col])\n",
      "                \u001b[38;5;28;01mexcept\u001b[39;00m KeyError:\n",
      "                    \u001b[38;5;28;01myield\u001b[39;00m vals\n",
      "\n",
      "        \u001b[38;5;28;01mdef\u001b[39;00m _series_round(ser: Series, decimals: int) -> Series:\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m is_integer_dtype(ser.dtype) \u001b[38;5;28;01mor\u001b[39;00m is_float_dtype(ser.dtype):\n",
      "                \u001b[38;5;28;01mreturn\u001b[39;00m ser.round(decimals)\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m ser\n",
      "\n",
      "        nv.validate_round(args, kwargs)\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m isinstance(decimals, (dict, Series)):\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m isinstance(decimals, Series) \u001b[38;5;28;01mand\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m decimals.index.is_unique:\n",
      "                \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\u001b[33m\"Index of decimals must be unique\"\u001b[39m)\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m is_dict_like(decimals) \u001b[38;5;28;01mand\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m all(\n",
      "                is_integer(value) \u001b[38;5;28;01mfor\u001b[39;00m _, value \u001b[38;5;28;01min\u001b[39;00m decimals.items()\n",
      "            ):\n",
      "                \u001b[38;5;28;01mraise\u001b[39;00m TypeError(\u001b[33m\"Values in decimals must be integers\"\u001b[39m)\n",
      "            new_cols = list(_dict_round(self, decimals))\n",
      "        \u001b[38;5;28;01melif\u001b[39;00m is_integer(decimals):\n",
      "            \u001b[38;5;66;03m# Dispatch to Block.round\u001b[39;00m\n",
      "            \u001b[38;5;66;03m# Argument \"decimals\" to \"round\" of \"BaseBlockManager\" has incompatible\u001b[39;00m\n",
      "            \u001b[38;5;66;03m# type \"Union[int, integer[Any]]\"; expected \"int\"\u001b[39;00m\n",
      "            new_mgr = self._mgr.round(\n",
      "                decimals=decimals,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "                using_cow=using_copy_on_write(),\n",
      "            )\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m self._constructor_from_mgr(new_mgr, axes=new_mgr.axes).__finalize__(\n",
      "                self, method=\u001b[33m\"round\"\u001b[39m\n",
      "            )\n",
      "        \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "            \u001b[38;5;28;01mraise\u001b[39;00m TypeError(\u001b[33m\"decimals must be an integer, a dict-like or a Series\"\u001b[39m)\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m new_cols \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mand\u001b[39;00m len(new_cols) > \u001b[32m0\u001b[39m:\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m self._constructor(\n",
      "                concat(new_cols, axis=\u001b[32m1\u001b[39m), index=self.index, columns=self.columns\n",
      "            ).__finalize__(self, method=\u001b[33m\"round\"\u001b[39m)\n",
      "        \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m self.copy(deep=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\n",
      "    \u001b[38;5;66;03m# ----------------------------------------------------------------------\u001b[39;00m\n",
      "    \u001b[38;5;66;03m# Statistical methods, etc.\u001b[39;00m\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m corr(\n",
      "        self,\n",
      "        method: CorrelationMethod = \u001b[33m\"pearson\"\u001b[39m,\n",
      "        min_periods: int = \u001b[32m1\u001b[39m,\n",
      "        numeric_only: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "    ) -> DataFrame:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Compute pairwise correlation of columns, excluding NA/null values.\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        method : {'pearson', 'kendall', 'spearman'} or callable\u001b[39m\n",
      "\u001b[33m            Method of correlation:\u001b[39m\n",
      "\n",
      "\u001b[33m            * pearson : standard correlation coefficient\u001b[39m\n",
      "\u001b[33m            * kendall : Kendall Tau correlation coefficient\u001b[39m\n",
      "\u001b[33m            * spearman : Spearman rank correlation\u001b[39m\n",
      "\u001b[33m            * callable: callable with input two 1d ndarrays\u001b[39m\n",
      "\u001b[33m                and returning a float. Note that the returned matrix from corr\u001b[39m\n",
      "\u001b[33m                will have 1 along the diagonals and will be symmetric\u001b[39m\n",
      "\u001b[33m                regardless of the callable's behavior.\u001b[39m\n",
      "\u001b[33m        min_periods : int, optional\u001b[39m\n",
      "\u001b[33m            Minimum number of observations required per pair of columns\u001b[39m\n",
      "\u001b[33m            to have a valid result. Currently only available for Pearson\u001b[39m\n",
      "\u001b[33m            and Spearman correlation.\u001b[39m\n",
      "\u001b[33m        numeric_only : bool, default False\u001b[39m\n",
      "\u001b[33m            Include only `float`, `int` or `boolean` data.\u001b[39m\n",
      "\n",
      "\u001b[33m            .. versionadded:: 1.5.0\u001b[39m\n",
      "\n",
      "\u001b[33m            .. versionchanged:: 2.0.0\u001b[39m\n",
      "\u001b[33m                The default value of ``numeric_only`` is now ``False``.\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        DataFrame\u001b[39m\n",
      "\u001b[33m            Correlation matrix.\u001b[39m\n",
      "\n",
      "\u001b[33m        See Also\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        DataFrame.corrwith : Compute pairwise correlation with another\u001b[39m\n",
      "\u001b[33m            DataFrame or Series.\u001b[39m\n",
      "\u001b[33m        Series.corr : Compute the correlation between two Series.\u001b[39m\n",
      "\n",
      "\u001b[33m        Notes\u001b[39m\n",
      "\u001b[33m        -----\u001b[39m\n",
      "\u001b[33m        Pearson, Kendall and Spearman correlation are currently computed using pairwise complete observations.\u001b[39m\n",
      "\n",
      "\u001b[33m        * `Pearson correlation coefficient <https://en.wikipedia.org/wiki/Pearson_correlation_coefficient>`_\u001b[39m\n",
      "\u001b[33m        * `Kendall rank correlation coefficient <https://en.wikipedia.org/wiki/Kendall_rank_correlation_coefficient>`_\u001b[39m\n",
      "\u001b[33m        * `Spearman's rank correlation coefficient <https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient>`_\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        >>> def histogram_intersection(a, b):\u001b[39m\n",
      "\u001b[33m        ...     v = np.minimum(a, b).sum().round(decimals=1)\u001b[39m\n",
      "\u001b[33m        ...     return v\u001b[39m\n",
      "\u001b[33m        >>> df = pd.DataFrame([(.2, .3), (.0, .6), (.6, .0), (.2, .1)],\u001b[39m\n",
      "\u001b[33m        ...                   columns=['dogs', 'cats'])\u001b[39m\n",
      "\u001b[33m        >>> df.corr(method=histogram_intersection)\u001b[39m\n",
      "\u001b[33m              dogs  cats\u001b[39m\n",
      "\u001b[33m        dogs   1.0   0.3\u001b[39m\n",
      "\u001b[33m        cats   0.3   1.0\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df = pd.DataFrame([(1, 1), (2, np.nan), (np.nan, 3), (4, 4)],\u001b[39m\n",
      "\u001b[33m        ...                   columns=['dogs', 'cats'])\u001b[39m\n",
      "\u001b[33m        >>> df.corr(min_periods=3)\u001b[39m\n",
      "\u001b[33m              dogs  cats\u001b[39m\n",
      "\u001b[33m        dogs   1.0   NaN\u001b[39m\n",
      "\u001b[33m        cats   NaN   1.0\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n",
      "        data = self._get_numeric_data() \u001b[38;5;28;01mif\u001b[39;00m numeric_only \u001b[38;5;28;01melse\u001b[39;00m self\n",
      "        cols = data.columns\n",
      "        idx = cols.copy()\n",
      "        mat = data.to_numpy(dtype=float, na_value=np.nan, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m method == \u001b[33m\"pearson\"\u001b[39m:\n",
      "            correl = libalgos.nancorr(mat, minp=min_periods)\n",
      "        \u001b[38;5;28;01melif\u001b[39;00m method == \u001b[33m\"spearman\"\u001b[39m:\n",
      "            correl = libalgos.nancorr_spearman(mat, minp=min_periods)\n",
      "        \u001b[38;5;28;01melif\u001b[39;00m method == \u001b[33m\"kendall\"\u001b[39m \u001b[38;5;28;01mor\u001b[39;00m callable(method):\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m min_periods \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "                min_periods = \u001b[32m1\u001b[39m\n",
      "            mat = mat.T\n",
      "            corrf = nanops.get_corr_func(method)\n",
      "            K = len(cols)\n",
      "            correl = np.empty((K, K), dtype=float)\n",
      "            mask = np.isfinite(mat)\n",
      "            \u001b[38;5;28;01mfor\u001b[39;00m i, ac \u001b[38;5;28;01min\u001b[39;00m enumerate(mat):\n",
      "                \u001b[38;5;28;01mfor\u001b[39;00m j, bc \u001b[38;5;28;01min\u001b[39;00m enumerate(mat):\n",
      "                    \u001b[38;5;28;01mif\u001b[39;00m i > j:\n",
      "                        \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\n",
      "                    valid = mask[i] & mask[j]\n",
      "                    \u001b[38;5;28;01mif\u001b[39;00m valid.sum() < min_periods:\n",
      "                        c = np.nan\n",
      "                    \u001b[38;5;28;01melif\u001b[39;00m i == j:\n",
      "                        c = \u001b[32m1.0\u001b[39m\n",
      "                    \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m valid.all():\n",
      "                        c = corrf(ac[valid], bc[valid])\n",
      "                    \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "                        c = corrf(ac, bc)\n",
      "                    correl[i, j] = c\n",
      "                    correl[j, i] = c\n",
      "        \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "            \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\n",
      "                \u001b[33m\"method must be either 'pearson', \"\u001b[39m\n",
      "                \u001b[33m\"'spearman', 'kendall', or a callable, \"\u001b[39m\n",
      "                \u001b[33mf\"'{method}' was supplied\"\u001b[39m\n",
      "            )\n",
      "\n",
      "        result = self._constructor(correl, index=idx, columns=cols, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m result.__finalize__(self, method=\u001b[33m\"corr\"\u001b[39m)\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m cov(\n",
      "        self,\n",
      "        min_periods: int | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        ddof: int | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[32m1\u001b[39m,\n",
      "        numeric_only: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "    ) -> DataFrame:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Compute pairwise covariance of columns, excluding NA/null values.\u001b[39m\n",
      "\n",
      "\u001b[33m        Compute the pairwise covariance among the series of a DataFrame.\u001b[39m\n",
      "\u001b[33m        The returned data frame is the `covariance matrix\u001b[39m\n",
      "\u001b[33m        <https://en.wikipedia.org/wiki/Covariance_matrix>`__ of the columns\u001b[39m\n",
      "\u001b[33m        of the DataFrame.\u001b[39m\n",
      "\n",
      "\u001b[33m        Both NA and null values are automatically excluded from the\u001b[39m\n",
      "\u001b[33m        calculation. (See the note below about bias from missing values.)\u001b[39m\n",
      "\u001b[33m        A threshold can be set for the minimum number of\u001b[39m\n",
      "\u001b[33m        observations for each value created. Comparisons with observations\u001b[39m\n",
      "\u001b[33m        below this threshold will be returned as ``NaN``.\u001b[39m\n",
      "\n",
      "\u001b[33m        This method is generally used for the analysis of time series data to\u001b[39m\n",
      "\u001b[33m        understand the relationship between different measures\u001b[39m\n",
      "\u001b[33m        across time.\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        min_periods : int, optional\u001b[39m\n",
      "\u001b[33m            Minimum number of observations required per pair of columns\u001b[39m\n",
      "\u001b[33m            to have a valid result.\u001b[39m\n",
      "\n",
      "\u001b[33m        ddof : int, default 1\u001b[39m\n",
      "\u001b[33m            Delta degrees of freedom.  The divisor used in calculations\u001b[39m\n",
      "\u001b[33m            is ``N - ddof``, where ``N`` represents the number of elements.\u001b[39m\n",
      "\u001b[33m            This argument is applicable only when no ``nan`` is in the dataframe.\u001b[39m\n",
      "\n",
      "\u001b[33m        numeric_only : bool, default False\u001b[39m\n",
      "\u001b[33m            Include only `float`, `int` or `boolean` data.\u001b[39m\n",
      "\n",
      "\u001b[33m            .. versionadded:: 1.5.0\u001b[39m\n",
      "\n",
      "\u001b[33m            .. versionchanged:: 2.0.0\u001b[39m\n",
      "\u001b[33m                The default value of ``numeric_only`` is now ``False``.\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        DataFrame\u001b[39m\n",
      "\u001b[33m            The covariance matrix of the series of the DataFrame.\u001b[39m\n",
      "\n",
      "\u001b[33m        See Also\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        Series.cov : Compute covariance with another Series.\u001b[39m\n",
      "\u001b[33m        core.window.ewm.ExponentialMovingWindow.cov : Exponential weighted sample\u001b[39m\n",
      "\u001b[33m            covariance.\u001b[39m\n",
      "\u001b[33m        core.window.expanding.Expanding.cov : Expanding sample covariance.\u001b[39m\n",
      "\u001b[33m        core.window.rolling.Rolling.cov : Rolling sample covariance.\u001b[39m\n",
      "\n",
      "\u001b[33m        Notes\u001b[39m\n",
      "\u001b[33m        -----\u001b[39m\n",
      "\u001b[33m        Returns the covariance matrix of the DataFrame's time series.\u001b[39m\n",
      "\u001b[33m        The covariance is normalized by N-ddof.\u001b[39m\n",
      "\n",
      "\u001b[33m        For DataFrames that have Series that are missing data (assuming that\u001b[39m\n",
      "\u001b[33m        data is `missing at random\u001b[39m\n",
      "\u001b[33m        <https://en.wikipedia.org/wiki/Missing_data#Missing_at_random>`__)\u001b[39m\n",
      "\u001b[33m        the returned covariance matrix will be an unbiased estimate\u001b[39m\n",
      "\u001b[33m        of the variance and covariance between the member Series.\u001b[39m\n",
      "\n",
      "\u001b[33m        However, for many applications this estimate may not be acceptable\u001b[39m\n",
      "\u001b[33m        because the estimate covariance matrix is not guaranteed to be positive\u001b[39m\n",
      "\u001b[33m        semi-definite. This could lead to estimate correlations having\u001b[39m\n",
      "\u001b[33m        absolute values which are greater than one, and/or a non-invertible\u001b[39m\n",
      "\u001b[33m        covariance matrix. See `Estimation of covariance matrices\u001b[39m\n",
      "\u001b[33m        <https://en.wikipedia.org/w/index.php?title=Estimation_of_covariance_\u001b[39m\n",
      "\u001b[33m        matrices>`__ for more details.\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        >>> df = pd.DataFrame([(1, 2), (0, 3), (2, 0), (1, 1)],\u001b[39m\n",
      "\u001b[33m        ...                   columns=['dogs', 'cats'])\u001b[39m\n",
      "\u001b[33m        >>> df.cov()\u001b[39m\n",
      "\u001b[33m                  dogs      cats\u001b[39m\n",
      "\u001b[33m        dogs  0.666667 -1.000000\u001b[39m\n",
      "\u001b[33m        cats -1.000000  1.666667\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> np.random.seed(42)\u001b[39m\n",
      "\u001b[33m        >>> df = pd.DataFrame(np.random.randn(1000, 5),\u001b[39m\n",
      "\u001b[33m        ...                   columns=['a', 'b', 'c', 'd', 'e'])\u001b[39m\n",
      "\u001b[33m        >>> df.cov()\u001b[39m\n",
      "\u001b[33m                  a         b         c         d         e\u001b[39m\n",
      "\u001b[33m        a  0.998438 -0.020161  0.059277 -0.008943  0.014144\u001b[39m\n",
      "\u001b[33m        b -0.020161  1.059352 -0.008543 -0.024738  0.009826\u001b[39m\n",
      "\u001b[33m        c  0.059277 -0.008543  1.010670 -0.001486 -0.000271\u001b[39m\n",
      "\u001b[33m        d -0.008943 -0.024738 -0.001486  0.921297 -0.013692\u001b[39m\n",
      "\u001b[33m        e  0.014144  0.009826 -0.000271 -0.013692  0.977795\u001b[39m\n",
      "\n",
      "\u001b[33m        **Minimum number of periods**\u001b[39m\n",
      "\n",
      "\u001b[33m        This method also supports an optional ``min_periods`` keyword\u001b[39m\n",
      "\u001b[33m        that specifies the required minimum number of non-NA observations for\u001b[39m\n",
      "\u001b[33m        each column pair in order to have a valid result:\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> np.random.seed(42)\u001b[39m\n",
      "\u001b[33m        >>> df = pd.DataFrame(np.random.randn(20, 3),\u001b[39m\n",
      "\u001b[33m        ...                   columns=['a', 'b', 'c'])\u001b[39m\n",
      "\u001b[33m        >>> df.loc[df.index[:5], 'a'] = np.nan\u001b[39m\n",
      "\u001b[33m        >>> df.loc[df.index[5:10], 'b'] = np.nan\u001b[39m\n",
      "\u001b[33m        >>> df.cov(min_periods=12)\u001b[39m\n",
      "\u001b[33m                  a         b         c\u001b[39m\n",
      "\u001b[33m        a  0.316741       NaN -0.150812\u001b[39m\n",
      "\u001b[33m        b       NaN  1.248003  0.191417\u001b[39m\n",
      "\u001b[33m        c -0.150812  0.191417  0.895202\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        data = self._get_numeric_data() \u001b[38;5;28;01mif\u001b[39;00m numeric_only \u001b[38;5;28;01melse\u001b[39;00m self\n",
      "        cols = data.columns\n",
      "        idx = cols.copy()\n",
      "        mat = data.to_numpy(dtype=float, na_value=np.nan, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m notna(mat).all():\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m min_periods \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mand\u001b[39;00m min_periods > len(mat):\n",
      "                base_cov = np.empty((mat.shape[\u001b[32m1\u001b[39m], mat.shape[\u001b[32m1\u001b[39m]))\n",
      "                base_cov.fill(np.nan)\n",
      "            \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "                base_cov = np.cov(mat.T, ddof=ddof)\n",
      "            base_cov = base_cov.reshape((len(cols), len(cols)))\n",
      "        \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "            base_cov = libalgos.nancorr(mat, cov=\u001b[38;5;28;01mTrue\u001b[39;00m, minp=min_periods)\n",
      "\n",
      "        result = self._constructor(base_cov, index=idx, columns=cols, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m result.__finalize__(self, method=\u001b[33m\"cov\"\u001b[39m)\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m corrwith(\n",
      "        self,\n",
      "        other: DataFrame | Series,\n",
      "        axis: Axis = \u001b[32m0\u001b[39m,\n",
      "        drop: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "        method: CorrelationMethod = \u001b[33m\"pearson\"\u001b[39m,\n",
      "        numeric_only: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "    ) -> Series:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Compute pairwise correlation.\u001b[39m\n",
      "\n",
      "\u001b[33m        Pairwise correlation is computed between rows or columns of\u001b[39m\n",
      "\u001b[33m        DataFrame with rows or columns of Series or DataFrame. DataFrames\u001b[39m\n",
      "\u001b[33m        are first aligned along both axes before computing the\u001b[39m\n",
      "\u001b[33m        correlations.\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        other : DataFrame, Series\u001b[39m\n",
      "\u001b[33m            Object with which to compute correlations.\u001b[39m\n",
      "\u001b[33m        axis : {0 or 'index', 1 or 'columns'}, default 0\u001b[39m\n",
      "\u001b[33m            The axis to use. 0 or 'index' to compute row-wise, 1 or 'columns' for\u001b[39m\n",
      "\u001b[33m            column-wise.\u001b[39m\n",
      "\u001b[33m        drop : bool, default False\u001b[39m\n",
      "\u001b[33m            Drop missing indices from result.\u001b[39m\n",
      "\u001b[33m        method : {'pearson', 'kendall', 'spearman'} or callable\u001b[39m\n",
      "\u001b[33m            Method of correlation:\u001b[39m\n",
      "\n",
      "\u001b[33m            * pearson : standard correlation coefficient\u001b[39m\n",
      "\u001b[33m            * kendall : Kendall Tau correlation coefficient\u001b[39m\n",
      "\u001b[33m            * spearman : Spearman rank correlation\u001b[39m\n",
      "\u001b[33m            * callable: callable with input two 1d ndarrays\u001b[39m\n",
      "\u001b[33m                and returning a float.\u001b[39m\n",
      "\n",
      "\u001b[33m        numeric_only : bool, default False\u001b[39m\n",
      "\u001b[33m            Include only `float`, `int` or `boolean` data.\u001b[39m\n",
      "\n",
      "\u001b[33m            .. versionadded:: 1.5.0\u001b[39m\n",
      "\n",
      "\u001b[33m            .. versionchanged:: 2.0.0\u001b[39m\n",
      "\u001b[33m                The default value of ``numeric_only`` is now ``False``.\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        Series\u001b[39m\n",
      "\u001b[33m            Pairwise correlations.\u001b[39m\n",
      "\n",
      "\u001b[33m        See Also\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        DataFrame.corr : Compute pairwise correlation of columns.\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        >>> index = [\"a\", \"b\", \"c\", \"d\", \"e\"]\u001b[39m\n",
      "\u001b[33m        >>> columns = [\"one\", \"two\", \"three\", \"four\"]\u001b[39m\n",
      "\u001b[33m        >>> df1 = pd.DataFrame(np.arange(20).reshape(5, 4), index=index, columns=columns)\u001b[39m\n",
      "\u001b[33m        >>> df2 = pd.DataFrame(np.arange(16).reshape(4, 4), index=index[:4], columns=columns)\u001b[39m\n",
      "\u001b[33m        >>> df1.corrwith(df2)\u001b[39m\n",
      "\u001b[33m        one      1.0\u001b[39m\n",
      "\u001b[33m        two      1.0\u001b[39m\n",
      "\u001b[33m        three    1.0\u001b[39m\n",
      "\u001b[33m        four     1.0\u001b[39m\n",
      "\u001b[33m        dtype: float64\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df2.corrwith(df1, axis=1)\u001b[39m\n",
      "\u001b[33m        a    1.0\u001b[39m\n",
      "\u001b[33m        b    1.0\u001b[39m\n",
      "\u001b[33m        c    1.0\u001b[39m\n",
      "\u001b[33m        d    1.0\u001b[39m\n",
      "\u001b[33m        e    NaN\u001b[39m\n",
      "\u001b[33m        dtype: float64\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n",
      "        axis = self._get_axis_number(axis)\n",
      "        this = self._get_numeric_data() \u001b[38;5;28;01mif\u001b[39;00m numeric_only \u001b[38;5;28;01melse\u001b[39;00m self\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m isinstance(other, Series):\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m this.apply(\u001b[38;5;28;01mlambda\u001b[39;00m x: other.corr(x, method=method), axis=axis)\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m numeric_only:\n",
      "            other = other._get_numeric_data()\n",
      "        left, right = this.align(other, join=\u001b[33m\"inner\"\u001b[39m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m axis == \u001b[32m1\u001b[39m:\n",
      "            left = left.T\n",
      "            right = right.T\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m method == \u001b[33m\"pearson\"\u001b[39m:\n",
      "            \u001b[38;5;66;03m# mask missing values\u001b[39;00m\n",
      "            left = left + right * \u001b[32m0\u001b[39m\n",
      "            right = right + left * \u001b[32m0\u001b[39m\n",
      "\n",
      "            \u001b[38;5;66;03m# demeaned data\u001b[39;00m\n",
      "            ldem = left - left.mean(numeric_only=numeric_only)\n",
      "            rdem = right - right.mean(numeric_only=numeric_only)\n",
      "\n",
      "            num = (ldem * rdem).sum()\n",
      "            dom = (\n",
      "                (left.count() - \u001b[32m1\u001b[39m)\n",
      "                * left.std(numeric_only=numeric_only)\n",
      "                * right.std(numeric_only=numeric_only)\n",
      "            )\n",
      "\n",
      "            correl = num / dom\n",
      "\n",
      "        \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;28;01min\u001b[39;00m [\u001b[33m\"kendall\"\u001b[39m, \u001b[33m\"spearman\"\u001b[39m] \u001b[38;5;28;01mor\u001b[39;00m callable(method):\n",
      "\n",
      "            \u001b[38;5;28;01mdef\u001b[39;00m c(x):\n",
      "                \u001b[38;5;28;01mreturn\u001b[39;00m nanops.nancorr(x[\u001b[32m0\u001b[39m], x[\u001b[32m1\u001b[39m], method=method)\n",
      "\n",
      "            correl = self._constructor_sliced(\n",
      "                map(c, zip(left.values.T, right.values.T)),\n",
      "                index=left.columns,\n",
      "                copy=\u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "            )\n",
      "\n",
      "        \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "            \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\n",
      "                \u001b[33mf\"Invalid method {method} was passed, \"\u001b[39m\n",
      "                \u001b[33m\"valid methods are: 'pearson', 'kendall', \"\u001b[39m\n",
      "                \u001b[33m\"'spearman', or callable\"\u001b[39m\n",
      "            )\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m drop:\n",
      "            \u001b[38;5;66;03m# Find non-matching labels along the given axis\u001b[39;00m\n",
      "            \u001b[38;5;66;03m# and append missing correlations (GH 22375)\u001b[39;00m\n",
      "            raxis: AxisInt = \u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m axis == \u001b[32m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m\n",
      "            result_index = this._get_axis(raxis).union(other._get_axis(raxis))\n",
      "            idx_diff = result_index.difference(correl.index)\n",
      "\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m len(idx_diff) > \u001b[32m0\u001b[39m:\n",
      "                correl = correl._append(\n",
      "                    Series([np.nan] * len(idx_diff), index=idx_diff)\n",
      "                )\n",
      "\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m correl\n",
      "\n",
      "    \u001b[38;5;66;03m# ----------------------------------------------------------------------\u001b[39;00m\n",
      "    \u001b[38;5;66;03m# ndarray-like stats methods\u001b[39;00m\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m count(self, axis: Axis = \u001b[32m0\u001b[39m, numeric_only: bool = \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Count non-NA cells for each column or row.\u001b[39m\n",
      "\n",
      "\u001b[33m        The values `None`, `NaN`, `NaT`, ``pandas.NA`` are considered NA.\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        axis : {0 or 'index', 1 or 'columns'}, default 0\u001b[39m\n",
      "\u001b[33m            If 0 or 'index' counts are generated for each column.\u001b[39m\n",
      "\u001b[33m            If 1 or 'columns' counts are generated for each row.\u001b[39m\n",
      "\u001b[33m        numeric_only : bool, default False\u001b[39m\n",
      "\u001b[33m            Include only `float`, `int` or `boolean` data.\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        Series\u001b[39m\n",
      "\u001b[33m            For each column/row the number of non-NA/null entries.\u001b[39m\n",
      "\n",
      "\u001b[33m        See Also\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        Series.count: Number of non-NA elements in a Series.\u001b[39m\n",
      "\u001b[33m        DataFrame.value_counts: Count unique combinations of columns.\u001b[39m\n",
      "\u001b[33m        DataFrame.shape: Number of DataFrame rows and columns (including NA\u001b[39m\n",
      "\u001b[33m            elements).\u001b[39m\n",
      "\u001b[33m        DataFrame.isna: Boolean same-sized DataFrame showing places of NA\u001b[39m\n",
      "\u001b[33m            elements.\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        Constructing DataFrame from a dictionary:\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df = pd.DataFrame({\"Person\":\u001b[39m\n",
      "\u001b[33m        ...                    [\"John\", \"Myla\", \"Lewis\", \"John\", \"Myla\"],\u001b[39m\n",
      "\u001b[33m        ...                    \"Age\": [24., np.nan, 21., 33, 26],\u001b[39m\n",
      "\u001b[33m        ...                    \"Single\": [False, True, True, True, False]})\u001b[39m\n",
      "\u001b[33m        >>> df\u001b[39m\n",
      "\u001b[33m           Person   Age  Single\u001b[39m\n",
      "\u001b[33m        0    John  24.0   False\u001b[39m\n",
      "\u001b[33m        1    Myla   NaN    True\u001b[39m\n",
      "\u001b[33m        2   Lewis  21.0    True\u001b[39m\n",
      "\u001b[33m        3    John  33.0    True\u001b[39m\n",
      "\u001b[33m        4    Myla  26.0   False\u001b[39m\n",
      "\n",
      "\u001b[33m        Notice the uncounted NA values:\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.count()\u001b[39m\n",
      "\u001b[33m        Person    5\u001b[39m\n",
      "\u001b[33m        Age       4\u001b[39m\n",
      "\u001b[33m        Single    5\u001b[39m\n",
      "\u001b[33m        dtype: int64\u001b[39m\n",
      "\n",
      "\u001b[33m        Counts for each **row**:\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.count(axis='columns')\u001b[39m\n",
      "\u001b[33m        0    3\u001b[39m\n",
      "\u001b[33m        1    2\u001b[39m\n",
      "\u001b[33m        2    3\u001b[39m\n",
      "\u001b[33m        3    3\u001b[39m\n",
      "\u001b[33m        4    3\u001b[39m\n",
      "\u001b[33m        dtype: int64\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        axis = self._get_axis_number(axis)\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m numeric_only:\n",
      "            frame = self._get_numeric_data()\n",
      "        \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "            frame = self\n",
      "\n",
      "        \u001b[38;5;66;03m# GH #423\u001b[39;00m\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m len(frame._get_axis(axis)) == \u001b[32m0\u001b[39m:\n",
      "            result = self._constructor_sliced(\u001b[32m0\u001b[39m, index=frame._get_agg_axis(axis))\n",
      "        \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "            result = notna(frame).sum(axis=axis)\n",
      "\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m result.astype(\u001b[33m\"int64\"\u001b[39m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m).__finalize__(self, method=\u001b[33m\"count\"\u001b[39m)\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m _reduce(\n",
      "        self,\n",
      "        op,\n",
      "        name: str,\n",
      "        *,\n",
      "        axis: Axis = \u001b[32m0\u001b[39m,\n",
      "        skipna: bool = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "        numeric_only: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "        filter_type=\u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        **kwds,\n",
      "    ):\n",
      "        \u001b[38;5;28;01massert\u001b[39;00m filter_type \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mor\u001b[39;00m filter_type == \u001b[33m\"bool\"\u001b[39m, filter_type\n",
      "        out_dtype = \u001b[33m\"bool\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m filter_type == \u001b[33m\"bool\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "            axis = self._get_axis_number(axis)\n",
      "\n",
      "        \u001b[38;5;28;01mdef\u001b[39;00m func(values: np.ndarray):\n",
      "            \u001b[38;5;66;03m# We only use this in the case that operates on self.values\u001b[39;00m\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m op(values, axis=axis, skipna=skipna, **kwds)\n",
      "\n",
      "        dtype_has_keepdims: dict[ExtensionDtype, bool] = {}\n",
      "\n",
      "        \u001b[38;5;28;01mdef\u001b[39;00m blk_func(values, axis: Axis = \u001b[32m1\u001b[39m):\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m isinstance(values, ExtensionArray):\n",
      "                \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m is_1d_only_ea_dtype(values.dtype) \u001b[38;5;28;01mand\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m isinstance(\n",
      "                    self._mgr, ArrayManager\n",
      "                ):\n",
      "                    \u001b[38;5;28;01mreturn\u001b[39;00m values._reduce(name, axis=\u001b[32m1\u001b[39m, skipna=skipna, **kwds)\n",
      "                has_keepdims = dtype_has_keepdims.get(values.dtype)\n",
      "                \u001b[38;5;28;01mif\u001b[39;00m has_keepdims \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "                    sign = signature(values._reduce)\n",
      "                    has_keepdims = \u001b[33m\"keepdims\"\u001b[39m \u001b[38;5;28;01min\u001b[39;00m sign.parameters\n",
      "                    dtype_has_keepdims[values.dtype] = has_keepdims\n",
      "                \u001b[38;5;28;01mif\u001b[39;00m has_keepdims:\n",
      "                    \u001b[38;5;28;01mreturn\u001b[39;00m values._reduce(name, skipna=skipna, keepdims=\u001b[38;5;28;01mTrue\u001b[39;00m, **kwds)\n",
      "                \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "                    warnings.warn(\n",
      "                        \u001b[33mf\"{type(values)}._reduce will require a `keepdims` parameter \"\u001b[39m\n",
      "                        \u001b[33m\"in the future\"\u001b[39m,\n",
      "                        FutureWarning,\n",
      "                        stacklevel=find_stack_level(),\n",
      "                    )\n",
      "                    result = values._reduce(name, skipna=skipna, **kwds)\n",
      "                    \u001b[38;5;28;01mreturn\u001b[39;00m np.array([result])\n",
      "            \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "                \u001b[38;5;28;01mreturn\u001b[39;00m op(values, axis=axis, skipna=skipna, **kwds)\n",
      "\n",
      "        \u001b[38;5;28;01mdef\u001b[39;00m _get_data() -> DataFrame:\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m filter_type \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "                data = self._get_numeric_data()\n",
      "            \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "                \u001b[38;5;66;03m# GH#25101, GH#24434\u001b[39;00m\n",
      "                \u001b[38;5;28;01massert\u001b[39;00m filter_type == \u001b[33m\"bool\"\u001b[39m\n",
      "                data = self._get_bool_data()\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\n",
      "        \u001b[38;5;66;03m# Case with EAs see GH#35881\u001b[39;00m\n",
      "        df = self\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m numeric_only:\n",
      "            df = _get_data()\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "            dtype = find_common_type([arr.dtype \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;28;01min\u001b[39;00m df._mgr.arrays])\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m isinstance(dtype, ExtensionDtype):\n",
      "                df = df.astype(dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "                arr = concat_compat(list(df._iter_column_arrays()))\n",
      "                \u001b[38;5;28;01mreturn\u001b[39;00m arr._reduce(name, skipna=skipna, keepdims=\u001b[38;5;28;01mFalse\u001b[39;00m, **kwds)\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m func(df.values)\n",
      "        \u001b[38;5;28;01melif\u001b[39;00m axis == \u001b[32m1\u001b[39m:\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m len(df.index) == \u001b[32m0\u001b[39m:\n",
      "                \u001b[38;5;66;03m# Taking a transpose would result in no columns, losing the dtype.\u001b[39;00m\n",
      "                \u001b[38;5;66;03m# In the empty case, reducing along axis 0 or 1 gives the same\u001b[39;00m\n",
      "                \u001b[38;5;66;03m# result dtype, so reduce with axis=0 and ignore values\u001b[39;00m\n",
      "                result = df._reduce(\n",
      "                    op,\n",
      "                    name,\n",
      "                    axis=\u001b[32m0\u001b[39m,\n",
      "                    skipna=skipna,\n",
      "                    numeric_only=\u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "                    filter_type=filter_type,\n",
      "                    **kwds,\n",
      "                ).iloc[:\u001b[32m0\u001b[39m]\n",
      "                result.index = df.index\n",
      "                \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\n",
      "            \u001b[38;5;66;03m# kurtosis excluded since groupby does not implement it\u001b[39;00m\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m df.shape[\u001b[32m1\u001b[39m] \u001b[38;5;28;01mand\u001b[39;00m name != \u001b[33m\"kurt\"\u001b[39m:\n",
      "                dtype = find_common_type([arr.dtype \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;28;01min\u001b[39;00m df._mgr.arrays])\n",
      "                \u001b[38;5;28;01mif\u001b[39;00m isinstance(dtype, ExtensionDtype):\n",
      "                    \u001b[38;5;66;03m# GH 54341: fastpath for EA-backed axis=1 reductions\u001b[39;00m\n",
      "                    \u001b[38;5;66;03m# This flattens the frame into a single 1D array while keeping\u001b[39;00m\n",
      "                    \u001b[38;5;66;03m# track of the row and column indices of the original frame. Once\u001b[39;00m\n",
      "                    \u001b[38;5;66;03m# flattened, grouping by the row indices and aggregating should\u001b[39;00m\n",
      "                    \u001b[38;5;66;03m# be equivalent to transposing the original frame and aggregating\u001b[39;00m\n",
      "                    \u001b[38;5;66;03m# with axis=0.\u001b[39;00m\n",
      "                    name = {\u001b[33m\"argmax\"\u001b[39m: \u001b[33m\"idxmax\"\u001b[39m, \u001b[33m\"argmin\"\u001b[39m: \u001b[33m\"idxmin\"\u001b[39m}.get(name, name)\n",
      "                    df = df.astype(dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "                    arr = concat_compat(list(df._iter_column_arrays()))\n",
      "                    nrows, ncols = df.shape\n",
      "                    row_index = np.tile(np.arange(nrows), ncols)\n",
      "                    col_index = np.repeat(np.arange(ncols), nrows)\n",
      "                    ser = Series(arr, index=col_index, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "                    \u001b[38;5;66;03m# GroupBy will raise a warning with SeriesGroupBy as the object,\u001b[39;00m\n",
      "                    \u001b[38;5;66;03m# likely confusing users\u001b[39;00m\n",
      "                    \u001b[38;5;28;01mwith\u001b[39;00m rewrite_warning(\n",
      "                        target_message=(\n",
      "                            \u001b[33mf\"The behavior of SeriesGroupBy.{name} with all-NA values\"\u001b[39m\n",
      "                        ),\n",
      "                        target_category=FutureWarning,\n",
      "                        new_message=(\n",
      "                            \u001b[33mf\"The behavior of {type(self).__name__}.{name} with all-NA \"\u001b[39m\n",
      "                            \u001b[33m\"values, or any-NA and skipna=False, is deprecated. In \"\u001b[39m\n",
      "                            \u001b[33m\"a future version this will raise ValueError\"\u001b[39m\n",
      "                        ),\n",
      "                    ):\n",
      "                        result = ser.groupby(row_index).agg(name, **kwds)\n",
      "                    result.index = df.index\n",
      "                    \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m skipna \u001b[38;5;28;01mand\u001b[39;00m name \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01min\u001b[39;00m (\u001b[33m\"any\"\u001b[39m, \u001b[33m\"all\"\u001b[39m):\n",
      "                        mask = df.isna().to_numpy(dtype=np.bool_).any(axis=\u001b[32m1\u001b[39m)\n",
      "                        other = -\u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;28;01min\u001b[39;00m (\u001b[33m\"idxmax\"\u001b[39m, \u001b[33m\"idxmin\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m lib.no_default\n",
      "                        result = result.mask(mask, other)\n",
      "                    \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\n",
      "            df = df.T\n",
      "\n",
      "        \u001b[38;5;66;03m# After possibly _get_data and transposing, we are now in the\u001b[39;00m\n",
      "        \u001b[38;5;66;03m#  simple case where we can use BlockManager.reduce\u001b[39;00m\n",
      "        res = df._mgr.reduce(blk_func)\n",
      "        out = df._constructor_from_mgr(res, axes=res.axes).iloc[\u001b[32m0\u001b[39m]\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m out_dtype \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mand\u001b[39;00m out.dtype != \u001b[33m\"boolean\"\u001b[39m:\n",
      "            out = out.astype(out_dtype)\n",
      "        \u001b[38;5;28;01melif\u001b[39;00m (df._mgr.get_dtypes() == object).any() \u001b[38;5;28;01mand\u001b[39;00m name \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01min\u001b[39;00m [\u001b[33m\"any\"\u001b[39m, \u001b[33m\"all\"\u001b[39m]:\n",
      "            out = out.astype(object)\n",
      "        \u001b[38;5;28;01melif\u001b[39;00m len(self) == \u001b[32m0\u001b[39m \u001b[38;5;28;01mand\u001b[39;00m out.dtype == object \u001b[38;5;28;01mand\u001b[39;00m name \u001b[38;5;28;01min\u001b[39;00m (\u001b[33m\"sum\"\u001b[39m, \u001b[33m\"prod\"\u001b[39m):\n",
      "            \u001b[38;5;66;03m# Even if we are object dtype, follow numpy and return\u001b[39;00m\n",
      "            \u001b[38;5;66;03m#  float64, see test_apply_funcs_over_empty\u001b[39;00m\n",
      "            out = out.astype(np.float64)\n",
      "\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m _reduce_axis1(self, name: str, func, skipna: bool) -> Series:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Special case for _reduce to try to avoid a potentially-expensive transpose.\u001b[39m\n",
      "\n",
      "\u001b[33m        Apply the reduction block-wise along axis=1 and then reduce the resulting\u001b[39m\n",
      "\u001b[33m        1D arrays.\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m name == \u001b[33m\"all\"\u001b[39m:\n",
      "            result = np.ones(len(self), dtype=bool)\n",
      "            ufunc = np.logical_and\n",
      "        \u001b[38;5;28;01melif\u001b[39;00m name == \u001b[33m\"any\"\u001b[39m:\n",
      "            result = np.zeros(len(self), dtype=bool)\n",
      "            \u001b[38;5;66;03m# error: Incompatible types in assignment\u001b[39;00m\n",
      "            \u001b[38;5;66;03m# (expression has type \"_UFunc_Nin2_Nout1[Literal['logical_or'],\u001b[39;00m\n",
      "            \u001b[38;5;66;03m# Literal[20], Literal[False]]\", variable has type\u001b[39;00m\n",
      "            \u001b[38;5;66;03m# \"_UFunc_Nin2_Nout1[Literal['logical_and'], Literal[20],\u001b[39;00m\n",
      "            \u001b[38;5;66;03m# Literal[True]]\")\u001b[39;00m\n",
      "            ufunc = np.logical_or  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n",
      "        \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "            \u001b[38;5;28;01mraise\u001b[39;00m NotImplementedError(name)\n",
      "\n",
      "        \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;28;01min\u001b[39;00m self._mgr.arrays:\n",
      "            middle = func(arr, axis=\u001b[32m0\u001b[39m, skipna=skipna)\n",
      "            result = ufunc(result, middle)\n",
      "\n",
      "        res_ser = self._constructor_sliced(result, index=self.index, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m res_ser\n",
      "\n",
      "    @doc(make_doc(\u001b[33m\"any\"\u001b[39m, ndim=\u001b[32m2\u001b[39m))\n",
      "    \u001b[38;5;66;03m# error: Signature of \"any\" incompatible with supertype \"NDFrame\"\u001b[39;00m\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m any(  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n",
      "        self,\n",
      "        *,\n",
      "        axis: Axis | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[32m0\u001b[39m,\n",
      "        bool_only: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "        skipna: bool = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "        **kwargs,\n",
      "    ) -> Series | bool:\n",
      "        result = self._logical_func(\n",
      "            \u001b[33m\"any\"\u001b[39m, nanops.nanany, axis, bool_only, skipna, **kwargs\n",
      "        )\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m isinstance(result, Series):\n",
      "            result = result.__finalize__(self, method=\u001b[33m\"any\"\u001b[39m)\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\n",
      "    @doc(make_doc(\u001b[33m\"all\"\u001b[39m, ndim=\u001b[32m2\u001b[39m))\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m all(\n",
      "        self,\n",
      "        axis: Axis | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[32m0\u001b[39m,\n",
      "        bool_only: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "        skipna: bool = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "        **kwargs,\n",
      "    ) -> Series | bool:\n",
      "        result = self._logical_func(\n",
      "            \u001b[33m\"all\"\u001b[39m, nanops.nanall, axis, bool_only, skipna, **kwargs\n",
      "        )\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m isinstance(result, Series):\n",
      "            result = result.__finalize__(self, method=\u001b[33m\"all\"\u001b[39m)\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\n",
      "    @doc(make_doc(\u001b[33m\"min\"\u001b[39m, ndim=\u001b[32m2\u001b[39m))\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m min(\n",
      "        self,\n",
      "        axis: Axis | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[32m0\u001b[39m,\n",
      "        skipna: bool = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "        numeric_only: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "        **kwargs,\n",
      "    ):\n",
      "        result = super().min(axis, skipna, numeric_only, **kwargs)\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m isinstance(result, Series):\n",
      "            result = result.__finalize__(self, method=\u001b[33m\"min\"\u001b[39m)\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\n",
      "    @doc(make_doc(\u001b[33m\"max\"\u001b[39m, ndim=\u001b[32m2\u001b[39m))\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m max(\n",
      "        self,\n",
      "        axis: Axis | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[32m0\u001b[39m,\n",
      "        skipna: bool = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "        numeric_only: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "        **kwargs,\n",
      "    ):\n",
      "        result = super().max(axis, skipna, numeric_only, **kwargs)\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m isinstance(result, Series):\n",
      "            result = result.__finalize__(self, method=\u001b[33m\"max\"\u001b[39m)\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\n",
      "    @doc(make_doc(\u001b[33m\"sum\"\u001b[39m, ndim=\u001b[32m2\u001b[39m))\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m sum(\n",
      "        self,\n",
      "        axis: Axis | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[32m0\u001b[39m,\n",
      "        skipna: bool = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "        numeric_only: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "        min_count: int = \u001b[32m0\u001b[39m,\n",
      "        **kwargs,\n",
      "    ):\n",
      "        result = super().sum(axis, skipna, numeric_only, min_count, **kwargs)\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m result.__finalize__(self, method=\u001b[33m\"sum\"\u001b[39m)\n",
      "\n",
      "    @doc(make_doc(\u001b[33m\"prod\"\u001b[39m, ndim=\u001b[32m2\u001b[39m))\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m prod(\n",
      "        self,\n",
      "        axis: Axis | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[32m0\u001b[39m,\n",
      "        skipna: bool = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "        numeric_only: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "        min_count: int = \u001b[32m0\u001b[39m,\n",
      "        **kwargs,\n",
      "    ):\n",
      "        result = super().prod(axis, skipna, numeric_only, min_count, **kwargs)\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m result.__finalize__(self, method=\u001b[33m\"prod\"\u001b[39m)\n",
      "\n",
      "    @doc(make_doc(\u001b[33m\"mean\"\u001b[39m, ndim=\u001b[32m2\u001b[39m))\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m mean(\n",
      "        self,\n",
      "        axis: Axis | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[32m0\u001b[39m,\n",
      "        skipna: bool = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "        numeric_only: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "        **kwargs,\n",
      "    ):\n",
      "        result = super().mean(axis, skipna, numeric_only, **kwargs)\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m isinstance(result, Series):\n",
      "            result = result.__finalize__(self, method=\u001b[33m\"mean\"\u001b[39m)\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\n",
      "    @doc(make_doc(\u001b[33m\"median\"\u001b[39m, ndim=\u001b[32m2\u001b[39m))\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m median(\n",
      "        self,\n",
      "        axis: Axis | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[32m0\u001b[39m,\n",
      "        skipna: bool = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "        numeric_only: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "        **kwargs,\n",
      "    ):\n",
      "        result = super().median(axis, skipna, numeric_only, **kwargs)\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m isinstance(result, Series):\n",
      "            result = result.__finalize__(self, method=\u001b[33m\"median\"\u001b[39m)\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\n",
      "    @doc(make_doc(\u001b[33m\"sem\"\u001b[39m, ndim=\u001b[32m2\u001b[39m))\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m sem(\n",
      "        self,\n",
      "        axis: Axis | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[32m0\u001b[39m,\n",
      "        skipna: bool = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "        ddof: int = \u001b[32m1\u001b[39m,\n",
      "        numeric_only: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "        **kwargs,\n",
      "    ):\n",
      "        result = super().sem(axis, skipna, ddof, numeric_only, **kwargs)\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m isinstance(result, Series):\n",
      "            result = result.__finalize__(self, method=\u001b[33m\"sem\"\u001b[39m)\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\n",
      "    @doc(make_doc(\u001b[33m\"var\"\u001b[39m, ndim=\u001b[32m2\u001b[39m))\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m var(\n",
      "        self,\n",
      "        axis: Axis | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[32m0\u001b[39m,\n",
      "        skipna: bool = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "        ddof: int = \u001b[32m1\u001b[39m,\n",
      "        numeric_only: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "        **kwargs,\n",
      "    ):\n",
      "        result = super().var(axis, skipna, ddof, numeric_only, **kwargs)\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m isinstance(result, Series):\n",
      "            result = result.__finalize__(self, method=\u001b[33m\"var\"\u001b[39m)\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\n",
      "    @doc(make_doc(\u001b[33m\"std\"\u001b[39m, ndim=\u001b[32m2\u001b[39m))\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m std(\n",
      "        self,\n",
      "        axis: Axis | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[32m0\u001b[39m,\n",
      "        skipna: bool = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "        ddof: int = \u001b[32m1\u001b[39m,\n",
      "        numeric_only: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "        **kwargs,\n",
      "    ):\n",
      "        result = super().std(axis, skipna, ddof, numeric_only, **kwargs)\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m isinstance(result, Series):\n",
      "            result = result.__finalize__(self, method=\u001b[33m\"std\"\u001b[39m)\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\n",
      "    @doc(make_doc(\u001b[33m\"skew\"\u001b[39m, ndim=\u001b[32m2\u001b[39m))\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m skew(\n",
      "        self,\n",
      "        axis: Axis | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[32m0\u001b[39m,\n",
      "        skipna: bool = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "        numeric_only: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "        **kwargs,\n",
      "    ):\n",
      "        result = super().skew(axis, skipna, numeric_only, **kwargs)\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m isinstance(result, Series):\n",
      "            result = result.__finalize__(self, method=\u001b[33m\"skew\"\u001b[39m)\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\n",
      "    @doc(make_doc(\u001b[33m\"kurt\"\u001b[39m, ndim=\u001b[32m2\u001b[39m))\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m kurt(\n",
      "        self,\n",
      "        axis: Axis | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[32m0\u001b[39m,\n",
      "        skipna: bool = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "        numeric_only: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "        **kwargs,\n",
      "    ):\n",
      "        result = super().kurt(axis, skipna, numeric_only, **kwargs)\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m isinstance(result, Series):\n",
      "            result = result.__finalize__(self, method=\u001b[33m\"kurt\"\u001b[39m)\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\n",
      "    kurtosis = kurt\n",
      "    product = prod\n",
      "\n",
      "    @doc(make_doc(\u001b[33m\"cummin\"\u001b[39m, ndim=\u001b[32m2\u001b[39m))\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m cummin(self, axis: Axis | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m, skipna: bool = \u001b[38;5;28;01mTrue\u001b[39;00m, *args, **kwargs):\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m NDFrame.cummin(self, axis, skipna, *args, **kwargs)\n",
      "\n",
      "    @doc(make_doc(\u001b[33m\"cummax\"\u001b[39m, ndim=\u001b[32m2\u001b[39m))\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m cummax(self, axis: Axis | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m, skipna: bool = \u001b[38;5;28;01mTrue\u001b[39;00m, *args, **kwargs):\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m NDFrame.cummax(self, axis, skipna, *args, **kwargs)\n",
      "\n",
      "    @doc(make_doc(\u001b[33m\"cumsum\"\u001b[39m, ndim=\u001b[32m2\u001b[39m))\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m cumsum(self, axis: Axis | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m, skipna: bool = \u001b[38;5;28;01mTrue\u001b[39;00m, *args, **kwargs):\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m NDFrame.cumsum(self, axis, skipna, *args, **kwargs)\n",
      "\n",
      "    @doc(make_doc(\u001b[33m\"cumprod\"\u001b[39m, \u001b[32m2\u001b[39m))\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m cumprod(self, axis: Axis | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m, skipna: bool = \u001b[38;5;28;01mTrue\u001b[39;00m, *args, **kwargs):\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m NDFrame.cumprod(self, axis, skipna, *args, **kwargs)\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m nunique(self, axis: Axis = \u001b[32m0\u001b[39m, dropna: bool = \u001b[38;5;28;01mTrue\u001b[39;00m) -> Series:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Count number of distinct elements in specified axis.\u001b[39m\n",
      "\n",
      "\u001b[33m        Return Series with number of distinct elements. Can ignore NaN\u001b[39m\n",
      "\u001b[33m        values.\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        axis : {0 or 'index', 1 or 'columns'}, default 0\u001b[39m\n",
      "\u001b[33m            The axis to use. 0 or 'index' for row-wise, 1 or 'columns' for\u001b[39m\n",
      "\u001b[33m            column-wise.\u001b[39m\n",
      "\u001b[33m        dropna : bool, default True\u001b[39m\n",
      "\u001b[33m            Don't include NaN in the counts.\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        Series\u001b[39m\n",
      "\n",
      "\u001b[33m        See Also\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        Series.nunique: Method nunique for Series.\u001b[39m\n",
      "\u001b[33m        DataFrame.count: Count non-NA cells for each column or row.\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        >>> df = pd.DataFrame({'A': [4, 5, 6], 'B': [4, 1, 1]})\u001b[39m\n",
      "\u001b[33m        >>> df.nunique()\u001b[39m\n",
      "\u001b[33m        A    3\u001b[39m\n",
      "\u001b[33m        B    2\u001b[39m\n",
      "\u001b[33m        dtype: int64\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.nunique(axis=1)\u001b[39m\n",
      "\u001b[33m        0    1\u001b[39m\n",
      "\u001b[33m        1    2\u001b[39m\n",
      "\u001b[33m        2    2\u001b[39m\n",
      "\u001b[33m        dtype: int64\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m self.apply(Series.nunique, axis=axis, dropna=dropna)\n",
      "\n",
      "    @doc(_shared_docs[\u001b[33m\"idxmin\"\u001b[39m], numeric_only_default=\u001b[33m\"False\"\u001b[39m)\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m idxmin(\n",
      "        self, axis: Axis = \u001b[32m0\u001b[39m, skipna: bool = \u001b[38;5;28;01mTrue\u001b[39;00m, numeric_only: bool = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "    ) -> Series:\n",
      "        axis = self._get_axis_number(axis)\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m self.empty \u001b[38;5;28;01mand\u001b[39;00m len(self.axes[axis]):\n",
      "            axis_dtype = self.axes[axis].dtype\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m self._constructor_sliced(dtype=axis_dtype)\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m numeric_only:\n",
      "            data = self._get_numeric_data()\n",
      "        \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "            data = self\n",
      "\n",
      "        res = data._reduce(\n",
      "            nanops.nanargmin, \u001b[33m\"argmin\"\u001b[39m, axis=axis, skipna=skipna, numeric_only=\u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "        )\n",
      "        indices = res._values\n",
      "        \u001b[38;5;66;03m# indices will always be np.ndarray since axis is not N\u001b[39;00m\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m (indices == -\u001b[32m1\u001b[39m).any():\n",
      "            warnings.warn(\n",
      "                \u001b[33mf\"The behavior of {type(self).__name__}.idxmin with all-NA \"\u001b[39m\n",
      "                \u001b[33m\"values, or any-NA and skipna=False, is deprecated. In a future \"\u001b[39m\n",
      "                \u001b[33m\"version this will raise ValueError\"\u001b[39m,\n",
      "                FutureWarning,\n",
      "                stacklevel=find_stack_level(),\n",
      "            )\n",
      "\n",
      "        index = data._get_axis(axis)\n",
      "        result = algorithms.take(\n",
      "            index._values, indices, allow_fill=\u001b[38;5;28;01mTrue\u001b[39;00m, fill_value=index._na_value\n",
      "        )\n",
      "        final_result = data._constructor_sliced(result, index=data._get_agg_axis(axis))\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m final_result.__finalize__(self, method=\u001b[33m\"idxmin\"\u001b[39m)\n",
      "\n",
      "    @doc(_shared_docs[\u001b[33m\"idxmax\"\u001b[39m], numeric_only_default=\u001b[33m\"False\"\u001b[39m)\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m idxmax(\n",
      "        self, axis: Axis = \u001b[32m0\u001b[39m, skipna: bool = \u001b[38;5;28;01mTrue\u001b[39;00m, numeric_only: bool = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "    ) -> Series:\n",
      "        axis = self._get_axis_number(axis)\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m self.empty \u001b[38;5;28;01mand\u001b[39;00m len(self.axes[axis]):\n",
      "            axis_dtype = self.axes[axis].dtype\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m self._constructor_sliced(dtype=axis_dtype)\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m numeric_only:\n",
      "            data = self._get_numeric_data()\n",
      "        \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "            data = self\n",
      "\n",
      "        res = data._reduce(\n",
      "            nanops.nanargmax, \u001b[33m\"argmax\"\u001b[39m, axis=axis, skipna=skipna, numeric_only=\u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "        )\n",
      "        indices = res._values\n",
      "        \u001b[38;5;66;03m# indices will always be 1d array since axis is not None\u001b[39;00m\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m (indices == -\u001b[32m1\u001b[39m).any():\n",
      "            warnings.warn(\n",
      "                \u001b[33mf\"The behavior of {type(self).__name__}.idxmax with all-NA \"\u001b[39m\n",
      "                \u001b[33m\"values, or any-NA and skipna=False, is deprecated. In a future \"\u001b[39m\n",
      "                \u001b[33m\"version this will raise ValueError\"\u001b[39m,\n",
      "                FutureWarning,\n",
      "                stacklevel=find_stack_level(),\n",
      "            )\n",
      "\n",
      "        index = data._get_axis(axis)\n",
      "        result = algorithms.take(\n",
      "            index._values, indices, allow_fill=\u001b[38;5;28;01mTrue\u001b[39;00m, fill_value=index._na_value\n",
      "        )\n",
      "        final_result = data._constructor_sliced(result, index=data._get_agg_axis(axis))\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m final_result.__finalize__(self, method=\u001b[33m\"idxmax\"\u001b[39m)\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m _get_agg_axis(self, axis_num: int) -> Index:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Let's be explicit about this.\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m axis_num == \u001b[32m0\u001b[39m:\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m self.columns\n",
      "        \u001b[38;5;28;01melif\u001b[39;00m axis_num == \u001b[32m1\u001b[39m:\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m self.index\n",
      "        \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "            \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\u001b[33mf\"Axis must be 0 or 1 (got {repr(axis_num)})\"\u001b[39m)\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m mode(\n",
      "        self, axis: Axis = \u001b[32m0\u001b[39m, numeric_only: bool = \u001b[38;5;28;01mFalse\u001b[39;00m, dropna: bool = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "    ) -> DataFrame:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Get the mode(s) of each element along the selected axis.\u001b[39m\n",
      "\n",
      "\u001b[33m        The mode of a set of values is the value that appears most often.\u001b[39m\n",
      "\u001b[33m        It can be multiple values.\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        axis : {0 or 'index', 1 or 'columns'}, default 0\u001b[39m\n",
      "\u001b[33m            The axis to iterate over while searching for the mode:\u001b[39m\n",
      "\n",
      "\u001b[33m            * 0 or 'index' : get mode of each column\u001b[39m\n",
      "\u001b[33m            * 1 or 'columns' : get mode of each row.\u001b[39m\n",
      "\n",
      "\u001b[33m        numeric_only : bool, default False\u001b[39m\n",
      "\u001b[33m            If True, only apply to numeric columns.\u001b[39m\n",
      "\u001b[33m        dropna : bool, default True\u001b[39m\n",
      "\u001b[33m            Don't consider counts of NaN/NaT.\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        DataFrame\u001b[39m\n",
      "\u001b[33m            The modes of each column or row.\u001b[39m\n",
      "\n",
      "\u001b[33m        See Also\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        Series.mode : Return the highest frequency value in a Series.\u001b[39m\n",
      "\u001b[33m        Series.value_counts : Return the counts of values in a Series.\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        >>> df = pd.DataFrame([('bird', 2, 2),\u001b[39m\n",
      "\u001b[33m        ...                    ('mammal', 4, np.nan),\u001b[39m\n",
      "\u001b[33m        ...                    ('arthropod', 8, 0),\u001b[39m\n",
      "\u001b[33m        ...                    ('bird', 2, np.nan)],\u001b[39m\n",
      "\u001b[33m        ...                   index=('falcon', 'horse', 'spider', 'ostrich'),\u001b[39m\n",
      "\u001b[33m        ...                   columns=('species', 'legs', 'wings'))\u001b[39m\n",
      "\u001b[33m        >>> df\u001b[39m\n",
      "\u001b[33m                   species  legs  wings\u001b[39m\n",
      "\u001b[33m        falcon        bird     2    2.0\u001b[39m\n",
      "\u001b[33m        horse       mammal     4    NaN\u001b[39m\n",
      "\u001b[33m        spider   arthropod     8    0.0\u001b[39m\n",
      "\u001b[33m        ostrich       bird     2    NaN\u001b[39m\n",
      "\n",
      "\u001b[33m        By default, missing values are not considered, and the mode of wings\u001b[39m\n",
      "\u001b[33m        are both 0 and 2. Because the resulting DataFrame has two rows,\u001b[39m\n",
      "\u001b[33m        the second row of ``species`` and ``legs`` contains ``NaN``.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.mode()\u001b[39m\n",
      "\u001b[33m          species  legs  wings\u001b[39m\n",
      "\u001b[33m        0    bird   2.0    0.0\u001b[39m\n",
      "\u001b[33m        1     NaN   NaN    2.0\u001b[39m\n",
      "\n",
      "\u001b[33m        Setting ``dropna=False`` ``NaN`` values are considered and they can be\u001b[39m\n",
      "\u001b[33m        the mode (like for wings).\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.mode(dropna=False)\u001b[39m\n",
      "\u001b[33m          species  legs  wings\u001b[39m\n",
      "\u001b[33m        0    bird     2    NaN\u001b[39m\n",
      "\n",
      "\u001b[33m        Setting ``numeric_only=True``, only the mode of numeric columns is\u001b[39m\n",
      "\u001b[33m        computed, and columns of other types are ignored.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.mode(numeric_only=True)\u001b[39m\n",
      "\u001b[33m           legs  wings\u001b[39m\n",
      "\u001b[33m        0   2.0    0.0\u001b[39m\n",
      "\u001b[33m        1   NaN    2.0\u001b[39m\n",
      "\n",
      "\u001b[33m        To compute the mode over columns and not rows, use the axis parameter:\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.mode(axis='columns', numeric_only=True)\u001b[39m\n",
      "\u001b[33m                   0    1\u001b[39m\n",
      "\u001b[33m        falcon   2.0  NaN\u001b[39m\n",
      "\u001b[33m        horse    4.0  NaN\u001b[39m\n",
      "\u001b[33m        spider   0.0  8.0\u001b[39m\n",
      "\u001b[33m        ostrich  2.0  NaN\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        data = self \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m numeric_only \u001b[38;5;28;01melse\u001b[39;00m self._get_numeric_data()\n",
      "\n",
      "        \u001b[38;5;28;01mdef\u001b[39;00m f(s):\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m s.mode(dropna=dropna)\n",
      "\n",
      "        data = data.apply(f, axis=axis)\n",
      "        \u001b[38;5;66;03m# Ensure index is type stable (should always use int index)\u001b[39;00m\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m data.empty:\n",
      "            data.index = default_index(\u001b[32m0\u001b[39m)\n",
      "\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\n",
      "    @overload\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m quantile(\n",
      "        self,\n",
      "        q: float = ...,\n",
      "        axis: Axis = ...,\n",
      "        numeric_only: bool = ...,\n",
      "        interpolation: QuantileInterpolation = ...,\n",
      "        method: Literal[\u001b[33m\"single\"\u001b[39m, \u001b[33m\"table\"\u001b[39m] = ...,\n",
      "    ) -> Series:\n",
      "        ...\n",
      "\n",
      "    @overload\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m quantile(\n",
      "        self,\n",
      "        q: AnyArrayLike | Sequence[float],\n",
      "        axis: Axis = ...,\n",
      "        numeric_only: bool = ...,\n",
      "        interpolation: QuantileInterpolation = ...,\n",
      "        method: Literal[\u001b[33m\"single\"\u001b[39m, \u001b[33m\"table\"\u001b[39m] = ...,\n",
      "    ) -> Series | DataFrame:\n",
      "        ...\n",
      "\n",
      "    @overload\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m quantile(\n",
      "        self,\n",
      "        q: float | AnyArrayLike | Sequence[float] = ...,\n",
      "        axis: Axis = ...,\n",
      "        numeric_only: bool = ...,\n",
      "        interpolation: QuantileInterpolation = ...,\n",
      "        method: Literal[\u001b[33m\"single\"\u001b[39m, \u001b[33m\"table\"\u001b[39m] = ...,\n",
      "    ) -> Series | DataFrame:\n",
      "        ...\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m quantile(\n",
      "        self,\n",
      "        q: float | AnyArrayLike | Sequence[float] = \u001b[32m0.5\u001b[39m,\n",
      "        axis: Axis = \u001b[32m0\u001b[39m,\n",
      "        numeric_only: bool = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "        interpolation: QuantileInterpolation = \u001b[33m\"linear\"\u001b[39m,\n",
      "        method: Literal[\u001b[33m\"single\"\u001b[39m, \u001b[33m\"table\"\u001b[39m] = \u001b[33m\"single\"\u001b[39m,\n",
      "    ) -> Series | DataFrame:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Return values at the given quantile over requested axis.\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        q : float or array-like, default 0.5 (50% quantile)\u001b[39m\n",
      "\u001b[33m            Value between 0 <= q <= 1, the quantile(s) to compute.\u001b[39m\n",
      "\u001b[33m        axis : {0 or 'index', 1 or 'columns'}, default 0\u001b[39m\n",
      "\u001b[33m            Equals 0 or 'index' for row-wise, 1 or 'columns' for column-wise.\u001b[39m\n",
      "\u001b[33m        numeric_only : bool, default False\u001b[39m\n",
      "\u001b[33m            Include only `float`, `int` or `boolean` data.\u001b[39m\n",
      "\n",
      "\u001b[33m            .. versionchanged:: 2.0.0\u001b[39m\n",
      "\u001b[33m                The default value of ``numeric_only`` is now ``False``.\u001b[39m\n",
      "\n",
      "\u001b[33m        interpolation : {'linear', 'lower', 'higher', 'midpoint', 'nearest'}\u001b[39m\n",
      "\u001b[33m            This optional parameter specifies the interpolation method to use,\u001b[39m\n",
      "\u001b[33m            when the desired quantile lies between two data points `i` and `j`:\u001b[39m\n",
      "\n",
      "\u001b[33m            * linear: `i + (j - i) * fraction`, where `fraction` is the\u001b[39m\n",
      "\u001b[33m              fractional part of the index surrounded by `i` and `j`.\u001b[39m\n",
      "\u001b[33m            * lower: `i`.\u001b[39m\n",
      "\u001b[33m            * higher: `j`.\u001b[39m\n",
      "\u001b[33m            * nearest: `i` or `j` whichever is nearest.\u001b[39m\n",
      "\u001b[33m            * midpoint: (`i` + `j`) / 2.\u001b[39m\n",
      "\u001b[33m        method : {'single', 'table'}, default 'single'\u001b[39m\n",
      "\u001b[33m            Whether to compute quantiles per-column ('single') or over all columns\u001b[39m\n",
      "\u001b[33m            ('table'). When 'table', the only allowed interpolation methods are\u001b[39m\n",
      "\u001b[33m            'nearest', 'lower', and 'higher'.\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        Series or DataFrame\u001b[39m\n",
      "\n",
      "\u001b[33m            If ``q`` is an array, a DataFrame will be returned where the\u001b[39m\n",
      "\u001b[33m              index is ``q``, the columns are the columns of self, and the\u001b[39m\n",
      "\u001b[33m              values are the quantiles.\u001b[39m\n",
      "\u001b[33m            If ``q`` is a float, a Series will be returned where the\u001b[39m\n",
      "\u001b[33m              index is the columns of self and the values are the quantiles.\u001b[39m\n",
      "\n",
      "\u001b[33m        See Also\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        core.window.rolling.Rolling.quantile: Rolling quantile.\u001b[39m\n",
      "\u001b[33m        numpy.percentile: Numpy function to compute the percentile.\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        >>> df = pd.DataFrame(np.array([[1, 1], [2, 10], [3, 100], [4, 100]]),\u001b[39m\n",
      "\u001b[33m        ...                   columns=['a', 'b'])\u001b[39m\n",
      "\u001b[33m        >>> df.quantile(.1)\u001b[39m\n",
      "\u001b[33m        a    1.3\u001b[39m\n",
      "\u001b[33m        b    3.7\u001b[39m\n",
      "\u001b[33m        Name: 0.1, dtype: float64\u001b[39m\n",
      "\u001b[33m        >>> df.quantile([.1, .5])\u001b[39m\n",
      "\u001b[33m               a     b\u001b[39m\n",
      "\u001b[33m        0.1  1.3   3.7\u001b[39m\n",
      "\u001b[33m        0.5  2.5  55.0\u001b[39m\n",
      "\n",
      "\u001b[33m        Specifying `method='table'` will compute the quantile over all columns.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.quantile(.1, method=\"table\", interpolation=\"nearest\")\u001b[39m\n",
      "\u001b[33m        a    1\u001b[39m\n",
      "\u001b[33m        b    1\u001b[39m\n",
      "\u001b[33m        Name: 0.1, dtype: int64\u001b[39m\n",
      "\u001b[33m        >>> df.quantile([.1, .5], method=\"table\", interpolation=\"nearest\")\u001b[39m\n",
      "\u001b[33m             a    b\u001b[39m\n",
      "\u001b[33m        0.1  1    1\u001b[39m\n",
      "\u001b[33m        0.5  3  100\u001b[39m\n",
      "\n",
      "\u001b[33m        Specifying `numeric_only=False` will also compute the quantile of\u001b[39m\n",
      "\u001b[33m        datetime and timedelta data.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df = pd.DataFrame({'A': [1, 2],\u001b[39m\n",
      "\u001b[33m        ...                    'B': [pd.Timestamp('2010'),\u001b[39m\n",
      "\u001b[33m        ...                          pd.Timestamp('2011')],\u001b[39m\n",
      "\u001b[33m        ...                    'C': [pd.Timedelta('1 days'),\u001b[39m\n",
      "\u001b[33m        ...                          pd.Timedelta('2 days')]})\u001b[39m\n",
      "\u001b[33m        >>> df.quantile(0.5, numeric_only=False)\u001b[39m\n",
      "\u001b[33m        A                    1.5\u001b[39m\n",
      "\u001b[33m        B    2010-07-02 12:00:00\u001b[39m\n",
      "\u001b[33m        C        1 days 12:00:00\u001b[39m\n",
      "\u001b[33m        Name: 0.5, dtype: object\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        validate_percentile(q)\n",
      "        axis = self._get_axis_number(axis)\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m is_list_like(q):\n",
      "            \u001b[38;5;66;03m# BlockManager.quantile expects listlike, so we wrap and unwrap here\u001b[39;00m\n",
      "            \u001b[38;5;66;03m# error: List item 0 has incompatible type \"float | ExtensionArray |\u001b[39;00m\n",
      "            \u001b[38;5;66;03m# ndarray[Any, Any] | Index | Series | Sequence[float]\"; expected \"float\"\u001b[39;00m\n",
      "            res_df = self.quantile(\n",
      "                [q],  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n",
      "                axis=axis,\n",
      "                numeric_only=numeric_only,\n",
      "                interpolation=interpolation,\n",
      "                method=method,\n",
      "            )\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m method == \u001b[33m\"single\"\u001b[39m:\n",
      "                res = res_df.iloc[\u001b[32m0\u001b[39m]\n",
      "            \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "                \u001b[38;5;66;03m# cannot directly iloc over sparse arrays\u001b[39;00m\n",
      "                res = res_df.T.iloc[:, \u001b[32m0\u001b[39m]\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m axis == \u001b[32m1\u001b[39m \u001b[38;5;28;01mand\u001b[39;00m len(self) == \u001b[32m0\u001b[39m:\n",
      "                \u001b[38;5;66;03m# GH#41544 try to get an appropriate dtype\u001b[39;00m\n",
      "                dtype = find_common_type(list(self.dtypes))\n",
      "                \u001b[38;5;28;01mif\u001b[39;00m needs_i8_conversion(dtype):\n",
      "                    \u001b[38;5;28;01mreturn\u001b[39;00m res.astype(dtype)\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "\n",
      "        q = Index(q, dtype=np.float64)\n",
      "        data = self._get_numeric_data() \u001b[38;5;28;01mif\u001b[39;00m numeric_only \u001b[38;5;28;01melse\u001b[39;00m self\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m axis == \u001b[32m1\u001b[39m:\n",
      "            data = data.T\n",
      "\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m len(data.columns) == \u001b[32m0\u001b[39m:\n",
      "            \u001b[38;5;66;03m# GH#23925 _get_numeric_data may have dropped all columns\u001b[39;00m\n",
      "            cols = Index([], name=self.columns.name)\n",
      "\n",
      "            dtype = np.float64\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m axis == \u001b[32m1\u001b[39m:\n",
      "                \u001b[38;5;66;03m# GH#41544 try to get an appropriate dtype\u001b[39;00m\n",
      "                cdtype = find_common_type(list(self.dtypes))\n",
      "                \u001b[38;5;28;01mif\u001b[39;00m needs_i8_conversion(cdtype):\n",
      "                    dtype = cdtype\n",
      "\n",
      "            res = self._constructor([], index=q, columns=cols, dtype=dtype)\n",
      "            \u001b[38;5;28;01mreturn\u001b[39;00m res.__finalize__(self, method=\u001b[33m\"quantile\"\u001b[39m)\n",
      "\n",
      "        valid_method = {\u001b[33m\"single\"\u001b[39m, \u001b[33m\"table\"\u001b[39m}\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01min\u001b[39;00m valid_method:\n",
      "            \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\n",
      "                \u001b[33mf\"Invalid method: {method}. Method must be in {valid_method}.\"\u001b[39m\n",
      "            )\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m method == \u001b[33m\"single\"\u001b[39m:\n",
      "            res = data._mgr.quantile(qs=q, interpolation=interpolation)\n",
      "        \u001b[38;5;28;01melif\u001b[39;00m method == \u001b[33m\"table\"\u001b[39m:\n",
      "            valid_interpolation = {\u001b[33m\"nearest\"\u001b[39m, \u001b[33m\"lower\"\u001b[39m, \u001b[33m\"higher\"\u001b[39m}\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m interpolation \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01min\u001b[39;00m valid_interpolation:\n",
      "                \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\n",
      "                    \u001b[33mf\"Invalid interpolation: {interpolation}. \"\u001b[39m\n",
      "                    \u001b[33mf\"Interpolation must be in {valid_interpolation}\"\u001b[39m\n",
      "                )\n",
      "            \u001b[38;5;66;03m# handle degenerate case\u001b[39;00m\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m len(data) == \u001b[32m0\u001b[39m:\n",
      "                \u001b[38;5;28;01mif\u001b[39;00m data.ndim == \u001b[32m2\u001b[39m:\n",
      "                    dtype = find_common_type(list(self.dtypes))\n",
      "                \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "                    dtype = self.dtype\n",
      "                \u001b[38;5;28;01mreturn\u001b[39;00m self._constructor([], index=q, columns=data.columns, dtype=dtype)\n",
      "\n",
      "            q_idx = np.quantile(np.arange(len(data)), q, method=interpolation)\n",
      "\n",
      "            by = data.columns\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m len(by) > \u001b[32m1\u001b[39m:\n",
      "                keys = [data._get_label_or_level_values(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;28;01min\u001b[39;00m by]\n",
      "                indexer = lexsort_indexer(keys)\n",
      "            \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "                k = data._get_label_or_level_values(by[\u001b[32m0\u001b[39m])\n",
      "                indexer = nargsort(k)\n",
      "\n",
      "            res = data._mgr.take(indexer[q_idx], verify=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "            res.axes[\u001b[32m1\u001b[39m] = q\n",
      "\n",
      "        result = self._constructor_from_mgr(res, axes=res.axes)\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m result.__finalize__(self, method=\u001b[33m\"quantile\"\u001b[39m)\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m to_timestamp(\n",
      "        self,\n",
      "        freq: Frequency | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "        how: ToTimestampHow = \u001b[33m\"start\"\u001b[39m,\n",
      "        axis: Axis = \u001b[32m0\u001b[39m,\n",
      "        copy: bool | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    ) -> DataFrame:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Cast to DatetimeIndex of timestamps, at *beginning* of period.\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        freq : str, default frequency of PeriodIndex\u001b[39m\n",
      "\u001b[33m            Desired frequency.\u001b[39m\n",
      "\u001b[33m        how : {'s', 'e', 'start', 'end'}\u001b[39m\n",
      "\u001b[33m            Convention for converting period to timestamp; start of period\u001b[39m\n",
      "\u001b[33m            vs. end.\u001b[39m\n",
      "\u001b[33m        axis : {0 or 'index', 1 or 'columns'}, default 0\u001b[39m\n",
      "\u001b[33m            The axis to convert (the index by default).\u001b[39m\n",
      "\u001b[33m        copy : bool, default True\u001b[39m\n",
      "\u001b[33m            If False then underlying input data is not copied.\u001b[39m\n",
      "\n",
      "\u001b[33m            .. note::\u001b[39m\n",
      "\u001b[33m                The `copy` keyword will change behavior in pandas 3.0.\u001b[39m\n",
      "\u001b[33m                `Copy-on-Write\u001b[39m\n",
      "\u001b[33m                <https://pandas.pydata.org/docs/dev/user_guide/copy_on_write.html>`__\u001b[39m\n",
      "\u001b[33m                will be enabled by default, which means that all methods with a\u001b[39m\n",
      "\u001b[33m                `copy` keyword will use a lazy copy mechanism to defer the copy and\u001b[39m\n",
      "\u001b[33m                ignore the `copy` keyword. The `copy` keyword will be removed in a\u001b[39m\n",
      "\u001b[33m                future version of pandas.\u001b[39m\n",
      "\n",
      "\u001b[33m                You can already get the future behavior and improvements through\u001b[39m\n",
      "\u001b[33m                enabling copy on write ``pd.options.mode.copy_on_write = True``\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        DataFrame\u001b[39m\n",
      "\u001b[33m            The DataFrame has a DatetimeIndex.\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        >>> idx = pd.PeriodIndex(['2023', '2024'], freq='Y')\u001b[39m\n",
      "\u001b[33m        >>> d = {'col1': [1, 2], 'col2': [3, 4]}\u001b[39m\n",
      "\u001b[33m        >>> df1 = pd.DataFrame(data=d, index=idx)\u001b[39m\n",
      "\u001b[33m        >>> df1\u001b[39m\n",
      "\u001b[33m              col1   col2\u001b[39m\n",
      "\u001b[33m        2023     1      3\u001b[39m\n",
      "\u001b[33m        2024     2      4\u001b[39m\n",
      "\n",
      "\u001b[33m        The resulting timestamps will be at the beginning of the year in this case\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df1 = df1.to_timestamp()\u001b[39m\n",
      "\u001b[33m        >>> df1\u001b[39m\n",
      "\u001b[33m                    col1   col2\u001b[39m\n",
      "\u001b[33m        2023-01-01     1      3\u001b[39m\n",
      "\u001b[33m        2024-01-01     2      4\u001b[39m\n",
      "\u001b[33m        >>> df1.index\u001b[39m\n",
      "\u001b[33m        DatetimeIndex(['2023-01-01', '2024-01-01'], dtype='datetime64[ns]', freq=None)\u001b[39m\n",
      "\n",
      "\u001b[33m        Using `freq` which is the offset that the Timestamps will have\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df2 = pd.DataFrame(data=d, index=idx)\u001b[39m\n",
      "\u001b[33m        >>> df2 = df2.to_timestamp(freq='M')\u001b[39m\n",
      "\u001b[33m        >>> df2\u001b[39m\n",
      "\u001b[33m                    col1   col2\u001b[39m\n",
      "\u001b[33m        2023-01-31     1      3\u001b[39m\n",
      "\u001b[33m        2024-01-31     2      4\u001b[39m\n",
      "\u001b[33m        >>> df2.index\u001b[39m\n",
      "\u001b[33m        DatetimeIndex(['2023-01-31', '2024-01-31'], dtype='datetime64[ns]', freq=None)\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        new_obj = self.copy(deep=copy \u001b[38;5;28;01mand\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m using_copy_on_write())\n",
      "\n",
      "        axis_name = self._get_axis_name(axis)\n",
      "        old_ax = getattr(self, axis_name)\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m isinstance(old_ax, PeriodIndex):\n",
      "            \u001b[38;5;28;01mraise\u001b[39;00m TypeError(\u001b[33mf\"unsupported Type {type(old_ax).__name__}\"\u001b[39m)\n",
      "\n",
      "        new_ax = old_ax.to_timestamp(freq=freq, how=how)\n",
      "\n",
      "        setattr(new_obj, axis_name, new_ax)\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m new_obj\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m to_period(\n",
      "        self, freq: Frequency | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m, axis: Axis = \u001b[32m0\u001b[39m, copy: bool | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "    ) -> DataFrame:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Convert DataFrame from DatetimeIndex to PeriodIndex.\u001b[39m\n",
      "\n",
      "\u001b[33m        Convert DataFrame from DatetimeIndex to PeriodIndex with desired\u001b[39m\n",
      "\u001b[33m        frequency (inferred from index if not passed).\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        freq : str, default\u001b[39m\n",
      "\u001b[33m            Frequency of the PeriodIndex.\u001b[39m\n",
      "\u001b[33m        axis : {0 or 'index', 1 or 'columns'}, default 0\u001b[39m\n",
      "\u001b[33m            The axis to convert (the index by default).\u001b[39m\n",
      "\u001b[33m        copy : bool, default True\u001b[39m\n",
      "\u001b[33m            If False then underlying input data is not copied.\u001b[39m\n",
      "\n",
      "\u001b[33m            .. note::\u001b[39m\n",
      "\u001b[33m                The `copy` keyword will change behavior in pandas 3.0.\u001b[39m\n",
      "\u001b[33m                `Copy-on-Write\u001b[39m\n",
      "\u001b[33m                <https://pandas.pydata.org/docs/dev/user_guide/copy_on_write.html>`__\u001b[39m\n",
      "\u001b[33m                will be enabled by default, which means that all methods with a\u001b[39m\n",
      "\u001b[33m                `copy` keyword will use a lazy copy mechanism to defer the copy and\u001b[39m\n",
      "\u001b[33m                ignore the `copy` keyword. The `copy` keyword will be removed in a\u001b[39m\n",
      "\u001b[33m                future version of pandas.\u001b[39m\n",
      "\n",
      "\u001b[33m                You can already get the future behavior and improvements through\u001b[39m\n",
      "\u001b[33m                enabling copy on write ``pd.options.mode.copy_on_write = True``\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        DataFrame\u001b[39m\n",
      "\u001b[33m            The DataFrame has a PeriodIndex.\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        >>> idx = pd.to_datetime(\u001b[39m\n",
      "\u001b[33m        ...     [\u001b[39m\n",
      "\u001b[33m        ...         \"2001-03-31 00:00:00\",\u001b[39m\n",
      "\u001b[33m        ...         \"2002-05-31 00:00:00\",\u001b[39m\n",
      "\u001b[33m        ...         \"2003-08-31 00:00:00\",\u001b[39m\n",
      "\u001b[33m        ...     ]\u001b[39m\n",
      "\u001b[33m        ... )\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> idx\u001b[39m\n",
      "\u001b[33m        DatetimeIndex(['2001-03-31', '2002-05-31', '2003-08-31'],\u001b[39m\n",
      "\u001b[33m        dtype='datetime64[ns]', freq=None)\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> idx.to_period(\"M\")\u001b[39m\n",
      "\u001b[33m        PeriodIndex(['2001-03', '2002-05', '2003-08'], dtype='period[M]')\u001b[39m\n",
      "\n",
      "\u001b[33m        For the yearly frequency\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> idx.to_period(\"Y\")\u001b[39m\n",
      "\u001b[33m        PeriodIndex(['2001', '2002', '2003'], dtype='period[Y-DEC]')\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        new_obj = self.copy(deep=copy \u001b[38;5;28;01mand\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m using_copy_on_write())\n",
      "\n",
      "        axis_name = self._get_axis_name(axis)\n",
      "        old_ax = getattr(self, axis_name)\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m isinstance(old_ax, DatetimeIndex):\n",
      "            \u001b[38;5;28;01mraise\u001b[39;00m TypeError(\u001b[33mf\"unsupported Type {type(old_ax).__name__}\"\u001b[39m)\n",
      "\n",
      "        new_ax = old_ax.to_period(freq=freq)\n",
      "\n",
      "        setattr(new_obj, axis_name, new_ax)\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m new_obj\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m isin(self, values: Series | DataFrame | Sequence | Mapping) -> DataFrame:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Whether each element in the DataFrame is contained in values.\u001b[39m\n",
      "\n",
      "\u001b[33m        Parameters\u001b[39m\n",
      "\u001b[33m        ----------\u001b[39m\n",
      "\u001b[33m        values : iterable, Series, DataFrame or dict\u001b[39m\n",
      "\u001b[33m            The result will only be true at a location if all the\u001b[39m\n",
      "\u001b[33m            labels match. If `values` is a Series, that's the index. If\u001b[39m\n",
      "\u001b[33m            `values` is a dict, the keys must be the column names,\u001b[39m\n",
      "\u001b[33m            which must match. If `values` is a DataFrame,\u001b[39m\n",
      "\u001b[33m            then both the index and column labels must match.\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        DataFrame\u001b[39m\n",
      "\u001b[33m            DataFrame of booleans showing whether each element in the DataFrame\u001b[39m\n",
      "\u001b[33m            is contained in values.\u001b[39m\n",
      "\n",
      "\u001b[33m        See Also\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        DataFrame.eq: Equality test for DataFrame.\u001b[39m\n",
      "\u001b[33m        Series.isin: Equivalent method on Series.\u001b[39m\n",
      "\u001b[33m        Series.str.contains: Test if pattern or regex is contained within a\u001b[39m\n",
      "\u001b[33m            string of a Series or Index.\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        >>> df = pd.DataFrame({'num_legs': [2, 4], 'num_wings': [2, 0]},\u001b[39m\n",
      "\u001b[33m        ...                   index=['falcon', 'dog'])\u001b[39m\n",
      "\u001b[33m        >>> df\u001b[39m\n",
      "\u001b[33m                num_legs  num_wings\u001b[39m\n",
      "\u001b[33m        falcon         2          2\u001b[39m\n",
      "\u001b[33m        dog            4          0\u001b[39m\n",
      "\n",
      "\u001b[33m        When ``values`` is a list check whether every value in the DataFrame\u001b[39m\n",
      "\u001b[33m        is present in the list (which animals have 0 or 2 legs or wings)\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.isin([0, 2])\u001b[39m\n",
      "\u001b[33m                num_legs  num_wings\u001b[39m\n",
      "\u001b[33m        falcon      True       True\u001b[39m\n",
      "\u001b[33m        dog        False       True\u001b[39m\n",
      "\n",
      "\u001b[33m        To check if ``values`` is *not* in the DataFrame, use the ``~`` operator:\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> ~df.isin([0, 2])\u001b[39m\n",
      "\u001b[33m                num_legs  num_wings\u001b[39m\n",
      "\u001b[33m        falcon     False      False\u001b[39m\n",
      "\u001b[33m        dog         True      False\u001b[39m\n",
      "\n",
      "\u001b[33m        When ``values`` is a dict, we can pass values to check for each\u001b[39m\n",
      "\u001b[33m        column separately:\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.isin({'num_wings': [0, 3]})\u001b[39m\n",
      "\u001b[33m                num_legs  num_wings\u001b[39m\n",
      "\u001b[33m        falcon     False      False\u001b[39m\n",
      "\u001b[33m        dog        False       True\u001b[39m\n",
      "\n",
      "\u001b[33m        When ``values`` is a Series or DataFrame the index and column must\u001b[39m\n",
      "\u001b[33m        match. Note that 'falcon' does not match based on the number of legs\u001b[39m\n",
      "\u001b[33m        in other.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> other = pd.DataFrame({'num_legs': [8, 3], 'num_wings': [0, 2]},\u001b[39m\n",
      "\u001b[33m        ...                      index=['spider', 'falcon'])\u001b[39m\n",
      "\u001b[33m        >>> df.isin(other)\u001b[39m\n",
      "\u001b[33m                num_legs  num_wings\u001b[39m\n",
      "\u001b[33m        falcon     False       True\u001b[39m\n",
      "\u001b[33m        dog        False      False\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;28;01mif\u001b[39;00m isinstance(values, dict):\n",
      "            \u001b[38;5;28;01mfrom\u001b[39;00m pandas.core.reshape.concat \u001b[38;5;28;01mimport\u001b[39;00m concat\n",
      "\n",
      "            values = collections.defaultdict(list, values)\n",
      "            result = concat(\n",
      "                (\n",
      "                    self.iloc[:, [i]].isin(values[col])\n",
      "                    \u001b[38;5;28;01mfor\u001b[39;00m i, col \u001b[38;5;28;01min\u001b[39;00m enumerate(self.columns)\n",
      "                ),\n",
      "                axis=\u001b[32m1\u001b[39m,\n",
      "            )\n",
      "        \u001b[38;5;28;01melif\u001b[39;00m isinstance(values, Series):\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m values.index.is_unique:\n",
      "                \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\u001b[33m\"cannot compute isin with a duplicate axis.\"\u001b[39m)\n",
      "            result = self.eq(values.reindex_like(self), axis=\u001b[33m\"index\"\u001b[39m)\n",
      "        \u001b[38;5;28;01melif\u001b[39;00m isinstance(values, DataFrame):\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m (values.columns.is_unique \u001b[38;5;28;01mand\u001b[39;00m values.index.is_unique):\n",
      "                \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\u001b[33m\"cannot compute isin with a duplicate axis.\"\u001b[39m)\n",
      "            result = self.eq(values.reindex_like(self))\n",
      "        \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "            \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m is_list_like(values):\n",
      "                \u001b[38;5;28;01mraise\u001b[39;00m TypeError(\n",
      "                    \u001b[33m\"only list-like or dict-like objects are allowed \"\u001b[39m\n",
      "                    \u001b[33m\"to be passed to DataFrame.isin(), \"\u001b[39m\n",
      "                    \u001b[33mf\"you passed a '{type(values).__name__}'\"\u001b[39m\n",
      "                )\n",
      "\n",
      "            \u001b[38;5;28;01mdef\u001b[39;00m isin_(x):\n",
      "                \u001b[38;5;66;03m# error: Argument 2 to \"isin\" has incompatible type \"Union[Series,\u001b[39;00m\n",
      "                \u001b[38;5;66;03m# DataFrame, Sequence[Any], Mapping[Any, Any]]\"; expected\u001b[39;00m\n",
      "                \u001b[38;5;66;03m# \"Union[Union[Union[ExtensionArray, ndarray[Any, Any]], Index,\u001b[39;00m\n",
      "                \u001b[38;5;66;03m# Series], List[Any], range]\"\u001b[39;00m\n",
      "                result = algorithms.isin(\n",
      "                    x.ravel(),\n",
      "                    values,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "                )\n",
      "                \u001b[38;5;28;01mreturn\u001b[39;00m result.reshape(x.shape)\n",
      "\n",
      "            res_mgr = self._mgr.apply(isin_)\n",
      "            result = self._constructor_from_mgr(\n",
      "                res_mgr,\n",
      "                axes=res_mgr.axes,\n",
      "            )\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m result.__finalize__(self, method=\u001b[33m\"isin\"\u001b[39m)\n",
      "\n",
      "    \u001b[38;5;66;03m# ----------------------------------------------------------------------\u001b[39;00m\n",
      "    \u001b[38;5;66;03m# Add index and columns\u001b[39;00m\n",
      "    _AXIS_ORDERS: list[Literal[\u001b[33m\"index\"\u001b[39m, \u001b[33m\"columns\"\u001b[39m]] = [\u001b[33m\"index\"\u001b[39m, \u001b[33m\"columns\"\u001b[39m]\n",
      "    _AXIS_TO_AXIS_NUMBER: dict[Axis, int] = {\n",
      "        **NDFrame._AXIS_TO_AXIS_NUMBER,\n",
      "        \u001b[32m1\u001b[39m: \u001b[32m1\u001b[39m,\n",
      "        \u001b[33m\"columns\"\u001b[39m: \u001b[32m1\u001b[39m,\n",
      "    }\n",
      "    _AXIS_LEN = len(_AXIS_ORDERS)\n",
      "    _info_axis_number: Literal[\u001b[32m1\u001b[39m] = \u001b[32m1\u001b[39m\n",
      "    _info_axis_name: Literal[\u001b[33m\"columns\"\u001b[39m] = \u001b[33m\"columns\"\u001b[39m\n",
      "\n",
      "    index = properties.AxisProperty(\n",
      "        axis=\u001b[32m1\u001b[39m,\n",
      "        doc=\u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        The index (row labels) of the DataFrame.\u001b[39m\n",
      "\n",
      "\u001b[33m        The index of a DataFrame is a series of labels that identify each row.\u001b[39m\n",
      "\u001b[33m        The labels can be integers, strings, or any other hashable type. The index\u001b[39m\n",
      "\u001b[33m        is used for label-based access and alignment, and can be accessed or\u001b[39m\n",
      "\u001b[33m        modified using this attribute.\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        pandas.Index\u001b[39m\n",
      "\u001b[33m            The index labels of the DataFrame.\u001b[39m\n",
      "\n",
      "\u001b[33m        See Also\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        DataFrame.columns : The column labels of the DataFrame.\u001b[39m\n",
      "\u001b[33m        DataFrame.to_numpy : Convert the DataFrame to a NumPy array.\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        >>> df = pd.DataFrame({'Name': ['Alice', 'Bob', 'Aritra'],\u001b[39m\n",
      "\u001b[33m        ...                    'Age': [25, 30, 35],\u001b[39m\n",
      "\u001b[33m        ...                    'Location': ['Seattle', 'New York', 'Kona']},\u001b[39m\n",
      "\u001b[33m        ...                   index=([10, 20, 30]))\u001b[39m\n",
      "\u001b[33m        >>> df.index\u001b[39m\n",
      "\u001b[33m        Index([10, 20, 30], dtype='int64')\u001b[39m\n",
      "\n",
      "\u001b[33m        In this example, we create a DataFrame with 3 rows and 3 columns,\u001b[39m\n",
      "\u001b[33m        including Name, Age, and Location information. We set the index labels to\u001b[39m\n",
      "\u001b[33m        be the integers 10, 20, and 30. We then access the `index` attribute of the\u001b[39m\n",
      "\u001b[33m        DataFrame, which returns an `Index` object containing the index labels.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df.index = [100, 200, 300]\u001b[39m\n",
      "\u001b[33m        >>> df\u001b[39m\n",
      "\u001b[33m            Name  Age Location\u001b[39m\n",
      "\u001b[33m        100  Alice   25  Seattle\u001b[39m\n",
      "\u001b[33m        200    Bob   30 New York\u001b[39m\n",
      "\u001b[33m        300  Aritra  35    Kona\u001b[39m\n",
      "\n",
      "\u001b[33m        In this example, we modify the index labels of the DataFrame by assigning\u001b[39m\n",
      "\u001b[33m        a new list of labels to the `index` attribute. The DataFrame is then\u001b[39m\n",
      "\u001b[33m        updated with the new labels, and the output shows the modified DataFrame.\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m,\n",
      "    )\n",
      "    columns = properties.AxisProperty(\n",
      "        axis=\u001b[32m0\u001b[39m,\n",
      "        doc=dedent(\n",
      "            \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m                The column labels of the DataFrame.\u001b[39m\n",
      "\n",
      "\u001b[33m                Examples\u001b[39m\n",
      "\u001b[33m                --------\u001b[39m\n",
      "\u001b[33m                >>> df = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})\u001b[39m\n",
      "\u001b[33m                >>> df\u001b[39m\n",
      "\u001b[33m                     A  B\u001b[39m\n",
      "\u001b[33m                0    1  3\u001b[39m\n",
      "\u001b[33m                1    2  4\u001b[39m\n",
      "\u001b[33m                >>> df.columns\u001b[39m\n",
      "\u001b[33m                Index(['A', 'B'], dtype='object')\u001b[39m\n",
      "\u001b[33m                \"\"\"\u001b[39m\n",
      "        ),\n",
      "    )\n",
      "\n",
      "    \u001b[38;5;66;03m# ----------------------------------------------------------------------\u001b[39;00m\n",
      "    \u001b[38;5;66;03m# Add plotting methods to DataFrame\u001b[39;00m\n",
      "    plot = CachedAccessor(\u001b[33m\"plot\"\u001b[39m, pandas.plotting.PlotAccessor)\n",
      "    hist = pandas.plotting.hist_frame\n",
      "    boxplot = pandas.plotting.boxplot_frame\n",
      "    sparse = CachedAccessor(\u001b[33m\"sparse\"\u001b[39m, SparseFrameAccessor)\n",
      "\n",
      "    \u001b[38;5;66;03m# ----------------------------------------------------------------------\u001b[39;00m\n",
      "    \u001b[38;5;66;03m# Internal Interface Methods\u001b[39;00m\n",
      "\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m _to_dict_of_blocks(self):\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Return a dict of dtype -> Constructor Types that\u001b[39m\n",
      "\u001b[33m        each is a homogeneous dtype.\u001b[39m\n",
      "\n",
      "\u001b[33m        Internal ONLY - only works for BlockManager\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        mgr = self._mgr\n",
      "        \u001b[38;5;66;03m# convert to BlockManager if needed -> this way support ArrayManager as well\u001b[39;00m\n",
      "        mgr = cast(BlockManager, mgr_to_mgr(mgr, \u001b[33m\"block\"\u001b[39m))\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m {\n",
      "            k: self._constructor_from_mgr(v, axes=v.axes).__finalize__(self)\n",
      "            \u001b[38;5;28;01mfor\u001b[39;00m k, v, \u001b[38;5;28;01min\u001b[39;00m mgr.to_dict().items()\n",
      "        }\n",
      "\n",
      "    @property\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m values(self) -> np.ndarray:\n",
      "        \u001b[33m\"\"\"\u001b[39m\n",
      "\u001b[33m        Return a Numpy representation of the DataFrame.\u001b[39m\n",
      "\n",
      "\u001b[33m        .. warning::\u001b[39m\n",
      "\n",
      "\u001b[33m           We recommend using :meth:`DataFrame.to_numpy` instead.\u001b[39m\n",
      "\n",
      "\u001b[33m        Only the values in the DataFrame will be returned, the axes labels\u001b[39m\n",
      "\u001b[33m        will be removed.\u001b[39m\n",
      "\n",
      "\u001b[33m        Returns\u001b[39m\n",
      "\u001b[33m        -------\u001b[39m\n",
      "\u001b[33m        numpy.ndarray\u001b[39m\n",
      "\u001b[33m            The values of the DataFrame.\u001b[39m\n",
      "\n",
      "\u001b[33m        See Also\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        DataFrame.to_numpy : Recommended alternative to this method.\u001b[39m\n",
      "\u001b[33m        DataFrame.index : Retrieve the index labels.\u001b[39m\n",
      "\u001b[33m        DataFrame.columns : Retrieving the column names.\u001b[39m\n",
      "\n",
      "\u001b[33m        Notes\u001b[39m\n",
      "\u001b[33m        -----\u001b[39m\n",
      "\u001b[33m        The dtype will be a lower-common-denominator dtype (implicit\u001b[39m\n",
      "\u001b[33m        upcasting); that is to say if the dtypes (even of numeric types)\u001b[39m\n",
      "\u001b[33m        are mixed, the one that accommodates all will be chosen. Use this\u001b[39m\n",
      "\u001b[33m        with care if you are not dealing with the blocks.\u001b[39m\n",
      "\n",
      "\u001b[33m        e.g. If the dtypes are float16 and float32, dtype will be upcast to\u001b[39m\n",
      "\u001b[33m        float32.  If dtypes are int32 and uint8, dtype will be upcast to\u001b[39m\n",
      "\u001b[33m        int32. By :func:`numpy.find_common_type` convention, mixing int64\u001b[39m\n",
      "\u001b[33m        and uint64 will result in a float64 dtype.\u001b[39m\n",
      "\n",
      "\u001b[33m        Examples\u001b[39m\n",
      "\u001b[33m        --------\u001b[39m\n",
      "\u001b[33m        A DataFrame where all columns are the same type (e.g., int64) results\u001b[39m\n",
      "\u001b[33m        in an array of the same type.\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df = pd.DataFrame({'age':    [ 3,  29],\u001b[39m\n",
      "\u001b[33m        ...                    'height': [94, 170],\u001b[39m\n",
      "\u001b[33m        ...                    'weight': [31, 115]})\u001b[39m\n",
      "\u001b[33m        >>> df\u001b[39m\n",
      "\u001b[33m           age  height  weight\u001b[39m\n",
      "\u001b[33m        0    3      94      31\u001b[39m\n",
      "\u001b[33m        1   29     170     115\u001b[39m\n",
      "\u001b[33m        >>> df.dtypes\u001b[39m\n",
      "\u001b[33m        age       int64\u001b[39m\n",
      "\u001b[33m        height    int64\u001b[39m\n",
      "\u001b[33m        weight    int64\u001b[39m\n",
      "\u001b[33m        dtype: object\u001b[39m\n",
      "\u001b[33m        >>> df.values\u001b[39m\n",
      "\u001b[33m        array([[  3,  94,  31],\u001b[39m\n",
      "\u001b[33m               [ 29, 170, 115]])\u001b[39m\n",
      "\n",
      "\u001b[33m        A DataFrame with mixed type columns(e.g., str/object, int64, float32)\u001b[39m\n",
      "\u001b[33m        results in an ndarray of the broadest type that accommodates these\u001b[39m\n",
      "\u001b[33m        mixed types (e.g., object).\u001b[39m\n",
      "\n",
      "\u001b[33m        >>> df2 = pd.DataFrame([('parrot',   24.0, 'second'),\u001b[39m\n",
      "\u001b[33m        ...                     ('lion',     80.5, 1),\u001b[39m\n",
      "\u001b[33m        ...                     ('monkey', np.nan, None)],\u001b[39m\n",
      "\u001b[33m        ...                   columns=('name', 'max_speed', 'rank'))\u001b[39m\n",
      "\u001b[33m        >>> df2.dtypes\u001b[39m\n",
      "\u001b[33m        name          object\u001b[39m\n",
      "\u001b[33m        max_speed    float64\u001b[39m\n",
      "\u001b[33m        rank          object\u001b[39m\n",
      "\u001b[33m        dtype: object\u001b[39m\n",
      "\u001b[33m        >>> df2.values\u001b[39m\n",
      "\u001b[33m        array([['parrot', 24.0, 'second'],\u001b[39m\n",
      "\u001b[33m               ['lion', 80.5, 1],\u001b[39m\n",
      "\u001b[33m               ['monkey', nan, None]], dtype=object)\u001b[39m\n",
      "\u001b[33m        \"\"\"\u001b[39m\n",
      "        \u001b[38;5;28;01mreturn\u001b[39;00m self._mgr.as_array()"
     ]
    }
   ],
   "source": [
    "??missing_predicted_df "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
